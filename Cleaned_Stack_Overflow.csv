,Id,Title,Text,OriginalText,CreationDate
0,59430106,implement federate algorithm Usinsg tensorflow federate,"implement federate algorithm Usinsg tensorflow federate   I read document tensorflow federate available tensorflow.org , sure implement federate algorithm . example , compile keras model , know convert tff.computation . seem order build federate algorithm one build iterative_process . anyone help regard ?     thank much ,","How to implement my own federated algorithm Usinsg tensorflow federated  I have read all the documents on the tensorflow federated available at tensorflow.org, but I am not sure how to implement my own federated algorithm. For example, I have a compiled keras model, I know how to convert this to tff.computation. It seems that in order to build a federated algorithm one should build an iterative_process. Can anyone help me in this regard?  
 Thank you so much,  
",43819.78742
1,59481435,valueerror : name Sequential use 4 time model . layer name unique ?,"valueerror : name Sequential use 4 time model . layer name unique ?   let consider , four model follow M1 ( client 1 ) , M2 ( client 2 ) , M3 ( client 3 ) , M4 ( client 4 ) . model similar structure .       after train client model . aggregate model together create new model let say EnsModel . that , use ensemble model retrain new datum client again . however , try ensemble update model again , face problem say ValueError : name Sequential use 4 time model . layer name unique ?    can anybody help out ? also one question . way model modify ensemble model structure client ?    thank you .","ValueError: The name Sequential is used 4 times in the model. All the layer names should be unique?  Lets consider, I have four models following as M1 (client 1), M2 (client 2), M3 (client 3), and M4 (client 4). Each model has a similar structure.  
 
 After training for each client model. I have aggregated these models together and create a new model which is lets say EnsModel. After that, I have used this ensemble model to retrain new data for each client again. However, when I tried to ensemble the updated models again, I faced this problem that says
ValueError: The name Sequential is used 4 times in the model. All the layer names should be unique? 
 Can anybody help me out? I also have one question. Is there any way that I can model modify the ensemble model structure for each client? 
 Thank you. 
",43824.82839
2,59484278,"pureframeworktensorfounderror , Runtime error -FedeartedLearning","pureframeworktensorfounderror , Runtime error -FedeartedLearning   I try Linear Regression algorithm Federated learning use pytorch face follow error . implement Colab . accord error might due code line train ( ) function . kindly help work Pysyft face error before .       and follow code :  ","PureFrameworkTensorFoundError, Runtime error -FedeartedLearning  I am trying a Linear Regression algorithm with Federated learning using Pytorch and I face the following error. I am implementing it on Colab. According to me this error might be due to some code line in the train() function. Kindly help is you have worked with Pysyft and have faced such error before.  
 
 And the following is the code: 
 
",43825.23825
3,59622300,resnet model Tensorflow Federated,"resnet model Tensorflow Federated   I try customize model Image classification tutorial Tensorflow Federated . ( it originally use sequential model ) use Keras ResNet50 begin train , always error incompatible shape    here code :      error information :     I feel shape incompatible epoch client information somehow miss . would thankful someone could give hint .    update :    the Assertion error happen   ","ResNet model in Tensorflow Federated  I tried to customize the model in Image classification tutorial in Tensorflow Federated. (It originally used a sequential model)
I use Keras ResNet50 but when it began to train, there is always an error Incompatible shapes 
 Here are my codes: 
 
 Error information:
 
 I feel that the shape is incompatible because the epoch and clients information were somehow missing. Would be very thankful if someone could give me a hint. 
 Updates: 
 The Assertion error happened during  
 
",43837.19944
4,59741397,Federated learning : convert image dataset tff simulation Clientdata,"Federated learning : convert image dataset tff simulation Clientdata   here code federate learn test      now want create sample_batch like tutorial tensorflow federtaed image classification    I write line find error      the error      TypeError Traceback ( most recent call last ) 1 training_set1.element_type_structure ---- > 2 example_dataset = training_set1.create_tf_dataset_for_client(training_set1.client_ids[0 ] )    TypeError : abstractproperty object support indexing      can tell must create dummy_batch order convert keras model tff.learning.from_compiled_keras_model(model , dummy_batch )","Federated learning : convert my own image dataset into tff simulation Clientdata  here is the code of my federated learning test 
 
 Now when I want to create sample_batch like the tutorial in the tensorflow federtaed for image classification 
 I write this line and it find this error 
 
 the error 
 
 TypeError                                 Traceback (most recent call last)
 in 
      1 training_set1.element_type_structure
----> 2 example_dataset = training_set1.create_tf_dataset_for_client(training_set1.client_ids[0]) 
 TypeError: abstractproperty object does not support indexing 
 
 Can you tell me how I must do to create dummy_batch in order to convert keras model into tff.learning.from_compiled_keras_model(model, dummy_batch) 
",43844.85674
5,59835749,implement data generator federate training,"implement data generator federate training   ( I post question   maybe also here ! )    I customize datum model federate interface training converge . confused issue image classification task , whole dataset extreme large can not store single    import memory one time . need load dataset hard disk batch memory real - timely use    instead    training , approach people use deal large datum .    I suppose    show image classification tutorial , model fit fix set datum . way adjust code let fit datum generator?I look source code still quite confused . would incredibly grateful hint .","Implement data generator in federated training  (I have posted the question on  and maybe also here!) 
 I have customized my own data and model to federated interfaces and the training converged. But I am confused about an issue that in an images classification task, the whole dataset is extreme large and it cant be stored in a single   nor be imported to memory for one time. So I need to load the dataset from the hard disk in batches to memory real-timely and use   instead of   during training, the approach people use to deal with large data. 
 I suppose in   shown in image classification tutorial, the model is fitted on a fixed set of data. Is there any way to adjust the code to let it fit to a data generator?I have looked into the source codes but still quite confused. Would be incredibly grateful for any hints. 
",43851.29477
6,60198252,low evaluation accuracy Resnet TensorFlow Federated,"low evaluation accuracy Resnet TensorFlow Federated   I implement Resnet34 model federate image classification tutorial . 10 round training accuracy high 90 % , however , evaluation accuracy use last round    always around 50 % .      I confuse what s possibly wrong evaluation part ? also , print untrainable variable ( mean variance BatchNorm ) server model , 0 1 update / average round . like could problem ? thank much !     update :      the code prepare training datum print result :      the training evaluation code :      the training evaluation result round :  ","Low evaluation accuracy of Resnet in TensorFlow Federated  I implemented Resnet34 model in federated images classification tutorial. After 10 rounds the training accuracy can be higher than 90%, however, the evaluation accuracy using the last rounds   is always around 50%. 
 
 I am very confused whats possibly wrong with the evaluation part? Also, I printed the untrainable variables (mean and variance in BatchNorm) of the servers model, which are 0 and 1 with no updates/averaging after those rounds. Should they be like that or that could be the problem?
Thanks very much!  
 Updates:   
 The codes to prepare training data and printed results: 
 
 The training and evaluation codes: 
 
 The training and evaluations results after each round: 
 
",43873.96762
7,60202610,"Pysyft Federated learning , error websocket","Pysyft Federated learning , Error Websockets   I try run federate learn pysyft ( ) create remote worker connect via websocket . however get error folllowe evaluation step .      there clear answer forum . anyone clue issue script .    my syft version :  ","Pysyft Federated learning, Error with Websockets  I am trying to run a federated learning from pysyft () that creates remote workers and connect to them via websockets. however I am getting an error in folllowing evaluation step. 
 
 There are no clear answer from their forum. does anyone have any clue as to what the issue is in this script. 
 My syft version: 
 
",43874.31501
8,68691256,attributeerror : module tensorflow_privacy attribute dpquery,"attributeerror : module tensorflow_privacy attribute DPQuery   I new machine learn try "" federate learn image classification "" code Tensorflow ( ) . run code Google Colab modify anything .      the work well . ( no error ) come below :      I get error    line :      I ve search solution like    none work .    please help . thank advance !","AttributeError: module tensorflow_privacy has no attribute DPQuery  I am new to machine learning and was trying out the ""federated learning for image classification"" code by Tensorflow (). I ran the code on Google Colab and did not modify anything. 
 
 The above works well. (no errors)
But when it comes to the below: 
 
 I got an error on the   line: 
 
 Ive searched for solutions like   but none works. 
 Please help.
Thanks in advance! 
",44415.41198
9,69385064,good way create custom federate image dataset TFF sqlite format ?,"good way create custom federate image dataset tff sqlite format ?   I go source cifar-100 inbuilt dataset decide create compatible version FairFace dataset order able leverage build - in function without many modification everywhere convert FairFace structure similar cifar-100 .    I search around unable find cifar-100 sqlite database create - specifically image convert BLOB storage . bit trial error , try way :      execute sample train datum similarly test datum . able load use decode method :      what notice , however , final sqlite.lzma compress archive 6.4 GB size whereas source archive dataset 555 MB . guess due way store image , compression work well could stored compatible manner . see cifar-100 code image load directly fixedlenfeature shape ( 32,32,3 ) mean store unable find way store image such . method work bytes_feature route .    what would well / recommend way go this ?","What is the best way to create a custom federated image dataset for TFF in SQLite format?  I went through the source for the CIFAR-100 inbuilt dataset and decided to create a compatible version for the FairFace dataset in order to be able to leverage the other built-in functions without many modifications everywhere once I convert FairFace into a structure very similar to CIFAR-100. 
 I did search around but was unable to find how the CIFAR-100 SQLite database was created - specifically how the images were converted into BLOB for storage. After a bit of trial and error, I tried doing it this way: 
 
 Executing this for each sample in the train data and similarly for test data. I am able to load it using this decoding method: 
 
 What I noticed, however, is that the final sqlite.lzma compressed archive is 6.4 GB in size whereas the source archive for the dataset was 555 MB. I am guessing that due to the way I am storing the images, compression is not working as well as it could if they were stored in a more compatible manner. I see from the CIFAR-100 code that the images are loaded directly as FixedLenFeatures of shape (32,32,3) which means that they were stored as such but I have been unable to find a way to store my images as such. The only method that worked for me was the bytes_feature route. 
 What would be the best/recommended way to go about this? 
",44469.06617
10,60866002,Pysyft client server,"pysyft client server   this question regard project federate learning use pysyft library , knowledge websocket help since pysyft use websockets server client interaction .    to start off , issue regard server client interaction . create dashboard launch pysyft server pysyft client connect aforementioned server . however , scenario want client disconnect server time time ( manual disconnection ) perform change model parameter .    my solution perform close ( ) pysyft websocketClientWorker call shutdown ( ) function websocket object . which , presume , close connection client server . whatever change model parameter do . recreate pysyft websocketClientWorker object perform model training again . however , face issue :   websocket._exception . websocketconnectionclosedexception : socket already close .   exception throw ( despite successful connection server ) iteration dataloader .    perhaps there s well way go scenario , miss certain fundamental understanding websocket . help appreciate . thank :)","Pysyft client and server  This question is with regards to my project on federated learning using the pysyft library, but those with the knowledge of websockets can help too since pysyft uses websockets for the server and client interaction. 
 To start off, i have an issue regarding server and client interaction. I have created a dashboard to launch a pysyft server and a pysyft client which connects to the aforementioned server. However, i have a scenario where i want to have the client disconnect from the server from time to time (manual disconnection) so as to perform changes in model parameters. 
 My solution was to perform a close() on the pysyft websocketClientWorker which calls the shutdown() function on the websocket object. Doing which, i presume, will close the connection between the client and the server. After whatever changes to the model parameters have been done. I will recreate the pysyft websocketClientWorker object again and perform the model training all over again. However, i am faced with the issue of :  websocket._exceptions.WebSocketConnectionClosedException: socket is already closed.  This exception is being thrown (despite the successful connection to the server) during the iteration of the dataloader. 
 Perhaps theres a better way to go about this scenario, or am i missing certain fundamental understanding of websockets. Any help will be appreciated. Thank you :) 
",43916.47017
11,60996324,Federated learning use custom model Pytorch / Pysyft,"Federated learning use custom model Pytorch / Pysyft   I try build federate learning model . scenario , 3 worker orchestrator . worker start train end training round , model send orchestrator , orchestrator calculate federate average send back new model , worker train new model etc . custom network AutoEncoder build scratch .    unfortunately get error message worker :   RuntimeError : forward ( ) miss value argument input . declaration : forward(classtype self , tensor input , tensor output ) - > ( tensor )   weird forward function define follow , inside AE class :    ","Federated learning using custom model in Pytorch/Pysyft  I am trying to build a federated learning model. In my scenario, I have 3 workers and an orchestrator. The workers start the training and at the end of each training round, the models are being sent to the orchestrator, the orchestrator calculates the federated average and sends back the new model, the workers train on that new model etc. The custom network is an AutoEncoder that I have built from scratch. 
 Unfortunately I am getting this error message from the workers:  RuntimeError: forward() is missing value for argument inputs. Declaration: forward(ClassType self, Tensor inputs, Tensor outputs) -> (Tensor)  which is weird because my forward function is defined as follows, inside the AE class: 
 
 
",43923.68262
12,61243073,tensorflow - federate support dynamic batch size ?,"tensorflow - federate support dynamic batch size ?   do tensorflow - federate support assign different batch - size different simulated device , change batch - size different epoch ?","Does tensorflow-federated support dynamic batch size?  Does tensorflow-federated support assigning different batch-size for different simulated devices, and changing batch-size for different epoch? 
",43937.21503
13,61520938,tf_encrypted.play config ?,"tf_encrypted.play config ?   while training model federate learn keras syft , to start worker different system client worker , particular line command exectue terminal .      this command execute system one client workers.when execute code      how prepare config file federate learning system ?","tf_encrypted.player how to config?  While training the model federated learning with keras on syft,to start workers on different system as client workers, particular line of command to be exectued on terminal. 
 
 this command should be executed on system which is one of my client workers.when executing the code 
 
 how to prepare the config file for federated learning on this system? 
",43951.42334
14,69499432,Federated Averaging TensorFlow,"Federated Averaging TensorFlow   I newbie federate learn getting know TensorFlow Federated TFF framework . question mind would really appreciate anybody clarify they :      do Federated Averaging algorithm aggregation algorithm support TFF ? differ Federated Stochastic Gradient Descent ?    Dose Federated Averaging require client train Neural Networks ? possible local datum train machine learning algorithm ?    I big datum , plan partition datum small dataset simulate part one client ? work TFF ? consider horizontal vertical federated learning ?      thank advance","Federated Averaging and TensorFlow  I am a newbie in federated learning and just getting to know TensorFlow Federated TFF framework. I have some questions in my mind I would be really appreciated it if anybody can clarify them: 
 
 Does Federated Averaging algorithm the only aggregation algorithm supported in TFF? and how it differs from Federated Stochastic Gradient Descent? 
 Dose Federated Averaging require each client to be trained with the Neural Networks? or it is possible for local data to be trained with any machine learning algorithm? 
 I have big data, and I am planning to partition my data into smaller datasets and simulated each part as one client? does this work in TFF? and does it consider horizontal or vertical federated learning? 
 
 Thanks in advance 
",44477.71072
15,69525476,"Federated Averaging ( fedavg ) resnet 18 batch_normalization make prediction first round , round","Federated Averaging ( fedavg ) resnet 18 batch_normalization make prediction first round , round   I try implement   . also . like trainable one , aggregate non - trainable parameter batch - normalization server average they . use 5 client dataset divide 5 randomly , 50k/5=10k training sample client , gross skewed distribution . test client , training , full test dataset,10k sample , also use test server . problem first training round despite client 20 - 25 % accuracy , server 10 % accuracy basically make nearly prediction input . case first round since round server almost always well accuracy client round . example      to solve issue first round try repeat dataset do not help . try use cifar10 training sample client mean instead create 5 different dataset 10k sample client use 50k sample dataset .      client obviously initialization guess due gpu use minor accuracy difference yet 45+% accuracy . see even do not help first round . use simple cnn , one available "" .main "" , suitable parameter problem do not exist . use      instead of      reduce problem first round overall bad performance try reproduce paper use latter parameter .    I also try pytorch get similar result .   result available github .    I confuse that . especially use entire training dataset client 45 % accuracy . also get good result follow round ? change first round other ? every time client initialization other , loss function , optimizer parameter . thing change actual initialization round .    so special initialization solve first round problem miss something ?    Edit :    when entire cifar10 training set use client dataset.repeat use repeat datum .      what catch attention client accuracy actually similar second round ( round 1 ) accuracy client dataset be not repeated(previous result ) . eventhough server 10 % accuracy do not affect much result next round .    this work simple cnn ( define main.py github )      as see simple cnn use server accuracy well good client accuracy , definitely well average , begin first round . try understand resnet fail make prediction regardless input . first round prediction look like      they return 3rd label .","Federated Averaging (fedavg) with resnet 18 that has batch_normalization makes the same prediction after first round, but in no other rounds  I was trying to implement  with . Also this is the . Just like trainable ones, I have aggregated non-trainable parameters of batch-normalization to server and averaged them. I have used 5 clients and dataset was divided to 5 randomly, 50k/5=10k training samples for each client, so there is no gross skewed distribution. I have tested each client, after training, with the full test dataset,10k samples, that I also use to test server. The problem is after first training round despite each client had 20-25% accuracy, the server has 10% accuracy and basically makes nearly the same predictions for each input. This is the only the case  for first round since after that round server has almost always better accuracy than any client had in that round. For example 
 
 To solve the issue with first round I tried to repeat the dataset but it didnt help. After that I tried to use all the cifar10 training samples for each client meaning instead of creating 5 different datasets of 10k samples for each client I used all 50k samples as the dataset. 
 
 Clients obviously had the same initialization but i guess due to gpu use there were some minor accuracy differences yet each had 45+% accuracy. But as you can see even this didnt help with the first round. When using a simple cnn, such as the one available in the "".main"", with suitable parameters this problem doesnt exist. And using 
 
 instead of 
 
 reduces this for problem the first round but it has overall worse performance and i am trying to reproduce a paper that used the latter parameters. 
 I have also tried the same with pytorch and got the very similar results.  The results for both are available in github. 
 I am very confused with that. Especially when I used entire training dataset and when each client had 45% accuracy. Also why get good results for following rounds? What changed between first round and the others? Every time clients had the same initialization with each other, same loss function, and same optimizer with the same parameters. The only thing that changed is the actual initialization between rounds. 
 So is there a special initialization that solves this first round problem or am I missing something? 
 Edit: 
 When the entire cifar10 training set is used for each client and dataset.repeat is used to repeat data. 
 
 What catches my attention here is the client accuracy here is actually very similar to second round (round 1) accuracy of clients when dataset wasnt repeated(previous results). so eventhough server had 10% accuracy it didnt affect much the results of the next round. 
 This is how it works with a simple cnn (defined in the main.py in github) 
 
 As we can see when a simple cnn is used server accuracy is better than the best client accuracy, and definitely better than the average, beginning from the very first round. I am trying to understand why the resnet fails to do that and makes the same predictions regardless of input. After the first round the predictions look like 
 
 They all return 3rd label. 
",44480.47816
16,69538510,tff support deployment across different device cloud ?,"tff support deployment across different device cloud ?   I would like deploy TFF way , one central ( aggregation ) server VM cloud two different vms node , train model . possible TFF ? protocol necessary communicate internet etc . tensorflow FL algorithm use different framework provide architecture ?    thank you","Does TFF support deployment across different devices and clouds?  I would like to deploy TFF in a way, where I have one central (aggregation) server on a VM in a cloud and two different VMs with nodes, that train the model. Is this possible with TFF? Does it have the protocols necessary to communicate over the internet etc. or is it more of a Tensorflow with FL algorithms that can be used with different frameworks that provide the architecture? 
 Thank you 
",44481.41464
17,69596586,change update client send server Tensorflow Federated,"change update client send server Tensorflow Federated   I m try understand Tensorflow Federated work , use simple_fedavg example .    I still understand change client send server , example .    I want send weight update , want send list form like this :      where    return 5 value :   , would like access information server side run    create weight use   .    so , basically , would like change    send list create instead weight then , server create custom list weight use information client send . creation new custom list weight would like server update model .    I actually try change     , know access    variable server procedure / function would need it .    I hope make clear enough since main language english .","How to change the update that the client send to the server Tensorflow Federated  Im trying to understand how Tensorflow Federated Works, using the simple_fedavg as example. 
 I still dont understand how to change what the client send to the server, for example. 
 I dont want to send all the weights of the update, i want to send a list formed like this: 
 
 Where   return 5 values:  , then i would like to access those information on the server side before running the    for creating the weights that i will use for the  . 
 So, basically, i would like to change   to send a list that i have created instead of all the weights and then, on the server create a custom list of weights using the information that the client sent. Only after the creation of the new custom list of weight i would like the server to update the model. 
 I actually tried to change the   of the  , but then i dont know how to access the   variable on the server and in which procedure/function i would need to do it. 
 I hope that i made myself clear enough since my main language is not english. 
",44485.61047
18,69841983,Intel OpenFL - RuntimeError : mat1 mat2 shape can not multiply ( 128x512 2048x4096 ),"Intel OpenFL - RuntimeError : mat1 mat2 shape can not multiply ( 128x512 2048x4096 )   I try run notebook ( that work fine google colab similar platform ) Intel OpenFL , new framework FL Intel . use MNIST transformation :      and net :      but error :      however , exactly network work well Google Colab . probably miss something OpenFL .","Intel OpenFL - RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x512 and 2048x4096)  I am trying to run my notebook (that works fine on google colab or other similar platforms) on Intel OpenFL, the new framework for FL of Intel.
I am using MNIST with this transformation: 
 
 and this is my net: 
 
 But I have this error: 
 
 However, exactly the same network works well on Google Colab. Probably I am missing something about OpenFL. 
",44504.65671
19,69891610,local Model performance Tensorflow Federated,local Model performance Tensorflow Federated   I implement federated learn tensorflow - federate . tutorial material available compare accuracy federate ( global ) model communication round . way compute accuracy local model compare federate ( global ) model .    summary : total number client : 15 communication round : local vs Federated Model performance    reference :      ( )  ,"Local Model performance in Tensorflow Federated  I am implementing federated learning through tensorflow-federated. The tutorial and all other material available compared the accuracy of the federated (global) model after each communication round. Is there a way I can compute the accuracy of each local model to compare against federated (global) model. 
 Summary:
Total number of clients: 15
For each communication round: Local vs Federated Model performance 
 References: 
 
 () 
 
",44509.03748
20,69965649,ModuleNotFoundError : module name syft.framework,ModuleNotFoundError : module name syft.framework   I try work example Federated Learning .   instal PySyft package get error .  ,"ModuleNotFoundError: No module named syft.frameworks  I am trying to work on this example of Federated Learning.

I have installed the PySyft package but I am getting this error. 
 
",44514.7415
21,70196914,TFF : finetune pretraine network : test accuracy still constant round,"TFF : finetune pretraine network : test accuracy still constant round   I would like fine - tune pre - train model Federated Learning , this :      and training loop :      the problem test accuracy still constant increase round :      I would like understand reason , another way this ? know dataset image dataset 3 class .","TFF: finetune with pretrained network : Test accuracy still constant after all rounds  I would like to Fine-tune the pre-trained model  with Federated Learning, So I do this: 
 
 And here is the training loop : 
 
 The problem is that test accuracy still constant and does not increase after all round  : 
 
 I would like to understand the reason, If there is another way to do this? Knowing that my dataset is an image dataset with 3 class. 
",44532.39226
22,70333328,tff : change code effect change test accuracy value,"tff : change code effect change test accuracy value   to improve   test thing , pretraine network centralize way emnist database . would like fine tune pretraine network federate code above . so , add :      the problem find test accuracy value compare test accuracy value without fine tuning pretraine network . please give solution .","TFF : change the code have no effect in changing test accuracy values  To improve this  and test other things, I was pretrained the network with a centralized way in EMNIST database. Then I would like to Fine tune the pretrained network with a federated code above.
So, I only added: 
 
 The problem is that I find same test accuracy values compared to test accuracy values without fine tuning a pretrained network.
Can you please give me solution. 
",44543.4451
23,70338012,run RAM use fileperuserclientdata,run RAM use fileperuserclientdata   I problem training use    - quickly run RAM 5 - 6 round 10 client per round . ram usage steadily increase round . try narrow realize issue actual iterative process creation client dataset . simply call    loop cause problem .    so minimal version code :      I use tensorflow - federate 19.0 .    be something wrong way create client dataset somehow expect RAM previous round free ?,"Running Out of RAM using FilePerUserClientData  I have a problem with training using   - I am quickly running out of RAM after 5-6 rounds with 10 clients per round.
The RAM usage is steadily increasing with each round.
I tried to narrow it down and realized that the issue is not the actual iterative process but the creation of the client datasets.
Simply calling   in a loop causes the problem. 
 So this is a minimal version of my code: 
 
 I am using tensorflow-federated 19.0. 
 Is there something wrong with the way I create the client datasets or is it somehow expected that the RAM from the previous round is not freed? 
",44543.69638
24,70590588,typeerror : _ _ init _ _ ( ) get unexpected keyword argument intialize_fn,"typeerror : _ _ init _ _ ( ) get unexpected keyword argument intialize_fn   I use TFF v:0.18 would like load pretraine network inside    write :      but find error :      I believe syntax error ,","TypeError: __init__() got an unexpected keyword argument intialize_fn  I use TFF v:0.18
I would like to load a pretrained network in the inside of   So I write this : 
 
 But I find this error: 
 
 I dont believe that the syntax is error, 
",44566.39806
25,70825390,limited number client use federate learning,"limited number client use federate learning   I start study federate learning want apply certain dataset , question rise up .    my datum contain record 3 category , 3 department . plan 3 different federate learning model category treat three department category distribute client .    be possible ? build federate learning model require thousand client ?    thank","Limited number of clients used in federated learning  I just started studying federated learning and want to apply it to a certain dataset, and there are some questions that have risen up. 
 My data is containing records of 3 categories, each of which is having 3 departments. I am planning to have 3 different federated learning models for each category and treat the three department of this category as the distributed clients. 
 Is this possible? or building federated learning models requires having thousands of clients? 
 Thanks 
",44584.77785
26,70990386,"flatten test image dataset create batch tuple ( flatten image , label ) ?","flatten test image dataset create batch tuple ( flatten image , label ) ?   I m work   use Federated Learning . preprocesse image    also obtain label image .      for obtain label :      how could make tuple flatten Image label need send client ? see tensorflow tutorial     from tutorial :  ","How to flatten test image dataset and create a batch of tuple of (flattened image , labels)?  Im working in   using Federated Learning. I have preprocessed the image from   and also obtained the labels of each images. 
 
 For obtaining labels: 
 
 How could I make a tuple of flattened Image and label that needs to send to the clients ?
As seen from tensorflow tutorial  
 From tutorial: 
 
",44596.72353
27,71006411,Keras : save GAN model optimiser state ?,"Keras : save GAN model optimiser state ?   I know one use use Checkpoint CheckpointManager tensorflow class save resume train GAN .    I look way save Generator ( G ) , Discriminator(D ) optimisation states manipulate model weight ( for G D ) . one use case average weight different Generator Federated Learning GAN .    I find way use Keras tensorflow .","Keras: How to save GAN model with optimiser state?  I know one use can be using Checkpoint and CheckpointManager tensorflow classes to save and resume training the GAN. 
 I am looking for a way to save the Generator (G) , Discriminator(D) and their optimisation states such that I can manipulate the model weights (for G and D). One use case for me is average the weights of different Generator in Federated Learning for GAN. 
 I found no way do to this using Keras or tensorflow. 
",44598.45249
28,71043010,Keras - set weight layer,"Keras - set weight layer   I want set weight exist model , VGG 16 . however , want set weight model   exclude last ( fully connect ) layer . try use   , cause error of      there one solution use loop set weight , inefficient .      be way set weight layer model ? thank !","Keras - how to set weights to some layers  I want to set weights to an existing model, such as VGG 16. However, I only want to set weights to the model  excluding the last (fully connected) layer . I have tried to use  , it will cause the error of 
 
 There is one solution used the for loop to set the weight, but it is inefficient. 
 
 Is there a way to set the weight to some layers of the model? Thanks! 
",44601.06898
29,71167600,build federate learning model unbalanced small dataset,"build federate learning model unbalanced small dataset   I work build federate learning model use TFF question :      I prepare dataset , separate file datum , feature different sample . would consider file single client . maintain TFF ?      the datum balance , meaning , size datum vary file . affect modeling process ?      the size data bit small , one file ( client ) 300 record another 1500 record , suitable build federate learning model ?        thank advance","How to build federated learning model of unbalanced and small dataset  I am working to build a federated learning model using TFF and I have some questions: 
 
 I am preparing the dataset, I have separate files of data, with same features and different samples. I would consider each of these files as a single client. How can I maintain this in TFF? 
 
 The data is not balanced, meaning, the size of data varies in each file. Is this affecting the modeling process? 
 
 The size of the data is a bit small, one file (client) is having 300 records and another is 1500 records, is it suitable to build a federated learning model? 
 
 
 Thanks in advance 
",44610.08726
30,62040659,Grid Search Applicable TFF FL . ?,"Grid Search Applicable TFF FL . ?   I m currently research TFF image classification ( Federated Learning Image Classification ) emnist .    I m look hyper parameter model learn rate optimizer . grid search good approach ? . real world scenario would simply sample client / device overall domain grid search would fix client sample 1st . case make sense grid search .     what would typical real world way select parameter , ie heuristic approach . ?    Colin . . .","Grid Search Applicable for TFF and FL.?  Im currently researching with TFF and image classification (Federated Learning for Image Classification) emnist. 
 Im looking at hyper parameters for the model learning rate and optimizer. Is grid search a good approach here ? . In a real world scenario would you simply sample clients/devices from the overall domain and if so if I was to do a grid search would I have to fix my client samples 1st. In which case does it make sense to do the grid search.  
 What would be a typical real world way of selecting parameters, ie is this more a heuristic approach. ? 
 Colin . . . 
",43978.42641
31,62083380,federate learn implement,federate learn implement   I new python machine learning . try implement follow code federate learn MNIST dataset work ! ! try train model distribute way local worker . jpeg version MNIST datum set use here . consist 42000 digit image class keep separate folder . load datum memory use code snippet keep 10 % datum testing train global model later on .   the follow error appear implement follow fl_implemetation.py      the original code use find here :       and second   fl_mnist_implementation_tutorial_utils.py  ,"federated learning implementing  I new in python and machine learning. I tried to implement the following code for federated learning with the MNIST dataset but it doesnt work !! it tried to train a model in a distributed way in local workers. the jpeg version of the MNIST data set is using here. It consists of 42000 digit images with each class kept in a separate folder. I will load the data into memory using this code snippet and keep 10% of the data for testing the trained global model later on.
 The following error appears when i implement the following fl_implemetation.py 
 
 The original code I am using can be found here: 
 
 
 and second  fl_mnist_implementation_tutorial_utils.py 
 
",43980.41752
32,62398875,transfer weight baseline model federate model ?,"transfer weight baseline model federate model ?     try something like Colab , get errno 21 , directory .    then try another method show below ,       just like assign_weights_to_keras_model ( ) transfer weight tff_model keras model , want transfer weight keras model tff_model . do ?","How to transfer weights from baseline model to federated model?  
 Tried something like this in Colab, but I get errno 21, is a directory. 
 Then I tried another method as shown below,   
 
 Just like assign_weights_to_keras_model() transfers weights from tff_model to keras model, I want to transfer weights from keras model to tff_model. How can this be done? 
",43998.0002
33,62803219,tensor Size Miss match loss function,"tensor Size Miss match loss function   1 : attempt perfrom pytorch training sequence use batch size , loss function appear error nn output batch put MSEloss function .    2 : try search nn padding , however covnet rather autoencoder , similar stack flow issue yield result .    3 : NN :      the train method :      error :  ","Tensor Size Miss match on loss function  1:
when attempting to perfrom a pytorch training sequence using batch sizes, my loss function appears to error when the nn output and a batch are put through a MSEloss function. 
 2:
have tried to search about nn padding, however this is not a covnet but rather an autoencoder, similar stack over flow issues have not yielded results. 
 3:
the NN: 
 
 the train method: 
 
 error: 
 
",44020.85693
34,63589819,attributeerror : websocketserverworker object attribute add_dataset,"attributeerror : websocketserverworker object attribute add_dataset   when use pysyft Federated Learning task , error :    AttributeError : websocketserverworker object attribute add_dataset      the error :      I know solve :(","AttributeError: WebsocketServerWorker object has no attribute add_dataset  When I using pysyft to do some Federated Learning task, there is an error: 
 AttributeError: WebsocketServerWorker object has no attribute add_dataset 
 
 the error: 
 
 I dont know how to solve it :( 
",44069.12439
35,71209010,MNIST Shard Descriptor : IndexError : list index range,"MNIST Shard Descriptor : IndexError : list index range   I work Federated Learning experiment use Intel OpenFL . want distribute dataset ( MNIST ) use different non - iidness scenario . follow official documentation :     this original work code :      basically , change mnistsharddescriptor class 2 node federation way :      I error line   :   one 2 node . know why , code exactly nodes federation .    EDIT : change position code write above , particular write class mnistsharddataset rather MnistShardDescriptor :      with able create federation and , node director , client start training , split truly random run experiment 2 time , time envoy different number sample . however node ( because use 2 node , one envoy ) envoy ( openFL call envoy worker client ) error index rangeâ€ ¦    EDIT2 : example datum split use openFL :     however dataset different , succeed adapt solution . example suggest I , sharde dataset like MNIST ? tutorial follow ?    entire error :      EDIT : interesting point : change dimension federation , increase 2 3 rank_worldsize inside envoy_config.yaml , training start ( and dataset divide random way , work , node different number sample ) . however work 2 node , create federation 3 without 3 node . indeed sample 8064 one node 9856 another node . however consider 60000 training sample MNIST , remain sample get lose , suppose last node ( which exist ) .","MNIST Shard Descriptor: IndexError: list index out of range  I am working on Federated Learning experiments using Intel OpenFL. I want to distribute my dataset (MNIST) using different non-iidness scenarios.
I am following their official documentation:  
 This is my original working code: 
 
 Basically, I changed the MnistShardDescriptor class in both my 2 nodes of the federation in this way: 
 
 I have this error at the line  :  but only in one of the 2 nodes. I do not know why, because the code are exactly the same on both nodes of my federation. 
 EDIT: I changed the position of the code I have written above, and in particular I wrote in the class MnistShardDataset rather than MnistShardDescriptor: 
 
 With this I am able to create the federation and, in the same node of the director, the clients start training, and the split is truly random because I ran the experiment 2 times, and each time the envoy had a different number of samples. However in the other node (because I am using 2 nodes, one for each envoy) with the envoy (openFL calls envoy the worker on a client) I have the same error of Index out of rangeâ€¦ 
 EDIT2: here is an example of data split using openFL:  
 However my dataset is different, and I am not succeeding in adapting this solution. Any other example can you suggest to me, about sharding a dataset like MNIST? A tutorial to follow? 
 Entire error: 
 
 EDIT: interesting point: If I change the dimension of my federation, increasing from 2 to 3 the rank_worldsize inside the envoy_config.yaml, training starts (and the dataset is divided in a random way, so it works, because each node has different number of samples). However it works only because I have 2 nodes, but I created a federation of 3 without the 3 node. Indeed the samples are 8064 for one node and 9856 for another node. However considering that I have 60000 training samples in MNIST, all the remaining samples got lost, because they are supposed to be in the last node (which does not exist). 
",44613.64897
36,71285825,use create_tf_dataset_for_client ( ) define training example dataset,"use create_tf_dataset_for_client ( ) define training example dataset   I prepare dataset federation setting , code below , multiple CSV file use consider single client .      I want access datum determine      column . type :      there row since big size datum   access datum tensor object ,   Question1   state       question2   split file training testing set start training process ?","Using create_tf_dataset_for_client() to define the training examples in the dataset  I am preparing a dataset for federation settings, in the code below, I have multiple CSV files and used each is considered a single client. 
 
 I wanted to access the data so I can determine the   and   column. so I typed: 
 
 there are more rows since I have a big size of data 
So I can access these data as they are tensor objects,
 Question1  how can I state that  
and  
 Question2  How can I split each file to training and testing sets to start the training process? 
",44619.62471
37,71441870,train global local model federate learning,"train global local model federate learning   while study Federated Learning , question pop mind need clarification .      we first define client , client split training testing set . training datum use train local model . now , test datum use for ? use test global model ? test local model ?    when train global model , first calculate resulted weight local model , send global model . model local client , validity check model send global model send anyway update global model .      be paper explain point ?","Training the global and local model in federated learning  While I am studying Federated Learning, I have some questions that popped up in my mind that needed some clarification. 
 
 We first have defined clients, each client will be split into training and testing sets. The training data are used to train the local models. Now, what testing data are used for? are they used to test the global model? or to test each local model? 
 when training the global model, we first calculate the resulted weight of each local model, and then send it to the global model. In modeling the local clients, is there any validity check on the model itself before sending to the global model or it is sent anyway and then it will be updated by the global model. 
 
 Are there any papers explaining these points? 
",44631.69721
38,71470160,TFF : trainable = true   cause decrinse accuracy,"TFF : trainable = true   cause decrinse accuracy   I work TFF , part code :      with model find test - accuracy value =    now , would like change   , test - accuracy value decrease    loss become   . normal , anyone tell why .","TFF: trainable=True  causes decrinsing of accuracy  I work with TFF, here is a part of my code : 
 
 With this model I find test-accuracy value =  
Now, I would like to change  , but the test-accuracy value decrease to   and loss becomes  . which is not normal, can anyone tell why. 
",44634.63968
39,71496155,tff : modify value state,"tff : modify value state   the state object return iterative_process.initialize ( ) typically Python container ( tuple , collection . OrderedDict , etc ) contain numpy array . would like value state random , instead begin loaded model . begin , write :      but test accuracy result change compare normal case(if load external model ) .    that s why , try solution :      but find error :      so case , define next_fn ? thank","TFF : Modify the value of state  The state object returned by iterative_process.initialize() is typically a Python container (tuple, collections.OrderedDict, etc) that contains numpy arrays. I would like that the value of state is not random, instead it begin from loaded model.
As the beginning, I write this : 
 
 But test accuracy result does not change at all comparing by the normal case(if I dont load an external model). 
 Thats why, I try this solution: 
 
 But I find this error: 
 
 So in my case, how can I define next_fn ?
Thanks 
",44636.4708
40,71630891,"mismatch number element type spec value ` to_representation_for_type ` . type spec 2 element , value 5","mismatch number element type spec value ` to_representation_for_type ` . type spec 2 element , value 5   I use tensorflow fedprox implement federate learning.(tff.learning.algorithms.build_unweighted_fed_prox )      and result training be :    round 3 , sparse_categorical_accuracy= 0.6435834    round 4 , sparse_categorical_accuracy= 0.6955319    round 5 , sparse_categorical_accuracy= 0.74295634    round 6 , sparse_categorical_accuracy= 0.78176934    round 7 , sparse_categorical_accuracy= 0.80838746    round 8 , sparse_categorical_accuracy= 0.8300672    round 9 , sparse_categorical_accuracy= 0.8486338    round 10 , sparse_categorical_accuracy , 0.86639416      but want evaluate model test datum get error :      how fix it ?","Mismatched number of elements between type spec and value in `to_representation_for_type`. Type spec has 2 elements, value has 5  I use tensorflow fedprox to implement federated learning.(tff.learning.algorithms.build_unweighted_fed_prox) 
 
 and the result of training is: 
 round  3, sparse_categorical_accuracy= 0.6435834 
 round  4, sparse_categorical_accuracy= 0.6955319 
 round  5, sparse_categorical_accuracy= 0.74295634 
 round  6, sparse_categorical_accuracy= 0.78176934 
 round  7, sparse_categorical_accuracy= 0.80838746 
 round  8, sparse_categorical_accuracy= 0.8300672 
 round  9, sparse_categorical_accuracy= 0.8486338 
 round 10, sparse_categorical_accuracy, 0.86639416 
 
 but when I want to evaluate my model on test data I get error: 
 
 How do I fix it? 
",44646.78374
41,71680438,centralize server model update aggregated client metric TensorflowFederated,"centralize server model update aggregated client metric TensorflowFederated   I design Federated Learning model TensorFlow Federated framework . define iterative process below ,      I 2 remote worker run tffruntime remote executor service context running computation define   . model broadcast client   , identify client metric aggregate applied server model . single api    enough get metric client , aggregate update server model ? mean identify server model update ? anyone please help understand this .","How the centralized server model is updated with aggregated client metrics in TensorflowFederated  I have designed the Federated Learning model with TensorFlow Federated framework. Defined the iterative process as below, 
 
 I have 2 remote workers running the tffruntime remote executor service and the context for running computation is defined as  . When the model is broadcasted to the client with  , how can we identify that the client metrics is aggregated and applied to the server model. Is the single api   is enough to get the metrics from clients, aggregate and then update the server model? If means how can we identify that the server model is updated? Can anyone please help me to understand this. 
",44650.66448
42,71687929,Flower Framework show federate loss,Flower Framework show federate loss     I try use federate learn framework flower TensorFlow . code seem compile fine show federate loss accuracy . wrong ?      ServerSide Code :      Server Side :,"Flower Framework is not showing federated loss  
 I am trying to use federated learning framework flower with TensorFlow. My code seems to compile fine but Its not showing federated loss and accuracy. What am I doing wrong? 
 
 ServerSide Code : 
 
 Server Side:
 
",44651.27546
43,71767784,accuracy 0 % binary classification,"accuracy 0 % binary classification   I use OpenFL framework Federated Learning experiment . run tutorial notebook without problem , example able run classification MNIST everything ok . use 2 client 2 different dataset . however , accuracy around 0 % binary classification problem . so , 2 class , "" neg "" "" pos "" dataset . image first dataset 3000x2951 image second 4892x4020 . resize 256x256 . network ResNet9 without sigmoid end , use BCEWithLogitsLoss ( ) . bit code , check everything ok :        I think correct . part wrong import datum federate learn framework bit tricky . basically dataset organized way : /Dataset1(2)/Train(Test)/neg(pos)/images.png . want extract x_train , y_train , x_t y_test follow exactly structure tutorial work . propose solution :      this code python script need load datum . then , inside Jupyter notebook cell order import dataset :      the strange thing loss decrease , accuracy remain 0 around 0 .      and go several round","Accuracy 0% for binary classification  I am using the OpenFL framework for doing Federated Learning experiments. I run their tutorial notebooks without problems, so for example I am able to run classification on MNIST and everything is ok.
Now I am using 2 clients with 2 different datasets. However, my accuracy is around 0% for a binary classification problem.
So, I have 2 classes, ""neg"" and ""pos"" for both datasets. Images of the first dataset are 3000x2951 while images of the second are 4892x4020. I resize both to 256x256. My network is a ResNet9 without any sigmoid at the end, because I am using BCEWithLogitsLoss(). Here a bit of code, to check if everything is ok: 
 
 
 I think that all this is correct. So the only part that can be wrong is when I import the data because in this federated learning framework is a bit tricky. Basically my datasets are organized both in this way: /Dataset1(2)/Train(Test)/neg(pos)/images.png. I want to extract x_train, y_train, x_test and y_test because I am following exactly the structure of a tutorial that works. So this is my proposed solution: 
 
 This code above is in a python script needed to load the data. Then, inside the Jupyter notebook I have these cells in order to import the dataset: 
 
 The strange thing is that the loss decreases, while the accuracy remains 0 or around 0. 
 
 And this goes on for several rounds 
",44657.56674
44,71883746,miss require positional argument :,miss require positional argument :   I try implement federate learning base LSTM approach .      but get error want define iterative_process .      how fix it ?,"Missing required positional argument:  I tried to implement federated learning based on the LSTM approach. 
 
 but I got this error when I want to define iterative_process. 
 
 How do I fix it? 
",44666.49896
45,71885781,compute mean weight multiple model ?,"compute mean weight multiple model ?   hi I m student I m work Federated Learning problem , proper tool like OpenFL Flower , start little experiment try local train use technique .    I manage train multiple model use iid datum , I m struggle    function collect model need take weight model compute mean . read documentation Keras Tensorflow I m use work , find function can not get work properly .    currently    that s work      in TensorFlow / Keras many way well simple one ?    thank advance help !","How to compute the mean of weights of multiple models?  Hi im a student and im working on a Federated Learning problem, but before doing that with the proper tools like OpenFL or Flower, I started a little experiment to try in local to train using this technique. 
 I managed to train multiple models using IID data, now Im struggling with the    function that should collect the models and then i need to take all the weights of these models and compute their mean. I read some documentation of Keras and Tensorflow that Im using for my work, and i found some functions but i cant get it to work properly. 
 Currently this is my    thats not working 
 
 In TensorFlow/Keras there are many way to do this but what is the best and simplest one? 
 Thank you in advance for the help! 
",44666.63595
46,72076723,attributeerror : mapdataset object attribute preprocess tensorflow_federated tff,"attributeerror : mapdataset object attribute preprocess tensorflow_federated tff   I m test tutorial non - iid distribution federate learning :     in post question   suggest use tff.simulation.datasets.build_single_label_dataset ( ) way produce non - iid distribution dataset .    I try apply first ( see code ) get error !          OrderedDict([(label , TensorSpec(shape= ( ) , dtype = tf.int32 , name = None ) ) , ( pixel , TensorSpec(shape=(28 , 28 ) , dtype = tf.float32 , name = none ) ) ] )              tf . Tensor(1 , shape= ( ) , dtype = int32 )          since dataset filter , able preprocess ! so , case , filter base label ?      the desire label = 1 label EMNIST ?    my question be :    how apply function tff.simulation.datasets.build_single_label_dataset ( ) get non - iid dataset   ( different number sample client )   specific tutorial !   detail without error regard filter dataset !    appreciate help !    thank lot !","AttributeError: MapDataset object has no attribute preprocess in tensorflow_federated tff  Im testing this tutorial with non-IID distribution for federated learning:
 
 In this posted question  it suggested to use tff.simulation.datasets.build_single_label_dataset() as a way to produce a non-IID distribution for the dataset. 
 I tried to apply that first (see the code) and got an error ! 
 
 
 
 OrderedDict([(label, TensorSpec(shape=(), dtype=tf.int32, name=None)), (pixels, TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))]) 
 
 
 
 
 
 tf.Tensor(1, shape=(), dtype=int32) 
 
 
 
 Since dataset is filtered, it is not able to preprocess!
So, in this case, it is filtered based on what label? 
 
 the desired label = 1 for which label in EMNIST? 
 My Question is: 
 How can I apply this function tff.simulation.datasets.build_single_label_dataset()
to get non-IID dataset  (different number of samples for each client)  in this specific tutorial !  in details without error regarding the filtered dataset! 
 Appreciate any help! 
 Thanks a lot! 
",44682.521
47,63723006,save Tensorflow Federated Model,save Tensorflow Federated Model   how easily save Tensorflow Federated model ? ( state )    a month ago use solution import   ServerState    FileCheckPointManager   work :      but solution long work   contain    methotd anymore .      also use old version ServerState metohd include get :      how easly save federate model ?,"How to save Tensorflow Federated Model  How can I easily save a Tensorflow Federated model? (state) 
 A few months ago I was using this solution after importing  ServerState  and  FileCheckPointManager  and it worked: 
 
 But now this solution no longer works because  does not contain   methotd anymore. 
 
 Also using the old version of ServerState where the metohd was included i get: 
 
 How can I easly save my federated model? 
",44077.49108
48,63878853,PySyft Worker overfitte,"PySyft Worker overfitte   I try train image classification ( cifar10 ) pysyft . trainsetup 10 worker every worker get betwen 800 1200 image dataset .    my Problem 250 - 300 epoch , train loss 0.005 model stop improve though test accuracy 45 % increase loss 1.5 - > 8.5 . try 100 worker 500 image stop 32 % . furthrmore implementation part comparison model FL Frameworks therefor model can not change datum load localy transform Dataloader . hence I m unexperienced Pytorch PySyft might make mistake training model though try stay close possible example .    I train model without PySyft reach 85 % think dataloader model problem . look like worker overfit datum training .    be way prevent worker overfit calculate loss global model instead worker ?    Trainer :      Model :      main :      Log :  ","PySyft Worker overfitting  I try to train a image classification (cifar10) with pysyft. My trainsetup has 10 workers where every worker gets betwen 800 and 1200 images of the dataset. 
 My Problem is that after about 250-300 epochs, the train loss is at about 0.005 and the model stops improving though the test accuracy is just at about 45% with an increasing loss 1.5 -> 8.5.
I tried the same with 100 workers on 500 images where it stoped at 32%.
Furthrmore the implementation is part of a comparison between models and FL Frameworks and therefor the model cant be changed and the data will be loaded localy and transformed into a Dataloader.
Hence Im very unexperienced with Pytorch and PySyft it might be that I made some mistakes when training the model though i tried to stay as close as possible with the example. 
 I trained the model without PySyft and it reached about 85% so I think my dataloader and model should be not the problem. For me it looks like the workers overfit on their own data during the training. 
 Is there a way to prevent workers to overfit or calculate a loss for the global model instead of the workers? 
 Trainer: 
 
 Model: 
 
 Main: 
 
 Log: 
 
",44088.25146
49,64037971,use dart pigeon federate model,"use dart pigeon federate model   i""m look convert dart package ( ) federate model use pigeon .    the documentation around comb two piece little sparse .    look video_player sample ( ) seem suggest federate model web platform separate .    however android io package part main package .    be historical artefact ios android package still need part main plugin ?    if separate correct package(s ) structure ?    be open source plugin use pigeon fully federate model could use sample ?","Using dart pigeon in a federated model  I""m looking at converting a dart package () to a federated model using pigeon. 
 The documentation around combing these two pieces is a little sparse. 
 Looking at the video_player sample () seems to suggest a federated model as the web platform is separate. 
 However both the android and ios packages are part of the main package. 
 Is this just an historical artefact or do the ios and android packages still need to be part of the main plugin? 
 If they can be separated out what is the correct package(s) structure? 
 Are then any open source plugins that use pigeon in a fully federated model that could be used as samples? 
",44098.01984
50,64050391,data target choosen federate learning ? ( pysyft ),"data target choosen federate learning ? ( PySyft )   I can not understand function train ( ) below , variable ( data , target ) choosen .      I guess 2 tensor represent 2 random image dataset train , loss function      be calculate every interaction different target ?    also different question : train network image cat , test image car accuracy reach 97 % . possible ? proper value I m something wrong ?    here entire code :  ","how data and target are choosen in a federated learning? (PySyft)  i cant understand how in function train() below, the variable (data, target) are choosen. 
 
 i guess they are 2 tensor representing 2 random images of dataset train, but then the loss function 
 
 is calculated at every interaction with different target? 
 Also i have different question: i trained the network with images of cats, then i test it with images of cars and the accuracy reached is 97%. How is this possible? is a proper value or im doing something wrong? 
 here is the entire code: 
 
",44098.67729
51,64760396,load Fashion MNIST dataset tensorflow fedarate ?,"load Fashion MNIST dataset Tensorflow Fedarated ?   I work project Tensorflow federate . manage use library provide TensorFlow Federated Learning simulation order load , train , test dataset .    for example , load emnist dataset      and get data set return load_data ( ) instance tff.simulation . ClientData . interface allow iterate client ids allow select subset datum simulation .      I try load fashion_mnist dataset Keras perform federate operation :      but get error      because Keras return Tuple Numpy array instead tff.simulation . clientdata like before :      to sum up ,      be way create tuple element    Keras Tuple Numpy array ?      another solution come mind use    load manually appropriate file a format    order get   , problem can not find url fashion_mnist    file format mean something like train test :          my final goal make fashion_mnist dataset work TensorFlow federate learning .","How to load Fashion MNIST dataset in Tensorflow Fedarated?  I am working on a project with Tensorflow federated. I have managed to use the libraries provided by TensorFlow  Federated Learning simulations in order to load,  train, and test some datasets. 
 For example, i load the emnist dataset 
 
 and it got the data sets returned by load_data() as instances of tff.simulation.ClientData. This is an interface that allows me to iterate over client ids and allow me to select subsets of the data for simulations. 
 
 I am trying to load the fashion_mnist dataset with Keras to perform some federated operations: 
 
 but I get this error 
 
 because Keras returns a Tuple of Numpy arrays instead of a tff.simulation.ClientData like before: 
 
 To sum up, 
 
 Is any way to create tuple elements of   from Keras Tuple Numpy arrays? 
 
 Another solution that comes to my mind is to use the
  and load
manually the appropriate files in a format   in order to get the  , but my problem is that i cant find the url for fashion_mnist    file format i mean something like that for both train and test: 
 
 
 
 My final goal is to make the fashion_mnist dataset work with the TensorFlow federated learning. 
",44144.95304
52,72086887,"valueerror : ` input_spec ` collections.abc . Mapping ( e.g. , dict ) , must contain entry key ` x ` , represent input(s )","valueerror : ` input_spec ` collections.abc . Mapping ( e.g. , dict ) , must contain entry key ` x ` , represent input(s )   I m test tutorial non - iid distribution federate learning : , use    way produce non - iid distribution dataset .    but face error regard keras value   .    the code :        ValueError :    collections.abc . Mapping ( e.g. , dict ) , must contain entry key   , represent input(s ) Keras model .      what mean ? solve it ?","ValueError: The `input_spec` is a collections.abc.Mapping (e.g., a dict), so it must contain an entry with key `x`, representing the input(s)  Im testing this tutorial with non-IID distribution for federated learning: , and using   as a way to produce a non-IID distribution for the dataset. 
 But I faced an error regarding keras values in the  . 
 The code: 
 
 
 ValueError: The   is a collections.abc.Mapping (e.g., a dict), so it must contain an entry with key  , representing the input(s) to the Keras model. 
 
 What does that mean? How can I solve it? 
",44683.53041
53,72121192,use transfer learning federate learning ?,use transfer learning federate learning ?   I try implement federate learning . ( use TensorFlow federate core )      and save server_state ( weight ) round :      now want use pre_traine model new federate learning case weight CNN layer fix weight 3 last layer change .    could someone help this ?,"How can I use transfer learning in federated learning?  I tried to implement federated learning. (Using TensorFlow federated core) 
 
 and save server_state (weights) after each round: 
 
 now I want to use this pre_trained model for a new federated learning case where the weights of the CNN layer are fixed and only the weights of the 3 last layers are changed. 
 could someone help me with how I can do this? 
",44686.09213
54,72146421,attributeerror : mapdataset object attribute client_ids tensorflow_federated tff,"attributeerror : mapdataset object attribute client_ids tensorflow_federated TFF   I m try test compression technique federate learn   non - iid   use api tff.simulation.datasets.build_single_label_dataset ( ) , follow post :            but define model train it , get   this error   :      the code :      what mean ? appreciate help !","AttributeError: MapDataset object has no attribute client_ids in tensorflow_federated TFF  Im trying to test a compression technique in federated learning with  non-IID  using this API tff.simulation.datasets.build_single_label_dataset(), following these posts: 
 
 
 
 
 But after defining the model and training it, I got  this error  : 
 
 The code: 
 
 What does that mean?
Appreciate any help! 
",44687.8049
55,72179718,tune hyper parameter cifar100 tensorflow_federate tff without drop accuracy ?,"tune hyper parameter cifar100 tensorflow_federate tff without drop accuracy ?   I m try test tutorial    cifar100 dataset ,   accuracy    drop   round !    do tuning hyper parameter reason ? ?    here code :      and output :      here input structure :      I know mistake !      be hyper parameter define layer create_original_fedavg_cnn_model ( ) wrong ? preprocess_train_dataset ( ) ?      how tune parameter tutorial cifar100 dataset ?        appreciate help ! thank .","How to tune hyper parameters for CIFAR100 in tensorflow_federated TFF without dropping in the accuracy?  Im trying to test this tutorial  with  CIFAR100 dataset , but the  accuracy  is  dropping  each round! 
 Does my tuning for the hyper parameter is the reason?? 
 Here is my code: 
 
 And this is the output: 
 
 Here is the input structure: 
 
 I dont know where is my mistake! 
 
 Are the hyper parameter that are defined in the layers in create_original_fedavg_cnn_model() wrong? or in preprocess_train_dataset()? 
 
 How to tune the parameters for the same tutorial for CIFAR100 dataset? 
 
 
 Appreciate any help! Thanks. 
",44691.05253
56,72263736,can not install tensorflow_federate,"can not install tensorflow_federate   I try install tensorflow federate .      but want import tensorflow federate , get warn google colab notebook restart .      also , try install tensorflow federate way :      but get error import tensorflow federate      how fix it ?","Cant to install tensorflow_federated  I try to install tensorflow federated. 
 
 but when I want to import tensorflow federated, I get this warning and after that google colab notebook is restarted. 
 
 Also, I try install tensorflow federated as this way: 
 
 but get error when import tensorflow federated 
 
 how do I fix it? 
",44697.75595
57,72335489,get ValueError apply transfer learn federate learning ( TFF ),"get ValueError apply transfer learn federate learning ( TFF )   I want use pre_traine model federate learning follow code :    first build model set weight model freeze convolutional layer remove 4 last layer .      next , build new model .      but get ValueError want use tff.learning.build_federated_averaging_process .      please help fix it .","Get ValueError when apply transfer learning in federated learning (TFF)  I want to use pre_trained model in federated learning as following code: 
 first I build my model and set the weights on model and then I freeze convolutional layers and remove 4 last layer. 
 
 next, I build new model. 
 
 but I get ValueError when I want to use tff.learning.build_federated_averaging_process. 
 
 please help me to fix it. 
",44703.29574
58,72467705,unbalanced client size federate learning,"unbalanced client size federate learning   I apply federate learn multiple file use Tensoflow Federated . problem be , size datum ( number record ) file different .      be problem federate learning training different size client ? overcome it ?    be way see client perform federate computation training ?    ","Unbalanced client size in federated learning  I am applying federated learning on multiple files using Tensoflow Federated. The problem is, that the size of data (number of records) in each file is different. 
 
 Is it a problem in federated learning training to have different sizes for each client? if there is how can I overcome it? 
 Is there a way that I can see how each client performing while federated computation training? 
 
 
",44713.8535
59,72556795,access labels TFF,"access label TFF   I follow   . I ve implement transfer learn fine - tuning dataset know access label whenever prediction . transform data right shape ( tf.data . Dataset ) use Keras model prediction . example want predict one label :     federated_train_data consist follow element :      First Tensor image shape second one represent encode label .    my goal illustrate true predict labels image , example :()    TLDR : way access label tf.data . dataset ?","How to access labels with TFF  I was following this  and . So Ive implemented transfer learning with fine-tuning on my dataset but I dont know how to access labels whenever I am doing predictions.
I transformed my data into the right shape (tf.data.Dataset) so I am using the Keras model for predictions. So for example if I want just to predict one label:  
 federated_train_data consists of following elements: 
 
 First Tensor is an image shape and the second one represents encoded labels. 
 My goal is to illustrate what are true and predicted labels of an image, for example:() 
 TLDR: Is there a way that you can access just labels when you have tf.data.Dataset? 
",44721.33969
60,72558094,[ flwr][sklearn ] try use Gradient Boosted tree,"[ flwr][sklearn ] try use Gradient Boosted tree   for day try implement gradient boost tree flwr . try example give . use LogisticRegression Model classification MNIST , work setup .    this problem arise : simply replace sklear.linear_model . LogisticRegression model    work because :    I know value initalize , equivalent   . anyone idea ?    if could make working version would try add flwr reference anybody .    thank advance","[flwr][sklearn] Trying to use Gradient Boosted Trees  for some days now I try to implement gradient boosted trees with flwr.
I tried the example given by .
They use a LogisticRegression Model for the classification of MNIST, which works in my setup. 
 This is where my problem arise:
Simply replacing the sklear.linear_model.LogisticRegression model with the   does not work because: 
 I dont know which values I have to initalize, which are equivalent to the  . Does anyone has an idea? 
 If I could make a working version I would try to add it to flwr as reference for anybody. 
 Thanks in advance 
",44721.40541
61,72584612,"unable list extension / v1beta1 , resource = ingress","unable list extension / v1beta1 , resource = ingress   I try use    version    apply service original file   , pop error say      initially looked    change anything relate    ingress part as :      well , change , generate error apply use    check status , error show again ... clue solve this . please someone give hint .","unable to list extensions/v1beta1, resource=ingresses  I was trying to use   with version   but after I applied the service with its original file as  , it pops out the error saying 
 
 Initially I looked into the   and changed anything related to   in the ingress part as: 
 
 Well, after changed, it does not generate the error when I apply but after I use   to check out the status, the same error shows again...
I have no clue how to solve this. Please someone give me some hint. 
",44723.5485
62,72652038,can not see local epoch output training tensorflow federate learning model ?,"can not see local epoch output training tensorflow federate learning model ?   I train tensorflow federate learning model . can not see output epoch . detail follow :        and output look follow :      be value global model round ? plot curve validation accuracy global model 100 epoch ( 10 round , 10 local epoch per round ) ? ( not tensorboard )","Why cant I see the local epochs output when training tensorflow federated learning model?  I am training a tensorflow federated learning model. I cannot see the output of epochs. Details are as follows: 
 
 
 And my output looks as follows: 
 
 Are these values for global model after each round? How can I plot the curves for validation accuracy of the global model for the 100 epochs (10 rounds, 10 local epochs per round)? (Not in tensorboard) 
",44728.89176
63,72698170,"TypeError : expect 1 argument , get 2 ....... datum = collection . OrderedDict(data , distributed_data[i ] )","TypeError : expect 1 argument , get 2 ....... datum = collection . OrderedDict(data , distributed_data[i ] )   I get follow error relate function definition wrong ?    Convert_to_client_data ( ) function federate learn try convert dataset federate dataset .    here declaration class Distribute use function give error    # Declaration Class Distribute      # function DEFINITION give error      ERROR STATEMENT function definition  ","TypeError: expected at most 1 arguments, got 2....... data = collections.OrderedDict(data, distributed_data[i])  I am getting the following error related to this function definition what is wrong? 
 Convert_to_client_data() is a function in federated learning where I am trying to convert a dataset into the federated dataset. 
 Here is the declaration of the class Distribute which is used in the function which gives the error 
 #Declaration of Class Distribute 
 
 #function DEFINITION which gives the error 
 
 ERROR STATEMENT for the function definition 
 
",44733.38506
64,72713816,privacy client global tokenizer Federated Learning ( TFF ) ?,"privacy client global tokenizer Federated Learning ( TFF ) ?   I currently stick dead end . try make image caption generator federate approach . initial idea different tokenizer client . pose issue however :      every client different sized vocabulary , thus different shape y , cause issue global model configuration .      to counter issue , could make size client equivalent large size across client , fill extra column client 0 .   example :   [ 0,1,1,1 ] map size 6 would become [ 0,1,1,1,0,0 ]      this bring last possible flaw , word different client different index . word "" rock "" client 1 might index 6 , index 9 another client . train global model , cause issue since model try learn different label indice word , impact accuracy ?        this bring final question : idea Federated Learning tokenize word train client single tokenizer ?","Is it against privacy of clients if I have a global tokenizer in Federated Learning (TFF)?  I am currently stuck in a dead end. I am trying to make an image caption generator from a federated approach. My initial idea was to have a different tokenizer for each client. That poses these issues however: 
 
 Every client will have a different sized vocabulary, and thus a
different shape of y, which will cause issues with the global model
configuration. 
 
 To counter the above issue, I could make size of y in each client
equivalent to the largest size across all clients, and fill the
extra columns in each client with 0.  Example:  [0,1,1,1] mapped to a size
of 6 would become [0,1,1,1,0,0] 
 
 This brings me to the last possible flaw, which is that the same
words in different clients will be having different indices. A word
""rock"" in client 1 might have an index of 6, while the same can have
an index of 9 in another client. While training the global model, it
will cause issues since the model is trying to learn different label
indices for the same word, which will impact the accuracy? 
 
 
 This brings me to the final question : Is it against the idea of Federated Learning to tokenize all the words of all the training clients in a single tokenizer? 
",44734.43588
65,72777309,switch federate centralized dataset -error may indicate try pass tensor NumPy call,"switch federate centralized dataset -error may indicate try pass tensor NumPy call   I m try switch federate set centralized learning . I ve create federate dataset , want create dataset centralized learning   create_tf_dataset_from_all_client   function . google error find maybe version NumPy TensorFlow correct function , current version :      python = = 3.9    tensorflow==2.8.2    numpy==1.21.6    tensorflow - federated==0.24.0      I find recent post tensorflow 2.8 match NumPy version    also , error might come function use create clientdata object :      error :  ","When switching from federated to centralized dataset -Error may indicate that youre trying to pass a Tensor to a NumPy call  Im trying to switch from a federated setting to centralized learning. Ive created a federated dataset, but I want to create a dataset for centralized learning with the  create_tf_dataset_from_all_clients  function. When I googled the error I found out that maybe versions of NumPy and TensorFlow are not correct for this function, my current versions are : 
 
 python == 3.9 
 tensorflow==2.8.2 
 numpy==1.21.6 
 tensorflow-federated==0.24.0 
 
 I havent found some recent posts about TensorFlow 2.8 and matching NumPy version 
 Also, the error might come from a function that I used to create the clientData object: 
 
 Error: 
 
",44739.80302
66,72792770,save weight tensorflow federate,save weight tensorflow federate   I want save weight loss get low reuse evaluation .      where :      be possible way save server weight hdf5 format checkpoint reuse it ?,"How to save weights in tensorflow federated  I want to save weights only when loss is getting lower and reuse them for evaluation. 
 
 where: 
 
 Is there a possible way to save server weights in hdf5 format or as a checkpoint and reuse it? 
",44740.85154
67,72818097,tensorflow Federated Learning resnet failse,"tensorflow Federated Learning resnet failse   I experiment tensorflow federate learn API . actualy try train simple resnet 10 client . base datum metric , training seem successful . evaluation well local federate fail .    do anyone advice ?    the model :      the model simple resnet . training use Tensorflow Federated Simulation Dataset emnist 10 client 10 epoch .     everything look fine far ...    I adjust provided function prepare datum . already test whole process simple CNN work quiet well .      do evaluation process tensorflow show strange result . accuracy around 11 percent loss something 7 8 .    if copy weight local model evaluation local , result . try predict single image test datum exception throw :      here model summaray :      I convert label to_categorical function karas util package . exception , input dense layer wrong ? training work ?","Tensorflow Federated Learning on ResNet failse  I do some some experiments with the tensorflow federated learning API. Actualy I try to train a simple ResNet on 10 Clients. Based on the data and metrics, the training seems to be successful. But the evaluation as well as local and federated fails. 
 Does  anyone have an advice? 
 The model: 
 
 The model is just a simple ResNet.
For the training I use the Tensorflow Federated Simulation Dataset for emnist and here 10 clients for 10 epochs.
 
 Everything looks fine so far... 
 I have adjusted the provided function for preparing the data. I have already tested the whole process with a simple CNN and all works quiet well. 
 
 Doing the evaluation process with tensorflow shows a strange result. The accuracy will be at around 11 percent and the loss has something between 7 and 8. 
 If I copy the weights to a local model and do the evaluation local, the same result. If I try to predict a single image from the test data an exception is thrown: 
 
 Here the model summaray: 
 
 I did not convert the labels with with to_categorical function from the karas util package. But why is the exception, the input of the dense layer is wrong? And why does the training work? 
",44742.62957
68,73024656,fedavg client optimizer ?,"fedavg client optimizer ?   in federated averaging , client optimizer SGD only ?    in paper   state "" one method FEDAVG ( McMahan et al . , 2017 ) , client perform multiple epoch SGD local dataset . "" base statement , client run Adam loss function , federate averaging ?    what difference federate averaging ( FedAvg ) Adaptive federate optimization ( FedOpt ) ( paper link above ) ?    in word different     ?","In FedAvg what is the client optimizer?  In federated averaging, does the client optimizer have to be SGD only? 
 In this paper  it states ""One such method is FEDAVG (McMahan et al., 2017), in which clients perform multiple epochs of SGD on their local datasets.""   Based on this statement, if the clients run Adam on their own loss function, it is not federated averaging? 
 What is the difference between federated averaging (FedAvg) and Adaptive federated optimization (FedOpt) (paper linked above)? 
 In other words what is the different between   and  ? 
",44760.63509
69,64962547,convert CSV file datum federate datum,convert CSV file datum federate datum   I try convert CSV dataset federate datum . please find code error get run code    code : import collection      error : ---------------------------------------------------------------------------  ,"Converting CSV file data into federated data  I am trying to convert my CSV dataset into a federated data. Please find the code and the error I am getting while I am running my code 
 code: import collections 
 
 Error: --------------------------------------------------------------------------- 
 
",44158.18494
70,65078203,solve pytorch / pylint error : torch.tensor callable ?,solve pytorch / pylint error : torch.tensor callable ?   when make python      an error come say : torch.tensor callable . know solve it . pytorch version 1.4.0 .,"How can I solve the pytorch/pylint error: torch.tensor is not callable?  when I make in python 
 
 an error came up that says: torch.tensor is not callable. And I do not know how to solve it.
I have pytorch version 1.4.0. 
",44165.72321
71,65078281,"runtimeerror : input.size(-1 ) must equal input_size . expect 200 , get 0 ---- PySyft / PyTorch / Federated Learning","runtimeerror : input.size(-1 ) must equal input_size . expect 200 , get 0 ---- PySyft / PyTorch / Federated Learning   do anyone know solution Error ? try switch pytorch network Federated Learning network always get Error .    I m use Google Colab train GPU . print size embed get 0 , understand datum use there .            the error throw line : lstm_out , ( h , t ) = self.lstm(embed )  ","RuntimeError: input.size(-1) must be equal to input_size. Expected 200, got 0 ---- PySyft / PyTorch / Federated Learning  does anyone know a solution for this Error? I am trying to switch my PyTorch network to an Federated Learning network but i always get this Error. 
 Im using Google Colab an train on GPU. When I print the size of embeds I get 0, but I dont understand why the data is not used there. 
 
 
 
 
 The Error throws in this line: lstm_out, (h,t) = self.lstm(embeds) 
 
",44165.72675
72,65471612,tensorflow_federate attribute namedtupletype,"tensorflow_federate attribute namedtupletype   I follow code   try run file same_OR.py    I also place input file "" initial_model_parameters.txt "" datum folder "" MNIST_data "" folder      I instal tensor flow federate command      and line also underlie red color      when tried execute go error      file "" same_OR.py "" , line 94 , BATCH_TYPE = tff . namedtupletype ( [ AttributeError : module tensorflow_federate attribute NamedTupleType      where problem ? anyone help ?","tensorflow_federated has no attribute NamedTupleType  I am following this code  and trying to run the file same_OR.py 
 I also place input file ""initial_model_parameters.txt""  and data folder ""MNIST_data"" in same folder 
 
 I installed tensor flow federated with this command 
 
 and this line is also underlied with red color 
 
 when i tried to execute go this error 
 
 File ""same_OR.py"", line 94, in 
BATCH_TYPE = tff.NamedTupleType([ AttributeError: module tensorflow_federated has no attribute NamedTupleType 
 
 where is the problem? anyone can help? 
",44192.99811
73,65481370,size mismatch tensorflow_federate eager executor,"size mismatch tensorflow_federate eager executor   I follow code   try run file same_OR.py    there problem    tf show unable import "" tensorflow.compat.v1 "" file "" sameOR.py ""      and list error .. anyone help ?      Traceback ( most recent call last ): File "" samOR.py "" , line 331 , local_model = federated_train(model , learning_rate , federated_train_data ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\utils\function_utils.py "" , line 561 ,   call   return context.invoke(self , arg ) file "" c:\users\aw\anaconda3\lib\site - packages\retrying.py "" , line 49 , wrapped_f return Retrying(*dargs , * * dkw).call(f , * args , * * kw ) file "" c:\users\aw\anaconda3\lib\site - packages\retrying.py "" , line 206 , call return attempt.get(self._wrap_exception ) file "" c:\users\aw\anaconda3\lib\site - packages\retrying.py "" , line 247 , get six.reraise(self.value[0 ] , self.value[1 ] , self.value[2 ] ) file "" c:\users\aw\anaconda3\lib\site - packages\six.py "" , line 703 , reraise raise value file "" c:\users\aw\anaconda3\lib\site - packages\retrying.py "" , line 200 , call attempt = attempt(fn(*args , * * kwargs ) , attempt_number , False ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\execution_context.py "" , line 213 , invoke arg = event_loop.run_until_complete ( file "" c:\users\aw\anaconda3\lib\asyncio\base_events.py "" , line 616 , run_until_complete return future.result ( ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 388 , _ wrap return await coro File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\execution_context.py "" , line 99 , _ ingest ingest = await asyncio.gather(*ingeste ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\execution_context.py "" , line 104 , _ ingest return await executor.create_value(val , type_spec ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py "" , line 286 , create_value return referenceresolvingexecutorvalue(await File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\caching_executor.py "" , line 245 , create_value await cached_value.target_future File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py "" , line 110 , create_value return await self._delegate ( file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py "" , line 105 , _ delegate result_value = await _ delegate_with_trace_ctx(coro , self._event_loop ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 388 , _ wrap return await coro File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn ( fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\federating_executor.py "" , line 383 , create_value return await self._strategy.compute_federated_value(value , type_spec ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\federated_resolving_strategy.py "" , line 272 , compute_federated_value result = await asyncio.gather ( [ file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py "" , line 281 , create_value val = await asyncio.gather ( file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py "" , line 286 , create_value return referenceresolvingexecutorvalue(await File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\caching_executor.py "" , line 245 , create_value await cached_value.target_future File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py "" , line 110 , create_value return await self._delegate ( file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py "" , line 105 , _ delegate result_value = await _ delegate_with_trace_ctx(coro , self._event_loop ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 388 , _ wrap return await coro File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py "" , line 464 , create_value return EagerValue(value , self._tf_function_cache , type_spec , self._device ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py "" , line 366 ,   init   File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py "" , line 326 , to_representation_for_type raise TypeError ( TypeError : apparent type float32[10 ] tensor [ -0.9900856 -0.9902875 -0.99910086 -0.9972545 -0.99561495 -0.99766624 -0.9964327 -0.99897027 -0.9960221 -0.99313617 ] match expect type float32[784,10 ] . ERROR : asyncio : task destroy pende ! task : < task pende name = task-7 coro=<trace .. async_trace ( ) run c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py:200 > wait_for=<future pende cb=[_chain_future .. _call_check_cancel ( ) c:\users\aw0000282f4dfe3d0 > ( ) ] >  ","Size mismatch in tensorflow_federated eager executor  I am following this code  and trying to run the file same_OR.py 
 there is a problem in   as tf its show that unable to import "" tensorflow.compat.v1"" File ""sameOR.py"" 
 
 and these are list of errors .. can anyone help? 
 
 Traceback (most recent call last):   File ""samOR.py"", line 331, in

local_models = federated_train(model, learning_rate, federated_train_data)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\utils\function_utils.py"",
line 561, in  call 
return context.invoke(self, arg)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py"", line 49, in
wrapped_f
return Retrying(*dargs, **dkw).call(f, *args, **kw)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py"", line 206, in
call
return attempt.get(self._wrap_exception)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py"", line 247, in
get
six.reraise(self.value[0], self.value[1], self.value[2])   File ""C:\Users\Aw\Anaconda3\lib\site-packages\six.py"", line 703, in reraise
raise value   File ""C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py"", line 200, in
call
attempt = Attempt(fn(*args, **kwargs), attempt_number, False)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py"",
line 213, in invoke
arg = event_loop.run_until_complete(   File ""C:\Users\Aw\Anaconda3\lib\asyncio\base_events.py"", line 616, in
run_until_complete
return future.result()   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 388, in _wrapped
return await coro   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py"",
line 99, in
_ingest
ingested = await asyncio.gather(*ingested)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py"",
line 104, in _ingest
return await executor.create_value(val, type_spec)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py"",
line 286, in create_value
return ReferenceResolvingExecutorValue(await   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py"",
line 245, in create_value
await cached_value.target_future   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py"",
line 110, in create_value
return await self._delegate(   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py"",
line 105, in _delegate
result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 388, in _wrapped
return await coro   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn( fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federating_executor.py"",
line 383, in create_value
return await self._strategy.compute_federated_value(value, type_spec)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federated_resolving_strategy.py"",
line 272, in compute_federated_value
result = await asyncio.gather( [   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py"",
line 281, in create_value
vals = await asyncio.gather(   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py"",
line 286, in create_value
return ReferenceResolvingExecutorValue(await   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py"",
line 245, in create_value
await cached_value.target_future   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py"",
line 110, in create_value
return await self._delegate(   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py"",
line 105, in _delegate
result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 388, in _wrapped
return await coro   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py"",
line 464, in create_value
return EagerValue(value, self._tf_function_cache, type_spec, self._device)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py"",
line 366, in  init    File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py"",
line 326, in to_representation_for_type
raise TypeError( TypeError: The apparent type float32[10] of a tensor [-0.9900856  -0.9902875  -0.99910086 -0.9972545  -0.99561495
-0.99766624  -0.9964327  -0.99897027 -0.9960221  -0.99313617] does not match the expected type float32[784,10]. ERROR:asyncio:Task was
destroyed but it is pending! task: <Task pending name=Task-7
coro=<trace..async_trace() running at
C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py:200>
wait_for=<Future pending
cb=[_chain_future.._call_check_cancel() at
C:\Users\Aw0000282F4DFE3D0>()]> 
 
",44193.71836
74,65491416,Resnet50 TFF give good result,"Resnet50 TFF give good result   I use tff 0.12.0 image dataset dog cat(2 label ) , test VGG16 , Ifind accuracy 0.9 change resnet50 , accuracy decrease 0.4 , write :      but accuracy exceed 0.46 even 100 round . part result :      help please ! ! !","Why Resnet50 with TFF does not give good results  I use TFF 0.12.0 and image dataset for dog and cat(2 labels), If I test with VGG16, Ifind accuracy 0.9 but If I change to ResNet50, accuracy decrease to 0.4, Here is what I write: 
 
 but accuracy does not exceed 0.46 even after 100 rounds. here is a part of the result : 
 
 Help Please!!! 
",44194.47931
75,65498670,"expect TensorFlow computation , find intrinsic","expect TensorFlow computation , find intrinsic   I follow code   try run file    require change        I get error . need suggestion .    I use     Python 3.8.3 version","Expected a TensorFlow computation, found intrinsic  I am following this code  and trying to run the file   with some required changes 
 
 
 I got these errors. I need suggestions. 
 I am using   
 Python 3.8.3 version 
",44194.87247
76,65527210,LSTM sequence prediction overfit one specific value,"LSTM sequence prediction overfit one specific value   hello guy new machine learning . implement federate learn   LSTM predict next label sequence . sequence look like   [ 2,3,5,1,4,2,5,7 ] . example , intention predict 7 sequence . try simple federate learn kera . use approach another model(Not LSTM ) work I , always overfit 2 . always predict 2 input . make input data balance , mean almost equal number label last index ( here 7 ) . I test datum simple deep learning greatly work . seem data mybe suitable LSTM issue . please help I . code federate learning . please let know information need , really need it . thank  ","LSTM sequence prediction overfits on one specific value only  hello guys i am new in machine learning. I am implementing federated learning on with  LSTM to predict the next label in a sequence . my sequence looks like this  [2,3,5,1,4,2,5,7] . for example, the intention is predict the 7 in this sequence. So I tried a simple federated learning with keras. I used this approach for another model(Not LSTM) and it worked for me, but here it always overfits on 2. it always predict 2 for any input. I made the input data so balance, means there are almost equal number for each label in last index (here is 7). I tested this data on simple deep learning and greatly works . so it seems to me this data mybe is not suitable for LSTM or any other issue. Please help me. This is my Code for my federated learning. Please let me know if more information is needed, I really need it. Thanks 
 
",44197.16777
77,65553960,build federated_averaging_process custom federate dataset load CSV file,build federated_averaging_process custom federate dataset load CSV file   my problem continue question     I manage load federate dataset give csv file load train test datum .    my question reproduce work example build iterative process perform custom federate averaging datum .    here code work :      this error get think problem error . wrong ? ?        thnx @Zachary Garrett solve error help add line code      my problem throw    this      what miss again ? maybe something layer sequential here  ,"How to build federated_averaging_process from custom federated dataset that loads from CSV file  My problem is a continue to this question  
 i manage to load a federated dataset from a given csv file and load both the train and the test data. 
 My question now is how to reproduce a working example to build an iterative process that performs a custom federated averaging on this data. 
 Here is my code but its not working: 
 
 This is the error that I got but I think my problem is more than this error. what I am doing wrong here ?? 
 
 
 thnx to @Zachary Garrett
i solve the above error with his help by adding these line of code 
 
 My problem now that is throwing in the   is this 
 
 what i miss again? maybe something in the layer sequential here 
 
",44199.80791
78,73083132,I m get * * numpyclient.fit return tuple 3 element . * * error run client.py file . could problem ?,I m get * * numpyclient.fit return tuple 3 element . * * error run client.py file . could problem ?   I use Flower code example try POC Federated Learning keep get error run client.py file :  ,"Im getting an **NumPyClient.fit did not return a tuple with 3 elements.** error when I run client.py file. What could be the problem?  I am using the Flower code example to try POC of Federated Learning but I keep getting the error below when I run the client.py file: 
 
",44764.66872
79,73326892,build federate system csv dataset SparkNL library ?,build federate system csv dataset SparkNL library ?   I interested federated system try one pre train multilingual model notebook .    I look tutorial use TFF Flower framework handle csv dataset .    so could suggest tutorial github repository help TFF Flower !,"How to build a federated system with CSV dataset with SparkNL library?  I am very interested in federated systems and i was trying one of the pre trained multilingual models such as this notebook . 
 I was looking for any tutorials using TFF or Flower frameworks that handle csv datasets. 
 So could you suggest any tutorials or github repositories to help me do that with TFF or Flower! 
",44784.87943
80,73407373,"typeerror : expect keras.losse . loss , find function","typeerror : expect keras.losse . loss , find function   I want build TFF model speech recognition system . this , use CNN - GRU model architecture CTC loss function . get error want build_federated_averaging_process think ctc_loss function can not fix it .    part code be :      and get error step :      how fix it ?","TypeError: Expected keras.losses.Loss, found function  I want to build a TFF model for speech recognition systems. For this, I use the CNN-GRU model architecture with a CTC loss function. but I got error when I wanted to build_federated_averaging_process and think its about the ctc_loss function but I cant fix it. 
 part of my code is: 
 
 and I got error in this step : 
 
 how do I fix it? 
",44791.73873
81,73431551,Federated learning,Federated learn   I two kind covid 19 dataset two client ( the first one ST Scan image second XRays image ) use federate learning approch . question use dataset two client although different type acheive heterogeneity try solve ?,"Federated learning  I have two kinds of covid 19 datasets as two clients (the first one ST Scan images and the second is XRays images) and I use federated learning approch.
The question is can I use those dataset as two clients although they have different type to acheive the heterogeneity and try to solve it ? 
",44794.17002
82,73456900,attributeerror : module syft attribute FederatedDataLoader,"attributeerror : module syft attribute FederatedDataLoader   I start use    implement federate - learning . follow one tutorial , get stick error :      Code use :      the tutorial follow use old version    support    deprecate . also , use    instead   . purpose    give tutorial load datum hence , transform   . link . equivalent function instead    load datum new version ?","AttributeError: module syft has no attribute FederatedDataLoader  I have just started using   to implement federated-learning. While following one of the tutorials, I got stuck on an error: 
 
 Code which I have used: 
 
 The tutorial which I am following uses an old version of   so the support for   has been deprecated. Also, I had to use   instead of  . The purpose of   as given in the tutorial is to load data and hence, transform it to  . This is the link for the . Is there any equivalent function instead of   to load data in the new version? 
",44796.42664
83,73502727,noise addition weight use Opacus Federated Learning set,"noise addition weight use Opacus Federated Learning set   I plan use Opacus implement differential privacy federate learning model basic doubt would love clear that .    so far understanding go , use Opacus , use optimizer like DPSGD add differential noise batch clientâ€ ™ s dataset â€œlocal trainingâ€. federate learning , train client model â€œlocal epochsâ€ send weight central server aggregation , add differential noise send model weight .    so question be , use DPSGD add noise every single batch every single client dataset local training could add noise local weight send out ? let local training epoch happen simply add noise outbound weight time departure ? miss ?","Noise addition to weights using Opacus in a Federated Learning setting  I am planning to use Opacus to implement differential privacy in my federated learning model but I have a very basic doubt that I would love to have cleared before that. 
 So as far as my understanding goes, using Opacus, we use an optimizer like DPSGD that adds differential noise to each batch of each clientâ€™s dataset while they are in â€œlocal trainingâ€. And in federated learning, we train client models for a few â€œlocal epochsâ€ before sending their weights out to a central server for aggregation, and we add differential noise before sending out the model weights. 
 So my question is, why do we use DPSGD to add noise to every single batch of every single client dataset during local training when we could just add noise to the local weights before they are sent out? Why do we not let the local training epochs happen as is and simply add noise to the outbound weights at the time of departure? What am I missing? 
",44799.6103
84,65828005,Question tff.simulation.datasets.stackoverflow.load_data(cache_dir = none ),"Question tff.simulation.datasets.stackoverflow.load_data(cache_dir = None )   I ve use function load datum stackoverflow data_set . however , one problem occur every time use function set cache_dir location kera / dataset location cache , still try download tar internet(even already 8.5 g tar file download local ) . simple way avoid download internet access local ?    I ve also try write save load function , seem can not apply HDF5ClientData type .","Question about tff.simulation.datasets.stackoverflow.load_data(cache_dir = None)  Ive been using this function to load data from stackoverflow data_set. However, one problem occurs that every time I use this function and set cache_dir to the location of the keras/dataset or the location of the cache, it still tries to download the tar from the internet(Even when I have already the 8.5G tar file download in local). Is there a simple way to avoid downloading from the internet and access by local? 
 Ive also tried to write the save and load function, but it seems they cannot be applied to HDF5ClientData type. 
",44217.54271
85,66259690,tff : test accuracy fluctuate,"tff : test accuracy fluctuate   I train resnet50 model TFF , use test accuracy test data evaluation , find many fluctuation show figure below , please avoid fluctuation ?  ","TFF : test accuracy fluctuate  I train a ResNet50 model with TFF, I use test accuracy on test data for evaluation, but I find many fluctuations as shown in the figure below, So please how can I avoid this fluctuation ? 
 
",44245.50719
86,66265109,"Federated Learning Tensorflow Federated , way apply early stop client side ?","Federated Learning Tensorflow Federated , way apply early stop client side ?   I use Tensorflow Federated train text classification model federate learn approach . way apply early Stopping client - side ? option cross - validation api ? thing able find evaluation :      which apply model end federate training round .    be miss something ?","Federated Learning in Tensorflow Federated, is there any way to apply Early stopping on the client side?  I am using Tensorflow Federated to train a text classification model with the federated learning approach.
Is there any way to apply Early Stopping on the client-side? Is there an option for cross-validation in the API?
The only thing I was able to find is the evaluation: 
 
 Which is applied to the model by the end of a federated training round. 
 Am I missing something? 
",44245.73031
87,66277912,validation accuracy get low number worker increase Federated Learning non - iid dataset,"validation accuracy get low number worker increase Federated Learning non - iid dataset   I use human activity recognition ( HAR ) dataset 6 class use federate learning ( FL ) . case , implement non - iid dataset assign ( 1 ) class dataset different 6 worker , ( 2 ) two class 3 different worker , ( 3 ) three class 2 different worker .    when run FL process , validation accuracy scenario ( 3 ) > ( 2 ) > ( 1 ) . expect scenario obtain almost validation accuracy . scenario , use hyperparameter setting include batch size , shuffle buffer , model configuration .    be common FL non - iid dataset problem result ?","The validation accuracy gets lower when the number of workers increases in Federated Learning with non-IID dataset  I use human activity recognition (HAR) dataset with 6 classes using federated learning (FL). In this case, I implement the non-IID dataset by assigning (1) each class dataset to different 6 workers, (2) two classes to 3 different workers, and (3) three classes to 2 different workers. 
 When I run the FL process, the validation accuracy for scenario (3) > (2) > (1). I expect that all scenarios will obtain almost the same validation accuracy. For each scenario, I use the same hyperparameter settings including batch size, shuffle buffer, and the model configuration. 
 Is it common in FL with the non-IID dataset or is there any problem with my result? 
",44246.53603
88,66289113,split dataset train test base client number use Federated learning,"split dataset train test base client number use Federated learning   I try use    split dataset 2 part , work well    Hope one give advice issue      Code part  ","How to split the dataset into train and test based on client number using Federated learning  I try to use   to split the dataset into 2 part, but it does not work well 
 Hope some one can give some advice on this issue 
 
 Code part 
 
",44247.31427
89,66304067,error execute federate learn text generation tutorial Colab,error execute federate learn text generation tutorial Colab   I try follow   federate learn TensorFlow execute line get error :      the error :    ,"Error while executing federated learning text generation tutorial in Colab  I am trying to follow this  on federated learning TensorFlow and when executing this line I get an error: 
 
 The error: 
 
 
",44248.65535
90,66312016,"Keras load model saving model , start train beginningï¼Ÿ","Keras load model saving model , start training beginningï¼ÿ     this output , see load model training , value loss still compare value training . really confuse it .    this code , want use two model ( after combine , final combining ) , use      . cuz want mimic Federated Learning process .    hope someone give idea .      I use    loop control training process , output last iteration ... , value accuracy loss almost compare first iteration  ","Keras load model after saving the model, why start training from the beginningï¼Ÿ  
 this is my output, as you can see when I load the model after training, the value of the loss is still the same compared with the value before training. I am really confused about it. 
 This is my code, I want to use two models (After combining, Final combining), and I use   and   . Cuz I want to mimic Federated Learning process. 
 Hope someone can give me some ideas. 
 
 I use the   loop to control the training process, the output is the last iteration... , the value of accuracy and loss is almost the same compared with the first iteration 
 
",44249.33734
91,66395599,use federate learn object detection,"use federate learn object detection   I plan use federate learn object detection algorithm already develop detect weed . research , see federate tensorflow example Image classification . like follow link :     my question use federate learn federate tensorflow object detection algorithm ? yes , would please provide link example ?","Using federated learning for object detection  I plan to use federated learning for an object detection algorithm I already developed for detecting weeds.
As I research, I see federated tensorflow examples on Image classification. Like the following link:
 
 My question is can we use federated learning and federated tensorflow for object detection algorithms?
If yes, would you please provide me with some links and examples? 
",44254.18641
92,66546336,initialize computation construct server state,"initialize computation construct server state   in federated learning context , like   show , initial weight global model ( at server level ) initialize randomly :   . want hand put initial weight download another model ( ) . please proceed , I m new TFF . thank","the initialize computation to construct the server state  In the federated learning context, and like this  shows, initial weights of global model (at server level) are initialized randomly with :  . I want to have the hand to put these initial weights by downloading them from another model ( ). So please how can I proceed, Im newer in TFF.
Thanks 
",44264.49307
93,66576677,accuracy decrease iteration federate learning set,"accuracy decrease iteration federate learning set   I work federate learning detect bad client .    Brief federate learning - Data divide various client , training do client side result send client central server aggregation client weight do aggregated model send local client training .    I work detection client send malicious update central server . use base code present .    I write method filter client detect client malicious remove client aggregation step . expect much performance difference one client weight remove global aggregation result confuse I . add piece code . noisy_client[itr ] ! = 0 occur 1/10 client occur client iteration .      if code use accuracy iteration increase steadily      but code use accuracy increase first iteration decrease iteration      I try reduce learn rate 0.01 0.001 also decrease batch size see behavior that . reason correct ?","Accuracy decreasing after iteration in federated learning setting  I am working on a federated learning to detect bad clients. 
 Brief about federated learning - Data is divided into various clients, training is done on client side and the results are then sent by each client to central server where aggregation of the client weights is done and the aggregated model is then again sent to local clients for training. 
 I am working on detection of client sending malicious updates to central server. I am using base code present . 
 I wrote a method filter client which will detect if some client is malicious and remove that client from aggregation step. I expected that there will not be much performance difference if one of the client weight is remove from global aggregation but the results are confusing me. I added this piece of code. noisy_client[itr] != 0 will only occur for 1/10 clients and it will occur for the same client in each iteration. 
 
 If this code is not used then the accuracy in each iteration is increasing steadily 
 
 But when the code is used accuracy increases for first few iterations and decreases after that for each iteration 
 
 I have tried reducing the learning rate from 0.01 to 0.001 and also decreasing the batch size but saw the same behavior after that.
What can be the reason for this and how this can be corrected ? 
",44266.20372
94,66579541,state = iterative_process.initialize ( ) dow Federated learning,"state = iterative_process.initialize ( ) dow Federated learning   I m new Federated learning , try implement code FL image classification , can not understand line :   , Weights affected server ?","What state = iterative_process.initialize() dow in Federated learning  Im new in Federated learning, I tried to implement the code of FL for image classification, but I cant understand this line :  , Weights affected to the server from where ? 
",44266.38751
95,66581075,WARNING : tensorflow : AutoGraph could transform    0x7fca141a6d08 > run as - be,"WARNING : tensorflow : AutoGraph could transform    0x7fca141a6d08 > run as - be   I implement code TFF image classification . TFF version 0.18.0 , write :      but find warning :      so please avoid warn . thank","WARNING:tensorflow:AutoGraph could not transform   at 0x7fca141a6d08> and will run it as-is  I implement the code of TFF of image classification. TFF version 0.18.0,
I write this : 
 
 But I find this warning: 
 
 So please how can I avoid this warning. Thanks 
",44266.45271
96,66875831,Federated reinforcement learning,"Federated reinforcement learning   I implement   federate deep Q - learn   PyTorch , use multiple agent , run DQN . problem use multiple replay buffer agent , append experience correspond agent ,   two element experience agent replay buffer , i. e. , "" current_state "" "" next_state ""   become first time slot . mean buffer , see   the value current state value next state . include simplified part code result below . Whay change current state next state already exixte buffer append ? something wrong define buffer global variable ? another idea ?    ","Federated reinforcement learning  I am implementing  federated deep Q-learning  by PyTorch, using multiple agents, each running DQN.
My problem is that when I use multiple replay buffers for agents, each appending experiences at the corresponding agent,  two elements of experiences in each agent replay buffer, i. e., ""current_state"" and ""next_state""  becomes the same after the first time slot. I mean in each buffer, we see  the same values for current states and the same values for next states .
I have included simplified parts of the code and results below. Whay is it changing the current states and next states already exixting in the buffer when doing append? Is there something wrong with defining the buffers as a global variable? or do you have another idea? 
 
 
",44285.73458
97,73524856,adaptive top - k selection machine learn,"adaptive top - k selection machine learn   in federated/ distribute learning , server send initially global model client , client train model locally select top k value , send value server .    how select adaptive k client ?   rather set top k value fix number ( e.g. k=3 , return top 3 value ) , want make top k value adaptive , example , client send top 4 value , may send 6 top value base define feature ( large value , large loss , ... etc )    be way that ?","Adaptive top-k selection in machine learning  In federated/ distributed learning, the server will send initially a global model to clients, and each client will train the model locally and then select the top k values, and send only these values to the server. 
 How I can select an adaptive k in each client?  rather than set top k value to fixed number (e.g. k=3, which return top 3 values), I want to make the top k values adaptive, for example, some clients will send top 4 values, other may send 6 top values based on a defined feature ( largest value, largest loss , ... etc) 
 Is there any way to do that? 
",44802.26877
98,74424083,Federated learning weight aggregation,"Federated learning weight aggregation   I would like add different weight client Federated learning , aggregation stage , client different impact global model .    for example :      I look suggestion implement approach .","Federated learning weighted aggregation  I would like to add different weights to clients in Federated learning, so in the aggregation stage, each client has a different impact on the global model. 
 For example: 
 
 I am looking for suggestions to implement this approach. 
",44878.81113
99,74596793,attributeerror : model object attribute _ backward_hooks,attributeerror : model object attribute _ backward_hooks   try implement reaserch paper :   train Monotone Network architechture :      when initialise network run random input :      it give follow error :      please help understand error fix it .,"AttributeError: Model object has no attribute _backward_hooks  Trying to implement the reaserch paper:

Training a Monotone Network with architechture: 
 
 When I initialise the network and run for random inputs: 
 
 It gives the following error: 
 
 Please help me understand what this error is and how to fix it. 
",44893.27203
100,67051923,module name tensorflow_fedarate,module name tensorflow_fedarate   I m window even google Collab can not import it . proper internet .  ,"No module named tensorflow_fedarated  Im on windows but even in google Collab I cant import it.
and I do have proper internet. 
 
",44298.09855
101,67077765,MODEL_SPEC Federated Learning ( use Tensorflow Federated Core ),"MODEL_SPEC Federated Learning ( use Tensorflow Federated Core )   I try use Federated code build federate learning algorithm . meet one problem . official tutorial , define Model Spec like follow :          I wonder require input model OrderedDict . could input model trainable Keras model ?    thank !","MODEL_SPEC in Federated Learning (Using Tensorflow Federated Core)  I am trying to use Federated code to build my own federated learning algorithm. But I met one problem. In the official tutorial, it define the Model Spec like following: 
 
 
 
 I am wondering if it is required to input the model as an OrderedDict. Could I input the model as a trainable Keras model? 
 Thanks! 
",44299.63994
102,67567802,loss increase update state,"loss increase update state   I would like update state , write :      my problem loss increase contrary accuracy make small decrease :      be another solution solve problem ? thank","loss increase when updating State  I would like to update state, So here is what i wrote: 
 
 My problem is loss increase contrary to the accuracy which makes a small decrease: 
 
 Is there another solution to solve this problem ?
Thanks 
",44333.42911
103,67570514,use tff.learning.build_federated_evaluation instead keras_evaluate,"use tff.learning.build_federated_evaluation instead keras_evaluate   I m new TFF , work . would like replace    function predefine function TFF :     so edit line :      in line :      the function evaluate example dataset contrary    , evaluate    totally . modify function evaluate totality    like   :","use tff.learning.build_federated_evaluation instead of keras_evaluate  Im newer in TFF, I work on this . I would like to replace   function by predefined function of TFF :  
 So how can I edit those lines : 
 
 In this line : 
 
 the function evaluate only on an example of dataset contrary to   , it evaluate on   totally. So how can I modify this function to evaluate on the totality of   like in the other  :  
",44333.55565
104,67602060,print state model Federated learning,"print state model Federated learning   I would like print ( before training ) state model :   , find error :  ","How to print state of model in Federated learning  I would like to print (before training) the state of model :
with   ,
I found this error : 
 
",44335.46402
105,67633859,norm clip technique TFF,"norm clip technique TFF   I m train dp federate learning model use "" dp - fedavg "" algorithm , base paper :      the paper propose two norm clip technique "" flat clipping "" "" per - layer clipping "" , perform experiment use "" per - layer clipping "" .    in case tff , attach dp - query aggregation process federate model , clip technique implement default ? way specify clip technique use ?","Norm clipping technique in TFF  Im training a DP federated learning model using the ""DP-FedAvg"" algorithm, which is based on below paper: 
 
 The paper proposes two norm clipping techniques ""flat clipping"" and ""per-layer clipping"", then performs the experiments using ""per-layer clipping"". 
 In case of TFF, when attaching a DP-query and an aggregation process to the federated model, which clipping technique is implemented by default? Is there a way to specify the clipping technique used? 
",44337.37932
106,67634399,"FL , client train different model architecture ?","FL , client train different model architecture ?   I practice , would like client train different architecture different model , possible ?","In FL, can clients train different model architectures?  I practice on this , I would like that each client train a different architecture and different model, Is this possible? 
",44337.40288
107,67678734,parameter CNN model return none,"parameter CNN model return None   I create CNN model like   . send device , set train . train local model , collect local_weight average get update global_model . try get item    function get     . thing local_model , get desire output . wrong ?      any help would appreciate .","The parameters of a CNN model is returning None  i create a CNN model like this  . Then i send it to device, set it to train. Then i train my local models, collect the local_weights and the average them to get updated global_model.
Now i am trying to get the items from the   function but all i get is   as  . When i do the same thing for the local_models, i get the desired output. What am i doing wrong? 
 
 Any help would be appreciated. 
",44340.86285
108,67810671,intial_clip_norm mean gaussian adaptive clip TFF ?,intial_clip_norm mean gaussian adaptive clip TFF ?   I try implement differentially private FL binary classification model use gaussian adaptive clip geometric method .      I know initial_l2_norm_clip initial value clip norm update base target_unclipped_quantile value .    how determine appropriate value initial_l2_norm_clip particular model ?    when set ( initial_l2_norm_clip ) 0.1 getting really low AOC ( around 0.4 ) set high value 1.0 get well AOC value ( around 0.8 ) case clip metric record iterative process always increase ( i.e go 0.1 0.3 1.0 1.2 )    my model run 13 round 10 client per round make difference ?,"What does intial_clip_norm mean in gaussian adaptive clipping in TFF?  I am trying to implement a Differentially private FL binary classification model using gaussian adaptive clipping geometric method. 
 
 I know that the initial_l2_norm_clip is the initial value of clipping norm which is updated based on the target_unclipped_quantile value. 
 How can we determine the appropriate value of initial_l2_norm_clip for a particular model? 
 when I set it (initial_l2_norm_clip) to 0.1 I am getting a really low AOC (around 0.4) but when I set it to a higher value of 1.0 I am getting a better AOC value (around 0.8) and in both cases the clip metric which is recorded by the iterative process always increases (i.e it goes from 0.1 to 0.3 and 1.0 to 1.2) 
 my model is running for 13 rounds with 10 clients per round does this make a difference? 
",44349.77281
109,67842524,Got error ( element 0 tensor require grad grad_fn ) perform learning use pytorch diabate datum set,Got error ( element 0 tensor require grad grad_fn ) perform learning use pytorch diabate datum set   I perform Federated learning use pysyft pytorch . use diabetes dataset . get error training(element 0 tensor require grad grad_fn ) . attach screen shot error also note book file :      my code :      my model :  ,"Got an error (element 0 of tensors does not require grad and does not have a grad_fn) while performing learning using pytorch with diabates data set  I am performing Federated learning using pysyft and pytorch. I am using a diabetes dataset.  I got this error while training(element 0 of tensors does not require grad and does not have a grad_fn). I am attaching the screen shots of my error and also the note book file: 
 
 My code: 
 
 My model: 
 
",44351.78103
110,67971878,Random Seed Tensorflow federate ?,"Random Seed Tensorflow federate ?   I want get reproducible result Tensorflow Federated code . implement seed ( random , numpy tensorflow ) , affect Tensorflow Federated . datum processing step reproducible , code snippet below .    I read Tensorflow Federated provide global seed function possibility save state . understand argumentation . anyone aware method / function help explain can not use seed Tensorflow Federated ?    appreciate every comment :) thank help .  ","Random Seed for Tensorflow federated?  I want to get reproducible results with my Tensorflow Federated code. For that I have implemented some seeds (random, numpy and tensorflow), but they arent affecting Tensorflow Federated. The data processing steps are all reproducible, it has to be in the code snippet below. 
 I have read that Tensorflow Federated doesnt provide a global seed function and that my only possibility is to save the state. But I dont understand this argumentation. Is anyone aware of a method/function that can help me out or explain to me why I cant use seeds with Tensorflow Federated? 
 Appreciate every comment :) Thanks for your help. 
 
",44361.59315
111,68018178,Federated Learning Image Classification colab,"Federated Learning Image Classification colab   I m new Federated learning , try implement code FL Image Classification , can not understand line    I confuse detail part . trying build sequential model Keras , train model , get error , may fix it ?    please guide thank you .    ","Federated Learning for Image Classification in colab  Im new in Federated learning, I tried to implement the code of FL for Image Classification, but I cant understand this line 
 I am confused in some detail parts. I am trying to build a sequential model in Keras, but when I train the model, I am getting this error, How may I fix it? 
 please guide me
thank you. 
 
 
",44364.46693
112,74886418,can not install import tensorflow_federated colab,"can not install import tensorflow_federated colab   I want try simple federate learn example python . it , need import tensorflow_federated package .      here stack trace      how resolve error ?   btw , read forum problem might resolve update python version , however still exist despite update v3.9   full stack trace follow ( I submit screenshot misinterpret stackoverflow quote code right format )","Cannot install and import tensorflow_federated in colab  I want to try a simple federated learning example in python. For it, I need to import tensorflow_federated package. 
 
 Here is the stack trace 
 
 How should I resolve this error? 
BTW, I read in a forum that the problem might be resolved by updating the python version, however it still exists despite I updated it to v3.9 
The full stack trace is as follows (I had to submit a screenshot of it was misinterpreted by stackoverflow as some quotes and codes that are not in the right format)
 
",44917.38793
113,74898751,flower run server client different machine,flower run server client different machine   I use   federate learning application . way run server client different machine real - world benchmark ?,"Flower running the server and clients on different machines  I use  for federated learning applications. Is there any way to run the server and clients on different machines for a real-world benchmark? 
",44918.44784
114,75171118,resolve module attribute entropy_decode_index error ubuntu TFF ?,"resolve module attribute entropy_decode_index error ubuntu TFF ?   I get "" module 0b1a516c7ccf3157373118bcf0f434168745c8a4 attribute entropy_decode_index error clean intall tensorflow federate ( TFF ) Ubuntu 22.04 . system : AMD 6900HS , Nvidia3050ti . first "" import tensorflow_federated "" line fail .    there even single entry google concern error message shock .    the detailed error message be : file "" /home / egosis / venv / lib / python3.9 / site - package / tensorflow_compression / python / ops/ init .py "" , line 17 ,       AttributeError : module 0b1a516c7ccf3157373118bcf0f434168745c8a4 attribute entropy_decode_index    every answer gladly appreciate .    I try instal TFF v0.46.0 , v0.45.0 v0.44.0 tff help .","How to resolve module has no attribute entropy_decode_index error in ubuntu for TFF?  I got ""module 0b1a516c7ccf3157373118bcf0f434168745c8a4 has no attribute entropy_decode_index error after a clean intall of tensorflow federated (TFF) on Ubuntu 22.04. System: AMD 6900HS, Nvidia3050ti. The first ""import tensorflow_federated"" line fails. 
 There is not even a single entry on google concerning this error message and I am shocked. 
 The detailed error message is:
File ""/home/egosis/venv/lib/python3.9/site-packages/tensorflow_compression/python/ops/ init .py"", line 17, in  
 
 AttributeError: module 0b1a516c7ccf3157373118bcf0f434168745c8a4 has no attribute entropy_decode_index 
 Every answer is gladly appreciated. 
 I tried installing TFF v0.46.0, v0.45.0 and v0.44.0 of tff but it did not help. 
",44945.45132
115,75205546,transferring model two pc via PostgresSQL database,"transferring model two pc via PostgresSQL database   I two pc want share tensorflow model "" hdf5 format "" federate learn manner via PostgresSQL database .    the model train locally machine , transfer database along training history . transfer do multiple cycle specific schedule .    I search online solution transfer file via PostgresSQL database , solution suggest tabulate data transfer , e.g. csv file datum , arbitrary file extension , like hdf5 .    can anyone help I , even roadmap , solution ? tutorial example similar scenario would suggest , would also appreciate .    thank help advance !","Transferring models between two PCs via PostgresSQL database  I have two PCs that want to share tensorflow models ""hdf5 format"" in a federated learning manner via a PostgresSQL database. 
 The models will be trained locally on both machines, and then transferred to the database along with the training history. The transfer will be done for multiple cycles in a specific schedule. 
 I searched online for solutions to transfer the files via PostgresSQL database, but all solutions suggest a tabulated data transfer, e.g. csv file data, not arbitrary file extensions, like hdf5. 
 Can anyone help me, even with a roadmap, for the solution?
If any tutorials or examples for similar scenarios would be suggested, that would be also appreciated. 
 Thanks for your help in advance! 
",44949.16278
116,75299930,"local dataset Federated learning : client side , local update perform different subset local dataset round ?","local dataset Federated learning : client side , local update perform different subset local dataset round ?   I wonder Federated Learning approach need split local dataset number batch equal number communication round . otherwise need update locally whole local dataset round .    building federate learning model","Local dataset in Federated learning: client side, is the local update performed on a different subset of the local dataset each round?  I was wondering if in a Federated Learning approach I need to split the local dataset in a number of batches equal to the number of communication rounds.
Otherwise I need to update locally on the whole local dataset each round. 
 Building a federated learning model 
",44957.67259
117,75480058,way upload deep learning model PostgreSQL database ?,"way upload deep learning model PostgreSQL database ?   I deep learning model ( tensorflow hdf5 format ) , want upload PostgreSQL database . single model may 500 mb , model need update upload / downloaded database frequently ( e.g. , every 30 min ) .    I m begineer PostgreSQL , information / receipe start would appreciate .","Is there a way to upload a deep learning model to a PostgreSQL database?  I have deep learning models (tensorflow in hdf5 format), which I want to upload to a PostgreSQL database.
A single model may be up to 500 MBs, and the models need to be updated and uploaded/downloaded from the database frequently (e.g., once every 30 mins). 
 Im a begineer to PostgreSQL, so any information/receipes to start with would be appreciated. 
",44974.15316
118,75549595,send PyTorch model weight network compress manner,"send PyTorch model weight network compress manner   I PyTorch model try integrate federate learning for . order this , need send model weight back forth server client . get size model weight , approximately 6 kb , dill / pickle send network , end ~65 mb , take long time , especially since send / receive must do many round training . realize always go extra overhead serialize python object , way might able compress weight use different datastructure transfer model weight back forth ?    I try   , result ~64 mb string must transfer internet , large . ive try compression via lzma blosc , yield little compression .","Sending PyTorch model weights over network in a compressed manner  I have a PyTorch model that I am trying to integrate federated learning for. In order to do this, I need to send the model weights back and forth between a server and a client. When I get the size of the model weights, it is approximately 6kb, but when I dill/pickle it to send over the network, it ends up being ~65mb, which takes a very long time, especially since this send/receive must be done for many rounds of training. I realize that there is always going to be extra overhead when serializing python objects, but is there a way I might be able to compress the weights further or use a different datastructure to transfer the model weights back and forth? 
 I tried  , which results in a ~64mb string that must be transferred over internet, which is too large. Ived tried compression via lzma and blosc, but they yield little compression. 
",44980.82059
119,75664095,"importerror : sys.meta_path None , Python likely shut down ; OverflowError : timeout fit c timeval ; exception thread Thread-1","importerror : sys.meta_path None , Python likely shut down ; OverflowError : timeout fit c timeval ; exception thread Thread-1   I get series error message , last one one mention first title , try run   Github repo local machine . need project boilerplate code later .    I paste dependency error end .    my try solve it :   look answer similar error   post , could figure solution case . also look answer      anomaly log , completely helpless .   also try change conda environment virtualenv environment run error . also try Python v3.9 3.10.9 3.10.10    thing look for , run cloned project :      there need prepare dataset already come clone project . follow rest step Readme .      you look logs server    directory .      I get error client log file    4 other .      remember download weight         Change python directory conda / virtualenv environment python ,      shell script , run they . I run script Git Bash .      the dependency help .        dependency      Error      previous error :   mention case help . face issue   solve instal    relate dependency .","ImportError: sys.meta_path is None, Python is likely shutting down; OverflowError: timeout doesnt fit into C timeval; Exception in thread Thread-1  I got a series of error messages, the last one being the one mentioned first in the title, while I was trying to run  Github repo on my local machine. I need that project as a boilerplate for my own code later. 
 I have pasted the dependencies and the error at the end. 
 My Tries to solve it: 
I have looked at the answers for a similar error in  post, but I could not figure out the solution for my case. I have also looked into answers for the   and    anomalies which were in the same log, but am completely helpless. 
I also tried changing from a conda environment to virtualenv environment but I ran into the same error. I also tried with Python v3.9 and 3.10.9 and 3.10.10 
 Things to look for, while running the cloned project: 
 
 There is no need to prepare the dataset as it already comes with the cloned project. Follow the rest of the steps as in the Readme. 
 
 You can look at the logs for the server in the   directory. 
 
 I got the error in the clients log files which are in   and all 4 others. 
 
 Remember to download the weights   in  
 
 Change the python directory to your conda/virtualenv environments python, in the   and   shell scripts, before running them. I ran those scripts in Git Bash. 
 
 The dependencies below should help. 
 
 
 Dependencies 
 
 Error 
 
 Previous errors: 
Just mentioning it in case it helps. I was facing issues with  which I solved by installing   and other related dependencies. 
",44992.65313
120,75720004,api call pysyft library cause modulenotfounderror ?,"api call pysyft library cause modulenotfounderror ?   I try work federate learning project begin . try import class call "" BaseDataset "" pysyft library show follow .      however follwe error pop up . check documentation any help much appreciate .      P.S. pysyft version 0.7.0      I try import class module . however    error still persist .","why is api calls from the pysyft library causing a ModuleNotFoundError?  I am trying to work on a federated learning project and I am just at the beginning. I tried to import a class called ""BaseDataset"" from the pysyft library as shown in the following. 
 
 However the follwing error is poping up. I have checked the documentation from Any help will be much appreciated. 
 
 P.S. I am on pysyft version 0.7.0 
 
 I tried to import a class from the module. However a   error is still persisting. 
",44998.39292
121,75721113,error : could find version satisfie requirement torchvision~=0.5.0 ( from syft ),"error : could find version satisfie requirement torchvision~=0.5.0 ( from syft )   last week iam work syft==0.2.9 work great ! week try install syft==0.2.9 error "" error : could find version satisfie requirement torchvision~=0.5.0 ( from syft ) ( from version : 0.1.6 , 0.1.7 , 0.1.8 , 0.1.9 , 0.2.0 , 0.2.1 , 0.2.2 , 0.2.2.post2 , 0.2.2.post3 , 0.8.2 , 0.9.0 , 0.9.1 , 0.10.0 , 0.10.1 , 0.11.0 , 0.11.1 , 0.11.2 , 0.11.3 , 0.12.0 , 0.13.0 , 0.13.1 , 0.14.0 , 0.14.1 ) error : match distribution find torchvision~=0.5.0 ""    then import syft library undefine    I need work TorchHook federate learn PyTorch    I use Google Colab .. also try code Jypter kaggle , show error    ","ERROR: Could not find a version that satisfies the requirement torchvision~=0.5.0 (from syft)  Last week iam working with syft==0.2.9 and it was working great!
but this week when i tried to install syft==0.2.9 i have this error
""ERROR: Could not find a version that satisfies the requirement torchvision~=0.5.0 (from syft) (from versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.8.2, 0.9.0, 0.9.1, 0.10.0, 0.10.1, 0.11.0, 0.11.1, 0.11.2, 0.11.3, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1)
ERROR: No matching distribution found for torchvision~=0.5.0"" 
 Then when import the syft library it was undefine 
 I need to work with TorchHook in federated learning by PyTorch 
 I use Google Colab.. Also i tried my code in Jypter and kaggle, all showing the same error 
 
 
",44998.46705
122,68233576,PySyft AttributeError : dataframe object attribute federate reading data csv,"PySyft AttributeError : dataframe object attribute federate reading datum csv   I try implement pysyft code federate leare csv datum . tutorial follow   use torch library FMNIST datum iamge . difficulty customize code csv datum .    this error get      File "" C:/user / python / PCA / federated_learning.py "" , line 175 , train_load = sy . FederatedDataLoader(train_set , transform = data_transformer.federate(worker ) , train = true , batch_size = args.batch_size , shuffle = true , * * kwargs ) AttributeError : Compose object attribute federate    ","PySyft AttributeError: DataFrame object has no attribute federate while reading data from csv  I am trying to implement that pysyft code for federated learing for my csv data . The tutorial i am following is this   they used torch library FMNIST data which is iamge . I am having difficulty in customizing this code for my csv data. 
 This is error i am getting 
 
 File ""C:/user/python/PCA/federated_learning.py"", line 175, in 
train_loader = sy.FederatedDataLoader(train_set, transform=data_transformer.federate(workers), train=True,
batch_size=args.batch_size, shuffle=True,  **kwargs) AttributeError:
Compose object has no attribute federate 
 
 
",44380.24225
123,68269539,issue set environment TensorFlow Federated Colab,"issue set environment TensorFlow Federated Colab   I new Federated Learning , try get start TensorFlow Federated . work tutorial "" Federated Learning Image Classification "" Colab , try install TensorFlow Federated , meet error :      after instal version library mention here , find still exist internal conflict instal library . anyone else face issue ? would great get pointer this !","Issues in setting up the environment for TensorFlow Federated on Colab  I am new to Federated Learning, and I am trying to get started with TensorFlow Federated. While working on the tutorial ""Federated Learning for Image Classification"" on Colab, I tried to install TensorFlow Federated, but was met with these errors: 
 
 After installing the versions of the libraries mentioned here, I found that there still exist some internal conflicts with the installed libraries. Has anyone else faced this issue? Would be great to get some pointers on this! 
",44383.46751
124,75874823,Federated learn Differential Privacy - bad test performance,"Federated learn Differential Privacy - bad test performance   I ve play time FL + dp thesis . use TFF case someone wonder .    I load datum as :      and set q sampling ratio      give define dp parameter :      Noise = 0.5    q = 0.015    n_clients_per_round = int(q*len(train_data.client_id ) )      I define aggregation factory :      and iterative process :      my training happen round follow :      the main issue training metric look good model learn slow steady rate   the test metric horrendous . look like model overfitte use dp ( know regulariser ) . absolutely confused .     I ve try several change noise learn structure modify internal round training batch size . start model train well without dp later add dp .    any idea happen ?    good regard ,","Federated learning with Differential Privacy - Bad test performance  Ive been playing for some time with FL + DP for my thesis.
I am using TFF in case someone is wondering. 
 I load my data as: 
 
 And I set Q as sampling ratio 
 
 Given this I define my DP parameters: 
 
 Noise = 0.5 
 Q = 0.015 
 n_clients_per_round = int(Q*len(train_data.client_ids)) 
 
 I define my aggregation factory: 
 
 And the iterative process: 
 
 My training happens in rounds as follows: 
 
 The main issue here is that the training metrics looks good and the model learns at a slow but steady rate but  the test metrics are horrendous . It looks like the model is overfitting while using DP (known to be a regulariser). I am absolutely confused.
 
 Ive tried several changes in the noise and learning structure so as modifying the internal rounds of training and the batch size.
I started with a model that trains well without DP to later add DP. 
 Any ideas why this is happening? 
 Best regards, 
",45014.35285
125,75918443,Federated Learning implementation code show RuntimeError : element input 0 1,"Federated Learning implementation code show RuntimeError : element input 0 1   ` import torch import torch.nn nn import torch.optim optim torch.utils.data import DataLoader , Dataset import numpy np sklearn.dataset import load_breast_cancer sklearn.model_selection import train_test_split      `    the code work perfectly upto num_rounds=96 numround give great equal 97 , show error :    ` RuntimeError Traceback ( most recent call last )     < cell line : 47 > ( ) 79 torch.no_grad ( ): 80 global_output = global_model(torch.tensor(x_train , dtype = torch.float32 ) ) --- > 81 global_loss = criterion(global_output , torch.tensor(y_train , dtype = torch.float32).view(-1 , 1 ) ) 82 global_pre = ( global_output > 0.5).int().numpy().flatten ( ) 83 accuracy = np.mean(global_pre = = y_train )    2 frame    /usr / local / lib / python3.9 / dist - package / torch / nn / functional.py binary_cross_entropy(input , target , weight , size_average , reduce , reduction ) 3093 weight = weight.expand(new_size ) 3094 - > 3095 return torch._C._nn.binary_cross_entropy(input , target , weight , reduction_enum ) 3096 3097    RuntimeError : element input 0 1 `","Federated Learning implementation code shows a RuntimeError: all elements of input should be between 0 and 1  `
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split 
 
 ` 
 the code works perfectly upto num_rounds=96 but when the numround is given greater then or equal to 97, it shows an error: 
 `
RuntimeError                              Traceback (most recent call last) 
  in <cell line: 47>()
79     with torch.no_grad():
80         global_outputs = global_model(torch.tensor(X_train, dtype=torch.float32))
---> 81         global_loss = criterion(global_outputs, torch.tensor(y_train, dtype=torch.float32).view(-1, 1))
82         global_pred = (global_outputs > 0.5).int().numpy().flatten()
83         accuracy = np.mean(global_pred == y_train) 
 2 frames 
 /usr/local/lib/python3.9/dist-packages/torch/nn/functional.py in binary_cross_entropy(input, target, weight, size_average, reduce, reduction)
3093         weight = weight.expand(new_size)
3094
-> 3095     return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
3096
3097 
 RuntimeError: all elements of input should be between 0 and 1
` 
",45019.43462
126,76106294,solve error get training client flower framework federate learning ?,"solve error get training client flower framework federate learning ?   I try implement Federated Learning use Flower framework python . get follow error start process .    here try ,      in code cid refer clientID ,","How do I solve the error which I get during training the clients in flower framework for federated learning?  I am trying to implement Federated Learning using Flower framework in python. I get the following error when I start the process. 
 Here is what I tried, 
 
 In the above code cid refers to the clientID, 
",45042.00998
127,76140070,resolve : model parameter load simulating federate learn Semantic Segmentation task use Flower Pytorch,"resolve : model parameter load simulating federate learn Semantic Segmentation task use Flower Pytorch   I m work federate UNET semantic segmentation workflow use flower Pytorch . right load datum run centralized training try federate see model parameter load properly . include google colab notebook code log output , keep question short .      I m leave incase someone trying implement similar workflow . feel free reach out .","Resolved: Model parameters not loading when simulating a federated learning Semantic Segmentation task using Flower and Pytorch  Im working on federating a UNET semantic segmentation workflow using flower and Pytorch. As of right now I can load the data and run a centralized training but once I try to federate it I see that model parameters are not being loaded properly. I have included a google colab notebook to the code and the log output, to keep the question short. 
 
 Im leaving this up here incase someone is trying to implement a similar workflow. Feel free to reach out. 
",45046.31944
128,76178468,Federated Learning would help centralise Hospitals clinical datum cohort ( database ) ? especially Electronic Health Records dataset,Federated Learning would help centralise Hospitals clinical datum cohort ( database ) ? especially Electronic Health Records dataset   what library use federate learning process ? datum encryption technique use protect dataset ?    I study article blog health sector difficult implement health organisation agree share datum . way trust federate learning would support protective way,"How Federated Learning would help to centralise Hospitals and clinical data cohorts (databases)? Especially Electronic Health Records datasets  What are the libraries we can use for federated learning process?
what are the data encryption techniques used to protect datasets? 
 I studied some articles and blogs but in health sector its difficult to implement because health organisations are not agree t share data. in other way they have no trust on federated learning that it would support as a protective way 
",45051.10133
129,76288080,Differential Privacy error PyTorch use Opacus PrivacyEngine - troubleshoot ?,Differential Privacy error PyTorch use Opacus PrivacyEngine - troubleshoot ?   the problem give code be :      .    the code give below :      how fix issue PrivacyEngine Opacus differential privacy ?,"Differential Privacy error in PyTorch using Opacus PrivacyEngine - how to troubleshoot?  The problem of the given code is: 
 
 . 
 The code is given below: 
 
 How do I fix this issue in the PrivacyEngine of Opacus for differential privacy? 
",45065.42407
130,76658088,can not install shfl python,"can not install shfl python   I try use shfl python library . import shfl , get error   , apparently can not install it .    I use three follow command unsuccessful error mention ( I use conda ) . python version   . conda version   , pip version   .    1-   ( base ) --- > get error :      2-    ( base ) --- > get error :      3-    ( because use conda environment ) --- > get error :  ","Cannot install shfl in python  I am trying to use shfl python library. When I import shfl, I get the error  , and apparently I cannot install it. 
 I have used three following commands and all are unsuccessful with the errors I mention below (I use conda). My python version is  . My conda version is  , and my pip version is  . 
 1-  (based on ) ---> I get this error: 
 
 2-   (based on ) ---> I get this error: 
 
 3-   (because I use conda environment) ---> I get this error: 
 
",45118.03132
131,76750150,library get weight local model every round Federated Learning ?,"library get weight local model every round Federated Learning ?   in federated learning , want get weight local model every round , cluster local client base weight , use training_process.get_model_weights(train_state ) get global weight only .    I use training_process.get_model_weights(train_state ) get global weight , find library function get weight client yet .","Is there an library to get weights of each local model every round of Federated Learning?  In federated learning, I want to get weights of each local model every round, then I will cluster local clients based on their weights, but I can just use training_process.get_model_weights(train_state) to get global weights only. 
 I did use training_process.get_model_weights(train_state) to get global weights, but I havent found any library or function to get weights of each clients yet. 
",45130.84462
132,76772278,"pytorch : calculate loss respect alpha , nn . paramter","pytorch : calculate loss respect alpha , nn . Paramter   I try implement follow algorithm . step 18 , gradient loss respect alpha compute try access .grad atribute alpha , get none , mean gradient compute alpha    my model follow :      with training loop go like this :      what problem implemntation .    I try different retrain_grad ( ) loss computation","Pytorch: Calculating the loss with respect to alpha, which is a nn.Paramter  I am trying to implement the following algorithm
. In step 18, the gradient of the loss with respect to alpha is being computed and when i try to access this .grad atribute for alpha, I get None, which means that there is no gradient computed for alpha 
 My model is as follow: 
 
 with a training loop that goes like this: 
 
 What is the problem with this implemntation. 
 I tried different retrain_grad() after the loss computation 
",45133.59834
133,76935633,could connect docker container,"could connect docker container   I federate server ( flower framework ) run docker container raspberry pi device network client ( my laptop ) . client able establish connection server .      I enable port forward docker container 8080 8000 . try connect client serverâ€ ™ s 192.168.0.104:8000 address port . get error      I disable firewall client ( my laptop ) .    I search whether raspberry pi firewall blocking connection , havenâ€ ™ t find solid information . miss anything , share information direction must head appreciate .    thank you .","Could not connect to the docker container  I have a federated server (flower framework) running in a docker container in the raspberry pi device in the same network as the client (My laptop). The client is not able to establish a connection with the server. 
 
 I enabled port forwarding for the docker container from 8080 to 8000. When I try to connect the client to the serverâ€™s 192.168.0.104:8000 address and port. I get the error 
 
 I have disabled the firewall in the client (my laptop). 
 I searched whether raspberry pi has any firewall blocking the connection, but I havenâ€™t found any solid information. Am I missing anything, sharing any information or direction in which I must head will be appreciated. 
 Thank you. 
",45157.60887
134,77107057,make model_average exclusive federate learning use Python thread,"make model_average exclusive federate learning use Python Threads   I create    thread use follow code :      in run function , several piece code , follow :      in reply function , call one function . want write code way every thread proceed next line calling function .    every thread must average model proceed next line . understand use Python condition variable . that ?    the follow function must mutually exclusive .      every thread proceed next line execute piece code .    I write code part implement federate learning algorithm .","make model_averaging exclusive in federated learning using Python Threads  I am creating   threads using the following code: 
 
 In the run function, there are several pieces of code, as follows: 
 
 In the reply function, I have called one function. I want to write this code in such a way that every thread will proceed to the next line after calling this function. 
 Every thread must average the model and then proceed to the next line. I understood that I have to use Python condition variable. How can I do that? 
 The following functions must be mutually exclusive. 
 
 Every thread will proceed to the next line after executing this piece of code. 
 I am writing this code as part of implementing a federated learning algorithm.
 
",45183.70968
135,77136636,"face AttributeError : module syft attribute VirtualWorker # create VirtualWorkers hook = syft . VirtualWorker(hook , id = hook )","face AttributeError : module syft attribute VirtualWorker # create VirtualWorkers hook = syft . VirtualWorker(hook , id = hook )   I face "" AttributeError : module syft attribute VirtualWorker "" "" # create VirtualWorkers hook = syft . VirtualWorker(hook , id=""hook "" ) ""    create VirtualWorkers    hook = syft . VirtualWorker(hook , id=""hook "" ) text alice = syft . VirtualWorker(hook , id=""alice "" `    I first try use    Create PySyft hook    hook = syft . TorchHook(torch ) `    create virtual worker    bob = syft . VirtualWorker(hook , id=""bob "" ) text but depricate used approach `","i am facing AttributeError: module syft has no attribute VirtualWorker for # Create VirtualWorkers hook = syft.VirtualWorker(hook, id=hook)   i am facing ""AttributeError: module syft has no attribute VirtualWorker"" for ""# Create VirtualWorkers hook = syft.VirtualWorker(hook, id=""hook"") "" 
 Create VirtualWorkers 
 hook = syft.VirtualWorker(hook, id=""hook"")
your text alice = syft.VirtualWorker(hook, id=""alice""` 
 i first tried using 
 Create a PySyft hook 
 hook = syft.TorchHook(torch)` 
 Create virtual workers 
 bob = syft.VirtualWorker(hook, id=""bob"")
your text but it was depricated so i used this approach ` 
",45188.71758
136,77377438,fit_round receive failure flwr framework ?,"fit_round receive failure flwr framework ?   I use flwr framework send random array client server server merge array send back client .      Client code :      scenario :   suppose two client [ 1 , 2 ] [ 3 , 4 ] datum . server collect dataset concatenate they . server [ 1 , 2 , 3 , 4 ] send back client . one round client [ 1 , 2 , 3 , 4 ] .    but get result expectation . error log server side follow :  ","Why fit_round received failures in flwr framework?  I am using flwr framework to send a random array from client to server and then server will merge the array and sends back to each of the clients. 
 
 Client code: 
 
 Scenario: 
Suppose two clients have [1, 2] and [3, 4] data. The server will collect these datasets and concatenate them. Then the server will have [1, 2, 3, 4] and send back to each of the clients. So after one round each client will have [1, 2, 3, 4]. 
 But I am getting the result as my expectation. The error log on the server side is as follows: 
 
",45226.96332
137,77513547,apply federate learn YOLOv8 model ?,"apply federate learn YOLOv8 model ?   I make model detect seven object detect people use YOLOv8 save .pt .    the dataset jpg txt file consist image label .    how apply Federated Learning YOLOv8n Google colab environment ?    I m beginner CV field .      I try above , fail they .","How can I apply federated learning to YOLOv8 model?  I made a model for detecting seven objects that detect people using YOLOv8 and saved it as .pt. 
 The dataset is a jpg and txt file consisting of images and labels. 
 How can I apply Federated Learning to YOLOv8n in a Google colab environment? 
 Im a beginner in CV field. 
 
 I tried the above, but I failed all of them. 
",45250.19625
138,77534661,tensor object attribute send,"tensor object attribute send   I use pysyft library 0.8.2 implement Federated Learning experiment . one part code suppose send tensor information client establish use pysyft command . attribute send ( ) get ( ) long support Pytorch 2.1.0 .    import torch import pysyft sy    bob = sy . Worker(name = bob ) print(bob ) print(bob.client_cache ) x = torch.tensor([1,2,3 ] ) print(x ) x.send(bob ) error message : tensor object attribute send print(x )    how overcome dilemma send tensor client ?    I know whether download old version pytorch get send ( ) get ( ) attribute another way send tensor pysyft client .","Tensor object has no attribute send  I am using the pysyft library 0.8.2 to implement Federated Learning experiment. At one part of the code I am supposed to send the tensor information over clients established using pysyft commands. But the attributes send() and get() are no longer supported by Pytorch 2.1.0. 
 import torch
import pysyft as sy 
 bob = sy.Worker(name=bob)
print(bob)
print(bob.client_cache)
x = torch.tensor([1,2,3])
print(x)
x.send(bob)   # error message: Tensor objects has no attributes send
print(x) 
 How to overcome this dilemma and send tensors over the clients? 
 I do not know whether I have to download an older version of pytorch to get send() and get() attributes or there will be another way to send the tensor over pysyft client. 
",45253.25703
139,77547784,can not import tensorflow_federate,can not import tensorflow_federate   an attribute Error raise import tensorflow_federated colab though install it .          -- > import tensorflow_federated tff : AttributeError : module numpy attribute _ no_nep50_warne    how solve it ? thank you !      ,"Cant import tensorflow_federated  An attribute Error raised when importing tensorflow_federated on colab though I did install it. 
 
 
 
 --> import tensorflow_federated as tff : AttributeError: module numpy has no attribute _no_nep50_warning 
 how can I solve it?
Thank you! 
 
 
 
",45255.50425
140,77732938,training federate model bert resnet pre - train model,training federate model bert resnet pre - train model   I want train multi - modal model federate learning environment . model definition .      this    code   . want train model get error .   load datum use generator . value error  ,"training federated model by bert and resnet pre-train model  I want to train a multi-modal model in the federated learning environment.
this is my model definition. 
 
 this is my   code  .
When I want to train the model I got this error. 
I load my data by using the generator.
and this is my value error 
 
",45289.6791
141,77798059,accuracy decrease global aggregation federate learn,"accuracy decrease global aggregation federate learn   I work federate learning project . write code stimulate process federate learning . however , global aggregation every iteration , test accuracy global model decrease lot remain unchanged follow iteration . algorithm aggregation use FedAvg . try split code different unit find problem . local training , select client train 3 epoch . experiment , five client select training aggregation , model use local vgg16 fork   , dataset MNIST split i.i.d manner client :      before aggregation local model , test accuracy local model use test datum global server ,      and use aggregation code aggregate weight select client :      and global test accuracy decrease remain as      although try increase epoch local training local accuracy increase   , global accuracy still fall value before . wrong place code aggregation ?    the test accuracy remain level local accuracy .","The accuracy decreased after global aggregation in federated learning  I am working on a federated learning project. I write a code to stimulate the process of federated learning. However, after global aggregation in every iteration, the test accuracy of the global model will decrease a lot and remain unchanged in the following iteration. The algorithm of aggregation I used is FedAvg. And I have tried to split my code into different units to find out the problem.
For the local training, the selected clients train for 3 epochs. In this experiment, all five clients will be selected for training and aggregation, the model I used for the local is the vgg16 forked from  , the dataset is the MNIST and split in i.i.d manner for each client: 
 
 Before the aggregation of the local model, I test the accuracy of the local model using the test data of the global server, 
 
 And I used the aggregation code below to aggregate the weights of selected clients: 
 
 And the global test accuracy decreases and remains the same as 
 
 Although I have try to increase the epochs of local training as the local accuracy increase to  , the global accuracy still fall into the same value as before. Is there any wrong place in my code for aggregation? 
 The test accuracy should remain at the same level as the local accuracy. 
",45302.27131
142,77876217,perform Federated Learning different dataset file output feature different input feature ?,"perform Federated Learning different dataset file output feature different input feature ?   Iâ€ ™ m apply federate learn several dataset , have similar output feature different input feature , cany that . feature mean column dataset . want know even possible do ? please provide comprehensive answer ?","How can I perform Federated Learning on different dataset files having same output feature but different input feature?  Iâ€™m apply federated learning on several datasets,having similar output feature but different input features, how cany I do that. By feature I mean columns in the dataset. I want to know is this even possible to do? Please provide a comprehensive answer? 
",45315.8792
143,77918043,multiple master centralize federate learning,"multiple master centralize federate learn   I look way create federate learn scenario three master client network , function similar centralize federated learning ,    do pytorch support , library , policy , algorithm pytorch would let achieve this ?","multiple masters in centralized federated learning  I am looking for a way to create a federated learning scenario with three masters and client network, and this functions similar to centralized federated learning, 
 does pytorch support this , are there any libraries,policies, algorithms in pytorch that would let me achieve this? 
",45323.2619
144,78138686,attributeerror : preprocessclientdata object attribute create_tf_dataset_for_client,attributeerror : preprocessclientdata object attribute create_tf_dataset_for_client   I project federate learning . get error .      can anyone help resolve ?    I try load different mnist dataset . find data attribute,"AttributeError: PreprocessClientData object has no attribute create_tf_dataset_for_clients  I am doing a project in federated learning . I got this error. 
 
 Can anyone help me to resolve it ? 
 I have tried to load different mnist dataset. But I couldnt find data with attributes  
",45362.25796
145,78176551,DataLoader cause ram crash pytorch Federated Learning : solution ?,"DataLoader cause ram crash pytorch Federated Learning : solution ?   I m try implement federate learn forecast solar photovoltaic generation use LADPU dataset . preprocesse dataset , partition segment simulate federate environment , align segment unique    value 10 different client . next step involve create sequence partitions LSTM model input . use    function this , target sequence      feature predict   . however , split training validation set set PyTorch    object ( include separate    evaluation ) , issue . colab session consistently crash due exhaust available RAM . try reduce batch size limit 6 csv file , but issue persist .    I new it , I refer tutorial documentation give   usecase . I can not figure problem possibly miss something . anyone please help .  ","DataLoader Causing RAM Crashes in PyTorch Federated Learning: Solutions?  Im trying to implement federated learning to forecast solar photovoltaic generation using the LADPU dataset.
After preprocessing the dataset, I partitioned it into segments to simulate a federated environment, aligning each segment with unique   values for 10 different clients.
The next step involved creating sequences from these partitions as LSTM model inputs.
I used a   function for this, targeting sequences with   and   features to predict  .
However, when I split these into training and validation sets and set up PyTorch   objects (including a separate   for evaluation), there is an issue. My Colab session consistently crashes due to exhausting all available RAM.
I tried to reduce the batch size and limit to 6 CSV files,but the issue persists. 
 I am very new to it,I am referring to the tutorials and documentation given in  for my usecase.I cant figure out the problem or possibly I am missing out on something. Can anyone please help. 
 
",45368.79517
146,78185619,two loss function same ?,"two loss function same ?   this loss function personalize federate learning framework . lambda equal 0 , client train locally . otherwise adjust parameter base similarity global model .    Version 1 , server return global_model every client :      Version 2 , server return parameter global_model every client :      Version 1 work well , version 2 turn completely local training matter lambda be .    I know why , look I ..","Why these two loss function are not the same?  This is a loss function of a personalized federated learning framework. When lambda equals 0, all clients train locally. Otherwise they adjust their parameters based on the similarity to the global model. 
 Version 1, server returns the global_model to every client: 
 
 Version 2, server returns the parameters of the global_model to every client: 
 
 Version 1 works well, but version 2 turns into completely local training no matter what lambda is. 
 I dont know why, they look the same to me.. 
",45370.41289
147,78192538,error TypeError : object type float len ( ) add parameter weights sum_model catboost classifier,"error TypeError : object type float len ( ) add parameter weights sum_model catboost classifier   I build CatBoost model simulate federate learn system first train local model catboost model use loop code :      later append local model sum use sum_model function Catboost package :      I get error whenever add weights=0.7 parameter :      TypeError : object type float len ( )      however , try code add weight parameter , work . suggestion might problem ?","Error TypeError: object of type float has no len() when adding parameter weights to sum_model in catboost classifier  I am building a CatBoost model to simulate the federated learning system at first I am training the local models on the same Catboost model using a for loop code: 
 
 Later I am appending all the local models and sum them using Sum_model function from the Catboost package: 
 
 I am getting this error whenever I add the weights=0.7 parameter: 
 
 TypeError: object of type float has no len() 
 
 However, I tried once the same code with adding the weights parameter, and it worked. Do you have any suggestions on what might be the problem? 
",45371.43569
148,78221905,send extra parameter server Federated learning Flower Tensorflow ?,"send extra parameter server Federated learning Flower Tensorflow ?   I want send extra parameter model update server utilize extra parameter server purpose . use Flower Tensorflow project . send extra parameter , model work perfectly . currently code .    how successfully send extra parameter value server receive it ?    thank help .    I try send additional parameter get_parameter method , receive FedAvg strategy . get error again .","How to send extra parameters to server in Federated learning with Flower and Tensorflow?  I want to send extra parameters with model updates to server and then utilize those extra parameters in server for other purposes. I am using Flower and Tensorflow for this project. Before sending extra parameters, my model was working perfectly. Currently I have these code . 
 How do I successfully send extra parameters or values in server and receive it? 
 Thank you for your help. 
 I tried to send additional parameters in get_parameter method, and receive it with FedAvg strategy. But I got this error again and again.  
",45376.90185
149,78271162,Federated Averaging somehow always give identical accuracy test set,"Federated Averaging somehow always give identical accuracy test set   I implement federate averaging     omitting preprocesse save datum test set 9 train set below :      my model look like this :      now train save weight train set :       see screenshot give different accuracy train    now federate averaging   without add weight since I ve divide dataset equal size .      I aggregate weight something like :      now issue I m run regardless many weight aggregate , accuracy check test end exact same . eg . 3 seperately ( i.e weight 0 - 2,3 - 5,6 - 8) :      with 9 :      I try test set initial weight instead give different accuracy :      I m honestly stumped curious happening . explanation correction error logic would appreciate .","Federated Averaging somehow always gives identical accuracy on test set  I am implementing federated averaging on the  
 Omitting the preprocessing I am saving the data into a test set and 9 train sets as below: 
 
 My model looks like this: 
 
 Now with these I am training and saving weights for each of the train sets: 
 
 
As you can see from the screenshot each of them does give different accuracies while training 
 Now for federated averaging I am  but without adding weights since Ive divided the dataset into equal sizes. 
 
 I am aggregating the weights with something like: 
 
 Now the issue Im running into is that regardless of how many weights I aggregate, the accuracy when checking for test ends up the exact same.
eg. with 3 of them seperately (i.e weights 0-2,3-5,6-8): 
 
 with all 9: 
 
 I have tried the test set with the initial weights instead and they do give me different accuracies: 
 
 Im honestly stumped and curious about how and why this is happening. Any explanation or corrections for any error in the logic would be appreciated. 
",45386.04493
150,78294778,module tensorflow_federated.python.learning attribute Model,"module tensorflow_federated.python.learning attribute Model   I instal tff 0.75.0 , TF 2.14.1 , Python 3.10.12 work Google Colab .    error program :      thisattributeerror : module tensorflow_federated.python.learning attribute Model      I try lot version downgrade upgrade downgrade conflict issue upgrade attribute error .    which version good resolve kind error ?","module tensorflow_federated.python.learning has no attribute Model  I have installed tff 0.75.0, TF is 2.14.1, Python is 3.10.12 and working on Google Colab. 
 Error in my program: 
 
 thisAttributeError: module tensorflow_federated.python.learning has no attribute Model 
 
 I have tried lots of versions by downgrading and upgrading when I do downgrading than I have conflict issues when doing upgrading than these attribute errors. 
 Which version is best to resolve these kinds of errors? 
",45390.81962
151,78389817,Flower API run multiple aggregation server,"Flower API run multiple aggregation server   I want use Flower develop distribute federate learning application , instead single aggregator , multiple server aggregation .   wonder possible run multiple server use Flower decentralize aggregation it ?","Flower API running with multiple aggregation servers  I want to use Flower for developing a distributed federated learning application, where instead of a single aggregator, there will be multiple servers for the aggregation. 
I am wondering if it is possible to run multiple servers using Flower to decentralize the aggregation and how to do it? 
",45408.43624
152,78398118,Nan value use nn . Dropout ( ) alexnet CIFAR-10 implement per - FedAvg algorithm,"Nan value use nn . Dropout ( ) alexnet CIFAR-10 implement per - FedAvg algorithm   I m implement per - FedAvg algorithm HF - MAML , Hessian Matrix product approximate disturb model parameter $ w$ small delta $ \delta$ ( e.g. 0.001 ) , calculate bellow :    $ h = \frac{\nabla ( w+\delta*\nabla w)-\nabla ( w-\delta*\nabla w)}{2*\delta}$    then use follow formula update model : $ w = w - \beta \time ( \nabla w ( I- \alpha h))$    where \alpha \beta predefine learning - rate - like parameter . identity matrix upper equation write python code :      after update local model , send server averaging . however , use AlexNet CIFAR-10 dataset , training loss suddenly explode Nan point . try lot method , way deal comment nn . Dropout ( ) function model .      I understand why . full model code training code follow .        I try follow :      low learning rate , i.e. Alpha beta . help . client model suddenly jump infinite training loss , update model server cause model degrade mess .      lower disturbing parameter \delta . become even bad , first round model get Nan test loss . believe could place issue hide .      disable two Dropout ( ) layer AlexNet . work , run smoothly towards end .        I believe Dropout somehow break training process , disable may overfit model . figure real issue use Dropout without concern .","Nan value when using nn.Dropout() in AlexNet on CIFAR-10 implementing Per-FedAvg algorithm  Im implementing the Per-FedAvg algorithm with HF-MAML, in which the Hessian Matrix product is approximated by disturbing model parameters $W$ with a small delta $\delta$ (e.g. 0.001), and is calculated as bellow: 
 $H = \frac{\nabla (w+\delta*\nabla w)-\nabla (w-\delta*\nabla w)}{2*\delta}$ 
 Then we use the following formula to update model:
$w = w - \beta \times ( \nabla w * (I- \alpha * H))$ 
 Where \alpha and \beta are predefined learning-rate-like parameters. I is the identity matrix so the upper equation can be written in python code: 
 
 After updating the local models, they are sent to server for averaging.
However, when I use AlexNet on CIFAR-10 dataset, the training loss will suddenly explode to Nan at some point. I tried a lot of methods, and the only way to deal with it is to comment the nn.Dropout() functions in model. 
 
 I just dont understand why. The full model code and the training code are as follows. 
 
 
 I tried the following: 
 
 lower the learning rate, i.e. Alpha and beta. Didnt help. Some clients model will suddenly jump to a infinite training loss, then updating these models to server will cause all models to degrade to a mess. 
 
 lower the disturbing parameter \delta. It becomes even worse, as in the first round all models get a Nan test loss. I believe this could be the place where the issue hides. 
 
 Disable the two Dropout() layer in AlexNet. It worked, and runs smoothly towards the end. 
 
 
 I believe the Dropout somehow break my training process, but disabling it may overfit the model. If I can figure out the real issue then I can use Dropout without concerns. 
",45410.50804
153,78398361,read Data Python use panda,"read Data Python use panda     what could problem follow code , ? read datum    I read datum te code give follow error  ","Reading Data in Python using pandas  
 What could be the problem with the following code,? its not reading the data 
 I was reading the data and te code is giving the following errors 
 
",45410.57182
154,78410724,GPU percentage allocation Python class,"GPU percentage allocation Python class   I m develop sort federate learning environment contain Server class 10 instance Client class . train various client one I d like specify upper limit regard GPU usage client . example :      this Client class I d like instantiate every client different value gpu_fraction then , Client execute training function , I d like use entire GPU pc percentage specify gpu_fraction .    I try code      before execute training function every client , seem work . test approach work use follow code :  ","GPU percentage allocation for a Python class  Im developing a sort of federated learning environment and it contains a Server class and 10 instances of the Client classes. I train the various clients one after the other and Id like to specify an upper limit regarding the GPU usage for each client.
For example: 
 
 this is my Client class and Id like to instantiate every client with a different value of gpu_fraction and then, when a Client executes the training function, Id like not to use the entire GPU of my PC but just the percentage specified by the gpu_fraction. 
 I tried with this code 
 
 before executing the training function for every client, but it doesnt seem to work.
To test if this approach works I used the following code: 
 
",45412.81821
155,78557504,Federated dataloader deprecate ?,"Federated dataloader deprecate ?   in federated Learning code below , I m use Pysyft . goal distribute fashionmnist dataset different client      and error be      I try many solution nothing work . please help !","Federated dataloader deprecated?  In the federated Learning code below, Im using Pysyft. the goal is to distribute the FashionMNIST dataset to  different clients 
 
 and the error is 
 
 I tried many solutions but nothing worked. please help ! 
",45442.94747
156,78567104,integrate Federated Learning use Flower framworke react js /flask web app,"integrate Federated Learning use Flower framworke react js /flask web app   I want create web application use React.js , Flask , Flower framework tensorflow image classification . stuck would appreciate tip resource . anyone help I ?    I ask GPT Gemini , answer work I .","How to integrate Federated Learning using Flower framworke in react js /flask web app  I want to create a web application using React.js, Flask, and the Flower framework with Tensorflow  for image classification. I am stuck and would appreciate any tips or resources. Can anyone help me? 
 I asked GPT and Gemini, but all the answers didnt work for me. 
",45445.70159
157,78742773,socket Mismatch Problem Federated Learning Project,"socket Mismatch Problem Federated Learning Project   I m try run FL project   , thing be , run client side run.sh . report warning / error :      I check code find    utilize    support connection . since requirement contain version package . instal   . so , version package follow :      I also ask ChatGPT , suggest use    instead . change it , new problem :      do anyone idea solve problem ? so , I d appreciative .    any idea solve problem would appreciate , limited answer .","Socket Mismatch Problem in Federated Learning Project  Im trying to running the FL project on  , the thing is, when I run the client side with run.sh. It reported the warning/error: 
 
 I checked the code and found that   utilizes the   to support connection. Since the requirements doesnt contain versions of these packages. I installed them with the  . So, the versions of these packages are as follows: 
 
 I also asked ChatGPT, it suggests to use   instead. But when I changed into it, there was a new problem: 
 
 Does anyone has idea how to solve this problem? If so, Id be very appreciative. 
 Any idea of how to solve this problem would be appreciated, not limited to the answer. 
",45486.14396
158,78835380,custom model aggregator TensorFlow Federated,"custom model aggregator TensorFlow Federated   I experiment TensorFlow Federated , simulate training process FedAvg algorithm .      I want use custom weight aggregate client update instead use number sample . know    parameter call    value accept class   , enum .    so , way seem write custom WeightedAggregator . I ve try follow   explain write unweighted aggregator , can not make work transforming weight one .    this I ve try do :      but get follow error :    aggregationplacementerror : "" result "" attribute return type    must place SERVER , find { < float32[7],float32,float32[1],float32>}@client .","Custom model aggregator TensorFlow Federated  I am experimenting with TensorFlow Federated, simulating a training process with the FedAvg algorithm. 
 
 I want to use custom weights to aggregate the clients updates instead of using their number of samples. I know that   has a parameter called   but the only value accepted is from the class  , which is an enum. 
 So, the only way to do that seems to be to write a custom WeightedAggregator. Ive tried following  that explains how to write an unweighted aggregator, but I cannot make it work transforming it into a weighted one. 
 This is what Ive tried to do: 
 
 But I get the following error: 
 AggregationPlacementError : The ""result"" attribute of return type of   must be placed at SERVER, but found {<float32[7],float32,float32[1],float32>}@CLIENTS. 
",45509.67139
159,78848605,valueerror : name model use 2 time model . layer name unique,"valueerror : name model use 2 time model . layer name unique   I m try take two retrain client federate learn pipeline average weight . work first training , second time I m get error try fix , can not figure issue be .    here error originate line   .    ","ValueError: The name model is used 2 times in the model. All layer names should be unique  Im trying to take two retrained clients in a federated learning pipeline and average their weights. It worked for the first training, but now the second time Im getting this error can I have tried to fix, but I cant figure out what the issue is. 
 Here is the error which originates from the line  . 
 
 
",45512.54763
160,78852053,problem increase number client federate learn,"problem increase number client federate learn   I run different dataset different number client federate learn code . however , work dataset , set value NUM_CLIENTS maximum 20 . client value exceed 20 , encounter error below . make mistake ?        I want increase number client 50","The problem of increasing the number of clients in federated learning  I am running different datasets with different numbers of clients on federated learning code. However, when working with some datasets, I can set the value of NUM_CLIENTS to a maximum of 20. When the client value exceeds 20, I encounter the error below. Where am I making a mistake? 
 
 
 I want to increase the number of clients to 50 
",45513.39666
161,78854316,unexpected mse Behavior Online Federated Learning Simulation use Random Fourier Features ( RFF ) Based Kernel LMS,"unexpected mse Behavior Online Federated Learning Simulation use Random Fourier Features ( RFF ) Based Kernel LMS   I try simulate Online Federated Learning framework present paper "" Communication - Efficient Online Federated Learning Framework Nonlinear Regression "" Gogineni et al . , 2022 . simulation involve use Random Fourier Features ( RFF ) kernel least - mean - square ( KLMS ) algorithm perform nonlinear regression task across multiple client federate setting .    Summary Implementation :      Number client : 100    Global Iterations : 1000    RFF Dimension : 200    Learning Rate : 0.75    number Participating Clients per Iteration : 20    Number Independent Monte Carlo Trials : 500      in global iteration , subset client select , client update local model use streaming datum . client share model updates global server , aggregate update form new global model .    Problem :   Mean Squared Error ( MSE ) compute simulation converge decreasing expect . instead , mse fluctuate significantly exhibit steady decline characteristic learning process . verify implementation methodology describe paper , result align present paper simulation .    Key Aspects Simulation :      the input signal client generate use first - order autoregressive ( AR ) model , parameter sample uniform distribution describe paper .    the client apply kernel LMS algorithm use random Fourier feature perform local nonlinear regression .    the global model update iteratively average weight select client global iteration .      Code Snippet :      what try :      implement Simulation :   follow methodology describe paper Gogineni et al . , implement federate learning framework random Fourier feature ( RFF ) kernel least - mean - square ( KLMS ) regression . involve generate synthetic datum multiple client , perform local model update , aggregate update global server .      verify Data Generation :   ensure input signal client generate use first - order autoregressive ( AR ) model parameter noise characteristic specify paper . also check implementation RFF transformation map input datum feature space .      Adjusted Learning Rate :   experiment different learning rate see would stabilize MSE . paper suggest learn rate 0.75 , try small large value see would effect .      check Model Updates :   verify global model update correctly compute average local model weight select client iteration .      Multiple Trials :   simulation run multiple independent Monte Carlo trial average randomness , suggest paper .        what expect :      MSE Convergence :   base paper result , expect mse show consistent decrease iteration , reflect improvement global model datum update accumulate .      Smoother MSE Curve :   fluctuation expect due random nature client selection datum , anticipate overall MSE curve would smooth converge low value model learn iteration .      result Consistent Paper :   expect simulation result align closely figure present paper , particularly regard convergence rate final steady - state mse value .    ","Unexpected MSE Behavior in Online Federated Learning Simulation Using Random Fourier Features (RFF) Based Kernel LMS  I am trying to simulate the Online Federated Learning framework presented in the paper ""Communication-Efficient Online Federated Learning Framework for Nonlinear Regression"" by Gogineni et al., 2022. The simulation involves using Random Fourier Features (RFF) with a kernel least-mean-square (KLMS) algorithm to perform a nonlinear regression task across multiple clients in a federated setting. 
 Summary of the Implementation: 
 
 Number of Clients: 100 
 Global Iterations: 1000 
 RFF Dimension: 200 
 Learning Rate: 0.75 
 Number of Participating Clients per Iteration: 20 
 Number of Independent Monte Carlo Trials: 500 
 
 In each global iteration, a subset of clients is selected, and each client updates its local model using streaming data. The clients then share their model updates with the global server, which aggregates these updates to form a new global model. 
 Problem: 
The Mean Squared Error (MSE) computed during the simulation is not converging or decreasing as expected. Instead, the MSE fluctuates significantly or does not exhibit the steady decline that should be characteristic of a learning process. I have verified the implementation against the methodology described in the paper, but the results do not align with those presented in the papers simulations. 
 Key Aspects of the Simulation: 
 
 The input signal at each client is generated using a first-order autoregressive (AR) model, with parameters sampled from uniform distributions as described in the paper. 
 The clients apply a kernel LMS algorithm using random Fourier features to perform the local nonlinear regression. 
 The global model is updated iteratively by averaging the weights of the selected clients in each global iteration. 
 
 Code Snippet: 
 
 What I Tried: 
 
 Implemented the Simulation:  I followed the methodology described in the paper by Gogineni et al., implementing the federated learning framework with random Fourier features (RFF) for kernel least-mean-square (KLMS) regression. This involved generating synthetic data for multiple clients, performing local model updates, and aggregating these updates on a global server. 
 
 Verified Data Generation:  I ensured that the input signal for each client was generated using a first-order autoregressive (AR) model with the parameters and noise characteristics specified in the paper. I also checked the implementation of the RFF transformation to map input data into the feature space. 
 
 Adjusted Learning Rate:  I experimented with different learning rates to see if it would stabilize the MSE. While the paper suggests a learning rate of 0.75, I tried smaller and larger values to see if this would have an effect. 
 
 Checked Model Updates:  I verified that the global model updates were correctly computed by averaging the local model weights from the selected clients in each iteration. 
 
 Multiple Trials:  The simulation was run over multiple independent Monte Carlo trials to average out randomness, as suggested by the paper. 
 
 
 What I Expected: 
 
 MSE Convergence:  Based on the papers results, I expected the MSE to show a consistent decrease over the iterations, reflecting the improvement of the global model as more data and updates are accumulated. 
 
 Smoother MSE Curve:  While some fluctuations are expected due to the random nature of client selection and data, I anticipated that the overall MSE curve would smooth out and converge to a lower value as the model learns over iterations. 
 
 Results Consistent with the Paper:  I expected my simulation results to align closely with the figures presented in the paper, particularly regarding the convergence rate and the final steady-state MSE values. 
 
 
",45513.80115
162,78860719,valueerror : unable create dataset ( name already exist ) federate learn,"valueerror : unable create dataset ( name already exist ) federate learn     here function problem :      I ve work federate learn pipeline I m encounter error retrain model . I ve try rename file , change path , rename layer , bunch thing error go away . please help !","ValueError: Unable to create dataset (name already exists) for federated learning  
 Here is the function that is the problem: 
 
 Ive been working on a federated learning pipeline and Im encountering this error when retraining my model. Ive tried renaming the file, changing the path, renaming the layers, and a bunch of other things but this error wont go away. Please help! 
",45516.36362
163,78886217,face problem run Federated Learning code,"face problem run Federated Learning code   I try run code follow link   use follow step :    1- Clone Repository :      2- Navigate Repository Directory :      3- install dependency :      4- Run Code :      but face problem :      any assistance , please ? would like get two figure result like training loss .","Facing a problem with running a Federated Learning code  I am trying to run the code in the following link  using the following steps: 
 1- Clone the Repository: 
 
 2- Navigate to the Repository Directory: 
 
 3- Install Dependencies: 
 
 4- Run the Code: 
 
 but I am facing a problem: 
 
 Any assistance, please? I would like to get two figures results like training loss. 
",45523.15632
164,78913655,Federated Learning ColabPro,"Federated Learning ColabPro   I try build Federating Learning ColabPro use Flower pytorch - lightning , need specify IP & Port number server client communicate it , also run server client seperately multiple terminal , problem know IP & Port number use , open multiple terminal time ColabPro .    I try model locally work .","Federated Learning in ColabPro  I am trying to build a Federating Learning on ColabPro using Flower and pytorch-lightning, but I need to specify an IP & Port number for the server so the clients can communicate with it, also I have to run the server and each client seperately through the multiple terminals, my problem now is I dont know which IP & Port numbers can I use, and how to open multiple terminals at same times on ColabPro. 
 I tried same model locally and it works. 
",45530.38601
165,78975525,slow Data Loading Low GPU Utilization PyTorch Federated Learning Frequent Client Switching,"slow Data Loading Low GPU Utilization PyTorch Federated Learning Frequent Client Switching   I m work federate learning project use PyTorch , focus medical imaging ( MRI ) datum . despite use SSD , dataset loading phase unusually slow , GPU utilization remain low across global epoch . client handle significant volume datum , frequent client switching seem exacerbate issue . I m look way optimize datum loading enhance gpu utilization .    Data Details :    each .npy file correspond pre - processed three - dimensional mri , approximately 20 mb size .    each client manage 500 1000 file , contribute total dataset size around 100 GB distribute across client .    here breakdown current setup :    I custom dataset class ,   , read    file . client federate learn framework initialize dataset load use    training . server side , training involve iterate select client train one one .    Server - Side Code Client Training :      Client - Side Data Loading Training Code :      Code TrainCNN_Data class :      to analyze performance bottleneck , set   2 client , allocate   100 .npy file . use    tool observe time take   one iteration   training   one 2 node .    I notice   78 %   time spend loading dataset .      question :      be common pitfall inefficiency way I m handle datum loading across multiple client could cause issue ?    how optimize datum loading process federate learn context improve training speed gpu usage ?      any insight suggestion tackle challenge would greatly appreciate !","Slow Data Loading and Low GPU Utilization in PyTorch Federated Learning with Frequent Client Switching  Im working on a federated learning project using PyTorch, focusing on medical imaging (MRI) data. Despite using an SSD, the dataset loading phase is unusually slow, and the GPU utilization remains very low across global epochs. Each client handles a significant volume of data, and the frequent client switching seems to exacerbate the issue. Im looking for ways to optimize data loading and enhance GPU utilization. 
 Data Details: 
 Each .npy file corresponds to a pre-processed three-dimensional MRI, approximately 20MB in size. 
 Each client manages between 500 and 1000 such files, contributing to a total dataset size of around 100GB distributed across clients. 
 Heres a breakdown of my current setup: 
 I have a custom dataset class,  , which reads   files. Each client in the federated learning framework initializes this dataset and loads it using a   during training. On the server side, training involves iterating through selected clients and training them one by one. 
 Server-Side Code for Client Training: 
 
 Client-Side Data Loading and Training Code: 
 
 Code for the TrainCNN_Data class: 
 
 To analyze performance bottlenecks,
I set up  2 clients , each allocated  100 .npy files .
I used the   tool to observe the time taken for  one iteration  of training on  one of the  2 nodes . 
 I noticed that  78%  of the time was spent loading the dataset. 
 
 Questions: 
 
 Are there any common pitfalls or inefficiencies in the way Im handling data loading across multiple clients that could be causing these issues? 
 How can I optimize the data loading process in this federated learning context to improve both training speed and GPU usage? 
 
 Any insights or suggestions on how to tackle these challenges would be greatly appreciated! 
",45546.83197
166,79070306,Kubernetes deployment Flower server Python fail Port server address already use,"Kubernetes deployment Flower server Python fail Port server address already use   I trying deploy Federated Learning server use Flower ( flwr ) Kubernetes cluster custom Docker image ( fl - server : late ) . server need run specific port host . goal ensure server find available port start avoid conflict service .    I implement Python class create deployment correspond service use Kubernetes API . code create deployment service :      below python script generate fl - server image :      I expect server start first available port . specify port use , script find next available port use start server .    even though script design check port availability , keep get follow error log deploy kubernete :      to try solve problem , verify port check logic work correctly run script locally . ensure Kubernetes deployment use late version Docker image ( fl - server : late ) . check service selector match labels pod . verified service use port use ss netstat within container .    here Dockerfile use build image :  ","Kubernetes deployment for Flower server in Python fails with Port in server address is already in use  I am trying to deploy a Federated Learning server using Flower (flwr) on a Kubernetes cluster with a custom Docker image (fl-server:latest). The server needs to run on a specific port and host. My goal is to ensure that the server finds an available port before starting to avoid conflicts with other services. 
 I have implemented a Python class to create both the deployment and the corresponding service using the Kubernetes API. Below is the code for creating the deployment and service: 
 
 below is the python script that generates the fl-server image: 
 
 I expected the server to start on the first available port. If the specified port is in use, the script should find the next available port and use it to start the server. 
 Even though the script is designed to check for port availability, I keep getting the following error in the logs when deploying in Kubernetes: 
 
 To try to solve the problem, I verified that the port checking logic works correctly by running the script locally.
I ensured that the Kubernetes deployment uses the latest version of the Docker image (fl-server:latest).
I checked that the service selector matches the labels of the pod.
I verified that no other services are using the port using ss and netstat within the container. 
 Here is my Dockerfile used to build the image: 
 
",45574.53611
167,69101385,"valueerror : Input 0 incompatible layer resnet50 : expect shape=(none , 180 , 180 , 3 ) , find shape=(180 , 180 , 3 )","valueerror : Input 0 incompatible layer resnet50 : expect shape=(none , 180 , 180 , 3 ) , find shape=(180 , 180 , 3 )   with TFF 0.18 , find problem :      here output input_spec      and model :  ","ValueError: Input 0 is incompatible with layer resnet50: expected shape=(None, 180, 180, 3), found shape=(180, 180, 3)  With TFF 0.18, I found this problem : 
 
 here is the output of input_spec 
 
 And here is my model: 
 
",44447.43611
168,69204874,centralize vs. federate convergence,"centralize vs. federate convergence   so I ve get datum 700 - some smart meter . datum meter include electricity usage take interval 15 min , outside temperature , humidity , national holiday ...   goal predict combine electricity usage user grid .   combine datum sum electricity train model ( normalization , batch , 3 lstm layer 512 node , dropout , relu activation , adam optimizer , absolute loss , default lr ) get good result happy with .   federate , user training private datum , use model ( server lr = 1.0 , less confusing think ) get really bad result .    unsystematically mess around batch size , switch adam SGD , change learn rate , up epoch , change number user calculate gradient round . nothing seem work .   should epoch order magnitude ? theoretical assurance exist set parameter model converge sum datum converge federate ?   soft question , may post code result need .","centralized vs. federated convergence  So Ive got some data from 700-some smart meters. Data from each meter includes electricity usage taken in intervals of 15 mins, outside temperature, humidity, if its a national holiday... 
The goal is to predict combined electricity usage of the users on the grid. 
When I combine the data by summing all the electricity and train my model (normalization, some batching, 3 lstm layers with 512 nodes, some dropout, relu activation, adam optimizer, absolute loss, default lr) I get good results which I am happy with. 
But when I do it in federated, with each user training on his private data, using the same model I did (server lr = 1.0, because its less confusing i think) i get really bad results.  
Unsystematically I messed around with batch size, switching adam for SGD, changing learning rates, upping the epochs, changing the number of users calculating gradients in each round. Nothing seemed to work.
 Should i just up the epochs in some order of magnitude? Do i have any theoretical assurance that there exists a set of parameters under which the same model that converged on the sum of data should should converge in federated? 
Its more of a soft question, but i may post the code or the results if needed. 
",44455.35069
169,69281046,change clip noise parameter differentially private training Tensorflow Federated,"change clip noise parameter differentially private training Tensorflow Federated   I m use Tensorflow Federated ( TFF ) train differential privacy . currently create Tensorflow Privacy NormalizedQuery pass tff differentiallyprivatefactory create AggregationProcess :      after broadcast server state client run client update function use AggregationProcess like this :      this work great , however want experiment change l2_norm_clip stddev several time training ( make clip big small various training round ) seem set parameter create AggregationProcess .    be possible change parameter train somehow ?","How to change clipping and noise parameters during differentially private training with Tensorflow Federated  Im using Tensorflow Federated (TFF) to train with differential privacy. Currently I am creating a Tensorflow Privacy NormalizedQuery and then passing it into a TFF DifferentiallyPrivateFactory to create an AggregationProcess: 
 
 After broadcasting the server state to clients I run a client update function and then use the AggregationProcess like this: 
 
 This works great, however I want to experiment with changing the l2_norm_clip and stddev several times during training (making clipping bigger and smaller at various training rounds) but it seems I can only set these parameters when I create the AggregationProcess. 
 Is is possible to change these parameters during training somehow? 
",44461.37014
170,69325272,TFF RuntimeError : attempt capture EagerTensor without build function,"TFF RuntimeError : attempt capture EagerTensor without build function   I TFF model run get error . provide x move forward implement like tutorial .    TF version = 2.5.1 tff version = 0.19.0    my snippet code be      I read another post error function scope model_fn could see problem .    the full script error like this ,      can anyone help fix this ? anything solve succeed .","TFF RuntimeError: Attempting to capture an EagerTensor without building a function  I have a TFF model to run But I got an error.
I provided the x and y and moved forward to implement it like the tutorial. 
 TF version = 2.5.1
TFF version = 0.19.0 
 My snippet code is 
 
 I read another post about this error but my all function are in the scope of model_fn and I could not see any other problems. 
 The full script error is like this, 
 
 Can anyone help me fix this? I did anything to solve it but have not succeeded. 
",44464.43681
171,69335892,"KeyError : 0 , tff strange error multi - outputs model","KeyError : 0 , tff strange error multi - outputs model   I multi output FedAvg model implement like Tutorial bit extend reach multi outputs version .    my model function like below ,      the Keras model last line like snippet code .      and TFF dataset build like below .      when use learn api like one below      I get error KeyError : 0 make confused , name output    collection . OrderedDict      and pass loss function class model_fn instead two list , get error below ,      can anyone help fix this ?","KeyError: 0, TFF strange error in multi-outputs model  I have a multi outputs FedAvg model that I implemented just like the  Tutorial and a bit extends to reach the multi outputs version. 
 My model function is like below, 
 
 the Keras models last lines are like the below snippet code. 
 
 and my TFF dataset is built like the below. 
 
 when I use the learning API like the one below 
 
 I got an error of KeyError: 0 that makes me confused, I do name the outputs same as the   collection.OrderedDict 
 
 and when I pass a loss function class in model_fn instead of two in a list, I got the error below, 
 
 can anyone help me fix this? 
",44465.60417
172,69385064,good way create custom federate image dataset TFF sqlite format ?,"good way create custom federate image dataset tff sqlite format ?   I go source cifar-100 inbuilt dataset decide create compatible version FairFace dataset order able leverage build - in function without many modification everywhere convert FairFace structure similar cifar-100 .    I search around unable find cifar-100 sqlite database create - specifically image convert BLOB storage . bit trial error , try way :      execute sample train datum similarly test datum . able load use decode method :      what notice , however , final sqlite.lzma compress archive 6.4 GB size whereas source archive dataset 555 MB . guess due way store image , compression work well could stored compatible manner . see cifar-100 code image load directly fixedlenfeature shape ( 32,32,3 ) mean store unable find way store image such . method work bytes_feature route .    what would well / recommend way go this ?","What is the best way to create a custom federated image dataset for TFF in SQLite format?  I went through the source for the CIFAR-100 inbuilt dataset and decided to create a compatible version for the FairFace dataset in order to be able to leverage the other built-in functions without many modifications everywhere once I convert FairFace into a structure very similar to CIFAR-100. 
 I did search around but was unable to find how the CIFAR-100 SQLite database was created - specifically how the images were converted into BLOB for storage. After a bit of trial and error, I tried doing it this way: 
 
 Executing this for each sample in the train data and similarly for test data. I am able to load it using this decoding method: 
 
 What I noticed, however, is that the final sqlite.lzma compressed archive is 6.4 GB in size whereas the source archive for the dataset was 555 MB. I am guessing that due to the way I am storing the images, compression is not working as well as it could if they were stored in a more compatible manner. I see from the CIFAR-100 code that the images are loaded directly as FixedLenFeatures of shape (32,32,3) which means that they were stored as such but I have been unable to find a way to store my images as such. The only method that worked for me was the bytes_feature route. 
 What would be the best/recommended way to go about this? 
",44469.06597
173,69464111,create federate model lstm stock prediction python,"create federate model lstm stock prediction python   -i column name [ "" date"",""open"",""high"",""close"",""volume"",""group "" ]    -i create additional column name "" Group "" represent ClientID      -i also split data train_data test_data :      -from create lstm model federate learn forecast prediction "" close "" value ?","how to create a federated model lstm for stock prediction in python  -i have column names [""Date"",""Open"",""High"",""Close"",""Volume"",""Group""] 
 -i created a additional column name ""Group"" to represent ClientID 
 
 -i also split the data into train_data and test_data: 
 
 -from here how can i create a lstm model to do federated learning and forecast the prediction for ""Close"" value? 
",44475.44028
174,59430106,implement federate algorithm Usinsg tensorflow federate,"implement federate algorithm Usinsg tensorflow federate   I read document tensorflow federate available tensorflow.org , sure implement federate algorithm . example , compile keras model , know convert tff.computation . seem order build federate algorithm one build iterative_process . anyone help regard ?     thank much ,","How to implement my own federated algorithm Usinsg tensorflow federated  I have read all the documents on the tensorflow federated available at tensorflow.org, but I am not sure how to implement my own federated algorithm. For example, I have a compiled keras model, I know how to convert this to tff.computation. It seems that in order to build a federated algorithm one should build an iterative_process. Can anyone help me in this regard?  
 Thank you so much,  
",43819.78681
175,59448706,get client model ( base Keras ) tensorflow federate ?,"get client model ( base Keras ) tensorflow federate ?   I look way get client model checkpoint investigate standard keras model . look   provide weight , way get save model client directly federate training ?","How to get client models (based on Keras) in tensorflow federated?  I am looking for a way to get client models as checkpoints that I can investigate as standard keras model. I looked into  but it only provides the weights, is there a way to get or save models from clients directly during federated training?  
",43821.9625
176,59622300,resnet model Tensorflow Federated,"resnet model Tensorflow Federated   I try customize model Image classification tutorial Tensorflow Federated . ( it originally use sequential model ) use Keras ResNet50 begin train , always error incompatible shape    here code :      error information :     I feel shape incompatible epoch client information somehow miss . would thankful someone could give hint .    update :    the Assertion error happen   ","ResNet model in Tensorflow Federated  I tried to customize the model in Image classification tutorial in Tensorflow Federated. (It originally used a sequential model)
I use Keras ResNet50 but when it began to train, there is always an error Incompatible shapes 
 Here are my codes: 
 
 Error information:
 
 I feel that the shape is incompatible because the epoch and clients information were somehow missing. Would be very thankful if someone could give me a hint. 
 Updates: 
 The Assertion error happened during  
 
",43837.19931
177,59741397,Federated learning : convert image dataset tff simulation Clientdata,"Federated learning : convert image dataset tff simulation Clientdata   here code federate learn test      now want create sample_batch like tutorial tensorflow federtaed image classification    I write line find error      the error      TypeError Traceback ( most recent call last ) 1 training_set1.element_type_structure ---- > 2 example_dataset = training_set1.create_tf_dataset_for_client(training_set1.client_ids[0 ] )    TypeError : abstractproperty object support indexing      can tell must create dummy_batch order convert keras model tff.learning.from_compiled_keras_model(model , dummy_batch )","Federated learning : convert my own image dataset into tff simulation Clientdata  here is the code of my federated learning test 
 
 Now when I want to create sample_batch like the tutorial in the tensorflow federtaed for image classification 
 I write this line and it find this error 
 
 the error 
 
 TypeError                                 Traceback (most recent call last)
 in 
      1 training_set1.element_type_structure
----> 2 example_dataset = training_set1.create_tf_dataset_for_client(training_set1.client_ids[0]) 
 TypeError: abstractproperty object does not support indexing 
 
 Can you tell me how I must do to create dummy_batch in order to convert keras model into tff.learning.from_compiled_keras_model(model, dummy_batch) 
",43844.85625
178,59835749,implement data generator federate training,"implement data generator federate training   ( I post question   maybe also here ! )    I customize datum model federate interface training converge . confused issue image classification task , whole dataset extreme large can not store single    import memory one time . need load dataset hard disk batch memory real - timely use    instead    training , approach people use deal large datum .    I suppose    show image classification tutorial , model fit fix set datum . way adjust code let fit datum generator?I look source code still quite confused . would incredibly grateful hint .","Implement data generator in federated training  (I have posted the question on  and maybe also here!) 
 I have customized my own data and model to federated interfaces and the training converged. But I am confused about an issue that in an images classification task, the whole dataset is extreme large and it cant be stored in a single   nor be imported to memory for one time. So I need to load the dataset from the hard disk in batches to memory real-timely and use   instead of   during training, the approach people use to deal with large data. 
 I suppose in   shown in image classification tutorial, the model is fitted on a fixed set of data. Is there any way to adjust the code to let it fit to a data generator?I have looked into the source codes but still quite confused. Would be incredibly grateful for any hints. 
",43851.29444
179,69499432,Federated Averaging TensorFlow,"Federated Averaging TensorFlow   I newbie federate learn getting know TensorFlow Federated TFF framework . question mind would really appreciate anybody clarify they :      do Federated Averaging algorithm aggregation algorithm support TFF ? differ Federated Stochastic Gradient Descent ?    Dose Federated Averaging require client train Neural Networks ? possible local datum train machine learning algorithm ?    I big datum , plan partition datum small dataset simulate part one client ? work TFF ? consider horizontal vertical federated learning ?      thank advance","Federated Averaging and TensorFlow  I am a newbie in federated learning and just getting to know TensorFlow Federated TFF framework. I have some questions in my mind I would be really appreciated it if anybody can clarify them: 
 
 Does Federated Averaging algorithm the only aggregation algorithm supported in TFF? and how it differs from Federated Stochastic Gradient Descent? 
 Dose Federated Averaging require each client to be trained with the Neural Networks? or it is possible for local data to be trained with any machine learning algorithm? 
 I have big data, and I am planning to partition my data into smaller datasets and simulated each part as one client? does this work in TFF? and does it consider horizontal or vertical federated learning? 
 
 Thanks in advance 
",44477.71042
180,69525476,"Federated Averaging ( fedavg ) resnet 18 batch_normalization make prediction first round , round","Federated Averaging ( fedavg ) resnet 18 batch_normalization make prediction first round , round   I try implement   . also . like trainable one , aggregate non - trainable parameter batch - normalization server average they . use 5 client dataset divide 5 randomly , 50k/5=10k training sample client , gross skewed distribution . test client , training , full test dataset,10k sample , also use test server . problem first training round despite client 20 - 25 % accuracy , server 10 % accuracy basically make nearly prediction input . case first round since round server almost always well accuracy client round . example      to solve issue first round try repeat dataset do not help . try use cifar10 training sample client mean instead create 5 different dataset 10k sample client use 50k sample dataset .      client obviously initialization guess due gpu use minor accuracy difference yet 45+% accuracy . see even do not help first round . use simple cnn , one available "" .main "" , suitable parameter problem do not exist . use      instead of      reduce problem first round overall bad performance try reproduce paper use latter parameter .    I also try pytorch get similar result .   result available github .    I confuse that . especially use entire training dataset client 45 % accuracy . also get good result follow round ? change first round other ? every time client initialization other , loss function , optimizer parameter . thing change actual initialization round .    so special initialization solve first round problem miss something ?    Edit :    when entire cifar10 training set use client dataset.repeat use repeat datum .      what catch attention client accuracy actually similar second round ( round 1 ) accuracy client dataset be not repeated(previous result ) . eventhough server 10 % accuracy do not affect much result next round .    this work simple cnn ( define main.py github )      as see simple cnn use server accuracy well good client accuracy , definitely well average , begin first round . try understand resnet fail make prediction regardless input . first round prediction look like      they return 3rd label .","Federated Averaging (fedavg) with resnet 18 that has batch_normalization makes the same prediction after first round, but in no other rounds  I was trying to implement  with . Also this is the . Just like trainable ones, I have aggregated non-trainable parameters of batch-normalization to server and averaged them. I have used 5 clients and dataset was divided to 5 randomly, 50k/5=10k training samples for each client, so there is no gross skewed distribution. I have tested each client, after training, with the full test dataset,10k samples, that I also use to test server. The problem is after first training round despite each client had 20-25% accuracy, the server has 10% accuracy and basically makes nearly the same predictions for each input. This is the only the case  for first round since after that round server has almost always better accuracy than any client had in that round. For example 
 
 To solve the issue with first round I tried to repeat the dataset but it didnt help. After that I tried to use all the cifar10 training samples for each client meaning instead of creating 5 different datasets of 10k samples for each client I used all 50k samples as the dataset. 
 
 Clients obviously had the same initialization but i guess due to gpu use there were some minor accuracy differences yet each had 45+% accuracy. But as you can see even this didnt help with the first round. When using a simple cnn, such as the one available in the "".main"", with suitable parameters this problem doesnt exist. And using 
 
 instead of 
 
 reduces this for problem the first round but it has overall worse performance and i am trying to reproduce a paper that used the latter parameters. 
 I have also tried the same with pytorch and got the very similar results.  The results for both are available in github. 
 I am very confused with that. Especially when I used entire training dataset and when each client had 45% accuracy. Also why get good results for following rounds? What changed between first round and the others? Every time clients had the same initialization with each other, same loss function, and same optimizer with the same parameters. The only thing that changed is the actual initialization between rounds. 
 So is there a special initialization that solves this first round problem or am I missing something? 
 Edit: 
 When the entire cifar10 training set is used for each client and dataset.repeat is used to repeat data. 
 
 What catches my attention here is the client accuracy here is actually very similar to second round (round 1) accuracy of clients when dataset wasnt repeated(previous results). so eventhough server had 10% accuracy it didnt affect much the results of the next round. 
 This is how it works with a simple cnn (defined in the main.py in github) 
 
 As we can see when a simple cnn is used server accuracy is better than the best client accuracy, and definitely better than the average, beginning from the very first round. I am trying to understand why the resnet fails to do that and makes the same predictions regardless of input. After the first round the predictions look like 
 
 They all return 3rd label. 
",44480.47778
181,69538510,tff support deployment across different device cloud ?,"tff support deployment across different device cloud ?   I would like deploy TFF way , one central ( aggregation ) server VM cloud two different vms node , train model . possible TFF ? protocol necessary communicate internet etc . tensorflow FL algorithm use different framework provide architecture ?    thank you","Does TFF support deployment across different devices and clouds?  I would like to deploy TFF in a way, where I have one central (aggregation) server on a VM in a cloud and two different VMs with nodes, that train the model. Is this possible with TFF? Does it have the protocols necessary to communicate over the internet etc. or is it more of a Tensorflow with FL algorithms that can be used with different frameworks that provide the architecture? 
 Thank you 
",44481.41458
182,69542184,runtimeerror : default context instal . use Tensorflow Federated,"runtimeerror : default context instal . use Tensorflow Federated   currently work federate - learn project use TensorFlow Federated . make request server check code working get error :      however , encounter specific condition .    Scenario go like ( all code bellow ):    a http request make website . function   upload_and_train    route / developers.py   handle request . inside this ,   start_processe   function call start training preprocess ( gather train datum , initialize hyperparameter etc ) . finally   federated_computation_new   function call ( which also crash ) start federate learning . crash reach call :   iterative_process.initialize ( ) .      the confusing part follow . run code locally , everything go well , training process work ; error . run server also work first request make . afterwards crash return error ( state detail bellow ) follow request restart server . work perfectly first call , proceed crash subsequent call .    this issue drive nut , can not figure out . remain idea something happen first call ( a process close something like that ) subsequent call get "" fresh "" start ? although happen first place .    full error message bellow :      First Function handle incoming request . request contain 4 parameter : 2 identifier "" use_case "" "" developer_""id "" 2 formdata file contain training datum , store locally .      the function start preprocesse :      the function federate training do :        the function : /home / itec / bogdan / Articonf / smart / tool / federate - training / app / venv / lib / python3.8 / site - package / tensorflow_federate / python / core / impl / util / function_utils.py "" , line 521 ,      thank much advance time patience .","RuntimeError: No default context installed.  when using Tensorflow Federated  Currently I am working on a federated-learning project using TensorFlow Federated.
I was making a request from a server to check if my code was working when I got this error: 
 
 However, I only encounter it under some specific conditions. 
 Scenario goes like this (all the code is bellow): 
 A http request is made from the website. The function  upload_and_train  in  routes/developers.py  handles the request. Inside this, the  start_processing  function is called which starts the training preprocess (gathering train data, initializing hyperparameters etc). Finally the  federated_computation_new  function is called (which is where it also crashes) which starts the federated learning.
It crashes when it reaches the call:  iterative_process.initialize() . 
 
 The confusing part is the following. If I run the code locally, everything goes well, the training process is working; no errors. If I run it on the server It also works for the first request made. Afterwards it crashes and returns the same error (stated in more details bellow) on all the following requests until I restart the server. Then it again works perfectly for the first call, and proceeds to crash on subsequent calls. 
 This issue is driving me nuts, I cant figure it out. My only remaining idea is that something is happening after the first call (a process is not closed or something like that) and on subsequent calls it doesnt get a ""fresh"" start? Although it shouldnt happen in the first place. 
 Full error message bellow: 
 
 First Function which handles the incoming requests.
The request contains 4 parameters: 2 identifiers the ""use_case"" and the ""developer_""id"" and 2 formData files which contain the training data, which is stored locally. 
 
 The function which starts the preprocessing: 
 
 The function where the federated training is being done: 
 
 
 The function: /home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py"", line 521, 
 
 Thank you very much in advance for your time and patience. 
",44481.59514
183,69591102,TensorFlow Federated ready production ?,"TensorFlow Federated ready production ?   currently try use federate analytic ( and eventually federate learning ) work . explore PyTorch Federated TensorFlow Federated . watch TensorFlow Federated Tutorials Google TechTalk , tutorial connect simulated data set available locally confirm TensorFlow Federated ready simulation production . know TensorFlow Federated ready production ?","When will TensorFlow Federated be ready for production?  Currently trying to use federated analytics (and eventually federated learning) at work. We are exploring PyTorch Federated and TensorFlow Federated. When I watched the TensorFlow Federated Tutorials on Google TechTalk, all tutorials were being connected to simulated data sets available locally and they confirmed that TensorFlow Federated is only ready for simulations and not for production. Do we know when TensorFlow Federated will be ready for production? 
",44484.92222
184,69596586,change update client send server Tensorflow Federated,"change update client send server Tensorflow Federated   I m try understand Tensorflow Federated work , use simple_fedavg example .    I still understand change client send server , example .    I want send weight update , want send list form like this :      where    return 5 value :   , would like access information server side run    create weight use   .    so , basically , would like change    send list create instead weight then , server create custom list weight use information client send . creation new custom list weight would like server update model .    I actually try change     , know access    variable server procedure / function would need it .    I hope make clear enough since main language english .","How to change the update that the client send to the server Tensorflow Federated  Im trying to understand how Tensorflow Federated Works, using the simple_fedavg as example. 
 I still dont understand how to change what the client send to the server, for example. 
 I dont want to send all the weights of the update, i want to send a list formed like this: 
 
 Where   return 5 values:  , then i would like to access those information on the server side before running the    for creating the weights that i will use for the  . 
 So, basically, i would like to change   to send a list that i have created instead of all the weights and then, on the server create a custom list of weights using the information that the client sent. Only after the creation of the new custom list of weight i would like the server to update the model. 
 I actually tried to change the   of the  , but then i dont know how to access the   variable on the server and in which procedure/function i would need to do it. 
 I hope that i made myself clear enough since my main language is not english. 
",44485.61042
185,69607949,implement custom encode Tensorflow Federated,"implement custom encode Tensorflow Federated   I create custom encoder / decoder like so :      now , would like use encode function encode weight client send server and , server , use decode function able obtain weight back . basically , instead send weight client server , want send necessary information let able create weight back 5 information .    the problem understand tell client use encoder send information server use decoder try do :     I m use   basic project .","How to implement custom encode Tensorflow Federated  I have created a custom encoder/decoder like so: 
 
 Now, i would like to use the encode function to encode all the weights that the client send to the server and, on the server, use the decode function to be able to obtain all the weights back. Basically, instead of sending all the weights from the client to the server, i want to send only some necessaries information that will let me able to create the weights back from only 5 informations. 
 The problem is that i dont understand how to tell the client to use this encoder to send the information and to the server to use the decoder before trying to do:
 
 Im using  as basic project. 
",44486.81667
186,69614134,tensorflow Federated object subscriptable,"tensorflow Federated object subscriptable   I run_one_round function like this :      but try do :      I get error : ""      while return value    operation inside main work fine .      the code same , can not use    loop inside    function ?      basically want access    variable client send use    operation list    function .    the problem maybe     ?","Tensorflow Federated object is not subscriptable  I have this run_one_round function like this: 
 
 But when i try to do: 
 
 I get this error:"" 
 
 While if i return the value   and then i do the same operations inside the main it works fine. 
 
 The code is the same, so why i cant use the   loop inside   function? 
 
 Basically i just want to access to the   variable that the client send using   and do some operation on that list before   function. 
 The problem maybe is that   is a  ? 
",44487.41597
187,69619028,access modify weight send client server tensorflow federate,"access modify weight send client server tensorflow federate   I m use Tensorflow Federated , I m actually problem try execute operation server read client update .    this function      I want print    operation weight client send server use    get so .    when try print get this      any way modify element ?    I try use    modification main ( I that ) try invocate new method rest operation server update , error be :     calculate_federated_mean name new function create .    this main :      base simple_fedavg project github [ tensorflow Federated simple_fedavg][1 ] basic project .    EDIT 1 :    so , thank @jakub Konecny make progress , find new problem actually understand .    so , use       with function :      call like inside    function      but get exception      EDIT 2 :    fix problem change decorator function         . seem work fine because , print variable    get    inside    get weight want start .","Access and modify weights sent from client on the server tensorflow federated  Im using Tensorflow Federated, but im actually have some problem while trying to executes some operation on the server after reading the client update. 
 This is the function 
 
 I want to print the   and doing some operation on the weights that the client sent to the server before using the   but i dont get how to do so. 
 When i try to print i get this 
 
 Any way to modify those elements? 
 I tried with using   doing the modification in the main (i can do that) and then i tried to invocate a new method for doing the rest of the operations for the server update, but the error is: 
 
where calculate_federated_mean was the name of the new function i created. 
 This is the main: 
 
 Based on the simple_fedavg project from github [Tensorflow Federated simple_fedavg][1] as basic project. 
 EDIT 1: 
 So, thanks to @Jakub Konecny i made some progress, but i have found a new problem that i dont actually understand. 
 So, if i use this  
 
 with those functions: 
 
 called like so inside the   function 
 
 but i get this exception 
 
 EDIT 2: 
 Fixed the problem above by changing the decorator of the functions   and   from   to  . Now seems to work fine because, if i print the variable   that i got from the   inside   i get the weights that i wanted from the start. 
",44487.66042
188,69739007,load datum client,"load data client   everyone :    I try load    federate process . example find , see local simulation .      but loading server datum ( simulation client datum ) .    I think necessary use    load dataset client . I m little lost .    could everyone help I , please ?    the rest code ( summary ) be :  ","Load data in each client  everyone: 
 I try to load the   in the federated processes. Into the example I can find, only see the local simulation. 
 
 but this is only loading server data (simulation client data). 
 I think that is necessary to use   to load each dataset by the client. Im a little lost. 
 Could everyone help me, please? 
 The rest of the code (summary) is: 
 
",44496.53333
189,69767043,training submodel instead full model Tensorflow Federated,"training submodel instead full model Tensorflow Federated   I m try modify TensorFlow Federated example . want create submodel original model use newly create one training phase send weight server update original model .    I know do inside    server send correct submodel directly client , prefer so .    for 2 problem :      seem like can not create new model inside    function like so :        the error one :      the model create like this :        be like theorical question . would like train sub model like say , would take original model weight send server    layer would assign sublist random weight submodel weight . example ,    layer 6 contain 100 element , new submodel layer 40 element , would choose random seed 40 element , training send seed server , would choose indece update they . correct ? second version create still 100 elements(40 random 60 equal 0 ) think mess model performance aggregate server side .      EDIT :    I modify    function like so :      add new parameter function    like so :      and    this :      now inside    use submodel :      I recieve error :      for model original one , copy function    inside    understand what s wrong","Training submodel instead of full model Tensorflow Federated  Im trying to modify TensorFlow Federated example. I want to create a submodel from the original model and use the newly created one for the training phase and then send the weights to the server so that he will update the original model. 
 I know this shouldnt have been done inside   but the server should send the correct submodel directly to the client, but for now i prefer doing so. 
 For now i have 2 problem: 
 
 Seems like i cant create a new model inside the   function like so: 
 
 
 The error is this one: 
 
 The model created is like this: 
 
 
 Is more like a theorical question. I would like to train a sub model like i said, so i would take the original model weights sent from the server   and for each layer i would assign a sublist of random weights to the submodel weights. For example,   for the layer 6 contains 100 elements, my new submodel for the same layer has only 40 elements, i would choose from a random with a seed the 40 elements, doing the training and then send the seed to the server, so that he would choose the same indeces and then update only them. Is that correct? My second version was to create still 100 elements(40 random and 60 equal to 0) but i think this will mess the model performance when aggregating on the server side. 
 
 EDIT: 
 I have modified the   function like so: 
 
 Adding a new parameter to the function   like so: 
 
 And in the   i did this: 
 
 Now inside the   i can use the submodel: 
 
 I recieve this error: 
 
 For now the model is the same as the original one, i copied the function   inside   so i dont understand whats wrong 
",44498.41806
190,69783251,custom aggregator client_state state,"custom aggregator client_state state   I want create custom aggregator state unique client state client . initialize define client state usual , use    place    placement since that s    want . also create     . problem know "" broadcast "" state back client . normally    take say    make copy equal number client . two client would    let say   . want    turn   .    I currently define client state outside aggregation process , pass    iterative process . use    collect state measurement aggregator , unstack outside . outside federate computation look like      in TFF      in aggregator      but try define handle client state completely inside aggregator plug aggregator    like      be possible ? how ?","custom aggregators with client_states as states  I want to create a custom aggregator where the state is the unique client state of each client. To initialize I can define client states as usual, and then use   to place   placement since thats what   wants. I can also do the same for creating   in the  . The problem is once I dont know how I can ""broadcast"" these states back into clients. Normally   takes say   and then makes copies of it equal to number of clients. so for two clients it would be   lets say  . What I want is to have   turning into  . 
 I am currently defining client states outside the aggregation process, and then passing these in   of iterative process. use   to collect these states from measurements of aggregator, and then unstack it outside. So from the outside of the federated computations it looks like 
 
 In TFF 
 
 in aggregator 
 
 But I am trying to define and handle these client states completely inside the aggregator so that I can plug this aggregator into   like 
 
 Is that possible? if so how? 
",44500.05069
191,60070016,sample softmax loss eval code work function call result ValueError,"sample softmax loss eval code work function call result ValueError   I implement skip - gram model federate learn setup . get input label follow way :      when define loss follow      I get follow error      but , follow code ( take eval section sampled_softmax_loss function ) work   same input label   ! !      how fix resolve issue ?","Sampled softmax loss eval code works but function call results in ValueError  I am implementing the skip-gram model in a federated learning setup. I get the inputs and label in the following way: 
 
 When I define the loss as follows 
 
 I get the following error 
 
 But, the following code (taken from eval section of sampled_softmax_loss function) works for the  same inputs and labels  !! 
 
 How to fix resolve this issue? 
",43866.26528
192,60077515,TFF : TensorSliceDataset,"TFF : TensorSliceDataset   in Federated learning context , try simulate code TFF type dataset DatasetV1Adapter ( tf.data . Dataset ) instead dataset emnist tutorial   type tensorslicedataset    so cause problem ? must change type dataset ?","TFF: TensorSliceDataset  In the Federated learning context, I try to simulate a code with TFF so the type of my dataset is DatasetV1Adapter (tf.data.Dataset) instead the dataset of emnist in the tutorial    was of type  TensorSliceDataset 
 So that can cause a problem ?  must I change the type of my dataset ? 
",43866.58472
193,60153603,tensorflow Federated : iterative Process unable train round,"tensorflow Federated : iterative Process unable train round   I write code tff dataset , code run correctly except line    in train_data , make 4 dataset , load tf.data . dataset , type DatasetV1Adapter      all run correctly get trainer state :      except , would begin train round code :      I can not . error come ! so , error ? type dataset ? way make datum federate ?","Tensorflow Federated : Why my iterative Process unable to train rounds  I write a code with TFF from my own dataset, all the code run correctly except 
this line 
 In train_data, I make 4 dataset, loaded with tf.data.Dataset, they have the type DatasetV1Adapter 
 
 all this run correctly and I get trainer and state: 
 
 Except, When I would to begin training and round with this code: 
 
 I cant. error comes! So, from where can be the error? from type of dataset? or the way that I make my data federated? 
",43871.64861
194,60181180,tensorflow federate : TypeError use customized dataset model,"tensorflow federate : TypeError use customized dataset model   I follow tutorial Federated Learning Image Classification , use dataset resnet50 . get error , run   .    I believe cause    code :      I get error    information      my environment      UPDATE    I ve upgrade tf==2.1.0 tff==0.12.0 , error disappear , get another error .    it seem generator reach last batch match input shape .     but imagedatagenerator need set   .Is anything wrong code ?  ","tensorflow federated : TypeError when using customized dataset and model  I am following the tutorial Federated Learning for Image Classification, but using my own dataset and resnet50. I got this error, when running  . 
 I believe it was caused by  
here is my code: 
 
 I got the error
 
here is more information 
 
 my environment 
 
 UPDATE 
 Ive upgraded tf==2.1.0 and tff==0.12.0, the error disappeared, but I got another error. 
 It seems that the generator reaches the last batch and does not match the input shape.  
 But ImageDataGenerator does not need to set  .Is there anything wrong with my code? 
 
",43873.1875
195,60183787,create Federated datum Time series datum ?,create Federated datum Time series datum ?   I try study federate machine learn time series datum . datum collect multiple client . convert datum federate datum ?,"How to create Federated data for Time series data?  I am trying to study  federated machine learning on time series data. The data is collected from multiple clients. How to convert this data into federated data ? 
",43873.34097
196,60194646,possible TRAIN neural network model Tensoflow Lite / or framework smartphone ?,possible TRAIN neural network model Tensoflow Lite / or framework smartphone ?   be possible TRAIN neural network model Tensoflow Lite / or framework smartphone ?    specifically context federative learning ?,"Is it possible to TRAIN a neural network model with Tensoflow Lite/Or any other frameworks on smartphones?  Is it possible to TRAIN a neural network model with Tensoflow Lite/Or any other frameworks on smartphones? 
 Specifically in the context for federative learning? 
",43873.75903
197,60198252,low evaluation accuracy Resnet TensorFlow Federated,"low evaluation accuracy Resnet TensorFlow Federated   I implement Resnet34 model federate image classification tutorial . 10 round training accuracy high 90 % , however , evaluation accuracy use last round    always around 50 % .      I confuse what s possibly wrong evaluation part ? also , print untrainable variable ( mean variance BatchNorm ) server model , 0 1 update / average round . like could problem ? thank much !     update :      the code prepare training datum print result :      the training evaluation code :      the training evaluation result round :  ","Low evaluation accuracy of Resnet in TensorFlow Federated  I implemented Resnet34 model in federated images classification tutorial. After 10 rounds the training accuracy can be higher than 90%, however, the evaluation accuracy using the last rounds   is always around 50%. 
 
 I am very confused whats possibly wrong with the evaluation part? Also, I printed the untrainable variables (mean and variance in BatchNorm) of the servers model, which are 0 and 1 with no updates/averaging after those rounds. Should they be like that or that could be the problem?
Thanks very much!  
 Updates:   
 The codes to prepare training data and printed results: 
 
 The training and evaluation codes: 
 
 The training and evaluations results after each round: 
 
",43873.96736
198,60265798,TFF : define tff.simulation . clientdata.from_clients_and_fn function ?,"TFF : define tff.simulation . ClientData.from_clients_and_fn Function ?   in federated learning context , one classmethod work would tff.simulation . ClientData.from_clients_and_fn . here , pass list client_ids function return appropriate dataset give client i d , hand fully functional ClientData .    I think here , approach defining function may use construct Python dict maps client id tf.data . dataset object -- you could define function take client i d , look dataset dict , return dataset . define function think wrong , think ?      I suppose 4 client dataset : ds","TFF: How define tff.simulation.ClientData.from_clients_and_fn Function?  In the federated learning context, One such classmethod that should work would be tff.simulation.ClientData.from_clients_and_fn. Here, if I pass a list of client_ids and a function which returns the appropriate dataset when given a client id, you will have your hands on a fully functional ClientData. 
 I think here, an approach for defining the function I may use is to construct a Python dict which maps client IDs to tf.data.Dataset objects--you could then define a function which takes a client id, looks up the dataset in the dict, and returns the dataset.
So I define function as below but I think it is wrong, what do you think? 
 
 I suppose here that the 4 clients have the same dataset :ds 
",43878.65069
199,60279026,print value pass client tensorflow federate ?,print value pass client tensorflow federate ?   I try understand tensorflow federate . refer   site . understand print value pass client function ?       and also anybody tell use tff.sequence_reduce .    please help .,"How to print values passed by client in tensorflow federated?  I am trying to understand tensorflow federated. I was referring to  site. Here I am not understanding how to print the values of passed by each client in this function?  
 
 and also can anybody tell me what is the use of tff.sequence_reduce. 
 Please help. 
",43879.44653
200,60285187,plot Histogram summary delta weight Federated Tensorflow ?,"plot Histogram summary delta weight Federated Tensorflow ?   I analyze method implement Tensorflow Federated FedAvg . need histogram every client delta weight communicate server . client separately call   , thing call follow api there .   . help would appreciated .","How to plot Histogram summary for delta weight in Federated Tensorflow?  I am analyzing a method that I have implemented in Tensorflow Federated with FedAvg. I need to have a histogram for every clients delta weights that are communicated to the server. Each client separately called in  , but the thing is I can not call the following API in there.  . any help would be appreciated. 
",43879.67708
201,60285568,learn parameter simulate device,learn parameter simulate device   do tensorflow - federate support assign different hyper - parameters(like batch - size learning rate ) different simulated device ?,"Learning parameters of each simulated device  Does tensorflow-federated support assigning different hyper-parameters(like batch-size or learning rate) for different simulated devices? 
",43879.69167
202,60457040,get TypeError : catch exception use accuracy Tensorflow Federated,"get TypeError : catch exception use accuracy Tensorflow Federated   this model , implement TensorFlow .       I get error TensorFlow Federated .       my dataset label kind two label    use    loss function . accuracy get back error . sure relate multiple label . loss calculate without problem remove accuracy . help would greatly appreciate .","get TypeError: Caught exception for using accuracy in Tensorflow Federated  This is my model, and I have implemented it once in TensorFlow.  
 
 I get this error in TensorFlow Federated.  
 
 My datasets label is a kind of two labels   and I used   for loss function. But the accuracy gets back the error. I am sure it is related to multiple labels. The loss calculated without any problem when I remove the accuracy. Any help would be greatly appreciated. 
",43889.75
203,69891610,local Model performance Tensorflow Federated,local Model performance Tensorflow Federated   I implement federated learn tensorflow - federate . tutorial material available compare accuracy federate ( global ) model communication round . way compute accuracy local model compare federate ( global ) model .    summary : total number client : 15 communication round : local vs Federated Model performance    reference :      ( )  ,"Local Model performance in Tensorflow Federated  I am implementing federated learning through tensorflow-federated. The tutorial and all other material available compared the accuracy of the federated (global) model after each communication round. Is there a way I can compute the accuracy of each local model to compare against federated (global) model. 
 Summary:
Total number of clients: 15
For each communication round: Local vs Federated Model performance 
 References: 
 
 () 
 
",44509.03681
204,69949143,tensorflow Federated Windows,tensorflow Federated Windows   can tensorflow Federated instal window ? documentation describe Ubuntu MacOS,"TensorFLow Federated on Windows  Can TensorFlow Federated be installed on Windows?
Documentation only describes Ubuntu and MacOS    
",44512.88611
205,70160910,use cifar-100 datase VGG19 model simple_fedavg example,"use cifar-100 datase VGG19 model simple_fedavg example   I m use   github tensorflow federate , try change dataset model , can not get positive feedback , accuracy always 1 % .    this code , change model part dataset simple_fedavg example . idea ? try different optimizer , still luck .  ","Using CIFAR-100 datased with VGG19 model in simple_fedavg example  Im using the  from the github of tensorflow federated, i was trying to change the dataset and the model, but i cant get any positive feedback, the accuracy is always at 1%. 
 This is the code, i just changed the model part and the dataset from the simple_fedavg example. Any idea? I tried with different optimizers, but still no luck. 
 
",44529.85069
206,70196914,TFF : finetune pretraine network : test accuracy still constant round,"TFF : finetune pretraine network : test accuracy still constant round   I would like fine - tune pre - train model Federated Learning , this :      and training loop :      the problem test accuracy still constant increase round :      I would like understand reason , another way this ? know dataset image dataset 3 class .","TFF: finetune with pretrained network : Test accuracy still constant after all rounds  I would like to Fine-tune the pre-trained model  with Federated Learning, So I do this: 
 
 And here is the training loop : 
 
 The problem is that test accuracy still constant and does not increase after all round  : 
 
 I would like to understand the reason, If there is another way to do this? Knowing that my dataset is an image dataset with 3 class. 
",44532.39167
207,70333328,tff : change code effect change test accuracy value,"tff : change code effect change test accuracy value   to improve   test thing , pretraine network centralize way emnist database . would like fine tune pretraine network federate code above . so , add :      the problem find test accuracy value compare test accuracy value without fine tuning pretraine network . please give solution .","TFF : change the code have no effect in changing test accuracy values  To improve this  and test other things, I was pretrained the network with a centralized way in EMNIST database. Then I would like to Fine tune the pretrained network with a federated code above.
So, I only added: 
 
 The problem is that I find same test accuracy values compared to test accuracy values without fine tuning a pretrained network.
Can you please give me solution. 
",44543.44444
208,70338012,run RAM use fileperuserclientdata,run RAM use fileperuserclientdata   I problem training use    - quickly run RAM 5 - 6 round 10 client per round . ram usage steadily increase round . try narrow realize issue actual iterative process creation client dataset . simply call    loop cause problem .    so minimal version code :      I use tensorflow - federate 19.0 .    be something wrong way create client dataset somehow expect RAM previous round free ?,"Running Out of RAM using FilePerUserClientData  I have a problem with training using   - I am quickly running out of RAM after 5-6 rounds with 10 clients per round.
The RAM usage is steadily increasing with each round.
I tried to narrow it down and realized that the issue is not the actual iterative process but the creation of the client datasets.
Simply calling   in a loop causes the problem. 
 So this is a minimal version of my code: 
 
 I am using tensorflow-federated 19.0. 
 Is there something wrong with the way I create the client datasets or is it somehow expected that the RAM from the previous round is not freed? 
",44543.69583
209,70376178,implement differential privacy federate learn,"implement differential privacy federate learn   I m beginner federate learning . try add gaussian noise gradient client_updata . anyone attempt , please teach do . thank advance .  ","How implement differential privacy in federated learning  Im beginner in federated learning.
I try to add gaussian noise to gradient in client_updata.
If anyone attempt to do , please teach me how to do.
Thank you in advance. 
 
",44546.36736
210,60463530,use different weight bias client tensorflow federate ?,use different weight bias client tensorflow federate ?   I want know possible use different weight bias client tensorflow_federated .    please help .,"Can I use different weights and bias for each of the clients in tensorflow federated?  I want to know if it is possible to use different weights and bias for each of the clients in tensorflow_federated. 
 Please help. 
",43890.37639
211,60489703,TFF use lot CPU,"TFF use lot cpu   when run code without TFF ( training model model.fit ( ) ) , notice use CPU 5 % code run GPU . introduce TFF : aside GPU , training take lot cpu ( order 90 % ) lot memory , knowing use : tensorflow Federated v 0.12.0 tensorflow v 2.1.0","TFF uses a lot of CPU  When I run my code without TFF (training my model with model.fit()), I notice that use of CPU is 5 % and my code run GPU . But if I introduce TFF : aside GPU,  training takes a lot of CPU (order of 90 %) and a lot of memory, Knowing that I use:
Tensorflow Federated v 0.12.0
Tensorflow v 2.1.0 
",43892.55417
212,60501245,broadcast different model client federated_tensorflow ?,broadcast different model client federated_tensorflow ?   I want know broadcast different model client server tensorflow_federated ?    can anyone please help ?,"Can I broadcast different models for each of the clients in federated_tensorflow?  I want to know if we can broadcast different models for each of the clients from the server in tensorflow_federated? 
 Can anyone please help? 
",43893.26875
213,60508005,accuracy increase TFF VGG16 model ?,"accuracy increase TFF VGG16 model ?   I build code TFF VGG16 model . however , training time , accuracy change stay around 0.5 even 11 round . try change learn rate significant effect . ! ! ! so , metric thing change code increase accuracy , run code , accuracy stable increase ! !    here code VGG16  ","Why my accuracy does not increase in TFF with VGG16 model?  I have build my code TFF with VGG16 model. However, at training time, my accuracy does not change and stays around 0.5 even after 11 rounds.
I have tried changing the learning rate but has no significant effect.!!!
So, What are the metrics and things that I can change in the code to increase the accuracy, because when I run my code, the accuracy is stable and dont increase!! 
 Here is the code of my VGG16 
 
",43893.54653
214,60564780,determinate number round TFF context,"determinate number round TFF context   in TFF , necessary determinate number round . so , obtain optimal performance model , know optimal number round ?","How determinate number of rounds in TFF context  In TFF, It is necessary to determinate number of rounds. So, to obtain optimal performance of our model, How we can know the optimal number of rounds? 
",43896.54931
215,60757397,TFF context : evaluation step depend training process ?,TFF context : evaluation step depend training process ?   we know evaluation step quite important evaluate model test basis . want know necessary go round step(training ) evaluation ? mean code like this ? correct like below ? ?      without go step      be possible give correct result ? thank all,"in TFF context : Is the evaluation step depends on training process?  We all know that the evaluation step is quite important  to evaluate our model on a test basis. I wanted to know if it is necessary to go through the round step(training) before doing the evaluation? that mean my code can be like this? it is correct like below?? 
 
 without going through this step 
 
 Is that possible and give me correct result?
Thanks for you all 
",43909.52361
216,60771007,tff : keep ( or saving ) state highest - perform,"tff : keep ( or saving ) state highest - perform   in TFF , variable    use evaluation like :      so keep varibale save find good one highest - perform","in TFF : How keeping (or saving) the state of highest-performing  in TFF, the variable    is used for evaluation like below : 
 
 So How we can keep this varibale or save it when I find the best one of highest-performing 
",43910.36736
217,60815004,ModuleNotFoundError : module name tensorflow_federated.python.research,"ModuleNotFoundError : module name tensorflow_federated.python.research   the follow error occur run   ( I attempt regenerate result paper ):        here full list anaconda environment information :    and use Pycharm Ubuntu 16.04 :    last least , try execute code terminal error continue exist , I m afraid problem concern Pycharm IDE .      it appreciate could give suggestion .","ModuleNotFoundError: No module named tensorflow_federated.python.research  The following error occurred while running  (I am attempting to regenerate the results of the paper): 
 
 
 Here is the full list of my anaconda environment information: 
 and I am using Pycharm in Ubuntu 16.04: 
 Last but not least, I have tried to execute the code in the terminal but the error continued to exist, so Im afraid that the problem is not concerned with the Pycharm IDE. 
 
 It will be appreciated if you could give me some suggestions. 
",43913.58264
218,60839809,Federated Learning image captioning,"Federated Learning Image Captioning   I m relatively new tensorflow , I ve read book machine learn I ve take Udacitys course . I ve task recreate Image Captioning Model find tutorial   use Federated Learning library tensorflow offer , far everything easy I ve manage understand I m suppose reach part designing model . federate learn tutorial ( ) , design variable part , suppose know shape weight bias ?    sorry obvious question I ve struggle shape quite sometime now , thank advance ! :)    EDIT : sorry , forgot add part question : suppose know variable model ? know weight bias base model along loss accuracy know good model perform , anything else need know ?","Federated Learning for Image Captioning  Im relatively new to tensorflow, Ive read a book about machine learning and Ive took Udacitys course. Ive been tasked with recreating the Image Captioning Model found on this tutorial  using the Federated Learning library that tensorflow offers, so far everything is easy and Ive managed to understand what Im supposed to do until I reached the part of designing the model. In the federated learning tutorial (), In designing the variables part, how am i supposed to know the shape of the weights and bias? 
 Sorry if this is an obvious question but ive been struggling with shapes for quite sometime now, Thank you in advance! :) 
 EDIT: Sorry, I forgot to add this part to the question: How am I supposed to know the variables of my model? I know that the weights and bias are the base of the model along with the loss and the accuracy is for me to know how good the model performs, but is there anything else I need to know? 
",43914.90556
219,60841235,prepare dataset(not image ) implement FedAVG Tensorflow Federated ?,"prepare dataset(not image ) implement FedAVG Tensorflow Federated ?   I want train federate model FedAvg Algorithm TFF ( Tensorflow Federated ) use 3 - channel ( X , Y , Z ) accelerometer dataset time frame length 128 .    my goal train federate model use       the guide TensorFlow Federated website mostly deal dataset already come desire format model      I m quite lose convert raw dataset desire format TFF .    the dataset use follow shape :       X : float Y : integer label dataset range 0 - 6    can anybody give pointer / example tackle this ?","How to prepare my dataset(Not Images) to implement FedAVG on Tensorflow Federated?  I want to train a federated model with the FedAvg Algorithm on TFF (Tensorflow Federated) using a 3-channel (X, Y, Z) accelerometer dataset with a time frame length of 128. 
 My goal is to train a federated model using  
 
 The guides on the TensorFlow Federated website mostly deal with datasets which already comes in the desired format for the model 
 
 Im quite lost on how to convert my raw dataset to the desired format for TFF. 
 The dataset I am using has the following shape:  
 
 X: are floats
Y: are the integer labels of my dataset ranging from 0-6 
 Can anybody give me some pointers/examples on how I can tackle this? 
",43915.00972
220,60876340,save train TensorFlow Federated model .h5 model ?,"save train TensorFlow Federated model .h5 model ?   I want save TensorFlow federate model train FedAvg Algorithm Keras/.h5 model . find document would like know may do . also possible , I d like access aggregate server model model client .    the code use train federate model below :  ","How can I save a trained TensorFlow Federated model as a .h5 model?  I want to save a TensorFlow federated model which was trained with the FedAvg Algorithm as a Keras/.h5 model. I couldnt find the documents on this and would like to know how it may be done.
Also if possible, Id like to have access to both the aggregated server model and the models of the clients. 
 The code I use to train the federated model is below: 
 
",43916.89097
221,60903579,error run TensorFlow Federated server,error run TensorFlow Federated server   I get follow error try load Tensorflow Federated library server . use tensorflow_federated version 0.13.1     the Cuda version server 10.2 . cudnn library 7.6 .    what    ask ?  ,"Error when running TensorFlow Federated on server  I am getting the following error when I try to load the Tensorflow Federated library on a server. I am using tensorflow_federated version 0.13.1  
 The Cuda version I have on the server is 10.2 . The Cudnn library is above 7.6. 
 What is the   that is being asked? 
 
",43918.68889
222,70398702,client level differential privacy Tensorflow Federated ( local dp ),"client level differential privacy Tensorflow Federated ( local dp )   I want implement local dp model use TFF , be , client train differentially private model send noisy gradient server , server aggregate distribute standard FL fashion . try change client optimizer keras dp optimizer , do not work . suggestion appreciate .","Client level differential privacy in Tensorflow Federated (Local DP)  I want to implement local DP model using TFF, that is, each client trains its own differentially private model and sends noisy gradients to the server, and the server just aggregates and distributes in a standard FL fashion. I tried changing the client optimizer to keras DP optimizer, but that didnt work. Any suggestions are appreciated. 
",44547.86389
223,70426568,apply custom encoder multiple client once ? use custom encoder run_one_round ?,"apply custom encoder multiple client once ? use custom encoder run_one_round ?   so goal basically implement . gradient sparsification quite simple already do building , would like use encoder recommend . additionally would like average non - zero gradient , say 10 client 4 nonzero gradient give position communication round would like divide sum gradient 4 , 10 . hope achieve sum gradient numerator mask , 1s 0s , denominator . also move forward add randomness gradient selection imperative create mask concurrently gradient selection . code right be      I run simple test manually follow step outline . work question / problem .      when use list tensor shape ( ex:2 2x25 tensor ) input , x , encode work without issue try use list tensor different shape ( 2x20 6x10 ) give error say        invalidargumenterror : shape input must match : values[0].shape = [ 2,20 ] ! = values.shape = [ 6,10 ] [ op : pack ] name : pack      how resolve issue ? say want use global top - k essential encode entire trainable model weight once . take , tensor different shape .      how average describe beginning ? example   do        mean_factory = tff.aggregator . MeanFactory ( tff.aggregator . EncodedSumFactory(mean_encoder_fn ) , numerator tff.aggregator . EncodedSumFactory(mean_encoder_fn ) , denominator )      be way repeat one output decode going numerator go denominator ? handle divide 0 0 ? tensorflow divide_no_nan function , use somehow need add eps each ?      how partition handle use encoder ? client get unique encoder hold unique state it ? discuss   client state use cross - silo setting yet happen client order change ?       recommend use . explain bit far ? mean run_one_round exactly encoder go use / combine client update aggregation ?      I additional information sparsity want pass encode . suggest method that ?    ","how to apply custom encoders to multiple clients at once? how to use custom encoders in run_one_round?  So my goal is basically implementing . Gradient sparsification is quite simple and I have already done this building on , but now I would like to use encoders as you have recommended . Additionally I would like to average only the non-zero gradients, so say we have 10 clients but only 4 have nonzero gradients at a given position for a communication round then I would like to divide the sum of these gradients to 4, not 10. I am hoping to achieve this by summing gradients at numerator and masks, 1s and 0s, at denominator. Also moving forward I will add randomness to gradient selection so it is imperative that I create those masks concurrently with gradient selection. The code I have right now is 
 
 I have run some simple tests manually following the steps you outlined . It works but I have some questions/problems. 
 
 When I use list of tensors of same shape (ex:2 2x25 tensors) as input,x, of encode it works without any issues but when I try to use list of tensors of different shapes (2x20 and 6x10) it gives and error saying 
 
 
 InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [2,20] != values.shape = [6,10] [Op:Pack] name: packed 
 
 How can I resolve this issue? As i said I want to use global top-k so it is essential I encode entire trainable model weights at once. Take the , all the tensors have different shapes. 
 
 How can I do the averaging I described at the beginning? For example  you have done 
 
 
 mean_factory = tff.aggregators.MeanFactory(
tff.aggregators.EncodedSumFactory(mean_encoder_fn), # numerator
tff.aggregators.EncodedSumFactory(mean_encoder_fn), # denominator ) 
 
 Is there a way to repeat this with one output of decode going to numerator and other going to denominator? How can I handle dividing 0 by 0? tensorflow has divide_no_nan function, can I use it somehow or do I need to add eps to each? 
 
 How is partition handled when I use encoders? Does each client get a unique encoder holding a unique state for it? As you have discussed  client states are used in cross-silo settings yet what happens if client ordering changes? 
 
  you have recommended using . Can you explain this a bit further? I mean in the run_one_round where exactly encoders go and how are they used/combined with client update and aggregation? 
 
 I have some additional information such as sparsity I want to pass to encode. What is the suggested method for doing that? 
 
 
",44550.77847
224,70434265,attributeerror : module tensorflow_federated.python.common_libs.structure attribute update_struct,"attributeerror : module tensorflow_federated.python.common_libs.structure attribute update_struct   I m use TFF 0.18 use :      I find error , solve problem without change TFF version .","AttributeError: module tensorflow_federated.python.common_libs.structure has no attribute update_struct  Im using TFF 0.18
When using : 
 
 I find this error, So how can I solve this problem without changing TFF version. 
",44551.45208
225,70563080,typeerror : can not capture result unsupported type tensorflow.python.keras.engine.functional . functional,typeerror : can not capture result unsupported type tensorflow.python.keras.engine.functional . functional   I would like load pretraine network inside    write :  ,"TypeError: Cannot capture a result of an unsupported type tensorflow.python.keras.engine.functional.Functional  I would like to load a pretrained network in the inside of  
So I write this : 
 
",44564.34028
226,70590588,typeerror : _ _ init _ _ ( ) get unexpected keyword argument intialize_fn,"typeerror : _ _ init _ _ ( ) get unexpected keyword argument intialize_fn   I use TFF v:0.18 would like load pretraine network inside    write :      but find error :      I believe syntax error ,","TypeError: __init__() got an unexpected keyword argument intialize_fn  I use TFF v:0.18
I would like to load a pretrained network in the inside of   So I write this : 
 
 But I find this error: 
 
 I dont believe that the syntax is error, 
",44566.39792
227,60920524,error use GPU base remote execution Tensorflow federate,"error use GPU base remote execution Tensorflow federate   I try experiment remote executor runtime example provide link .     if use CPU base tensorflow , everything work fine . however , GPU base tensorflow follow error occur aborts execution :      how solve ? anyone face similar issue ?","Error while using GPU based remote execution with Tensorflow federated  I am trying to experiment with remote executor runtime with the example provided on this link.
 
 If I using CPU based tensorflow, then everything works fine. However, for GPU based tensorflow
the follow error occurs and aborts execution: 
 
 How do I solve this ? Have anyone faced similar issues ? 
",43919.86667
228,60935065,way simulate communication cost tensorflow - federate ?,"way simulate communication cost tensorflow - federate ?   I work optimize communication cost Federated Learning . therefore , need simulate realistic network delay measure communication overhead ( the communication client server ) . possible TFF ? realistic networking model communication Federated Learning setting ?","Is there a way to simulate the communications costs in tensorflow-federated?  I am working on optimizing the communication costs in Federated Learning. Therefore, I need to simulate realistic network delays and measure communication overhead (the communication between the clients and the server). Is it possible to do that with TFF? Is there a realistic networking model for communications in Federated Learning setting? 
",43920.68681
229,60966874,run event loop tf federate,run event loop tf federate   I try code mention homepage tensorflow federate site ....      get error :      complete code :      how run sample code ?,"running the event loop in tf federated  I tried the code mentioned on homepage of tensorflow federated site.... 
 
 Got the error: 
 
 Complete code: 
 
 How do I run the sample code? 
",43922.36458
230,60982530,"ValueError : Tensor(cnn / conv2d / kernel:0 , shape= ( ) , dtype = resource ) must graph Tensor(Placeholder:0 , shape= ( ) , dtype = variant )","ValueError : Tensor(cnn / conv2d / kernel:0 , shape= ( ) , dtype = resource ) must graph Tensor(Placeholder:0 , shape= ( ) , dtype = variant )   I new Deep Learning TFF . need use CNN classify image EMNIST . see tutorial GitHub name Federated Learning Image Classification . create Network name CNN , use forward_pass function instance cnn model calculate prediction . TFF need pass model variable trainable variable tff.learning . Model . print CNN model.variable . know name use cnn_conv2d_kernel represent cnn / conv2d / kernel . code :    the model.variable print :      my variable create pass trainable non_trainable variable tff.learning . Model :      )      my partial tff.learning . Model code :      please forgive poor English help please.(please )    now , I new problem :  ","ValueError: Tensor(cnn/conv2d/kernel:0, shape=(), dtype=resource) must be from the same graph as Tensor(Placeholder:0, shape=(), dtype=variant)  I am a newer in Deep Learning and TFF. I need to use a CNN to classify images from EMNIST. And I see the tutorials on GitHub named Federated Learning for Image Classification. I create a Network named CNN, and then I use forward_pass function to instance a cnn model to calculate the predictions. But TFF need to pass the model variables as trainable variables to the tff.learning.Model. I print the CNN model.variables. I dont know how to named them so I use cnn_conv2d_kernel to represents cnn/conv2d/kernel. Here is my code: 
 the model.variables printed: 
 
 My variables created to pass trainable and non_trainable variables to tff.learning.Model: 
 
 ) 
 
 my partial tff.learning.Model code: 
 
 please forgive my poor English and help me please.(Please) 
 Now ,I have a new problem: 
 
",43923.02569
231,60998080,TFF : simulate training random sample user round,"TFF : simulate training random sample user round   I would like simulate code federate learn image classification random sample user round , tutorial use client training , insteed , would modify code way , round random sample client choose . change code force choice client randomly  ","TFF: How simulate training on random samples of users in each round  I would like to simulate this code of federated learning for image classification with random samples of users in each round,
This tutorial uses all clients on training, insteed, I would to modify this code in such a way, in each round a random samples of clients are chosen.
 So what we can change in this code to force it to choice client randomly 
 
",43923.75069
232,61008774,would one implement class weighting individual federate learn client ?,"would one implement class weighting individual federate learn client ?   I attempt utilise TensorFlow Federated image classification task 7 class 3 - 5 client . client different class distribution label . successfully implement   use - case look improvement . question :      can individual client different class weight loss function base class distribution unique client ?     if so , would one implement this ?     if not , federate averaging process require client global model share loss function ?  ","How would one implement class weighting for individual federated learning clients?  I am attempting to utilise TensorFlow Federated for an image classification task with 7 classes and 3-5 clients. Each client has a different class distribution of labels. I have successfully implemented  for my use-case and am now looking for improvements. I have a few questions: 
 
 Can individual clients have different class weights in their loss function based on the class distribution that is unique to that client?  
 If so, how would one implement this?  
 If not, is it because federated averaging process requires that the clients and the global model share the same loss function? 
 
",43924.39236
233,61025323,"eminst datum convert ( 28 * 28 ) [ -1 , 784 ] instead [ 0,784 ] image classification problem ?","eminst datum convert ( 28 * 28 ) [ -1 , 784 ] instead [ 0,784 ] image classification problem ?   this code snippet     the example image classification problem use federate learning . function pre - processing function emnist datum ( which size 28 * 28 ) . anyone help understand datum reshape -1 784 ? far understand , convert two dimensional one dimensional array easy process . sure -1 include . 0 784 would enough ?  ","Why the eminst data is converted from (28*28) to [-1, 784] instead of [0,784] in image classification problem?  This is code snippet from  
 The example is of image classification problem using federated learning. Below function is pre-processing function of emnist data (which is of size 28*28). Can anyone help to understand why the data was reshaped to -1 to 784? as far as I understand, we convert it from two dimensional to one dimensional array because it is easier to process. But I am not sure why -1 was included. Isnt it 0 o 784 would have been enough? 
 
",43925.3375
234,61034455,TensorFlow Federated : write Input Spec model one input,"TensorFlow Federated : write Input Spec model one input   I m try make image captioning model use federate learning library provide tensorflow , I m stick error       this input_spec :       the model take image feature first input list vocabulary second input , can not express input_spec variable . try express list list still work . try next ?","TensorFlow Federated: How can I write an Input Spec for a model with more than one input  Im trying to make an image captioning model using the federated learning library provided by tensorflow, but Im stuck at this error  
 
 this is my input_spec:  
 
 The model takes image features as the first input and a list of vocabulary as a second input, but I cant express this in the input_spec variable. I tried expressing it as a list of lists but it still didnt work. What can I try next? 
",43925.85903
235,61054659,KeyError : unable open object ( object example exist ),KeyError : unable open object ( object example exist )   I get error want create HDF5ClientData instance like emnsit . code :      and add datum mynist.hdf5 before . know happen .      here error like :  ,"KeyError: Unable to open object (object examples doesnt exist)  I got this error when I want to create a HDF5ClientData instance just like the emnsit. Here is my code: 
 
 And I have added some data into mynist.hdf5 before. I dont know why it happen. 
 
 here is my error like: 
 
",43927.29931
236,61056770,application hang train tff Model use create Client DataSet,"application hang train tff Model use create Client DataSet   I create    follow EMNIST . train model seem trap infinite loop RAM get fill short time . code . print dataset EMNIST dataset draw comparison (   DataSet ):      here result :      and part use    replace EMNIST :      my model work well EMNIST . change emnist dataset , "" Python3 Google compute Engine "" become busy . even wait long time nothing calculate , interrupt it .","Application hangs if training tff Model using a created Client DataSet  I create a   following EMNIST. But When I train my model it seems to be trapped in a infinite loop and RAM gets filled in a short time. Here is the code. I print my dataset and EMNIST dataset to draw a comparison (  is my DataSet): 
 
 Here is the result: 
 
 and this is the part I use   to replace EMNIST: 
 
 My model can work well with EMNIST. But if I change EMNIST to my dataset, the ""Python3 Google compute Engine"" becomes busy. Even after waiting a long time nothing is calculated, so I have to interrupt it. 
",43927.39861
237,61102268,can not run tensorflow - federate GPU,"can not run tensorflow - federate GPU   I try run python code use    GPU . set environment , use   . first , install   , python code recognize GPU , use   . however , soon install   , python stop see GPU start use cpu ! ! use Ubuntu 16.04.6 LTS . try plenty combination different version package :  ","Cant run Tensorflow-federated on GPU  I am trying to run my python code which uses   on a GPU. To set up my environment, I use  . First, I install  , and my python code then can recognize the GPU, I use  . However, as soon as I install  , my python stops seeing any GPU and starts using CPUs!! 
I am using Ubuntu 16.04.6 LTS. I tried a plenty of combinations of different versions of the packages: 
 
",43929.575
238,61108381,error try tff.learning.assign_weights_to_keras_model method,error try tff.learning.assign_weights_to_keras_model method   I would like try   TFF   find error witch can not understand . use assign_weight evaluate model code :      error message :  ,"Error while trying tff.learning.assign_weights_to_keras_model method  I would like to try this  of TFF  with this  but I find error witch I cant understand. I use assign_weight and after that I evaluate my model
Here is my code : 
 
 Error message : 
 
",43929.80556
239,61136411,allocate 600 example client 700 train model TFF ?,"allocate 600 example client 700 train model TFF ?   I meet strange problem use create datum set TFF . create data set federate training , allocate 5 client example follow : 600 600 300 700 300 . train model , find number example 600 600 600 600 700 . confuse . then , print process information create datum set check HDF5 file dataset , 600 600 300 700 300 . use code see many example client HDF5 file , result 700 :      I use code instance datum set see many example client :      I use code instance datum set third client debug :      I allocate third client 700 example create datum set . iterate data client find show 600 example . tff HDF5 file show 700 too .","Why I allocate 600 examples to a client but there are 700 when I train the model in TFF?  I met a strange problem when I used my created data set in TFF. I created a data set for federated training, where I allocate 5 clients examples as follows: 600 600 300 700 300. But when I trained them in model, I found the number of examples is 600 600 600 600 700. I was so confused. And then, I printed the process information of my created data set and checked the HDF5 file of the dataset, and both of them were 600 600 300 700 300. 
I use this code to see how many examples in the client in the HDF5 file, the result is 700: 
 
 I use this code to instance the data set and see how many examples in the client: 
 
 I use this code to instance the data set of third client and debug: 
 
 I allocated the third client 700 examples when I created the data set. But when I iterated data of this client I found it showed 600 examples. The tff HDF5 file showed 700 too. 
",43931.34306
240,61152605,Async - FL Model,"Async - FL Model   how perform asynchronous model training use tff framework ?    I review iterative training process loop , however sure know client model receive .","Async - FL Model  How to perform asynchronous model training using TFF framework? 
 I review the iterative training process loop, however I am not sure how to know which clients models are received. 
",43932.2375
241,61199743,server broadcast max number example every client train cycle FL ? action invasion privacy ?,server broadcast max number example every client train cycle FL ? action invasion privacy ?   I train FL model . select 5 client every cycle . want get example gap client maximum quantity client . server broadcast max number example among 5 client other cycle ? legal ?,"Can Server broadcast the max number of examples to every client in a train cycle in FL? Is this action an invasion of privacy?  I am training a FL model. I select 5 clients every cycle. I want to get the examples gap between a client and the maximum quantity client. Can Server broadcast the max number of examples among the 5 clients to others during this cycle? Is it legal?  
",43935.09722
242,61219479,create Non - IID datum set like fedavg paper McMahan test accuracy datum set 0.5 ?,"create Non - IID datum set like fedavg paper McMahan test accuracy datum set 0.5 ?   I create Non - IID datum set divide 60000 examples(10 class every class 6000 example ) 200 fragment , every fragment 300 example . 100 client allocate 2 fragment randomly every client . situation client .     I use datum set train TFF model . accuracy train set 0.99 accuracy test set 0.5 . try many time change . think maybe model over - fit add two dropout test , get result . change relu ( ) funcion leakyrelu ( ) , change optimizer function SGD Adam , accuracy also 0.5 . why . know Non - IID cause descend accuracy FedAvg relieve it . tff use FedAvg aggregate client model mean use FedAvg underlie structure , right ? get low accaracy ?","Why I create a Non-IID data set like the FedAvg in paper of McMahan but test accuracy of this data set is just only 0.5?  I create a Non-IID data set where I divide 60000 examples(10 classes and every class has 6000 examples) to 200 fragments, and every fragment  has 300 examples. There are 100 clients and I allocate 2 fragments randomly to every client. This is the situation of some clients. 
 
 I use this data set to train my TFF model. The accuracy of train set is about 0.99 but the accuracy of test set is only about 0.5. I try many times but no change. 
And I think maybe the model is over-fit so I add two dropout to test, but I get the same result. Then I change relu() funcion to leakyrelu(), and change the optimizer function from SGD to Adam, but accuracy also is about 0.5. I dont why. I know Non-IID will cause descend of accuracy and FedAvg can relieve it. TFF use FedAvg to aggregate client model that means I have use FedAvg to be my underlying structure, is it right? But why I get a so low accaracy?   
",43936.02431
243,70715524,TensorFlow Federated - work sparsetensor,"TensorFlow Federated - work SparseTensors   I use TensorFlow Federated simulate scenario client host remote server work sparse dataset federate setting .    presently , code capable run small subset sparse dataset load server - side pass remote worker host another device . datum SVM Light format load sklearn   load_svmlight_file   function , need convert tensor work within tff . current solution involve convert sparse datum dense array , set   tf.data . dataset.from_tensor_slice   function use keras model ( follow exist example tff ) .    this work , take significant memory resource suitable dataset can not run remotely six sample due sparse data serialized size , locally hundred sample due size memory .    to mitigate this , convert datum SparseTensors , approach fail due   tff.learning.from_keras_model   function expect pair TensorSpec input_spec value , sparsetensorspec input_spec label TensorSpec .    so , concrete example know method work SparseTensors within keras model tff ? must tensor now ? datum load fine convert regular Tensors need find solution work sparse datum .    if presently way so , example strategy within tff work small subset datum time , either load directly remote client pass server ?    thank !","TensorFlow Federated - How to work with SparseTensors  I am using TensorFlow Federated to simulate a scenario in which clients hosted on a remote server can work with our very sparse dataset in a federated setting. 
 Presently, the code is capable of running with a small subset of the very sparse dataset being loaded on the server-side and passing it to the remote workers hosted on another device. The data is in SVM Light format and can be loaded through sklearns  load_svmlight_file  function, but needs to be converted into Tensors to work within tff. The current solution to do so involves converting the very sparse data into a dense array, then setting it up through the  tf.data.Dataset.from_tensor_slices  function for use with a keras model (following existing examples for tff). 
 This works, but takes up significant memory resources and is not suitable for the dataset as it cannot be run remotely for more than six samples due to the sparse datas serialized size, nor locally with more than a few hundred samples due to the size in memory. 
 To mitigate this, I converted the data into SparseTensors, but this approach fails due to the  tff.learning.from_keras_model  function expecting a pair of TensorSpec input_spec values, not a SparseTensorSpec input_spec with the labels being TensorSpec. 
 So, are there any concrete examples or known methods to work with SparseTensors within keras models in tff? Or must they be as Tensors for now? The data loads fine when not converted to regular Tensors so I will need to find a solution for working with the sparse data. 
 If there is presently no way to do so, are there examples of strategies within tff to work with very small subsets of data at a time, either being loaded directly with the remote client or being passed from the server? 
 Thanks! 
",44575.80278
244,70745268,TensorFlow Federated - Loading preprocessing datum remote client,"TensorFlow Federated - Loading preprocessing datum remote client   Part simulation program working allow client load local datum device without server able access datum .    follow idea , follow code configure assign client path load datum from . although datum svmlight format , loading line - by - line still allow preprocesse afterwards .      the code allow path load runtime remote client - side follow line code .      here , data variable iterate use display content client remote device call tf.print ( ) . but , need preprocess datum appropriate format continue . presently attempt convert string Tensor svmlight format SparseTensor appropriate format .    the issue that , although define preprocessing method work standalone scenario ( i.e. define function test manually define Tensor format ) , fail code execute client update @tf.function tff algorithm . specify error execute notebook cell contain @tff.tf_computation function call @tf.function preprocessing retrieve datum .    ValueError : Shape must rank 1 rank 0 { { node Reshape_2 } } = Reshape[T = DT_INT64 , Tshape = DT_INT32](StringToNumber_1 , Reshape_2 / shape ) input shape : [ ? , ? ] , [ ] .    since issue occur execute client @tff.tf_computation update function call @tf.function preprocesse code , wonder allow function perform preprocesse datum without error . assume get function properly run define call remotely work .    any idea address issue ? thank help !    for reference , preprocesse function use tf computation manipulate datum . although optimal yet , code presently use . inspire   string_split example . extract code put directly client @tf.function loading textlinedataset well , also fail .      Update ( Fix )    follow advice jakub comment , issue fix enclose reshape expand_dim call [ ] , need . issue run code within tff .  ","TensorFlow Federated - Loading and preprocessing data on a remote client  Part of the simulation program that I am working on allows clients to load local data from their device without the server being able to access that data. 
 Following the idea from , I have the following code configured to assign the client a path to load the data from. Although the data is in svmlight format, loading it line-by-line can still allow it to be preprocessed afterwards. 
 
 The code above allows a path to be loaded during runtime from the remote clients-side by the following line of code. 
 
 Here, the data variable can be iterated through and can be used to display the contents on the client on the remote device when calling tf.print(). But, I need to preprocess this data into an appropriate format before continuing. I am presently attempting to convert this from a string Tensor in svmlight format into a SparseTensor of the appropriate format. 
 The issue is that, although the defined preprocessing method works in a standalone scenario (i.e. when defined as a function and tested on a manually defined Tensor of the same format), it fails when the code is executed during the client update @tf.function in the tff algorithm. Below is the specified error when executing the notebook cell which contains a @tff.tf_computation function which calls an @tf.function which does the preprocessing and retrieves the data. 
 ValueError: Shape must be rank 1 but is rank 0 for {{node Reshape_2}} = Reshape[T=DT_INT64, Tshape=DT_INT32](StringToNumber_1, Reshape_2/shape) with input shapes: [?,?], []. 
 Since the issue occurs when executing the clients @tff.tf_computation update function which calls the @tf.function with the preprocessing code, I am wondering how I can allow the function to perform the preprocessing on the data without errors. I assume that if I can just get the functions to properly be run when defined that when called remotely it will work. 
 Any ideas on how to address this issue? Thank you for your help! 
 For reference, the preprocessing function uses tf computations to manipulate the data. Although not optimal yet, below is the code presently being used. This is inspired from  on string_split examples. I have extracted the code to put directly into the clients @tf.function after loading the TextLineDataset as well, but this also fails. 
 
 Update (Fix) 
 Following the advice from Jakubs comment, the issue was fixed by enclosing the reshape and expand_dim calls in [], when needed. Now there is no issue running the code within tff. 
 
",44578.72569
245,70825390,limited number client use federate learning,"limited number client use federate learning   I start study federate learning want apply certain dataset , question rise up .    my datum contain record 3 category , 3 department . plan 3 different federate learning model category treat three department category distribute client .    be possible ? build federate learning model require thousand client ?    thank","Limited number of clients used in federated learning  I just started studying federated learning and want to apply it to a certain dataset, and there are some questions that have risen up. 
 My data is containing records of 3 categories, each of which is having 3 departments. I am planning to have 3 different federated learning models for each category and treat the three department of this category as the distributed clients. 
 Is this possible? or building federated learning models requires having thousands of clients? 
 Thanks 
",44584.77778
246,71037598,gather client weight server TFF ?,"gather client weight server TFF ?   I try implement custom aggregation use tff change code   . would like rewrite    client weight place server computation .    remove tff - nightly , try use   .    this far :      however result follow exception :  ","How to gather all client weights at server in TFF?  I am trying to implement a custom aggregation using TFF by changing the code from this  . I would like to rewrite   so that all the client weights are placed at the server for further computations. As   was removed from tff-nightly, I am trying to do that using  . 
 This is what I have so far: 
 
 However this results in the following Exception: 
 
",44600.69722
247,71160311,tensorflow federate can not import google collabs notebook,"tensorflow federate can not import google collabs notebook   I write follow code new google collab notebook :      and get error message import   :      these error seem spawn module instal colab itself , instead code .   any idea do fix this ?","Tensorflow federated cant be imported on google collabs notebook  I wrote following codes on a new google collabs notebook: 
 
 And I got these error messages while importing  : 
 
 These errors seem to be spawning from the modules installed on the colabs itself, instead of my code.
 Any idea on what can be done to fix this? 
",44609.61667
248,71167600,build federate learning model unbalanced small dataset,"build federate learning model unbalanced small dataset   I work build federate learning model use TFF question :      I prepare dataset , separate file datum , feature different sample . would consider file single client . maintain TFF ?      the datum balance , meaning , size datum vary file . affect modeling process ?      the size data bit small , one file ( client ) 300 record another 1500 record , suitable build federate learning model ?        thank advance","How to build federated learning model of unbalanced and small dataset  I am working to build a federated learning model using TFF and I have some questions: 
 
 I am preparing the dataset, I have separate files of data, with same features and different samples. I would consider each of these files as a single client. How can I maintain this in TFF? 
 
 The data is not balanced, meaning, the size of data varies in each file. Is this affecting the modeling process? 
 
 The size of the data is a bit small, one file (client) is having 300 records and another is 1500 records, is it suitable to build a federated learning model? 
 
 
 Thanks in advance 
",44610.08681
249,71179882,Runtime Error : tensorflow.python.framework.errors_impl . NotFoundError : could find metadata file . [ [ { { node LoadDataset/_1 } } ] ] [ op : DatasetFromGraph ],"Runtime Error : tensorflow.python.framework.errors_impl . NotFoundError : could find metadata file . [ [ { { node LoadDataset/_1 } } ] ] [ op : DatasetFromGraph ]   as , try execute    orchestrator ( server ) datum save edge node ( client ) use    method :      however , I m get follow error :      TF datum save use    method . implementation work execute locally :     python - 3.7    librarie version :    tensorflow - 2.5.2    tensorflow - estimator - 2.5.0    tensorflow - federate - 0.19.0    any help would appreciate .","Runtime Error: tensorflow.python.framework.errors_impl.NotFoundError: Could not find metadata file. [[{{node LoadDataset/_1}}]] [Op:DatasetFromGraph]  As , trying to execute   but on orchestrator (server) with data saved on edge node (client) using   method: 
 
 However, Im getting the following error: 
 
 TF data was saved using   method. The implementation works when executed locally:  
 python - 3.7 
 libraries versions: 
 tensorflow - 2.5.2 
 tensorflow-estimator - 2.5.0 
 tensorflow-federated - 0.19.0 
 Any help would be most appreciated. 
",44610.88194
250,71231671,solve ValueError : unable unpack value [ ] tf.compat.v1.graphdef,"solve ValueError : unable unpack value [ ] tf.compat.v1.GraphDef   I m follow tutorial tensorflow_federate : custom_federated_algorithms_2 . everything work copy run tutorials code . wanna change code familar tff . bug appear .    my runtime environment :    python :     tensorflow :     tensorflow_federate :     Code orginal code testing model tutorial :      and change    into :      thank structure model change , process forward pass need change too :      I change    code .      and work fine far . implement    section , error appear even use original code .  ","How to solve ValueError: Unable to unpack value [] as a tf.compat.v1.GraphDef  Im following the tutorial of TensorFlow_Federated: custom_federated_algorithms_2. Everything works when I just copy and run the tutorials code. So I wanna change the code by myself for being more familar with tff. Then bug appeared. 
 My runtime environment: 
 python:  
 tensorflow:  
 tensorflow_federated:  
 Code below is the orginal code of testing model in tutorial: 
 
 And I changed the   into: 
 
 Thanks to the structure of model changed, the process of forward pass needs to be changed too: 
 
 I didnt change the   code. 
 
 And it works fine so far. But when implementing the   section, errors appeared even I just using the original code. 
 
",44615.21806
251,61243073,tensorflow - federate support dynamic batch size ?,"tensorflow - federate support dynamic batch size ?   do tensorflow - federate support assign different batch - size different simulated device , change batch - size different epoch ?","Does tensorflow-federated support dynamic batch size?  Does tensorflow-federated support assigning different batch-size for different simulated devices, and changing batch-size for different epoch? 
",43937.21458
252,61268081,install Tensorflow federate directly GitHub local download ?,"install Tensorflow federate directly GitHub local download ?   I want access feature TensorFlow federate ( tff.python.research ) present pip3 install method .    I m work remote server bazel , thus can not build source . way get install late work version TFF GitHub REPO ?    ( )","How to install Tensorflow federated directly from GitHub or local download?  I want to have access to features from TensorFlow federated (tff.python.research) which arent present with the pip3 install method. 
 Im working on a remote server that does not have bazel, thus I cannot build from source. Are there other ways to get and install the latest working version of TFF from its GitHub REPO? 
 () 
",43938.38889
253,61393106,tensorflow - federate support place training datum client side ?,"tensorflow - federate support place training datum client side ?   its awesome see tensorflow - federate could support distribute training now . refer example . however , seem training datum send server client epoch , client(remote_executor_service ) hold dataset . different typical federate learn scenario . wonder could place training datum separately client ?","Does tensorflow-federated support placing training data on client side?  Its very awesome to see that tensorflow-federated could support distributed training now. I referred to the example . 
However, it seems the training data are sent from server to client at each epoch, and the client(remote_executor_service) doesnt hold any dataset. It is different from typical federated learning scenario. So I was wondering could I place training data separately on each client? 
",43944.71806
254,61393382,build research use external package research project,"build research use external package research project   I want perform research regard quantization / sparsification , would like use run_experiment.py script template , clean matter research part pip package wonder possible build reuse dependency ( as run_experiment.py function research use ) . sure however it . familiar bazel . able install run script , that s all . guidance would highly appreciate ! possible would good know well ! thank advice matter .    EDIT : build something use bazel bazel - bin know however reuse script , want python manner        somehthing similar script","build research and use it as an external package for research project  I want to perform some research regarding quantization/sparsification, I would like to use run_experiment.py script as a template, to do so in a clean matter as research is not part of the pip package I was wondering if it is possible to build it myself and then reuse it as a dependency (as in run_experiment.py some functions from research are used). I am not sure however how to do it. I am not familiar with bazel. I was able to install it and run the script, thats all. Any guidance would be highly appreciated! Or if its not possible it would be good to know as well! Thank you for any advice in this matter. 
 EDIT:
I built something using bazel and I have it in bazel-bin I dont know now however how to reuse it in my script, as if I just wanted to do it in a python manner  
   
or somehthing similar in my script 
",43944.72847
255,61419057,TFF : create Non - IID dataset,"TFF : create Non - IID dataset   I 2 class every class 140 example , 4 client , would like create non - iid dataset like paper McMahan , divide example fragment ?","TFF: How create a Non-IID dataset  I have 2 classes and every class has 140 examples, and I have 4 clients, I would like to create a non-iid dataset like the paper of McMahan, how divide examples into fragments ?  
",43945.98403
256,61450093,TFF : accuracy increase simulate random sample user,"TFF : accuracy increase simulate random sample user   by simulate tff code random choice client round , find accuracy increase 0.9 relapse 0.5 0.8 0.6 on , increase . idea ? thank you !","TFF: accuracy is not increasing while simulating random samples of users  By simulating a tff code with random choice of clients in each round, I find that the accuracy increases to 0.9 then relapses to 0.5 and then from 0.8 to 0.6 and so on, it is not increasing.
have you any idea? 
Thank you! 
",43948.03403
257,61458419,tensorflow Federated | tff.learning.from_keras_model ( ) model DenseFeature layer multiple input,"tensorflow Federated | tff.learning.from_keras_model ( ) model DenseFeature layer multiple input   I try federate keras model multiple input . input categorical numerical , DenseFeature layer embed value .    the problem use    expect input_spec dictionary 2 element ( x , y ) multiple input distinguish model perform embed correctly feature_columns function densefeature layer .    how handle single feature column model accept x input without proper column name ?    here code error :            error call :        preprocessed_example_dataset.element_spec :  ","Tensorflow Federated | tff.learning.from_keras_model() with a model with DenseFeature layer and multiple inputs  I am trying to federate a keras model which has multiple inputs.
These some of these inputs are categorical and some of them are numerical, so I have some DenseFeature layers to embed the values. 
 The problem is that using    to expect as input_spec a dictionary with just 2 elements (x,y) but I have multiple inputs which then I have to distinguish in the model to perform the Embedding correctly with the feature_columns functions and the DenseFeature layers. 
 How can I handle the single feature columns if the model accepts just an x as input without proper columns names? 
 Here is the code and the error: 
 
 
 
 
 error when called: 
 
 
 preprocessed_example_dataset.element_spec: 
 
",43948.5
258,61603476,NameError : name filecheckpointmanager define saving model,"NameError : name filecheckpointmanager define saving model   after simulate code federate learn image classification , would like save model add two line      so code :      but error appear :       I appreciate tell solve problem","NameError: name FileCheckpointManager is not defined while saving model  after simulating this code of federated learning for image classification, I would like to save my model so I add this two lines 
 
 So here is all my code: 
 
 But this error does appear:  
 
 I will appreciate it if you told me how I solve this problem 
",43955.98889
259,71251685,module keras.api._v2.keras.experimental attribute peepholelstmcell,"module keras.api._v2.keras.experimental attribute PeepholeLSTMCell   I try install tensorflow_federate google colab . use      and work . try import get error :      I know get error , problem before .    I also use follow code install tensorflow - federate :      but get error .    how fix it ?    my version be :    ,   ,","module keras.api._v2.keras.experimental has no attribute PeepholeLSTMCell  I tried to install tensorflow_federated in google colab. I used 
 
 and it worked. but now when I try to import it get this error: 
 
 I dont know why I get this error, because I didnt have any problem before. 
 I also used the following code to install tensorflow-federated: 
 
 but I get the same error. 
 How do I fix it? 
 My versions are: 
 ,
 ,
 
",44616.50347
260,71273332,tff.simulation.datasets . clientdata build federate learning model CSV file,"tff.simulation.datasets . clientdata build federate learning model CSV file   I build federate learning model use dataset . aim build multi classification model . datum present separate 8 csv file .    I follow instruction   show code below .      but give error      I read   find    method would work , replace    error disappear do not know right next ?    my question be :      it right method upload datum client ?    if possible upload CSV file separately , combine datum one CSV file consider non - iid datum train accordingly ? need guidance here      and thank advance","tff.simulation.datasets.ClientData to build federated learning model from CSV files  I am building a federated learning model using my own dataset.
I aim to build a multi classification model.
The data are presented in separate 8 CSV files. 
 I followed the instructions in this  As shown in the code below. 
 
 but it gave me this error 
 
 I was reading this  and found that   methods would work, so I replaced with   and the error disappeared but I dont know if it is right and what is next? 
 My questions are: 
 
 it this is a right method to upload the data to the clients? 
 if it is not possible to upload the CSV files separately, can I combine all of the data into one CSV file and then consider them as a non-IID data and train them accordingly?
I need some guidance here 
 
 and thanks in advance 
",44618.05556
261,71285825,use create_tf_dataset_for_client ( ) define training example dataset,"use create_tf_dataset_for_client ( ) define training example dataset   I prepare dataset federation setting , code below , multiple CSV file use consider single client .      I want access datum determine      column . type :      there row since big size datum   access datum tensor object ,   Question1   state       question2   split file training testing set start training process ?","Using create_tf_dataset_for_client() to define the training examples in the dataset  I am preparing a dataset for federation settings, in the code below, I have multiple CSV files and used each is considered a single client. 
 
 I wanted to access the data so I can determine the   and   column. so I typed: 
 
 there are more rows since I have a big size of data 
So I can access these data as they are tensor objects,
 Question1  how can I state that  
and  
 Question2  How can I split each file to training and testing sets to start the training process? 
",44619.62431
262,71289273,TFF : train_test_client_split partition client datum,"TFF : train_test_client_split partition client datum   I build federate learning model . write code below , keep get error , also true please let know use function    properly ?        the file path correct , know problem here ?","TFF: train_test_client_split to partition each client data  I am building a federated learning model.
I have written the code below, but I keep getting the error, which is also not true
please let me know how to use the function   properly? 
 
 
 The file is there and the path is correct, but I dont know what it the problem here? 
",44619.97847
263,71322383,tff : define usage Tensorflow.take ( ) function,tff : define usage Tensorflow.take ( ) function   I try mimic federate learning implementation provide   order understand code clearly . reach point need clarification in .        what    refer to ? batch take datum train 3 testing ?    what    mean ?  ,"Tff: define the usage of Tensorflow.take() function  I am trying to mimic the federated learning implementation provided  in order to understand the code clearly.
I reached to this point where I need clarification in. 
 
 
 what does   refer to? are these batches are taking from the data to training and the 3 are for testing? 
 what does   mean? 
 
",44622.50208
264,71330639,split datum training testing federate learn,"split datum training testing federate learn   I new federate learning currently experiment model follow official TFF documentation . stick issue hope find explanation here .    I use dataset , datum distribute multiple file , file single client ( as plan structure model ) . dependant independent variable define .    now , question split datum training testing set client(file ) federate learning ? like -normally- centralize ML model   follow code implement far :   note   code inspire official documentation   almost similar application , aim split client training testing client aim split datum inside client .      my understanding supervise ML split data training testing set code , sure Federated learn whether work way not ?      so , please look explanation issue proceed training phase .","splitting the data into training and testing in federated learning  I am new in federated learning
I am currently experimenting with a model by following the official TFF documentation. But I am stuck with an issue and hope I find some explanation here. 
 I am using my own dataset, the data are distributed in multiple files, each file is a single client (as I am planning to structure the model). and the dependant and independent variables have been defined. 
 Now, my question is how can I split the data into training and testing sets in each client(file) in federated learning? like what we -normally- do in the centralized ML models 
The following code is what I have implemented so far:
 note  my code is inspired by the official documentation and this  which is almost similar to my application, but it aims to split the clients as training and testing clients itself while my aim is to split the data inside these clients. 
 
 My understanding to supervised ML is to split the data into training and testing sets as in the below code, I am not sure how to do this in Federated learning and whether it will work this way or not? 
 
 So, please I am looking for an explanation for this issue so I can proceed to the training phase. 
",44623.00278
265,71396780,load multiple csv file ( silos ) compose Tensorflow Federated dataset,"load multiple csv file ( silos ) compose Tensorflow Federated dataset   I work pre - process datum already siloe separate csv file represent separate local datum federate learning .    to correct implement federate learn multiple csv TensorFlow Federated , try reproduce approach toy example iris dataset . however , try use method   , get error :      the current code follow , first , load three iris dataset CSV file ( 50 sample each ) dictionary filename iris1.csv , iris2.csv , iris3.csv :      create new dict tensor :      finally , try convert Tensorflow Dataset Tensorflow Federated dataset :      that raise error :      I also try use Python dictionary instead OrderedDict error same . experiment , use Google Colab   reference run TensorFlow 2.8.0 TensorFlow Federated version 0.20.0 . also use previous question reference :        I sure good way derive case beyond toy example , please , suggestion bring already siloe datum tff test , thankful .","Loading multiple CSV files (silos) to compose Tensorflow Federated dataset  I am working on pre-processed data that were already siloed into separated csv files to represent separated local data for federated learning. 
 To correct implement the federated learning with these multiple CSVs on TensorFlow Federated, I am just trying to reproduce the same approach with a toy example in the iris dataset. However, when trying to use the method  , I am getting the error: 
 
 The current code is as follows, first, load the three iris dataset CSV files (50 samples on each) into a dictionary from the filenames iris1.csv, iris2.csv, and iris3.csv: 
 
 Creating a new dict with tensors: 
 
 Finally, trying to converting the Tensorflow Dataset into a Tensorflow Federated Dataset: 
 
 That raises the error: 
 
 I also tried to use Python dictionary instead of OrderedDict but the error is the same. For this experiment, I am using Google Colab with  as reference running with TensorFlow 2.8.0 and TensorFlow Federated version 0.20.0. I also used these previous questions as references: 
 
 
 I am not sure if this is a good way that derives for a case beyond the toy example, please, if any suggestion on how to bring already siloed data for TFF tests, I am thankful. 
",44628.60972
266,71426658,tensorflow Federated learn multiple machine,tensorflow Federated learn multiple machine   I try implement federate learn Tensorflow Federated . able run tensorflow model dataset exist client machine . process follow below .      I one server machine host dataset use federated learning . create model TFF learn average process server .    the remote executor service run client machine(GCP VM ) . server broadcast work fine model training execute client machine .    but datum model training pass parameter client machine broadcast process . way train model data host client machine ?  ,"Tensorflow Federated learning on multiple machines  I am trying to implement federated learning with Tensorflow Federated. I am not able to run the tensorflow model on the dataset existing on the client machine. The process followed is as below. 
 
 I have one server machine which host the dataset to be used for federated learning. I have created the model and TFF learning average process in the server. 
 The remote executor service is running on a client machine(GCP VM). The server broadcast is working fine and the model training is executing on the client machine. 
 But the data for the model training is passed as a parameter to client machine with the broadcast process. Is there a way to train the model with the data hosted on the client machine? 
 
",44630.64236
267,71428904,"valueerror : layer sequential expect 1 input(s ) , receive 10 input tensor","valueerror : layer sequential expect 1 input(s ) , receive 10 input tensor   I follow TFF tutorial build FL model datum contain different CSV file consider different client . follow , build Keras model function follow      then follow instruction run    function tutorial , like   ,   ,     . run def    get error      note :      each CSV file 10 column feature ( input ) one column label ( output ) .    I add    arbitrary , really know shape datum column ?      so , question be , feed datum keras model overcome error    thank advance","ValueError: Layer sequential expects 1 input(s), but it received 10 input tensors  I am following TFF tutorials to build my FL model
My data is contained in different CSV files which are considered as different clients.
Following this , and build the Keras model function as following 
 
 Then I followed instructions and run other   functions as the tutorial, like  ,  ,   and  . But when I run the def   I got this error 
 
 Notes: 
 
 each CSV file has 10 column as features (input) and one column as label (output). 
 I added the   arbitrary, I dont really know what are the shape of the data is in each column? 
 
 So, the question is, how to feed the data to the keras model and overcome this error 
 Thanks in advance 
",44630.75972
268,71441616,"mnist dataset , MobileNet show low accuracy tff learn environment show high accuracy tensorflow env . improve accuracy ?","mnist dataset , MobileNet show low accuracy tff learn environment show high accuracy tensorflow env . improve accuracy ?   the accuracy stick 0.111 every round . model give accuracy 91 % normal tensorflow environment . optimizer use scenario SGD . model function : `      `","On Mnist dataset, MobileNet is showing low accuracy in tff learning environment but shows high accuracy in tensorflow env. How to improve accuracy?  The accuracy is stuck on 0.111 on every round. But the same model gives an accuracy of 91% in the normal tensorflow environment. The optimizer used in both scenarios is SGD. The model function :
` 
 
 ` 
",44631.68472
269,71441870,train global local model federate learning,"train global local model federate learning   while study Federated Learning , question pop mind need clarification .      we first define client , client split training testing set . training datum use train local model . now , test datum use for ? use test global model ? test local model ?    when train global model , first calculate resulted weight local model , send global model . model local client , validity check model send global model send anyway update global model .      be paper explain point ?","Training the global and local model in federated learning  While I am studying Federated Learning, I have some questions that popped up in my mind that needed some clarification. 
 
 We first have defined clients, each client will be split into training and testing sets. The training data are used to train the local models. Now, what testing data are used for? are they used to test the global model? or to test each local model? 
 when training the global model, we first calculate the resulted weight of each local model, and then send it to the global model. In modeling the local clients, is there any validity check on the model itself before sending to the global model or it is sent anyway and then it will be updated by the global model. 
 
 Are there any papers explaining these points? 
",44631.69653
270,71470160,TFF : trainable = true   cause decrinse accuracy,"TFF : trainable = true   cause decrinse accuracy   I work TFF , part code :      with model find test - accuracy value =    now , would like change   , test - accuracy value decrease    loss become   . normal , anyone tell why .","TFF: trainable=True  causes decrinsing of accuracy  I work with TFF, here is a part of my code : 
 
 With this model I find test-accuracy value =  
Now, I would like to change  , but the test-accuracy value decrease to   and loss becomes  . which is not normal, can anyone tell why. 
",44634.63958
271,71496155,tff : modify value state,"tff : modify value state   the state object return iterative_process.initialize ( ) typically Python container ( tuple , collection . OrderedDict , etc ) contain numpy array . would like value state random , instead begin loaded model . begin , write :      but test accuracy result change compare normal case(if load external model ) .    that s why , try solution :      but find error :      so case , define next_fn ? thank","TFF : Modify the value of state  The state object returned by iterative_process.initialize() is typically a Python container (tuple, collections.OrderedDict, etc) that contains numpy arrays. I would like that the value of state is not random, instead it begin from loaded model.
As the beginning, I write this : 
 
 But test accuracy result does not change at all comparing by the normal case(if I dont load an external model). 
 Thats why, I try this solution: 
 
 But I find this error: 
 
 So in my case, how can I define next_fn ?
Thanks 
",44636.47014
272,61677696,model performance improve federated learning training,"model performance improve federated learning training   I follow   create image classification experiment ( 7 class ) aim train classifier 3 silo datum TFF framework .    before training begin , convert model tf keras model use    evaluate validation set . regardless label , model predict one class . expect training model occur yet . however , repeat step federate average round problem persist . validation image predict one class . also save tf keras model weight round make prediction test set - change .    some step take check source issue :      check tf keras model weight update FL model convert round - updating .    ensure buffer size great training dataset size client .    compare prediction class distribution training dataset . class imbalance one class model predict necessarily majority class . also , always class . part , predict class 0 .    increase number round 5 epoch per round 10 . computationally intensive quite large model train approx 1500 image per client .    investigate TensorBoard log training attempt . training loss decrease round progress .    try much simple model - basic CNN 2 conv layer . allow greatly increase number epoch round . evaluate model test set , predict 4 different class performance remain bad . would indicate would need increase number round epoch original model increase variation prediction . difficult due large training time would result .      Model detail :    the model use XceptionNet base model weight unfrozen . perform well classification task training image pool global dataset . aim hopefully achieve comparable performance FL .      here train code :  ","Model performance not improving during federated learning training  I have followed  to create an image classification experiment (7 classes) with the aim of training a classifier on 3 silos of data with the TFF framework. 
 Before training begins, I convert the model to a tf keras model using   to evaluate on my validation set. Regardless of the label, the model only predicts one class. This is to be expected as no training of the model has occurred yet. However, I repeat this step after each federated averaging round and the problem persists. All validation images are predicted to one class. I also save the tf keras model weights after each round and make predictions on the test set - no changes. 
 Some of the steps I have taken to check the source of the issue: 
 
 Checked if the tf keras model weights are updating when the FL model is converted after each round - they are updating. 
 Ensured that the buffer size is greater than the training dataset size for each client. 
 Compared the predictions to the class distribution in the training datasets. There is a class imbalance but the one class that the model predicts is not necessarily the majority class. Also, it is not always the same class. For the most part, it predicts only class 0. 
 Increased the number of rounds to 5 and epochs per round to 10. This is computationally very intensive as it is quite a large model being trained with approx 1500 images per client. 
 Investigated the TensorBoard logs from each training attempt. The training loss is decreasing as the round progresses. 
 Tried a much simpler model - basic CNN with 2 conv layers. This allowed me to greatly increase the number of epochs and rounds. When evaluating this model on the test set, it predicted 4 different classes but the performance remains very bad. This would indicate that I just would need to increase the number of rounds and epochs for my original model to increase the variation in predictions. This is difficult due the large training time that would be a result. 
 
 Model details: 
 The model uses the XceptionNet as the base model with the weights unfrozen. This performs well on the classification task when all the training images are pooled into a global dataset. Our aim is to hopefully achieve a comparable performance with FL. 
 
 Here is my training code: 
 
",43959.46181
273,61786305,TFF loading pre - train Keras model,"TFF loading pre - train Keras model   my goal load base model .hdf5 file ( its Keras model ) , continue train federate learning . initialize base model FL :      however , seem like result state.model weight randomly initialize , different saved model . evaluate model performance even federate training , perform randomly initialize model : 50 % accuracy . here evaluate performance :      how initialize tff model save model weight ?","TFF loading a pre-trained Keras model  My goal is to load a base model from a .hdf5 file (its a Keras model), and continue to train it with federated learning. Here is how I initialize the base model for FL: 
 
 However, it seems like the resulting state.model weights are randomly initialized, and are different from my saved model. When I evaluate the models performance even before any federated training, it performs as a randomly initialized model: 50% accuracy. Heres how I evaluate the performance: 
 
 How can I initialize a tff model with the saved model weights? 
",43964.95625
274,61882422,` tensorflow_federated.learning.from_keras_model ( ) ` long contain dummy_batch keyword ?,"` tensorflow_federated.learning.from_keras_model ( ) ` long contain dummy_batch keyword ?   I run tensorflow federate tutorial code   . get error       the provide notebook update    late version , tff version 0.14.0 . version 0.14.0 , long need feed dummy batch ? usual tff work pipline change ?    P.S. Downgrading    version 0.13.1 work .","`tensorflow_federated.learning.from_keras_model()` no longer contains dummy_batch keyword?  I ran the tensorflow federated tutorial code on  . I got this error  
 
 The provided notebook updates the   to latest version, so tff version is 0.14.0. So in version 0.14.0, we no longer need to feed the dummy batch? Is usual tff working pipline has changed? 
 P.S. Downgrading   to version 0.13.1 works. 
",43970.11736
275,62040659,Grid Search Applicable TFF FL . ?,"Grid Search Applicable TFF FL . ?   I m currently research TFF image classification ( Federated Learning Image Classification ) emnist .    I m look hyper parameter model learn rate optimizer . grid search good approach ? . real world scenario would simply sample client / device overall domain grid search would fix client sample 1st . case make sense grid search .     what would typical real world way select parameter , ie heuristic approach . ?    Colin . . .","Grid Search Applicable for TFF and FL.?  Im currently researching with TFF and image classification (Federated Learning for Image Classification) emnist. 
 Im looking at hyper parameters for the model learning rate and optimizer. Is grid search a good approach here ? . In a real world scenario would you simply sample clients/devices from the overall domain and if so if I was to do a grid search would I have to fix my client samples 1st. In which case does it make sense to do the grid search.  
 What would be a typical real world way of selecting parameters, ie is this more a heuristic approach. ? 
 Colin . . . 
",43978.42639
276,71506975,"valueerror : miss data input input_2 . pass datum dictionary key [ y , x ] . expect follow key : [ input_2 ]","valueerror : miss data input input_2 . pass datum dictionary key [ y , x ] . expect follow key : [ input_2 ]   follow previous code   process evaluate federate learning model get couple issue . code evaluation      this error message      so would problem here ? use method    right place ? since -as write - use   create centralize evaluation dataset . need use centralize dataset ?","ValueError: Missing data for input input_2. You passed a data dictionary with keys [y, x]. Expected the following keys: [input_2]  Following the previous code  I am in process to evaluate the federated learning model and I got couple of issues.
This is the code for evaluation 
 
 this is the error message 
 
 So what would be the problem here?
and is the use of the method   in its right place? since -as it is written in the - used for  create a centralized evaluation dataset . why do we need to use centralized dataset? 
",44637.17014
277,71607216,"print client local update ( loss , accuracy ) tensorflow federate","print client local update ( loss , accuracy ) tensorflow federate     but work . display blank value client execute first round . please look it . thank    round 1 , metric = ordereddict([(broadcast , ( ) ) , ( aggregation , OrderedDict([(value_sum_process , ( ) ) , ( weight_sum_process , ( ) ) ] ) ) , ( train , { accuracy : 0.0990099 , loss : 2.7817621 , num_examples : 202.0 , per_client / accuracy : < ConcatenateDataset shape : ( ) , type : tf.float32 > , per_client / loss : < ConcatenateDataset shape : ( ) , type : tf.float32 > , per_client / num_examples : < ConcatenateDataset shape : ( ) , type : tf.float32 > } ) ] )","how can print client local updates (loss, accuracy) in tensorflow federated  
 But it did not work. It displays blank values for a client on executing the first round. Can you please look into it. Thanks 
 round 1, metrics=OrderedDict([(broadcast, ()), (aggregation, OrderedDict([(value_sum_process, ()), (weight_sum_process, ())])), (train, {accuracy: 0.0990099, loss: 2.7817621, num_examples: 202.0, per_client/accuracy: <ConcatenateDataset shapes: (), types: tf.float32>, per_client/loss: <ConcatenateDataset shapes: (), types: tf.float32>, per_client/num_examples: <ConcatenateDataset shapes: (), types: tf.float32>})]) 
",44644.74236
278,71630891,"mismatch number element type spec value ` to_representation_for_type ` . type spec 2 element , value 5","mismatch number element type spec value ` to_representation_for_type ` . type spec 2 element , value 5   I use tensorflow fedprox implement federate learning.(tff.learning.algorithms.build_unweighted_fed_prox )      and result training be :    round 3 , sparse_categorical_accuracy= 0.6435834    round 4 , sparse_categorical_accuracy= 0.6955319    round 5 , sparse_categorical_accuracy= 0.74295634    round 6 , sparse_categorical_accuracy= 0.78176934    round 7 , sparse_categorical_accuracy= 0.80838746    round 8 , sparse_categorical_accuracy= 0.8300672    round 9 , sparse_categorical_accuracy= 0.8486338    round 10 , sparse_categorical_accuracy , 0.86639416      but want evaluate model test datum get error :      how fix it ?","Mismatched number of elements between type spec and value in `to_representation_for_type`. Type spec has 2 elements, value has 5  I use tensorflow fedprox to implement federated learning.(tff.learning.algorithms.build_unweighted_fed_prox) 
 
 and the result of training is: 
 round  3, sparse_categorical_accuracy= 0.6435834 
 round  4, sparse_categorical_accuracy= 0.6955319 
 round  5, sparse_categorical_accuracy= 0.74295634 
 round  6, sparse_categorical_accuracy= 0.78176934 
 round  7, sparse_categorical_accuracy= 0.80838746 
 round  8, sparse_categorical_accuracy= 0.8300672 
 round  9, sparse_categorical_accuracy= 0.8486338 
 round 10, sparse_categorical_accuracy, 0.86639416 
 
 but when I want to evaluate my model on test data I get error: 
 
 How do I fix it? 
",44646.78333
279,71672074,TFF : evaluate federate learning model get large increase loss value,"TFF : evaluate federate learning model get large increase loss value   I try evaluate Federated Learning model follow . code below      after that , train multiple round evaluate      I see accuracy increase , loss value large . fix it ? also , see train result every round ?","TFF: evaluating the federated learning model and got a large increase of loss value  I am trying to evaluate the Federated Learning model following this . As in the code below 
 
 after that, I train it for multiple rounds and then evaluate 
 
 I see that the accuracy increased, but the loss value is very large. Why is that and how can I fix it?
also, how can I see the train results of every round? 
",44650.23889
280,71680438,centralize server model update aggregated client metric TensorflowFederated,"centralize server model update aggregated client metric TensorflowFederated   I design Federated Learning model TensorFlow Federated framework . define iterative process below ,      I 2 remote worker run tffruntime remote executor service context running computation define   . model broadcast client   , identify client metric aggregate applied server model . single api    enough get metric client , aggregate update server model ? mean identify server model update ? anyone please help understand this .","How the centralized server model is updated with aggregated client metrics in TensorflowFederated  I have designed the Federated Learning model with TensorFlow Federated framework. Defined the iterative process as below, 
 
 I have 2 remote workers running the tffruntime remote executor service and the context for running computation is defined as  . When the model is broadcasted to the client with  , how can we identify that the client metrics is aggregated and applied to the server model. Is the single api   is enough to get the metrics from clients, aggregate and then update the server model? If means how can we identify that the server model is updated? Can anyone please help me to understand this. 
",44650.66389
281,71710530,train local model federate learning use logistic regression,"train local model federate learning use logistic regression   I build federate learning model use Tensorflow federate , follow tutorial provide official documentation . see , implementation provide use neural network local ML model . follow snippet .      since build multi - classification model ( 9 ) feature ( 4 ) target label . use different ML model local training , like ( logistic regression ) ? adjust that ?","Train the local model in federated learning using logistic regression  I am building a federated learning model using Tensorflow federated, and I am following the tutorials provided in the official documentation.
As I can see, most of the implementations provided are using a neural network as the local ML model. As I just did in the following snippet. 
 
 Since I am building a multi-classification model with (9) features and (4) target labels.
Can I use a different ML model for local training, like (logistic regression )? and how can I adjust that? 
",44652.71319
282,71748346,Keras model prediction tensorflow federate learning,"Keras model prediction tensorflow federate learn   I work TensorFlow Federated framework design keras model binary classification problem . define iterative process    broadcast model     after step execute try run prediction ,      but apply tff learn model weight state model , prediction work expect . show value row .      upon consecutive research , understand value -0.2798368 value state Modelweights        do need apply state model weight server model explicitly tff.learning.build_federated_averaging_process api take care update server model default ? give tff tutorial "" the aggregate model delta apply server use tf.keras.optimizer . optimizer.apply_gradient method server optimizer . ""      any guidance / suggestion go wrong ?","Keras model prediction after tensorflow federated learning  I am working with TensorFlow Federated framework and designed a keras model for a binary classification problem. I defined the iterative process with   and broadcasted the model with
 
 After the above steps are executed I tried to run the prediction, 
 
 But after applying the tff learning model weights of the state to the model, the prediction is not working as expected. It is showing the same value for all the rows. 
 
 Upon consecutive research, I understood that the the above value -0.2798368 is the value in state Modelweights 
 
 
 Do we need to apply the state model weights to the server model explicitly or the tff.learning.build_federated_averaging_process api will take care of updating the server model by default? It is given in the tff tutorial that ""The aggregate model delta is applied at the server by using the tf.keras.optimizers.Optimizer.apply_gradients method of the server optimizer."" 
 
 Any guidance/suggestions here as where am I going wrong? 
",44656.34375
283,71822452,Epochs vs Rounds federate learn,"Epochs vs Rounds federate learn   I apply federate averaging federate learning model . run model thousand round model still converge . increase number epoch training , differ number round ? reach convergence , since try increase number round take long time train ( I use Google Colab , execution time 24 hour also try subscribe Google Colab Pro use GPU work well )    the code training result provide below      and output show","Epochs vs Rounds in federated learning  I am applying federated averaging on my federated learning model. After running the model for thousands rounds the model still did not converged.
How can I increase the number of epochs in training, and how it differs from the number of rounds?
And how can I reach to convergence, since I tried to increase the number of rounds but it take long time to train (I am using Google Colab, and the execution time can not be more than 24 hours I also tried subscribed to Google Colab Pro to use the GPU but it did not work well) 
 The code and the training results are provided below 
 
 And the output in shown in
 
",44662.14722
284,71839866,anyone give comprehensive guide instal tensorflow - federate M1 Mac ?,"anyone give comprehensive guide instal tensorflow - federate M1 Mac ?   I follow instruction give official tf documentation , can not resolve various problem encounter . anyone experience instal tff m1 mac show overall process ?      everything seem fine accord terminal output , however , after      I get RunTimeError :      how resolve this ?","Can anyone give me a comprehensive guide to installing tensorflow-federated on M1 Mac?  i followed the instructions given by the official tf documentation, but i just cannot resolve the various problems encountered.
Did anyone have the experience installing tff on m1 mac and can show me your overall process? 
 
 everything seems to be fine according to the terminal output, however,
after 
 
 i got a RunTimeError: 
 
 how to resolve this? 
",44663.37639
285,71883746,miss require positional argument :,miss require positional argument :   I try implement federate learning base LSTM approach .      but get error want define iterative_process .      how fix it ?,"Missing required positional argument:  I tried to implement federated learning based on the LSTM approach. 
 
 but I got this error when I want to define iterative_process. 
 
 How do I fix it? 
",44666.49861
286,62063550,tensorflow Federated Image Classification Example # epoch major effect . model overfitte ?,"tensorflow Federated Image Classification Example # epoch major effect . model overfitte ?   I ve try characterize learning process ( accuracy loss ) Federated Learning Image Classification notebook tutorial TF Federated .    I m see major improvement speed convergence modify epoch hyperparameter . change epoch 5 , 10 , 20 etc . I m also see major increase training accuracy . suspect overfitte occur , though evaluate test set accuracy still high .    wonder go on . ?     my understand epoch param control forward / back prop client per round training . correct ? ie 10 round train 10 client 10 epoch would 10 Epochs X 10 client X 10 round . realise lager range client need etc expect see poor accuracy test set .     what see what s go on . could use evaluation check something like learn curve see overfitte occur ?     appear give single datum point , get individual test accuracy test example validate ?","Tensorflow Federated Image Classification Example #Epochs has major effect. Is the model overfitting?  Ive been trying to characterize the learning process (accuracy and loss) on the Federated Learning for Image Classification notebook tutorial with TF Federated. 
 Im seeing major improvements in speed of convergence by modifying the epoch hyperparameter. 
Changing epochs from 5, 10, 20 etc. But Im also seeing major increase in training accuracy. 
I suspect overfitting is occurring, though then I evaluate on the test set accuracy is still high. 
 Wondering what is going on. ?  
 My understanding is that the epoch param controls the # of forward/back prop on each client per round of training. Is this correct ? 
So ie 10 rounds of training on 10 clients with 10 epochs would be 10 Epochs X 10 Clients X 10 rounds.
Realise a lager range of clients is needed etc but I was expecting to see poorer accuracy on the test set.  
 What can I do to see whats going on. Could I use the evaluation check with something like learning curves to to see if overfitting is occurring ? 
 
Only appears to give a single data point, how can I get the individual test accuracy for each test example validated? 
",43979.47639
287,62092301,tff : TypeError save model,"tff : TypeError saving model   please need Help ! write code TFF , would like save model add line end code       the error be :  ","TFF : TypeError while saving model  Please I need Help!
After writing my code of TFF, I would like to save my model So I add this line in the end of code  
 
 The error was: 
 
",43980.75972
288,62273164,can not run event loop another loop run,"can not run event loop another loop run   RuntimeError : can not run event loop another loop run    try setup tensorflow_federate local . import version right :    CUDA = 10.1 ,     python = 3.6.9 ,    tensorflow = 2.2.0 ,    tf_federate = late    this error happen google Colab . but , happen local machine try federate computation . get runtime error : runtimeerror : can not run event loop another loop run  ","Cannot run the event loop when another loop is running  RuntimeError: Cannot run the event loop while another loop is running 
 Trying to setup tensorflow_federated in my local. All import versions are right: 
 CUDA = 10.1,  
 python = 3.6.9, 
 tensorflow = 2.2.0, 
 tf_federated = latest 
 This error is not happening in google Colab. But, happens in my local machine when I am trying to do any federated computations. I get the runtime error: 
RuntimeError: Cannot run the event loop while another loop is running 
 
",43991.01944
289,62298296,Kernel freeze run federate computation tensorflow_federate nest_asyncio,"Kernel freeze run federate computation tensorflow_federate nest_asyncio   I try run simple federate computation use tensorflow_federated . tff.federated_computation ( ) - > run this , kernel freeze able run cell .    TF - Federated need asyncio prevent   error .     my code available .","Kernel freezes when running federated computation with tensorflow_federated and nest_asyncio  I try to run a simple federated computation using tensorflow_federated.
tff.federated_computation() -> after running this, the kernel freezes and am not able to run other cells. 
 TF-Federated needs asyncio to prevent  error.  
 My code is available .  
",43992.32361
290,62311087,privacy Secrity training model use federate learning,privacy Secrity training model use federate learning   do federate learning provide privacy security model train ?,"Privacy Secrity for training model when using federated learning  Does federated learning provide privacy securities for the model being trained?  
",43992.7875
291,62323656,"TFF Federated Learning , Evaluation approach","TFF Federated Learning , Evaluation Approach   validate typical AI / ML model predicate datum available locally . split datum e.g. 80/20 % split , 80 % datum training , 20 % test / evaluation . scenario isnâ€ ™ t applicable FL paradigm .     use evaluation function TFF , validate individual   client   level   global   level . i.e.     next word prediction example scenario : perspective solution developer , may wish evaluate model accuracy   large   number user , perspective   single   user , want next word prediction model perform personal need .    Example ,       where previously define function random_client randomly sample domain available client . ?     do evaluate single client multiple client ?","TFF Federated Learning, Evaluation Approach  Validating with typical AI/ML models is predicated on all the data being available locally. 
Splitting the data into e.g. 80/20 % split, 80% data for training, and 20% for test/evaluation. 
This scenario isnâ€™t applicable to the FL paradigm.  
 Using the evaluation function with TFF, should you validate at the individual  client  level or at a  global  level. i.e.  
 Next word prediction example scenario:
From the perspective of the solution developer, you may wish to evaluate model accuracy over a  larger  a number of users, but from the perspective of a  single  user, you want your next word prediction model to be performed for your personal needs. 
 Example,  
 
 Where you have a previously define function random_clients to randomly sample from the domain of available clients.?  
 Do you evaluate on a single client or on multiple clients? 
",43993.49028
292,62332459,TFF : Custom input spec custom datum set - TypeError : object type TensorSpec len ( ),"TFF : Custom input spec custom datum set - TypeError : object type TensorSpec len ( )   1 : problem : need use custom datum set tff simulation . build tff / python / research / compression example run_experiment.py . error :       highlighting :   TypeError : object type TensorSpec len ( )    2 : try : look response to :   describe would need produce custom input spec for . might miss understand input spec .    if need this , well way , please tell .    3 : source :  ","TFF: Custom input spec with custom data set - TypeError: object of type TensorSpec has no len()  1: problem:
I have the need to use a custom data set in a tff simulation. I have built on the tff/python/research/compression example run_experiment.py. 
The error:  
 
 highlighting:  TypeError: object of type TensorSpec has no len() 
 2: have tried:
I have looked at the response to:  
describing what would be needed to produce a custom input spec for. 
I might be miss understanding input spec. 
 If I dont need to do this, and there is a better way, please tell. 
 3: source: 
 
",43993.82778
293,71898178,use tff.learning.build_federated_evaluation multiple round,"use tff.learning.build_federated_evaluation multiple round   I want evaluate federate learning model use   . initially , get reasonable result . run evaluation process multiple round ( as training phase do ) get stable result ?    the evaluation code provide below .      the evaluation output .  ","Use tff.learning.build_federated_evaluation for multiple rounds  I want to evaluate my federated learning model using  . Initially, got reasonable results. but can I run the evaluation process for multiple rounds (as in the training phase done ) to get more stable results? 
 The evaluation code is provided below. 
 
 The evaluation output. 
 
",44667.975
294,71899247,fedprox tensorflow federate ( TypeError : can not unpack non - iterable LearningProcessOutput object ),"fedprox tensorflow federate ( TypeError : can not unpack non - iterable LearningProcessOutput object )     on execute round 1 , throw ( typeerror : can not unpack non - iterable LearningProcessOutput object ) .    it work fine use Fedavg , fedprox","fedprox tensorflow federated (TypeError: cannot unpack non-iterable LearningProcessOutput object)  
 On executing the round 1, it throws  (TypeError: cannot unpack non-iterable LearningProcessOutput object). 
 It was working fine when we use Fedavg, but not with fedprox 
",44668.18194
295,71988768,"reproducibility , control Randomness , operator - level Randomness TFF","reproducibility , control Randomness , operator - level Randomness TFF   I TFF code take slightly different optimization path training across different run , despite set operator - level seed , numpy seed sample client round , etc .   talk randomness expectation TFF , find answer slightly confusing . case aspect randomness can not directly control even set operator - level seed one could ; one can not control way sub - session start end ?    to specific , operator - level seed code already set :      per - round client sampling ( which use numpy ) . verify initial model state across run , soon train start , model state start diverge across different run . divergence gradual / slow case , always .    the code quite complex , add here .","Reproducibility, Controlling Randomness, Operator-level Randomness in TFF  I have a TFF code that takes a slightly different optimization path while training across different runs, despite having set all the operator-level seeds, numpy seeds for sampling clients in each round, etc. The  does talk about randomness and expectation in TFF, but I found the answer slightly confusing. Is it the case that some aspects of the randomness cant be directly controlled even after setting all the operator-level seeds that one could; because one cant control the way sub-sessions are started and ended? 
 To be more specific, these are all the operator-level seeds that my code already sets:   and   for per-round client sampling (which uses numpy). I have verified that the initial model state is the same across runs, but as soon as training starts, the model states start diverging across different runs. The divergence is gradual/slow in most cases, but not always. 
 The code is quite complex, so not adding it here. 
",44675.55
296,72022654,attributeerror : module tensorflow_federated.python.learning attribute assign_weights_to_keras_model,attributeerror : module tensorflow_federated.python.learning attribute assign_weights_to_keras_model     it throw error can not assign weight . early work .,"AttributeError: module tensorflow_federated.python.learning has no attribute assign_weights_to_keras_model  
 It throws an error that we cannot assign weights. Earlier it was working. 
",44678.10833
297,72035825,typeerror : type object subscriptable import tensorflow_federated tff,"typeerror : type object subscriptable importing tensorflow_federated tff   I m work colab notebook , import tff ( import tensorflow_federated tff ) work month , suddenly , try import tff usual faced problem ..      even run colab tutorial itself ! link   issue !    appreciate idea suggestion !","TypeError: type object is not subscriptable when importing tensorflow_federated as tff  Im working in colab notebook, and the importing of tff (import tensorflow_federated as tff) was working for months, but suddenly, now when I try to import tff as usual I faced this problem.. 
 
 Even when I run it in the colab tutorial itself! in this link  I have the same issue! 
 Appreciate any idea or suggestions! 
",44678.92222
298,72052364,Models tensorflow Federated get stucke 0.1 accuracy,"Models tensorflow Federated get stucke 0.1 accuracy   I m try train federate model mnist dataset . use code avaible   setup . dataset version use one kera ( not federate version leaf use tff ) . I m make partition it , save dictionary implement ClientData instance   .   apply change work fine . however , change model simulation , every round give ~0.1 accuracy .    the model tutorial simple get , input layer 28 * 28=784 neuron stack output layer dim 10 Softmax activation :      and new model cnn :      Accuracy change round round first case , increase , reach 0.94 quite fast . second case run 240 round 3 fix client , 20k element each , 10 epoch , batch size 32 . still get ~0.1 accuracy loss ~2.3    the model work fine dataset . already test centrilize version federate version use Flower framework reach 0.99 accuracy . reason can not make work tff .    Environment : MacOs BigSur tensorflow==2.8.0 tensorflow - federated==0.22.0    I expect metric loss change more . could problem use Models ?    full code :      I ve similar problem model well , e.g. MobileNetV2 implement tf cifar10 : ` model = tf.keras.applications . MobileNetV2((32 , 32 , 3 ) , classes=10 , weight = none )","Models in Tensorflow Federated get stucked at 0.1 accuracy  Im trying train a federated model for the mnist dataset. I am using the code avaible at  for the setup.
The dataset version being used is the the one from keras (not the federated version from leaf that is used in tff). Im making a partition of it, saving it on a dictionary and implementing my ClientData instance with  . 
Applying this change works just fine. However, if I change the model from the simulation, every round gives me a ~0.1 accuracy. 
 The model in the tutorial is as simple as it can get, an input layer of 28*28=784 neurons stacked over an output layer of dim 10 with Softmax activation: 
 
 And the new model is a cnn: 
 
 Accuracy changed from round to round on the first case, increasing, reaching 0.94 quite fast.
On the second case I ran it for about 240 rounds with 3 fixed clients, 20k elements each, 10 epochs, batch size 32. Still couldnt get out of the ~0.1 accuracy and loss of ~2.3 
 The model works fine for this dataset. I already tested it on a centrilized version and a federated version using Flower framework reaching 0.99 accuracy. But for some reason I cant make it work on tff. 
 Environment:
MacOs BigSur
tensorflow==2.8.0
tensorflow-federated==0.22.0 
 I expect the metrics and loss to change more. Could it be that there is a problem with using other Models? 
 Full code: 
 
 Ive had a similar problem with other models as well, e.g.  MobileNetV2 implemented in tf for cifar10:
`model = tf.keras.applications.MobileNetV2((32, 32, 3), classes=10, weights=None) 
",44680.12778
299,72059732,unable install tensorflow Federated Apple Silicon M1,unable install Tensorflow Federated Apple Silicon M1   I TensorFlow ( 2.8.0 ) instal run Apple Silicon M1 MacBook . face dependency error try install tensorflow - federate error run    terminal :  ,"Unable to install Tensorflow Federated on Apple Silicon M1  I have TensorFlow (2.8.0) installed and running on my Apple Silicon M1 MacBook. But facing dependency error on trying to install tensorflow-federated with the below error on running   in terminal : 
 
",44680.61528
300,72076723,attributeerror : mapdataset object attribute preprocess tensorflow_federated tff,"attributeerror : mapdataset object attribute preprocess tensorflow_federated tff   I m test tutorial non - iid distribution federate learning :     in post question   suggest use tff.simulation.datasets.build_single_label_dataset ( ) way produce non - iid distribution dataset .    I try apply first ( see code ) get error !          OrderedDict([(label , TensorSpec(shape= ( ) , dtype = tf.int32 , name = None ) ) , ( pixel , TensorSpec(shape=(28 , 28 ) , dtype = tf.float32 , name = none ) ) ] )              tf . Tensor(1 , shape= ( ) , dtype = int32 )          since dataset filter , able preprocess ! so , case , filter base label ?      the desire label = 1 label EMNIST ?    my question be :    how apply function tff.simulation.datasets.build_single_label_dataset ( ) get non - iid dataset   ( different number sample client )   specific tutorial !   detail without error regard filter dataset !    appreciate help !    thank lot !","AttributeError: MapDataset object has no attribute preprocess in tensorflow_federated tff  Im testing this tutorial with non-IID distribution for federated learning:
 
 In this posted question  it suggested to use tff.simulation.datasets.build_single_label_dataset() as a way to produce a non-IID distribution for the dataset. 
 I tried to apply that first (see the code) and got an error ! 
 
 
 
 OrderedDict([(label, TensorSpec(shape=(), dtype=tf.int32, name=None)), (pixels, TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))]) 
 
 
 
 
 
 tf.Tensor(1, shape=(), dtype=int32) 
 
 
 
 Since dataset is filtered, it is not able to preprocess!
So, in this case, it is filtered based on what label? 
 
 the desired label = 1 for which label in EMNIST? 
 My Question is: 
 How can I apply this function tff.simulation.datasets.build_single_label_dataset()
to get non-IID dataset  (different number of samples for each client)  in this specific tutorial !  in details without error regarding the filtered dataset! 
 Appreciate any help! 
 Thanks a lot! 
",44682.52083
301,72086887,"valueerror : ` input_spec ` collections.abc . Mapping ( e.g. , dict ) , must contain entry key ` x ` , represent input(s )","valueerror : ` input_spec ` collections.abc . Mapping ( e.g. , dict ) , must contain entry key ` x ` , represent input(s )   I m test tutorial non - iid distribution federate learning : , use    way produce non - iid distribution dataset .    but face error regard keras value   .    the code :        ValueError :    collections.abc . Mapping ( e.g. , dict ) , must contain entry key   , represent input(s ) Keras model .      what mean ? solve it ?","ValueError: The `input_spec` is a collections.abc.Mapping (e.g., a dict), so it must contain an entry with key `x`, representing the input(s)  Im testing this tutorial with non-IID distribution for federated learning: , and using   as a way to produce a non-IID distribution for the dataset. 
 But I faced an error regarding keras values in the  . 
 The code: 
 
 
 ValueError: The   is a collections.abc.Mapping (e.g., a dict), so it must contain an entry with key  , representing the input(s) to the Keras model. 
 
 What does that mean? How can I solve it? 
",44683.52986
302,72121192,use transfer learning federate learning ?,use transfer learning federate learning ?   I try implement federate learning . ( use TensorFlow federate core )      and save server_state ( weight ) round :      now want use pre_traine model new federate learning case weight CNN layer fix weight 3 last layer change .    could someone help this ?,"How can I use transfer learning in federated learning?  I tried to implement federated learning. (Using TensorFlow federated core) 
 
 and save server_state (weights) after each round: 
 
 now I want to use this pre_trained model for a new federated learning case where the weights of the CNN layer are fixed and only the weights of the 3 last layers are changed. 
 could someone help me with how I can do this? 
",44686.09167
303,72132691,use different metric tf.keras.metrics mutli - classification model,"use different metric tf.keras.metrics mutli - classification model   I use TensorFlow federate framework multiclassification problem . follow   use metric ( ) measure model accuracy . want explore measure like ( auc , recall , F1 , precision ) get error . code error message provide below .      the error      be muti classification problem , can not use measure it ? so , metric may use measure multi - classification model .","Use different metrics in tf.keras.metrics for mutli-classification model  I am using the TensorFlow federated framework for
a multiclassification problem. I am following the  and most of them use the metric ( ) to measure the models accuracy.
I wanted to explore the other measures like (AUC, recall, F1, and precision) but I am getting the errors.
The code and the error message are provided below. 
 
 The error 
 
 Is it because of the muti classification problem, that we cannot use these measures with it? and if so, is there any other metric I may use to measure my multi-classification model. 
",44686.81319
304,72146421,attributeerror : mapdataset object attribute client_ids tensorflow_federated tff,"attributeerror : mapdataset object attribute client_ids tensorflow_federated TFF   I m try test compression technique federate learn   non - iid   use api tff.simulation.datasets.build_single_label_dataset ( ) , follow post :            but define model train it , get   this error   :      the code :      what mean ? appreciate help !","AttributeError: MapDataset object has no attribute client_ids in tensorflow_federated TFF  Im trying to test a compression technique in federated learning with  non-IID  using this API tff.simulation.datasets.build_single_label_dataset(), following these posts: 
 
 
 
 
 But after defining the model and training it, I got  this error  : 
 
 The code: 
 
 What does that mean?
Appreciate any help! 
",44687.80486
305,72179718,tune hyper parameter cifar100 tensorflow_federate tff without drop accuracy ?,"tune hyper parameter cifar100 tensorflow_federate tff without drop accuracy ?   I m try test tutorial    cifar100 dataset ,   accuracy    drop   round !    do tuning hyper parameter reason ? ?    here code :      and output :      here input structure :      I know mistake !      be hyper parameter define layer create_original_fedavg_cnn_model ( ) wrong ? preprocess_train_dataset ( ) ?      how tune parameter tutorial cifar100 dataset ?        appreciate help ! thank .","How to tune hyper parameters for CIFAR100 in tensorflow_federated TFF without dropping in the accuracy?  Im trying to test this tutorial  with  CIFAR100 dataset , but the  accuracy  is  dropping  each round! 
 Does my tuning for the hyper parameter is the reason?? 
 Here is my code: 
 
 And this is the output: 
 
 Here is the input structure: 
 
 I dont know where is my mistake! 
 
 Are the hyper parameter that are defined in the layers in create_original_fedavg_cnn_model() wrong? or in preprocess_train_dataset()? 
 
 How to tune the parameters for the same tutorial for CIFAR100 dataset? 
 
 
 Appreciate any help! Thanks. 
",44691.05208
306,72230991,tff : Print state receive client,"tff : Print state receive client   I would like print state receive client training , loop :      here    state round , would like see state receive client 4 client . thank","TFF : Print state that receives each client  I would like to print the state that receives each client after training,
Here is my loop: 
 
 Here   is the state in each round, but I would like to see the state that receives each client from the 4 clients.
Thanks 
",44694.59236
307,72241747,add noise ( differential privacy ) client weight federal learning ?,"add noise ( differential privacy ) client weight federal learning ?   I want add noise gradient client side . modify     , work .      the error be      I add noise server side use   , add noise client side ?","How to add noise (differential privacy) to clients weights in federal learning?  I want to add noise to the gradient on the client side. I modified   to  , but it doesnt work. 
 
 The error is 
 
 I can add noise on the server side using the  , but how to add noise on the client side? 
",44695.65347
308,72263736,can not install tensorflow_federate,"can not install tensorflow_federate   I try install tensorflow federate .      but want import tensorflow federate , get warn google colab notebook restart .      also , try install tensorflow federate way :      but get error import tensorflow federate      how fix it ?","Cant to install tensorflow_federated  I try to install tensorflow federated. 
 
 but when I want to import tensorflow federated, I get this warning and after that google colab notebook is restarted. 
 
 Also, I try install tensorflow federated as this way: 
 
 but get error when import tensorflow federated 
 
 how do I fix it? 
",44697.75556
309,72327186,pass y_true Confusion Matrix federate learning model,"pass y_true Confusion Matrix federate learning model   I build multi - classification federate learning model use TensorFlow . want generate confusion matrix model , know find y_true y_pre federated computation code . federate computation code :        the confusion matrix code be :      so , right way generate confusion matrix federate learning find    pass function ?","Pass y_true for Confusion Matrix of federated learning model  I am building a multi-classification federated learning model using TensorFlow. And I want to generate a confusion matrix for my model, but I dont know how to find the y_true and y_pred in my federated computation code.
The federated computation code: 
 
 
 The confusion matrix code is: 
 
 so, is this the right way to generate a confusion matrix for federated learning and how can I find the   to pass it to the function? 
",44702.26597
310,62398225,use building federate averaging process - TypeError : expect callable .... find Enhanced Model,"use building federate averaging process - TypeError : expect callable .... find Enhanced Model   1 issue large    I produce iterative process via tff.learning.build_federated_averaging_process ( ) . receive error :       highlighting :      and      2 try      look another similar issue   try make model_fn collection.abc callable ,    create new error .      3 code :      iterative process :      model bulder :          create model ( for good measure )    ","When using building a federated averaging process - TypeError: Expected a callable.... found Enhanced Model  1 issue at large 
 I am producing a iterative process via tff.learning.build_federated_averaging_process(). and receive the error:  
 
 highlighting: 
 
 and 
 
 2 have tried 
 
 looked at another similar issue   have tried to make
model_fn a collection.abc Callable,   
only creates a new error. 
 
 3 some code: 
 
 iterative process: 
 
 model bulder: 
 
 
 
 create model (for good measure) 
 
 
",43997.94861
311,62398875,transfer weight baseline model federate model ?,"transfer weight baseline model federate model ?     try something like Colab , get errno 21 , directory .    then try another method show below ,       just like assign_weights_to_keras_model ( ) transfer weight tff_model keras model , want transfer weight keras model tff_model . do ?","How to transfer weights from baseline model to federated model?  
 Tried something like this in Colab, but I get errno 21, is a directory. 
 Then I tried another method as shown below,   
 
 Just like assign_weights_to_keras_model() transfers weights from tff_model to keras model, I want to transfer weights from keras model to tff_model. How can this be done? 
",43998.0
312,62416384,"get_flat_tensor_specs nest.flatten(element_spec ) , [ ] ) result AttributeError : list object attribute _ flat_tensor_specs","get_flat_tensor_specs nest.flatten(element_spec ) , [ ] ) result AttributeError : list object attribute _ flat_tensor_specs   AttributeError : list object attribute _ flatten_tensor_spec      problem : currently , create iterative process build federate averaging process , able pass functool . partial successful . however , must error code produce structure need model_fn go correctly .    have try : look input datum . custom data set build autoencoder original TF solution never use label . solution build take training datum , train model , work test datum , validate validation set produce threshold . might issue underlying production .    source :          trackback error          Additional Error list :      ","get_flat_tensor_specs nest.flatten(element_spec), []) results in AttributeError: list object has no attribute _flat_tensor_specs  AttributeError: list object has no attribute _flatten_tensor_specs 
 
 problem:
Currently, when creating an iterative process with a build federated averaging process, I am able to pass in a functools. partial successful.
however, there must be an error in the above code that produces a structure needed for the model_fn to go through
correctly. 
 have tried:
looking at the input data. This custom data set is built for a autoencoder and the original TF solution never used labels. As this solution is built to take in the training data, train the model, then work on the test data, and validate on the validation set to produce a threshold.
There might be a issue with the underlying production. 
 sources: 
 
 
 
 trackback error 
 
 
 
 Additional Error list: 
 
 
 
",43998.82083
313,62544709,additive noise need calibrate sensitivity differential privacy ?,"additive noise need calibrate sensitivity differential privacy ?   as beginner differential privacy , would like variance noise mechanism need calibrate sensitivity ? purpose that ? happen calibrate add random variance ?    Example scenario   laplacian noise , scale parameter calibrate ?","Why additive noise needs to be calibrated with sensitivity in differential privacy?  As a beginner to differential privacy, I would like to why the variance for noise mechanisms needs to be calibrated with sensitivity? What is the purpose of that? What happens if we dont calibrate it and add a random variance? 
 Example scenario  In Laplacian noise, why scale parameter is calibrated? 
",44005.93611
314,62578714,FedProx TensorFlow Federated,FedProx TensorFlow Federated   would anyone know implement FedProx optimisation algorithm TensorFlow Federated ? implementation seem available online develop directly TensorFlow . tff implementation would enable easy comparison experiment utilise FedAvg framework support .    this link FedProx repo :     Link paper :,"FedProx with TensorFlow Federated  Would anyone know how to implement the FedProx optimisation algorithm with TensorFlow Federated? The only implementation that seems to be available online was developed directly with TensorFlow. A TFF implementation would enable an easier comparison with experiments that utilise FedAvg which the framework supports. 
 This is the link to the FedProx repo:  
 Link to the paper:  
",44007.6375
315,62598087,way cast federate value ?,"way cast federate value ?   if federate value , say    I d like cast    easy way this ? thank !","Is there a way to cast a federated value?  If I have a federated value, say   that Id like to cast to   is there an easy way to do this? Thanks! 
",44008.64861
316,62657818,transfer knowledge learn distribute source domain,"transfer knowledge learn distribute source domain   to resolve problem non - iid datum federate learning , read paper add new node different datum domain transfer knowledge decentralize nodes . question information transfer , update datum ?","transfer knowledge learned from distributed source domains  To resolve the problem of non-iid data in federated learning, I read a paper which add a new node with a different data domain and transfer knowledge from decentralized nodes. My question is what is the information transfered, is that updates or data ? 
",44012.53264
317,62694286,TFF : change evaluation function Federated learning,"TFF : change evaluation function Federated learning   to implement code TFF , use method      but I m understand method evaluate accuracy across client . so , like question indicate , would like change metric code evaluation funtion TFF , proceed , link please code fucntion . thank ! !","TFF: How Can I change the evaluation function of Federated learning  To implement my code with TFF, I use the method 
 
 But Im not understanding how this method evaluate accuracy across clients. So, like my question indicates, I would like to change the metrics and code of this evaluation funtion in TFF, so how I can proceed, link please of code fucntion.
Thanks!! 
",44014.43681
318,72335489,get ValueError apply transfer learn federate learning ( TFF ),"get ValueError apply transfer learn federate learning ( TFF )   I want use pre_traine model federate learning follow code :    first build model set weight model freeze convolutional layer remove 4 last layer .      next , build new model .      but get ValueError want use tff.learning.build_federated_averaging_process .      please help fix it .","Get ValueError when apply transfer learning in federated learning (TFF)  I want to use pre_trained model in federated learning as following code: 
 first I build my model and set the weights on model and then I freeze convolutional layers and remove 4 last layer. 
 
 next, I build new model. 
 
 but I get ValueError when I want to use tff.learning.build_federated_averaging_process. 
 
 please help me to fix it. 
",44703.29514
319,72384343,GradientTape variable weight sum two Sequential model tensorflow,"GradientTape variable weight sum two sequential model TensorFlow   Suppose want minimize follow equation use gradient descent :         model weight    weight , 0 1 , sum result combine model      ( here refer   ) .      in ,   suggest update alpha base gradient model    apply minibatch . try watch without , always lead       some information initialization model :    the    default implementation    ( find ) create model      model .      some experiment suggest Zachary Garrett :    it seem whenever weight sum calculate , new weight model assign , lose track previous trainable variable sum model . again , lead    whenever    call . gradient seem   .      another edit : think strategy get work , bad practice manually set      work . tip improve this ?  ","GradientTape for variable weighted sum of two Sequential models in TensorFlow  Suppose we want to minimize the following equation using gradient descent: 
  with   and   the model weights and   the weight, between 0 and 1, for the sum resulting in the combined model   or   (here referred to as  ). 
 
 In the ,  suggests updating alpha based on the gradients of model   applied on a minibatch. I tried it with the watch or without, but it always leads to  
 
 Some more information about the initialization of the models: 
 The   is the default implementation from   (found ) by creating a model with   and a   model. 
 
 Some more experimenting as suggested below by Zachary Garrett: 
 It seems that whenever this weighted sum is calculated, and the new weights for the model are assigned, then it loses track of the previous trainable variables of both summed models. Again, it leads to the   whenever   is called. All gradients seem to be  . 
 
 Another edit:
I think I have a strategy to get it working, but it is bad practice as manually setting   or   does not work. Any tips on improving this? 
 
",44706.89167
320,72428317,module tensorflow_federated.python attribute federated_computation,module tensorflow_federated.python attribute federated_computation   I follow instruction github say install Tensorflow Federated Collab need install version 0.20.0 get error try run toturial .        error :      what problem understand ? install google colab . resource problem .,"module tensorflow_federated.python has no attribute federated_computation  I follow the instructions in the github that says to install Tensorflow Federated with Collab we need to install version 0.20.0 but I get this error when I try to run the toturials. 
 
 
 Error: 
 
 What is the problem I dont understand? How can I install it on google colab. There is no resource for this problem. 
",44711.05208
321,72428249,version Tensorflow federate module federated_computation ?,"version Tensorflow federate module federated_computation ?   I try install Tensorflow federate google collab , conflict version , either get error install previous version similar error .      if want install new version give "" this require version version "" installation . confuse . easy way use tensorflow federate learning ? try install locally also work . hard use it ?        if uninstalled package instal give error mention above    if try import ignore error picture give error new version      and error version 20  ","What version of Tensorflow federated has the module federated_computation?  I am trying to install Tensorflow federated on google collab, but there is a conflict with versions, I either get this error if I install previous versions or similar errors. 
 
 If I want to install the new version it gives the ""this requires this version but you have this version"" during the installation.
I am very confused. Is there an easy way to use Tensorflow federated learning? I tried to install it locally but that also didnt work.
Why is it so hard to use it? 
 
 
 If I uninstalled all packages and installed them again it gives me the error mentioned above 
 If I try to import it ignoring the errors in the pictures it gives me this error with a newer version 
 
 And this error with version 20 
 
",44711.03611
322,72467705,unbalanced client size federate learning,"unbalanced client size federate learning   I apply federate learn multiple file use Tensoflow Federated . problem be , size datum ( number record ) file different .      be problem federate learning training different size client ? overcome it ?    be way see client perform federate computation training ?    ","Unbalanced client size in federated learning  I am applying federated learning on multiple files using Tensoflow Federated. The problem is, that the size of data (number of records) in each file is different. 
 
 Is it a problem in federated learning training to have different sizes for each client? if there is how can I overcome it? 
 Is there a way that I can see how each client performing while federated computation training? 
 
 
",44713.85347
323,72484653,problem evaluate model tensorflow federate . Accuracy stucke 0.1 evaluation,"problem evaluate model tensorflow federate . Accuracy stucke 0.1 evaluation   I model implement tensorflow federate , train solve classification problem cifar10 dataset . dataset make TestClientData .    the model MobileNetV2 module   . initialize state datum model proper form call    iteration , plus training test metric print . training metric show improvement , however test metric get stucke 0.1 accuracy loss stucke well .    test do define keras dummy model architecture specification , receive weight state via   .    I ve careful use loss , optimizer accuracy federate model centralized keras model use evaluation . Ill add print get training loop , print weight state correspond one keras model check weight assignment work , do . donâ€ ™ t know else check .      ------------CODE------------------    the setup like this :      the function perform training - evaluation loop one , call function 3 round , 3 fix client 1 epoch per client :  ","Problem when evaluating a model in tensorflow federated. Accuracy stucked at 0.1 only on evaluation  I have a model implemented in tensorflow federated, trained to solve a classification problem on the cifar10 dataset. The dataset is made with the TestClientData. 
 The model is a MobileNetV2 from the module  . I initialize a state with the data and model in the proper form and call to   on each iteration, plus the training and test metrics are printed. Training metrics show improvement, however test metrics get stucked at 0.1 accuracy and the loss is stucked as well. 
 Test is done by defining a keras dummy model of the same architecture and specifications, which receives the weights from the state via  . 
 Ive been careful to use the same loss, optimizer and accuracy on the federated model and the centralized keras model used for evaluation. Ill add a print of what I get from the training loop, I print some weights of the state and the corresponding ones on the keras model just to check that the weights assignment works, and it does. I donâ€™t know what else to check. 
 
 ------------CODE------------------ 
 The setup is like this: 
 
 The function performing the training-evaluation loop is this one, I call on the function on 3 rounds, 3 fixed clients and 1 epoch per client: 
 
",44715.17708
324,72495342,prepare image dataset federate model ?,"prepare image dataset federate model ?   how could transform dataset ( compose image ) federate dataset ? trying create something similar emnist dataset .      tff.simulation.datasets.emnist.load_data ( only_digit = true , cache_dir = none )  ","How can I prepare my image dataset for a federated model?  How could I transform my dataset (composed of images) in a federated dataset?
I am trying to create something similar to emnist but for my own dataset. 
 
 tff.simulation.datasets.emnist.load_data(
only_digits=True, cache_dir=None ) 
 
",44715.89583
325,72501778,use Tensorflow Federated Windows ?,"use Tensorflow Federated Windows ?   I try use tensorflow tutorial image classification use Federated Learning     Firstly , pip dependency resolver error pop up , instal require library version ask for .    however , face one 2 issue :      if try import    , give follow error :          I find forum suggest downgrade tensorflow - federated==0.22 . however , run import statement , throw error implicitly import class long Keras ( optimizerv1 ) .      I really fond tensorflow workflow . workaround make work window ?    PS : try Google Colab Jupyter Notebook .","How to use Tensorflow Federated on Windows?  I am trying to use Tensorflows tutorial of doing image classification using Federated Learning over  
 Firstly, there were some pip dependency resolver errors popping up, but I installed the required libraries with the versions it asked for. 
 However, I am facing one of 2 issues: 
 
 If I try to import   , it gives the following error: 
 
 
 
 I found a forum suggesting to downgrade to tensorflow-federated==0.22. However, when I do that and run the import statement, it throws an error again because its is implicitly importing a class which is no longer there in Keras (OptimizerV1). 
 
 I am really fond of Tensorflows workflow. Is there any workaround of making it work on Windows? 
 PS: I tried it in both Google Colab and Jupyter Notebook. 
",44716.72778
326,72514759,find true predict label Tensorflow Federated,"find true predict label Tensorflow Federated   I multi - class classification problem try evaluate federate learning model analyze true Predicted value produce classification report .    but stick y_true y_pre , know extract federate computation . block federate model training :      the classification report want reach to :      any help much appreciate . thank","Find the true and predicted labels in Tensorflow Federated  I am having a multi-class classification problem and trying to evaluate the federated learning model by analyzing the True and Predicted values and producing the classification report. 
 But I am stuck with the y_true and y_pred, I dont know how to extract them for the federated computation.
The block of my federated model training: 
 
 The classification report I want to reach to: 
 
 Any help will be so much appreciated.
Thanks 
",44718.33819
327,72514941,train local model SVM instead NN federate learning,"train local model SVM instead NN federate learning   I dataset numeric feature label . build federate learning model use TensorFlow ( TFF ) . basically , model ( neural network ) always explain TFF tutorial . want ask chance build another model local client , SVM ? since suit dataset .    my neural network :  ","Train local model with SVM instead of NN in federated learning  I have a dataset with numeric features and labels. I am building a federated learning model using TensorFlow (TFF).
Basically, the model that I have is the (neural network) which is always explained in the TFF tutorials.
I want to ask if there is a chance to build another model for the local clients, such as SVM? since it suits my dataset. 
 My neural network: 
 
",44718.35139
328,62711362,tff : difference split client train test split client dataset train test,"tff : difference split client train test split client dataset train test   in   paper , author choose 2500 training client 900 client evaluation    but , split dataset client training test . so , would like know well ? importance split client training evaluation ? thank ! !","TFF : Difference between split clients into train and test or split each client dataset into train and test  In  paper, the authors choose 2500  training clients and 900 clients for evaluation 
 but in this , they split the dataset of each client into training and test. So, I would like to know which is better ? and what is the importance of spliting clients into training and evaluation ?
Thanks!! 
",44015.34861
329,62754913,attempt capture EagerTensor without build function error : build Federated Averaging process,"attempt capture EagerTensor without build function error : build Federated Averaging Process   I get attempt capture EagerTensor without build function error try build federate averaging process . try remedy compatibility v1 & v2 give similar stack overflow question , viz . , use tf.compat.v1.enable_eager_execution ( ) , tf.disable_v2_behaviour ( ) , etc . but , nothing work . revelvant code extract give below . complete code Python notebook give .  ","Attempting to capture an EagerTensor without building a function Error: While building Federated Averaging Process  I am getting Attempting to capture an EagerTensor without building a function error while trying to build my federated averaging process. I have tried all remedies for compatibility of v1 & v2 given in other other similar stack overflow questions, viz., using tf.compat.v1.enable_eager_execution() , tf.disable_v2_behaviour(), etc. But, nothing worked. My revelvant code extract is given below. My complete code in a Python notebook is given here . 
 
",44018.47083
330,62786889,error Encoding Hub . KerasLayer use TFF,error Encoding Hub . KerasLayer use TFF   an error generate training federate model use hub . KerasLayer . detail error stack trace give below . complete code available gist . help suggestion regard would appreciate . thank .  ,"Error While Encoding with Hub.KerasLayer while using TFF  An error is being generated while training a federated model that uses hub.KerasLayer. The details of error and stack trace is given below. The complete code is available of gist . Help and suggestion in this regard would be appreciated. Thanks. 
 
",44020.12569
331,62832704,Accuracy decrease Slowly Epoch Tensorflow Federated Training,"Accuracy decrease Slowly Epoch Tensorflow Federated Training   my Tensorflow Federated model take long converge . use model without TFF wrapping , train tensoflow 2.0 , accuracy reach 0.97 within epoch . however , TFF training model able reach 0.03 30 epoch . could reason low accuracy TFF training . way improve this . code give below :  ","Accuracy is Decreasing Too Slowly with each Epoch in Tensorflow Federated Training  My Tensorflow Federated model is taking too long to converge. When I use the same model without TFF wrapping, training it with tensoflow 2.0, the accuracy reaches 0.97 within few epochs. However, with TFF training the same model is able to reach only 0.03 in 30 epochs. What could be the reason for such low accuracy during TFF training. Is there a way to improve this. My code is given below: 
 
",44022.45069
332,62840937,tff : ValueError Error check model target,"tff : ValueError Error check model target   I would like implement code image classification tensorflow - federate , create model pass federate averaging process , find error can not understand here . part code implement TFF      the error be :      thank help ! !","TFF :ValueError Error when checking model target  I would like to implement a code of image classification with tensorflow-federated, So when I create the model and I pass it to federated averaging process, I find error that I cant understand here. Here is a part of my code implemented with TFF 
 
 The error was: 
 
 Thanks for help!! 
",44022.80139
333,62893523,build model use multiple feature Tensorflow Federated ?,"build model use multiple feature Tensorflow Federated ?   I follow code problem try create OrderedDict multiple feature input ( i.e. , feature a - g ) one label h.      it show error like execute   :      I read alternative , however clear implement case . hence , correctly assign order dict multiple feature TFF ?    the current example_dataset.element_spec follow :      I want element_spec become like this :      how make element_spec latter one use batch_format_fn ?","How to build a model using multiple features in Tensorflow Federated?  I have the following codes and problem when trying to create OrderedDict for multiple feature inputs (i.e., features a-g) and one label h. 
 
 It shows an error like this when executing  : 
 
 I have read this alternative , however it is not clear how to implement it in my case. Hence, how to correctly assign ordered dict for the multiple features in TFF? 
 The current example_dataset.element_spec is as follows: 
 
 I want the element_spec becomes like this: 
 
 How to make the element_spec as the latter one using the batch_format_fn? 
",44026.45278
334,72556795,access labels TFF,"access label TFF   I follow   . I ve implement transfer learn fine - tuning dataset know access label whenever prediction . transform data right shape ( tf.data . Dataset ) use Keras model prediction . example want predict one label :     federated_train_data consist follow element :      First Tensor image shape second one represent encode label .    my goal illustrate true predict labels image , example :()    TLDR : way access label tf.data . dataset ?","How to access labels with TFF  I was following this  and . So Ive implemented transfer learning with fine-tuning on my dataset but I dont know how to access labels whenever I am doing predictions.
I transformed my data into the right shape (tf.data.Dataset) so I am using the Keras model for predictions. So for example if I want just to predict one label:  
 federated_train_data consists of following elements: 
 
 First Tensor is an image shape and the second one represents encoded labels. 
 My goal is to illustrate what are true and predicted labels of an image, for example:() 
 TLDR: Is there a way that you can access just labels when you have tf.data.Dataset? 
",44721.33958
335,72561857,0 Accuracy federate training,"0 Accuracy federate training   I trying implement simple binary classifier   dataset use Tensorflows federate learning framework . follow   tutorial do far :      implement classical centralize model(outside tff ) achieve convergence accurate result      try integrate approach wthin Federated framework see :        function      Main      where 41 feature label . I also check label correctly 0 1 . point federate datum signature :      finally ,      the result loop 0.0 accuracy iteration loss really change .   problem probably relate model training process since think dataset correct format can not figure be .   result mention probably indicate model training also output something completely different ( 0,1 ) .   also note state(model weight ) change iteration .   idea ?","0 Accuracy for federated training  I am trying to implement a simple binary classifier for the  dataset using Tensorflows federated learning framework.
Following  tutorial what i have done so far is : 
 
 implemented a classical centralized model(outside of tff) achieving convergence and accurate results 
 
 Tried to integrate this approach wthin the Federated framework as seen below : 
 
 
 Functions 
 
 Main 
 
 Where we have 41 features and a label.I have also checked the labels here and they correctly are between 0 and 1.
At this point federated data signature is : 
 
 Finally, 
 
 The result of the loop above is 0.0 accuracy for each iteration and  loss that is not really changing. 
The problem is probably related to the model and the training process since i think the dataset is in correct format but i cant figure out what it is. 
The results mentioned probably indicate that the model is not training at all and also that it outputs something completely different from (0,1). 
It is also noted that the state(models weights) do change after each iteration. 
Any ideas? 
",44721.59167
336,72617036,weight transmission protocol Federated Machine Learning,"weight transmission protocol Federated Machine Learning   I wonder , federate machine learning , train local model , intend update cloud model , protocol use transmit weight ? also , use tensorflow federate machine learning , transmit weight ( use library protocol ) ?    kind regard ,","Weight transmission protocol in Federated Machine Learning  I am wondering, in federated machine learning, when we train our local models, and intend to update the cloud model, what protocol we use to transmit those weight? Also, when we use the tensorflow federated machine learning, how we transmit the weight (using which library and protocol)? 
 Kind regards, 
",44726.52153
337,72652038,can not see local epoch output training tensorflow federate learning model ?,"can not see local epoch output training tensorflow federate learning model ?   I train tensorflow federate learning model . can not see output epoch . detail follow :        and output look follow :      be value global model round ? plot curve validation accuracy global model 100 epoch ( 10 round , 10 local epoch per round ) ? ( not tensorboard )","Why cant I see the local epochs output when training tensorflow federated learning model?  I am training a tensorflow federated learning model. I cannot see the output of epochs. Details are as follows: 
 
 
 And my output looks as follows: 
 
 Are these values for global model after each round? How can I plot the curves for validation accuracy of the global model for the 100 epochs (10 rounds, 10 local epochs per round)? (Not in tensorboard) 
",44728.89167
338,72674232,accuracy increase Tensorflow Federated Learning,"accuracy increase Tensorflow Federated Learning   I run code tensorflow federate learning ( 10 epoch , 100 round ) , accuracy increase around 0.5 . part code follow :      and ,      I see question stackoverflow this , find solution anywhere . I would appreciate help .","Accuracy does not increase in Tensorflow Federated Learning  I am running the code in tensorflow federated learning (10 epochs, 100 rounds), but the accuracy is not increasing and its around 0.5. Part of my code is as follows: 
 
 And, 
 
 I saw few questions on stackoverflow on this, but couldnt find the solution anywhere.I would appreciate any help. 
",44731.17569
339,72698170,"TypeError : expect 1 argument , get 2 ....... datum = collection . OrderedDict(data , distributed_data[i ] )","TypeError : expect 1 argument , get 2 ....... datum = collection . OrderedDict(data , distributed_data[i ] )   I get follow error relate function definition wrong ?    Convert_to_client_data ( ) function federate learn try convert dataset federate dataset .    here declaration class Distribute use function give error    # Declaration Class Distribute      # function DEFINITION give error      ERROR STATEMENT function definition  ","TypeError: expected at most 1 arguments, got 2....... data = collections.OrderedDict(data, distributed_data[i])  I am getting the following error related to this function definition what is wrong? 
 Convert_to_client_data() is a function in federated learning where I am trying to convert a dataset into the federated dataset. 
 Here is the declaration of the class Distribute which is used in the function which gives the error 
 #Declaration of Class Distribute 
 
 #function DEFINITION which gives the error 
 
 ERROR STATEMENT for the function definition 
 
",44733.38472
340,72713816,privacy client global tokenizer Federated Learning ( TFF ) ?,"privacy client global tokenizer Federated Learning ( TFF ) ?   I currently stick dead end . try make image caption generator federate approach . initial idea different tokenizer client . pose issue however :      every client different sized vocabulary , thus different shape y , cause issue global model configuration .      to counter issue , could make size client equivalent large size across client , fill extra column client 0 .   example :   [ 0,1,1,1 ] map size 6 would become [ 0,1,1,1,0,0 ]      this bring last possible flaw , word different client different index . word "" rock "" client 1 might index 6 , index 9 another client . train global model , cause issue since model try learn different label indice word , impact accuracy ?        this bring final question : idea Federated Learning tokenize word train client single tokenizer ?","Is it against privacy of clients if I have a global tokenizer in Federated Learning (TFF)?  I am currently stuck in a dead end. I am trying to make an image caption generator from a federated approach. My initial idea was to have a different tokenizer for each client. That poses these issues however: 
 
 Every client will have a different sized vocabulary, and thus a
different shape of y, which will cause issues with the global model
configuration. 
 
 To counter the above issue, I could make size of y in each client
equivalent to the largest size across all clients, and fill the
extra columns in each client with 0.  Example:  [0,1,1,1] mapped to a size
of 6 would become [0,1,1,1,0,0] 
 
 This brings me to the last possible flaw, which is that the same
words in different clients will be having different indices. A word
""rock"" in client 1 might have an index of 6, while the same can have
an index of 9 in another client. While training the global model, it
will cause issues since the model is trying to learn different label
indices for the same word, which will impact the accuracy? 
 
 
 This brings me to the final question : Is it against the idea of Federated Learning to tokenize all the words of all the training clients in a single tokenizer? 
",44734.43542
341,72734353,error import tensorflow_federate Google Colab Tutorial,"error import tensorflow_federate Google Colab Tutorial   I ve work tutorial   Federated Learning Image Classification , run tutorial code Google colab give error import   tensorflow_federated      Code ( get error line 4 ):      error :      I ve try update python version 3.9 ( as mention fix available ) work .    solve :    I follow   instal 0.20.0 version   tensorflow - federate   work I  ","Error while importing tensorflow_federated on Google Colab Tutorial  Ive been working on the tutorial for  Federated Learning for Image Classification , and while running the tutorial code on Google colab its giving me error while importing  tensorflow_federated 
 
 Code (getting error on line 4): 
 
 Error: 
 
 Ive tried updating the python version to 3.9 (as mentioned in some of the fixes available) but it didnt work. 
 Solved: 
 I followed this  and installed the 0.20.0 version of  tensorflow-federated  which worked for me 
 
",44735.72986
342,72777309,switch federate centralized dataset -error may indicate try pass tensor NumPy call,"switch federate centralized dataset -error may indicate try pass tensor NumPy call   I m try switch federate set centralized learning . I ve create federate dataset , want create dataset centralized learning   create_tf_dataset_from_all_client   function . google error find maybe version NumPy TensorFlow correct function , current version :      python = = 3.9    tensorflow==2.8.2    numpy==1.21.6    tensorflow - federated==0.24.0      I find recent post tensorflow 2.8 match NumPy version    also , error might come function use create clientdata object :      error :  ","When switching from federated to centralized dataset -Error may indicate that youre trying to pass a Tensor to a NumPy call  Im trying to switch from a federated setting to centralized learning. Ive created a federated dataset, but I want to create a dataset for centralized learning with the  create_tf_dataset_from_all_clients  function. When I googled the error I found out that maybe versions of NumPy and TensorFlow are not correct for this function, my current versions are : 
 
 python == 3.9 
 tensorflow==2.8.2 
 numpy==1.21.6 
 tensorflow-federated==0.24.0 
 
 I havent found some recent posts about TensorFlow 2.8 and matching NumPy version 
 Also, the error might come from a function that I used to create the clientData object: 
 
 Error: 
 
",44739.80278
343,72792770,save weight tensorflow federate,save weight tensorflow federate   I want save weight loss get low reuse evaluation .      where :      be possible way save server weight hdf5 format checkpoint reuse it ?,"How to save weights in tensorflow federated  I want to save weights only when loss is getting lower and reuse them for evaluation. 
 
 where: 
 
 Is there a possible way to save server weights in hdf5 format or as a checkpoint and reuse it? 
",44740.85139
344,72818097,tensorflow Federated Learning resnet failse,"tensorflow Federated Learning resnet failse   I experiment tensorflow federate learn API . actualy try train simple resnet 10 client . base datum metric , training seem successful . evaluation well local federate fail .    do anyone advice ?    the model :      the model simple resnet . training use Tensorflow Federated Simulation Dataset emnist 10 client 10 epoch .     everything look fine far ...    I adjust provided function prepare datum . already test whole process simple CNN work quiet well .      do evaluation process tensorflow show strange result . accuracy around 11 percent loss something 7 8 .    if copy weight local model evaluation local , result . try predict single image test datum exception throw :      here model summaray :      I convert label to_categorical function karas util package . exception , input dense layer wrong ? training work ?","Tensorflow Federated Learning on ResNet failse  I do some some experiments with the tensorflow federated learning API. Actualy I try to train a simple ResNet on 10 Clients. Based on the data and metrics, the training seems to be successful. But the evaluation as well as local and federated fails. 
 Does  anyone have an advice? 
 The model: 
 
 The model is just a simple ResNet.
For the training I use the Tensorflow Federated Simulation Dataset for emnist and here 10 clients for 10 epochs.
 
 Everything looks fine so far... 
 I have adjusted the provided function for preparing the data. I have already tested the whole process with a simple CNN and all works quiet well. 
 
 Doing the evaluation process with tensorflow shows a strange result. The accuracy will be at around 11 percent and the loss has something between 7 and 8. 
 If I copy the weights to a local model and do the evaluation local, the same result. If I try to predict a single image from the test data an exception is thrown: 
 
 Here the model summaray: 
 
 I did not convert the labels with with to_categorical function from the karas util package. But why is the exception, the input of the dense layer is wrong? And why does the training work? 
",44742.62917
345,72874108,define create_tf_dataset_from_all_clients ( ) function,"define create_tf_dataset_from_all_clients ( ) function   I try make centralized dataset federate one . datum contain path , client_id label    so first create clientdata object use function accept client i d      create clientdata :      I expect dataset different label file code produce dataset one file it . trying implement graph execution method ?    I try use similar function create clientdata object work federate setting produces expect dataset , use function give error try produce centralized dataset","how to define create_tf_dataset_from_all_clients() function  I am trying to make a centralized dataset from a federated one. Data contains path, client_id and label 
 So first I create a clientdata object using a function that accepts the clients id 
 
 creating clientdata: 
 
 I expected a dataset with different labels and files but this code is producing a dataset with only one file in it. Is it because I am trying to implement the graph execution method? 
 I tried using a similar function for creating a clientdata object that works for federated settings and produces the expected dataset, but using the same function gives me an error when I try to produce a centralized dataset 
",44747.775
346,72876080,use custom accuracy tensorflow federate,use custom accuracy tensorflow federate     it throw AttributeError : convert code :     AttributeError :,"how to use custom accuracy in tensorflow federated  
 It throws an AttributeError: in converted code:  
 AttributeError:  
",44747.92569
347,62906596,attributeerror : Tensor.op meaningless eager execution enable use multiple feature input Tensorflow federate,"attributeerror : Tensor.op meaningless eager execution enable use multiple feature input Tensorflow federate   I problem inputte multiple feature input follow :      I get code . however , get full traceback follow . eventually , get error AttributeError : Tensor.op meaningless eager execution . seem something wrong build model especially input inside tf.keras.model function .      how solve issue ?","AttributeError: Tensor.op is meaningless when eager execution is enabled when using multiple feature inputs in Tensorflow federated  I have a problem when inputting multiple feature inputs as follows: 
 
 I get this code from this . However, I got the full traceback as follows. Eventually, I get an error AttributeError: Tensor.op is meaningless when eager execution. It seems that there is something wrong with the built model especially the inputs inside the tf.keras.model function. 
 
 How to solve this issue? 
",44027.09236
348,62993389,change dataset type execution stack,"change dataset type execution stack   the problem change dataset one type another different point execution stack . example , add new dataset class member property interest ( which inherit one class ops.data.dataset_ops like UnaryDataset ) , result later execution point ( client_update function ) , dataset convert _ VaraintDataset Type hence add attribute lose . question retain member attribute newly define dataset class course execution . emnist example type change parallelmapdataset _ VariantDataset .    in function client_dataset training_utils.py line 194 , modify show type dataset follow      the output :      then tf.function client_update invoke client fed_avg_schedule.py line 178 , dataset different type      the output would :      I might wrong do tracking find point function ( _ to_components(self , value ) DatasetSpec ) call conversion :      EDIT - follow suggest answer    below change introduce simpel_fedavg example pull recent version federate repo    first , add / modify line build_fed_avg_process simple_fedavg_tff.py      in simple_fedavg_tf.py , add follow print line meta_data      in main file emnist_simple_fedavg.py , modife follow line main training loop main function :      which work get follow error :  ","Change of the dataset type in the execution stack  The problem is the change of the dataset from one type to another during different points of the execution stack. For example, if I add a new dataset class with more member properties of interest (which inherits from one of the classes in ops.data.dataset_ops like UnaryDataset), the result is at later execution point (client_update function), the dataset is converted to _VaraintDataset Type and hence any added attributes are lost. So the question is how to retain the member attributes of the newly defined dataset class over the course of execution. Below is the emnist example where the type changes from ParallelMapDataset to _VariantDataset. 
 In the function client_dataset of training_utils.py line 194, I modified it to show the type of the dataset as follows 
 
 The output is : 
 
 Then in the tf.function client_update which is invoked by the clients in the fed_avg_schedule.py line 178, the dataset is of different type 
 
 The output would be : 
 
 I might be wrong but I have done some tracking and found that at some point the function (_to_components(self, value) of DatasetSpec) is called which does the conversion: 
 
 EDIT - following the suggested answer 
 Below are the changes i have introduced to the simpel_fedavg example after pulling the recent version of the federated repo 
 First, i add/modified the lines below to build_fed_avg_process of simple_fedavg_tff.py 
 
 In the simple_fedavg_tf.py, I have added the following print line of the meta_data 
 
 In the main file emnist_simple_fedavg.py, I modifed the following lines of the main training loop in main function: 
 
 Which did not work out and i am getting the following error: 
 
",44032.43472
349,63043501,exactly happen call IterativeProcess.next federated training datum ?,"exactly happen call IterativeProcess.next federated training datum ?   I go Federated Learning tutorial . wonder .next function work call iterative process . assume train data list list . outer list list client inner list batch datum client . then , create iterative process , example , federate averaging process initialize state . exactly happen call iterativeprocess.next training datum . take datum randomly round ? take datum client one batch time ?    Assume list tf.data . dataset represent client datum . add randomness sampling list next iteration federate learning ?    my dataset necessarily length . one completely iterate over , dataset wait dataset completely iterate datum not ?","What exactly happens when we call IterativeProcess.next on federated training data?  I went through the Federated Learning tutorial. I was wondering how .next function work when we call it on an iterative process.
Assuming that we have train data which is a list of lists. The outer list is a list of clients and the inner lists are batches of data for each client. Then, we create an iterative process, for example, a federated averaging process and we initialize the state.
What exactly happens when we call IterativeProcess.next on this training data. Does it take from these data randomly in each round? Or just take data from each client one batch at a time? 
 Assume that I have a list of tf.data.Datasets each representing a client data. How can I add some randomness to sampling from this list for the next iteration of federated learning? 
 My datasets are not necessarily the same length. When one of them is completely iterated over, does this dataset waits for all other datasets to completely iterate over their data or not? 
",44034.89583
350,63090535,tensorflow Federated TFF still Simulation Environment ?,"tensorflow Federated TFF still Simulation Environment ?   TensorFlow Federated ( TFF ) open - source framework ML computation decentralize datum .    as per Stack overflow       TFF provide simulation environment use Federated Learning ( FL ) research . yet "" real world "" FL deployment platform .      but , tensorflow release history show many release version TF 2.x well .      can anybody comment , TFF still simulation environment use "" real world "" FL deployment platform ?","Tensorflow Federated TFF still a Simulation Environment?  TensorFlow Federated (TFF) is an open-source framework for ML and other computations on decentralized data. 
 As per Stack overflow  
 
 TFF only provides a simulation environment for use in Federated
Learning (FL) research. There is not yet a ""real world"" FL deployment
platform. 
 
 But, tensorFlow release history shows that now there are many release versions for TF 2.x as well. 
 
 Can anybody comment, if TFF is still or simulation environment or can be used as ""real world"" FL deployment platform? 
",44037.67153
351,63201833,error run gan / experiment / emnist : run_experiment use Bazel : run command support within workspace,"error run gan / experiment / emnist : run_experiment use Bazel : run command support within workspace   I fail run "" bazel run tensorflow_federate / python / research / gan / experiment / emnist : run_experiment "" , give error : "" the run command support within workspace ( below directory WORKSPACE file ) . ""      there workspace empty file "" federate "" git repo , run "" touch WORKSPACE "" .     my test installation run "" python -c "" import tensorflow_federated tff ; print(tff.federated_computation(lambda : hello World ) ( ) ) "" succeed .    I also run "" bazel run tensorflow_federate / python / research / gan / experiment / emnist : train "" .    here configuration :    Python 3.6.9    Tensorflow 2.2.0    Tensorflow - Federated 0.16.1    Bazel 3.4.1    I build TensorFlow Federated python package source use Bazel link :","Error when running gans/experiments/emnist:run_experiments using Bazel: The run command is only supported from within a workspace  I failed running ""bazel run tensorflow_federated/python/research/gans/experiments/emnist:run_experiments"", which gives me the error: ""The run command is only supported from within a workspace (below a directory having a WORKSPACE file)."" 
 
 There is a WORKSPACE empty file in my ""federated"" git repo, and I run ""touch WORKSPACE"".
 
 My test of installation by running ""python -c ""import tensorflow_federated as tff; print(tff.federated_computation(lambda: Hello World)())"" succeeds. 
 I can also run ""bazel run tensorflow_federated/python/research/gans/experiments/emnist:train"". 
 Here is my configuration: 
 Python 3.6.9 
 Tensorflow 2.2.0 
 Tensorflow-Federated 0.16.1 
 Bazel 3.4.1 
 I build the TensorFlow Federated python package from source using Bazel from this link:  
",44044.19375
352,72887912,can not import tensorflow_federated tff,"can not import tensorflow_federated tff   when try import tensorflow_federated get error , anyone idea why ?  ","cannot import tensorflow_federated as tff  When I try to import tensorflow_federated I got this error, anyone has the idea why? 
 
",44748.74236
353,72899013,install Tensorflow - Federated 0.28.0 win10 ?,"install Tensorflow - Federated 0.28.0 win10 ?   I need function api belong new version Tensorflow Federated . accord tutorial official website , type follow install new version .      unfortunately , installation finish , version 0.17.0 , publish 2020 . therefore , want know install Tensorflow - Federated 0.28.0 win10 .","How to install Tensorflow-Federated 0.28.0 on win10?  I need some function or api which belongs to the newest version of Tensorflow Federated. According to the tutorial of official website, I type the following to install the newest version. 
 
 Unfortunately, when the installation has been finished, the version is 0.17.0, which was published in 2020. Therefore, I just want to know how to install Tensorflow-Federated 0.28.0 on win10. 
",44749.575
354,72915271,tensorflow - federate : TypeError :   ( ) take 0 positional argument 1 give,tensorflow - federate : TypeError :   ( ) take 0 positional argument 1 give   I use    version 0.28 . try implement   getting follow error :      my code follow :      can someone please tell wrong here ?,"tensorflow-federated: TypeError:  () takes 0 positional arguments but 1 was given  I am using   version 0.28. I tried to implement  but I am getting the following error: 
 
 My code is as follows: 
 
 Can someone please tell me what I am doing wrong here? 
",44750.74792
355,73007445,tensorflow federate - learn give error colab,"tensorflow federate - learn give error colab   I try run .    however , far ,    code giving follow error :      any suggestion would greatly appreciate . thank time .","Tensorflow federated-learning giving error in colab  I am trying to run the . 
 However, so far, the   code is giving the following error: 
 
 Any suggestion would be greatly appreciated. Thanks for your time. 
",44758.85208
356,73024656,fedavg client optimizer ?,"fedavg client optimizer ?   in federated averaging , client optimizer SGD only ?    in paper   state "" one method FEDAVG ( McMahan et al . , 2017 ) , client perform multiple epoch SGD local dataset . "" base statement , client run Adam loss function , federate averaging ?    what difference federate averaging ( FedAvg ) Adaptive federate optimization ( FedOpt ) ( paper link above ) ?    in word different     ?","In FedAvg what is the client optimizer?  In federated averaging, does the client optimizer have to be SGD only? 
 In this paper  it states ""One such method is FEDAVG (McMahan et al., 2017), in which clients perform multiple epochs of SGD on their local datasets.""   Based on this statement, if the clients run Adam on their own loss function, it is not federated averaging? 
 What is the difference between federated averaging (FedAvg) and Adaptive federated optimization (FedOpt) (paper linked above)? 
 In other words what is the different between   and  ? 
",44760.63472
357,73032606,VGG16 increase accuracy TFF,"VGG16 increase accuracy TFF   I try transfer learn dataset . manage transfer learn resnet get decent accuracy . try VGG16 accuracy stay time loss change . preprocesse image tf.keras.applications.vgg16.preprocess_input . also , try transfer learn centralized manner work fine .      training round :  ","VGG16 doesnt increase accuracy in TFF  I am trying to do transfer learning on my own dataset. I managed to do transfer learning with resnet and I got decent accuracy. But when I try VGG16 my accuracy stays the same all the time and loss is changing. I preprocessed my images with  tf.keras.applications.vgg16.preprocess_input. Also, I tried to do transfer learning in a centralized manner and it works fine. 
 
 Training round: 
 
",44761.30139
358,73041436,"explain tff.to_type((tf.int64 , [ 2 ] ) ) ?","explain tff.to_type((tf.int64 , [ 2 ] ) ) ?   I learn Tensorflow - Federated , know explain syntax   . consider    create tff data type , know mean [ 2 ] .","How to explain tff.to_type((tf.int64, [2]))?  I am learning Tensorflow-Federated, while I dont know how to explain the syntax  . I consider   can create a tff data type, but I dont know the meaning of [2]. 
",44761.74236
359,73053135,evaluation model tensorflow federate,evaluation model tensorflow federate   I follow   tutorial image classification use tff . difference use 3d image size 128x128x3 .   training process evaluate model training round see below :      where :      in case get result like one :      we clearly see model learn produce well training accuracy validation freeze . suspect somehow one class predict ( problem 4 class ) . weird thing :   change        still get evaluation result clearly see training data result different . idea this ?   tff internally preprocesse evaluation step ?,"Evaluation of model tensorflow federated  I am following  tutorial for image classification using tff. The only difference is that i am using 3d images of size 128x128x3. 
During the training process i evaluate the model in each training round as seen below: 
 
 where : 
 
 In such a case i get results like the ones below : 
 
 We can clearly see that the model is learning producing better training accuracy but the validation is frozen. What i suspect is that somehow only one class is predicted ( my problem has 4 classes).
The weird thing is this : 
If i change   to   in   i still get the same evaluation results but i can clearly see that for the training data the results are different.
Any ideas about this? 
Is tff doing internally any preprocessing for the evaluation step? 
",44762.58681
360,73068175,oserror : [ errno 24 ] many open file training differential privacy tensorflow - federate,oserror : [ errno 24 ] many open file training differential privacy tensorflow - federate   I learn function Differential Privacy Tensorflow - federate . follow display first training .   break happen 2nd loop like follow .   please tell deal that .,"OSError: [Errno 24] Too many open files when training differential privacy in tensorflow-federated  I am learning about the function of Differential Privacy in Tensorflow-federated. The following is the display of the first training.

The break happened  in the 2nd loop like the following.

Please tell me how to deal with that. 
",44763.61042
361,73112324,create tensorflow - federate system local differential privacy ?,"create tensorflow - federate system local differential privacy ?   I create centralized differential privacy system accord official manual Tensorflow - federate . however , research need local differential privacy system base Tensorflow - federate . anyone know it ?","How to create a tensorflow-federated system by local differential privacy?  I have created a centralized differential privacy system according to the official manual of Tensorflow-federated. However, my research need a local differential privacy system based on Tensorflow-federated. Does anyone know how to do it? 
",44767.675
362,63229611,learn rate set call function tff.learning.build_federated_averaging_process,"learn rate set call function tff.learning.build_federated_averaging_process   I m carry federate learning process use function tff.learning.build_federated_averaging_process create iterative process federate learning . mention TFF tutorial , function two argument call client_optimizer_fn server_optimizer_fn , opinion , represent optimizer client server , respectively . fedavg paper , seem client carry optimization server averaging operation , exactly server_optimizer_fn learn rate mean ?","Learning rate setting when calling the function tff.learning.build_federated_averaging_process  Im carrying out a federated learning process and use the function  tff.learning.build_federated_averaging_process to create an iterative process of federated learning. As mentioned in the TFF tutorial,  this function has two arguments called client_optimizer_fn and server_optimizer_fn, which in my opinion, represent the optimizer for client and server, respectively. But in the FedAvg paper, it seems that only clients carry out the optimization while the server only do the averaging operation, so what exactly is the server_optimizer_fn doing and what does its learning rate mean? 
",44046.52708
363,63456076,tensorflow Federated Object Detection API,tensorflow Federated Object Detection API   I try implement demo object detection model train tensorflow federate .    right I m bit lose try figure modify model_lib_v2 train_loop incluse tff client code . train_loop alread optimizer model_fn build tff   also need Keras loss function .    furthermore I m right sure even possible add TFF function object detection Api simulation basic Keras model .    have anyone already try train object detection model TFF ?,"Tensorflow Federated with Object Detection API  I try to implement a demo of my object detection model that is trained with tensorflow federated. 
 Right now im a bit lost because I try to figure out how to modify the model_lib_v2 train_loop so that it inclused the tff client code. In the train_loop I alread have the optimizer and the model_fn but to build the tff  I also need a Keras loss function. 
 Furthermore Im right now not sure if it is even possible to add TFF functions to the Object detection Api or if its more a simulation for basic Keras models. 
 Has anyone already tried to train a object detection model with TFF ? 
",44060.74236
364,63456963,compression method Federated Learning,"compression method Federated Learning   I notice Gradient Quantization compression method already implement TFF framework . non - traditional compression method select sub - model dropping part global model ? come across "" Federated Dropout "" compression method paper "" expand Reach Federated Learning Reducing Client Resource Requirements "" ( ) . idea Federated Dropout method already support Tensorflow Federated . not , insight implement ( the main idea method drop fix percentage activation filter global model exchange train small sub - model ) ?","Other compression methods for Federated Learning  I noticed that the Gradient Quantization compression method is already implemented in TFF framework. How about non-traditional compression methods where we select a sub-model by dropping some parts of the global model? I come across the ""Federated Dropout"" compression method in the paper ""Expanding the Reach of Federated Learning by Reducing Client Resource Requirements"" (). Any idea if Federated Dropout method is already supported in Tensorflow Federated. If not, any insights how to implement it (the main idea of the method is dropping a fixed percentage of the activations and filters in the global model to exchange and train a smaller sub-model)? 
",44060.78542
365,63460420,Federated Tensorflow memory - overload single gpu,"Federated Tensorflow memory - overload single GPU   I m try federate learning use tensorflow . I ve create model base . change it : supply image size 112x112 3 channel ( i.e. size input layer 112x112x3 ) . try use multiple model ( around 50 100 image each ) , get "" out memory "" exception . look output   , make sense : reason program take memory single GPU . avoid it ?    some comment :      I use   , I m pretty sure show memory usage actual memory usage . see grow time .    TensorFlow recognize gpu : run program , 0 mb occupy . also line    log .    ","Federated Tensorflow memory-overloads a single GPU  Im trying to do federated learning using tensorflow.
Ive created a model based on . Now I change it: I supply it with images of size 112x112 with 3 channels each (I.e. the size of the input layer is 112x112x3). When I try to use multiple models (around 50 with about 100 images each), I get ""out of memory"" exception. Looking at output of  , it makes sense: for some reason my program takes memory only from a single GPU. How can I avoid it? 
 Some comments: 
 
 I use  , so Im pretty sure that the shown memory usage is the actual memory usage. And I do can see it growing over time. 
 TensorFlow recognizes other GPUs: before I run the program, they have 0MB occupied. Also there is line   in logs. 
 
 
",44061.0375
366,73184351,extract aggregate gradient tensorflow_federated ?,"extract aggregate gradient tensorflow_federated ?   I tensorflow model like this      I set iterative_process follow      I learn obtain aggregated weight   , still need know obtain aggregated gradient .","How to extract the aggregated gradient from tensorflow_federated?  I have a tensorflow model like this 
 
 I set the iterative_process in the following 
 
 I have learnt that we can obtain the aggregated weight by  , but I still need to know how to obtain the aggregated gradients. 
",44773.62431
367,73198156,client participation federate computation round,"client participation federate computation round   I build federate learning model use Tensorflow Federated . base read tutorial paper , understand state - of - the - art method ( FedAvg ) work select random subset client round .    my concern be :      I small number client . totally 8 client , select 6 client training keep 2 testing .    all datum provide local device , use TFF simulation environment .    if use 6 client round federate communication round , would wrong execution FedAvg method ?    note planning also use experiment use . aim use different server optimization method compare performance . so , would ( all client participate procedure ) work not ?      thank advance","Client participation in the federated computation rounds  I am building a federated learning model using Tensorflow Federated.
Based on what I have read in the tutorials and papers, I understood that the state-of-the-art method (FedAvg) is working by selecting a random subset of clients at each round. 
 My concern is: 
 
 I am having a small number of clients. Totally I have 8 clients, I select 6 clients for training and I kept 2 for testing. 
 All of the data are provided on my local device, so I am using the TFF as the simulation environment. 
 If I use all of the 6 clients in all of the rounds during federated communication rounds, would this be a wrong execution of the FedAvg method? 
 Note that I am planning also to use the same experiment used in this . That aims to use different server optimization methods and compare their performance. So, would (all clients participating procedure) works here or not? 
 
 Thanks in advance 
",44774.77431
368,73199007,noisemultipli mean tensorflow - federate tutorial ?,"noisemultipli mean tensorflow - federate tutorial ?   I find term    follow part tensorflow - federate tutorial .      I read paper differential privacy adaptive clipping . guess    noise input system . however , find    scalar set . actually , different noise put correspond weight_variable , confuse that .","What does noisemultiplier mean in tensorflow-federated tutorial?  I find the term   in the following part of tensorflow-federated tutorial. 
 
 I have read the paper about differential privacy with adaptive clipping . I guess   is the noise we input to the system. However, I find the   is a scalar we set. Actually, the different noise should be put into the corresponding weight_variables, so I am so confused about that. 
",44774.83611
369,73303926,"fedl - raise ValueError , dataset must test training","fedl - raise ValueError , dataset must test training   currently I m work implement code "" differentially private Federated Learning : Client Level Perspective "" GitHub link . however , follow instruction get error be      I run    follow instruction still get error !      you re welcome want check full code . thank lot ! !","FedL - raise ValueError, dataset must be testing or training  Currently Im working on implementing code in ""Differentially Private Federated Learning: A Client Level Perspective"" where the GitHub link is .
However, I follow the instruction but got an error which is 
 
 I just run   and follow the instruction but still get an error! 
 
 Youre welcome if you want to check the full code .
Thanks a lot!! 
",44783.39722
370,73326892,build federate system csv dataset SparkNL library ?,build federate system csv dataset SparkNL library ?   I interested federated system try one pre train multilingual model notebook .    I look tutorial use TFF Flower framework handle csv dataset .    so could suggest tutorial github repository help TFF Flower !,"How to build a federated system with CSV dataset with SparkNL library?  I am very interested in federated systems and i was trying one of the pre trained multilingual models such as this notebook . 
 I was looking for any tutorials using TFF or Flower frameworks that handle csv datasets. 
 So could you suggest any tutorials or github repositories to help me do that with TFF or Flower! 
",44784.87917
371,73346020,Custom accuracy tff federate learn use keras.metric,Custom accuracy tff federate learn use keras.metric   ,"Custom accuracy in tff federated learning using keras.metric  
 
",44786.69167
372,73407373,"typeerror : expect keras.losse . loss , find function","typeerror : expect keras.losse . loss , find function   I want build TFF model speech recognition system . this , use CNN - GRU model architecture CTC loss function . get error want build_federated_averaging_process think ctc_loss function can not fix it .    part code be :      and get error step :      how fix it ?","TypeError: Expected keras.losses.Loss, found function  I want to build a TFF model for speech recognition systems. For this, I use the CNN-GRU model architecture with a CTC loss function. but I got error when I wanted to build_federated_averaging_process and think its about the ctc_loss function but I cant fix it. 
 part of my code is: 
 
 and I got error in this step : 
 
 how do I fix it? 
",44791.73819
373,63498907,way TFF client internal state ?,"way TFF client internal state ?   the code TFF tutorial research project see generally keep track server state . iâ€ ™ d like internal client state ( for instance , additional client internal neural network completely decentralize donâ€ ™ t update federate manner ) would influence federate client computation .    however , client computation see , function server state datum . possible accomplish above ?","Is there a way for TFF clients to have internal states?  The code in the TFF tutorials and in the research projects I see generally only keep track of server states.  Iâ€™d like there to be internal client states (for instance, additional client internal neural networks which are completely decentralized and donâ€™t update in a federated manner) that would influence the federated client computations. 
 However, in the client computations I have seen, they are only functions of the server states and the data.  Is it possible to accomplish the above? 
",44063.23542
374,63539599,use class_weight keras model Tensorflow Federated Learning ( TFF ),"use class_weight keras model Tensorflow Federated Learning ( TFF )   my dataset class imbalance , want use class_weight enable classifi heavily weight minor class . general setting , assign class weight below :      be way assign class_weight tensorflow federate learning ? code federate learn below :  ","Can I use class_weight in keras model in Tensorflow Federated Learning (TFF)  My dataset is class imbalanced, so I want to use class_weight which enables the classifier heavily weight minor class. In general setting, I can assign class weight as below: 
 
 Is there any way that I can assign class_weight in tensorflow federated learning? My code for federated learning is below: 
 
",44065.76181
375,63577775,way load multiple .h5 model files corresponding clients(tff . client ) run federate averaging ?,"way load multiple .h5 model files corresponding clients(tff . client ) run federate averaging ?   I beginner federate learn use tff . server two remote client . use grpc send receive .h5 files bidirectional byte streaming . would like load two .h5 two client run federate average weight . ?    @tff.federated_computation(SERVER_MODEL_TYPE , client_data_type ) def federated_eval(model , datum ): return tff.federated_mean ( tff.federated_map(local_eval , [ tff.federated_broadcast(model ) , datum ] ) )    be way implement federate computation load weight ?","Is there a way to load multiple .h5 model files as corresponding clients(tff.Clients) and run federated averaging?  I am a beginner in federated learning using tff. I have a server and two remote clients. Using gRPC I have sent and received .h5 files with bidirectional byte streaming. I would like to load these two .h5 as two clients and run federated averaging on the weights. How do I do this ? 
 @tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)
def federated_eval(model, data):
return tff.federated_mean(
tff.federated_map(local_eval, [tff.federated_broadcast(model), data])) 
 Is there a way to implement federated computation on loaded weights ? 
",44068.47431
376,63723518,tensorflowfederate : pass tensor tff.federated_computation,"tensorflowfederate : pass tensor tff.federated_computation   I trialle TFF tutorial ( MNIST ) single machine trying perform multi - machine process use MNIST datum .    clearly , can not use    use GRPC learn pass datum one machine another .    my scenario server dispatch initial model ( with zero ) participate client model run local datum . client dispatch new weight server perform federated_mean .    I think use    could hopefully customise    function ( 2nd argument ) fail ... even sure use approach send model get weight back remote client .    then think could use      decorator . however , since weight array list ( as number client ) , unable understand create    point list list . help someone model federation distribute dataset handy understand .    Regards , Dev .","TensorFlowFederated: Passing tensor to tff.federated_computation  I have trialled TFF tutorial (MNIST) on my single machine and now I am trying to perform a multi-machine process using MNIST data. 
 Clearly, I cannot use   so I have used GRPC to learn how to pass data from one machine to another. 
 My scenario is that Server will dispatch the initial model (with zeroes) to all the participating clients where the model will run on local data. Each client will dispatch the new weights to the server that will perform federated_mean. 
 I was thinking of using   where I could hopefully customise the   function (2nd argument) but I failed... I am not even sure if we use this approach to send the model and get the weights back from remote clients. 
 Then I thought I could use   under   decorator. However, since weights are arrays and I have a list of them (as I have a number of clients), I am unable to understand how do I create a   that points to that a list of lists. Any help from someone who has modelled federation on distributed dataset will be handy to understand. 
 Regards,
Dev. 
",44077.51181
377,73502727,noise addition weight use Opacus Federated Learning set,"noise addition weight use Opacus Federated Learning set   I plan use Opacus implement differential privacy federate learning model basic doubt would love clear that .    so far understanding go , use Opacus , use optimizer like DPSGD add differential noise batch clientâ€ ™ s dataset â€œlocal trainingâ€. federate learning , train client model â€œlocal epochsâ€ send weight central server aggregation , add differential noise send model weight .    so question be , use DPSGD add noise every single batch every single client dataset local training could add noise local weight send out ? let local training epoch happen simply add noise outbound weight time departure ? miss ?","Noise addition to weights using Opacus in a Federated Learning setting  I am planning to use Opacus to implement differential privacy in my federated learning model but I have a very basic doubt that I would love to have cleared before that. 
 So as far as my understanding goes, using Opacus, we use an optimizer like DPSGD that adds differential noise to each batch of each clientâ€™s dataset while they are in â€œlocal trainingâ€. And in federated learning, we train client models for a few â€œlocal epochsâ€ before sending their weights out to a central server for aggregation, and we add differential noise before sending out the model weights. 
 So my question is, why do we use DPSGD to add noise to every single batch of every single client dataset during local training when we could just add noise to the local weights before they are sent out? Why do we not let the local training epochs happen as is and simply add noise to the outbound weights at the time of departure? What am I missing? 
",44799.60972
378,73655593,tensor object attribute numpy,"tensor object attribute numpy   I work tensorflow federate ( tff ) . problem arise call iterative process pass instance model create .    I declare keras model use server client . basically want modify client model weight bias order perform mathematical function they . mathematical function perform model weight bias use function name process . process function return weight layer tf numpy format ( the funtion process use tf.convert_to_tensor command convert numpy return weight / bias get / set_weights command use )      I create instant Keras model name as      now access weight bias use follow function ( proccesse ) assign new weight bias mathmatical operation      follow that , use follow function      then call iterator tff .      however get follow error :      can someone please help this . do not know wrong part code error even pop out . please note dtype weight / bias model layer use process function same . thank advance","Tensor object has no attribute numpy  I am working on tensorflow federated (tff). The problem arises when I call the iterative process and pass on the instance of the model created. 
 I have declared a keras model which is used at both the server and at the client. I basically want to modify the client models weights and biases in order to perform mathematical functions on them. These mathematical functions are performed on the models weights and biases by using function named  processed.
The processed function can return weights and layers both in tf or numpy format (the funtion processed just uses tf.convert_to_tensor command to convert the numpy returned weights/biases from the get/set_weights command used) 
 
 I create an instant of the above Keras model named as 
 
 Now I am accessing the weights and biases by using the following function (proccessed) and assigning them new weights and biases after some mathmatical operations 
 
 Following that, I use the following function 
 
 Then I call the iterator of tff. 
 
 However I get the following error: 
 
 Can someone please help me with this. I dont know what is wrong and from which part of the code the error is even popping out. Please note that the dtype of weights/biases of model layers before and after using the processed function are same.
Thanks in Advance 
",44812.93819
379,73671061,tensorflow - federate support decision tree training model ?,"tensorflow - federate support decision tree training model ?   go tutorial TFF ( tensorflow - federate ) , seem perform federate average gradient descent iteration use TFF well understand accomplish easily . however , train scenario decision tree training clear whether implementation readily available . particular , TF - DF ( tensorflow decision forest ) integrate well TFF . so , anyone example implement regression tree training ? thank .","Does tensorflow-federated support decision tree training model?  Going over the tutorials for TFF (tensorflow-federated), it seems that performing federated averaging and gradient descent iterations using TFF is well understood and can accomplished easily. However, for other training scenarios such as decision tree training it is not clear to me whether such an implementation is readily available. In particular, does the TF-DF (tensorflow decision forest) integrates well with TFF. If so, does anyone have an example for implementing a regression tree training? Thanks. 
",44814.43472
380,73720935,get error even enable eager execution,"get error even enable eager execution   I work tensorflow federate . follow import      consider follow model      what model be ; extract weight bias layer , perform various operation re - assigning process / modify weight bias respective layer . make instance model here :      I call follow algo :      however , get follow error .      I try type , i.e. , L1 B1 kk KB in      but get error . also start notebook , add follow      what might cause error ?","Getting error even after enabling eager execution  I am working on tensorflow federated.
I have the following imports 
 
 Consider the following model 
 
 What I am doing in this model is; extracting the weights and biases of all the layers, performing various operations on them and re-assigning the processed/modified weights and biases to their respective layers.
I make an instance of the model here: 
 
 I then call the following algo: 
 
 However, I get the following error. 
 
 I have tried both types , i.e., L1 and B1 and kk and KB in 
 
 But I am getting the same error. Also at the start of the notebook, I added the following 
 
 What might be causing this error? 
",44818.725
381,73734072,replace weight set_weights method,"replace weight set_weights method   I use tensorflow federate follow import .      consider follow keras model      I make instance create_keras_model , i.e. ,      I call follow function      follow that , call upon iterative process      which give follow error      any suggestion remove error ?","Replacing of weights with set_weights or any other method  I am using tensorflow federated with following imports. 
 
 Consider the following keras model 
 
 I made an instance of the create_keras_model, i.e., 
 
 I then call the following function 
 
 Following that, I call upon the iterative process 
 
 Which gives the following error 
 
 Any suggestion for removing the error? 
",44819.65903
382,63809453,tensorflow Federated update model server,"tensorflow Federated update model server   New Tensorflow sure specific question Tensorflow Federated .    I m study adversarial attack federate learning . I m curious weight receive server update client .    for example , code benign update :      I see initial weight receive server assign      use train batch datum local client .      inside function training occur ( I think )    update . part make sense    calculate :      it seem difference      use , originally set equal first line    function ? I m assume    alter    somehow see connection    use reduce function   .    thank , help appreciate !","How does Tensorflow Federated update model from server  New to Tensorflow so not sure if this is a specific question for Tensorflow Federated. 
 Im studying adversarial attack on federated learning in this . Im curious how the weights received from the server are updated at the client. 
 For example, here is the code for a benign update: 
 
 I can see that the initial weights received from the server are assigned to   then   is used to train on a batch of data on the local client. 
 
 Inside this function training occurs and (I think)   is updated. The part that doesnt make sense to me is how the   is calculated: 
 
 It seems that the difference between   and   is used, but didnt we originally set these to be equal in the first line of the   function? Im assuming the   alters   somehow but I dont see the connection between   used in the reduce function and  . 
 Thanks, any help appreciated! 
",44083.425
383,63917893,run TensorFlow Federated GPU Colab,"run TensorFlow Federated GPU Colab   be way   use GPU provide Colab   run   training session TFF   fast ? train Federated Models require 1 hour seem use GPU runtime provide benefit all .    the TFF page High - Performance Simulation still empty can not find guide use GPU TFF .    any suggestion ? thank you !    tf tff version :      number client round :      Input datum element spec :      similarly text generation tutorial I m work sequence place , model quite similar :      Function create model :      Federated Avg      State init :      Training Loop :  ","Run TensorFlow Federated on GPU with Colab  Is there a way to  use the GPU provided by Colab  to run the  training sessions of TFF  faster?
Training Federated Models requires more than 1 hour and it seems that using a GPU runtime does not provide any benefit at all. 
 The TFF page of High-Performance Simulation is still empty and I cannot find any guide to use the GPU with TFF. 
 Any suggestion?
Thank you! 
 tf and tff versions: 
 
 Number of clients at each round: 
 
 Input data element spec: 
 
 Similarly to the text generation tutorial im working with sequence of places, the model is quite similar: 
 
 Function to create the model: 
 
 Federated Avg 
 
 State init: 
 
 Training Loop: 
 
",44090.42847
384,63955527,tensorflow federate : map remote - worker remote dataset iterative_process.next ?,tensorflow federate : map remote - worker remote dataset iterative_process.next ?   I would like point federated_train_data remote client datum show code below . be possible ? ?    if implementation require try out . kindly point relevant code .        this,"Tensorflow federated : How to map the remote-worker with remote datasets in iterative_process.next?  I would like to point the federated_train_data to remote client data as shown in the code below.Is this possible? How ? 
 If not what further implementation is required for me to try this out. Kindly point me to the relevant code. 
 
 
 This is from  
",44092.50694
385,63990564,map make_remote_executor ( ) method define client server- tff.framework.create_executor_factor(make_remote_executor ),"map make_remote_executor ( ) method define client server- tff.framework.create_executor_factor(make_remote_executor )   I still beginner federate learning- would like clarify understand remote client - server scenario give remote_executor_example.py .      I hope image clear , kindly clarify component right place context remote client - server scenario .    if understand correct , else please correct I :    how map factory remote- make_remote_executor ( ) method client side ?","How to map the make_remote_executor() method defined on the client from the server- tff.framework.create_executor_factor(make_remote_executor)  I am still a beginner in federated learning- I would like to clarify my understanding in a remote client-server scenario given the remote_executor_example.py. 
 
 I hope the image is clear, Kindly clarify if the above components are in the right place in the context of a remote client-server scenario. 
 If the above understanding is correct, else please correct me: 
 how do we map the factory to the remote- make_remote_executor() method on the client side? 
",44095.44028
386,64046242,apply Differential Privacy TensorFlow Federated,"apply Differential Privacy TensorFlow Federated   I try use Tensorflow Privacy TFF follow two example provide   dataset . make sure sample target format correctly everything work add dp process clip noise . unfortunately , execution dp enable model diverge instead converge , train validation loss increase round .      I try different combination clip noise_multipli without achieve result .. example :      any idea could problem ? noise_multipli : false everything work properly .. definition dp_query averaging process basically use example :      thank you !","Applying Differential Privacy in TensorFlow Federated  I was trying to use Tensorflow Privacy with TFF following the two examples provided in  with my own dataset.
I made sure that samples and target were formatted correctly and everything worked before adding the DP process with clipping and noise.
Unfortunately, in any execution with dp enable the model diverge instead of converging, with both train and validation loss increasing at each round. 
 
 I have tried with different combinations of clip and noise_multiplier but without achieving any results..
Here is an example: 
 
 Any idea on what could be the problem? With noise_multiplier : False everything was working properly..
The definition of the DP_query and the averaging process is basically the same used in the example: 
 
 Thank you! 
",44098.51042
387,64053996,TensorFlow federate : Keras model custom learning algorithm,"TensorFlow federate : Keras model custom learn algorithm    tutorial describe build TFF computation kera model .   tutorial describe build custom TFF computation scratch , possibly custom federate learning algorithm .    what need combination these : want build custom federate learning algorithm , want use exist keras model .   Q.   do ?    the second tutorial require    base   , know get it . see variable    ( where   ) , doubt need .    of course , implement model hand ( as second tutorial ) , want avoid it .","TensorFlow Federated: Keras model with custom learning algorithm   tutorial describes how to build a TFF computation from keras model.
 tutorial describes how to build a custom TFF computation from scratch, possibly with a custom federated learning algorithm. 
 What I need is a combination of these: I want to build a custom federated learning algorithm, and I want to use an existing keras model.  Q.  How can it be done? 
 The second tutorial requires   which is based on  , but I dont know how to get it. I can see some variables in   (where  ), but I doubt its what I need. 
 Of course, I can implement the model by hand (as in the second tutorial), but I want to avoid it. 
",44098.85556
388,64183256,tensorflow Federated hierarchical fashion,"tensorflow Federated hierarchical fashion   I m try use tensorflow federate simulate federate learn algorithm hierarchical topology . I ve read , strategy implement ( such tff.learning.build_federated_averaging_process ) , rely single aggregation server . way network complex standard n - client 1 - server ?","Tensorflow Federated in a hierarchical fashion  Im trying to use tensorflow federated to simulate a federated learning algorithm in a hierarchical topology. For what Ive read, only a few strategies are implemented (such as tff.learning.build_federated_averaging_process), which relies on a single aggregation server. Is there any way to have networks that are more complex than the standard n-clients 1-server? 
",44107.44028
389,64196780,run multiple epoch client federate - tensorflow,"run multiple epoch client federate - tensorflow   be way federate - tensorflow make client train model multiple epoch dataset ? find tutorial solution could modify dataset run dataset.repeat(NUMBER_OF_EPOCHS ) , modify dataset ?","Running multiple epochs in clients of federated-tensorflow  Is there any way in federated-tensorflow to make clients train the model for multiple epochs on their dataset? I found on the tutorials that a solution could be modifying the dataset by running dataset.repeat(NUMBER_OF_EPOCHS), but why should I modify the dataset? 
",44108.66111
390,64280312,accuracy increase,"accuracy increase   I use TFF   0.12.0   run code federate learn image classification VGG16 , part code :      after run , see accuracy increase , know initialize 100 round .  ","Why accuracy does not increase  I use TFF  0.12.0  and I run a code of federated learning for image classification with VGG16, and here is a part of my code: 
 
 After running, I see that accuracy does not increase, knowing that I initialize 100 rounds. 
 
",44113.52917
391,64331370,attributeerror : module tensorflow_federated.python.learning attribute ModelWeights,"attributeerror : module tensorflow_federated.python.learning attribute ModelWeights   I use TFF 0.12.0 , line :      I find error :      how change line functional version 0.12.0 thank","AttributeError: module tensorflow_federated.python.learning has no attribute ModelWeights  I use TFF 0.12.0, in this line : 
 
 I find this error: 
 
 How can I change this line to be functional with version 0.12.0
Thanks 
",44117.34931
392,73776503,get shape layer model ?,"get shape layer model ?   consider follow model      be way get shape / size / dimension layer(s ) model ? example model , conv2d_1 shape ( 64,1,5,5 ) conv2d_2 shape ( 32,64,5,5 ) ?","How to get shapes of all the layers in a model?  Consider the following model 
 
 Is there any way I can get the shape/size/dimensions of the all the layer(s) of a model ?
For example in the above model, conv2d_1 has shape of (64,1,5,5) while conv2d_2 has shape of (32,64,5,5)? 
",44823.68333
393,73845079,use tensorflow federate library google colab ?,"use tensorflow federate library google colab ?   I try use tensorflow_federate library google colab can not figure this . search lot internet same , everywhere give , need install library google colab use directly , able so . anyone use library google colab tell install / directly use it ?","How to use tensorflow federated library in google colab?  I am trying to use the tensorflow_federated library in google colab but cannot figure out how to do this. I have searched a lot on the internet for the same, but everywhere its given, you dont need to install this library in google colab and you can use it directly, but I am not able to do so. Can anyone who has used this library in google colab tell me how to install/directly use it? 
",44829.58194
394,73889434,attributeerror : module tensorflow_federate attribute template,"attributeerror : module tensorflow_federate attribute template   federated_algorithm = tff.template . IterativeProcess ( initialize_fn = initialize_fn , next_fn = next_fn )    TF=2.1.0 Tff=0.13.0    they show attribute error .","AttributeError: module tensorflow_federated has no attribute templates  federated_algorithm = tff.templates.IterativeProcess(
initialize_fn = initialize_fn, next_fn = next_fn) 
 TF=2.1.0
Tff=0.13.0 
 they are showing attribute error. 
",44833.07361
395,74031314,attributeerror : module tensorflow_federated.python.learning attribute algorithm,"attributeerror : module tensorflow_federated.python.learning attribute algorithm   I try run code give Tensorflow , pertain Tensorflow - Federated . code follow :      however , get follow error :      could someone please help out ?","AttributeError: module tensorflow_federated.python.learning has no attribute algorithms  I am trying to run the code given by Tensorflow , pertaining to Tensorflow-Federated.
The code is as follows: 
 
 However, I am getting the following error: 
 
 Could someone please help me out? 
",44845.68681
396,74413904,tensorflow Federated : give model train 2 different datset calcaulate euclidian distance model,tensorflow Federated : give model train 2 different datset calcaulate euclidian distance model   I next word prediction model base federate learn tensorflow model . server need calculate distance model weigtht receive round . idea it ?,"Tensorflow Federated: given a model train it with 2 different datsets and calcaulate euclidian distance between these models  I have a next word prediction model based on federated learning with tensorflow model. My server need to calculate the distance between the model weigtht I receive in each round. Do you have any idea how to do it? 
",44877.61597
397,74572371,download Google Landmark v2 dataset use TensorFlow Federated,download Google Landmark v2 dataset use TensorFlow Federated   I m attempt download use Google Landmark v2 dataset use TensoFlow Federated follow code :      at point download error occur :    valueerror : incomplete corrupt file detect . md5 file hash match provide value 825975950b2e22f0f66aa8fd26c1f153 images_000.tar .    I ve try Google CoLab personal machine error occur .    be anyway get around issue ?    thank help appreciate .,"How to download the Google Landmark v2 dataset using TensorFlow Federated  Im attempting to download and use the Google Landmark v2 dataset using TensoFlow Federated with the following code: 
 
 At some point during the download this error occurs: 
 ValueError: Incomplete or corrupted file detected. The md5 file hash does not match the provided value of 825975950b2e22f0f66aa8fd26c1f153  images_000.tar. 
 Ive tried on Google CoLab and my personal machine but the same error occurs. 
 Is there anyway to get around this issue? 
 Thanks any help appreciated. 
",44890.49167
398,74624325,import tensorflow_federated tff error google colab,"import tensorflow_federated tff error google colab   hello I m work google colab issue import tensorflow_federated tff work fine early know problem now .    here code : instal nessacery pip libarie everything work fine version 0.20.0 tff . also try install late version 0.33.0 working could anyone help please wrong ? ? ?            here import :      here error try import tff :      also error try first pip :    error : pip dependency resolver currently take account package instal . behaviour source follow dependency conflict . pymc 4.1.4 require cachetools>=4.2.1 , cachetool 3.1.1 incompatible . grpcio - status 1.48.2 require grpcio>=1.48.2 , grpcio 1.46.5 incompatible . google - colab 1.0.0 require portpicker~=1.3.1 , portpicker 1.5.2 incompatible . google - cloud - bigquery 3.3.6 require grpcio<2.0dev,>=1.47.0 , grpcio 1.46.5 incompatible .","import tensorflow_federated as tff error in google colab  Hello im working on google colab and i have an issue with importing tensorflow_federated as tff it was working fine earlier and i dont know what is the problem now. 
 here is my code:
I installed all the nessacery pip libaries and everything was working fine with version 0.20.0 of tff. I also tried to install the latest version 0.33.0 but its not working could anyone help me please what is wrong??? 
 
 
 
 
 here is my imports: 
 
 here is my error when i try to import tff : 
 
 Also there is an error when i try the first pip: 
 ERROR: pips dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
pymc 4.1.4 requires cachetools>=4.2.1, but you have cachetools 3.1.1 which is incompatible.
grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.46.5 which is incompatible.
google-colab 1.0.0 requires portpicker~=1.3.1, but you have portpicker 1.5.2 which is incompatible.
google-cloud-bigquery 3.3.6 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.46.5 which is incompatible. 
",44895.32153
399,74635696,train tff metric federate training datum client,"train tff metric federate training datum client   I follow .    here perform training federate train datum :      and evaluate testing set .    how get tff training ( accuracy / loss ) metric custom code federate learning ?    early , use :      and able print tff metric :      but understant show tff metric custom tensorflow federate training process .","Training tff metrics on federated training data of clients  I am following . 
 Here I perform training on federated train data: 
 
 and then evaluate the testing set. 
 How can I get the tff training (accuracy/loss) metrics in custom code of federated learning? 
 Earlier, I was using: 
 
 and then I was able to print tff metrics: 
 
 But I dont understant how I can show tff metrics in my custom tensorflow federated training process. 
",44896.02569
400,64367417,Google - Colab tutorial tensorflow - federate fail launch Tensorboard,"Google - Colab tutorial tensorflow - federate fail launch Tensorboard   I try run Google Colab , tutorial   . first all , error Colab section   display model metric Tensorboard , cell :      which get solve follow way :      however stick section because , trying run tensorboard get error :      search error , post suggest , try uninstall / reinstall package     , solve . assume problem generate package conflict , version relevant Colab package follow :      do anyone know solve this ?","Google-Colab tutorial on Tensorflow-federated failing when launching Tensorboard  I am trying to run the Google Colab , which is a tutorial for  . First of all, there is an error in the Colab section  Displaying model metrics on Tensorboard , in the cell: 
 
 which gets solved in the following way: 
 
 However I am stuck in the same section because, when trying to run tensorboard I get the error: 
 
 Searching for the error, as other posts suggested, I tried to uninstall/reinstall the packages   and  , but it did not solve. Assuming the problem is generated by package conflicts, the versions of the most relevant Colab packages are the following: 
 
 Does anyone know how to solve this? 
",44119.34167
401,64374989,TFF : Remote Executor,"TFF : Remote Executor   we set federate scenario Server Client different physical machine .     server , use docker container kickstart :      the borrow .   we believe create local executor [ Ref 1 ] help create grpc server [ Ref 2 ] .    Ref 1 :      Ref 2 :      next client 1 , call tff.framework . RemoteExecutor connect grpc server .      our understanding base Remote Executor run client connect grpc server .    assume correct , send a      tff.tf_computation      from server client print output client side ensure whole setup work well .","TFF: Remote Executor  We are setting up a federated scenario with Server and Client on different physical machines. 
 
On the server, we have used the docker container to kickstart: 
 
 The above has been borrowed from .  We believe this creates a local executor [Ref 1]  which helps create a gRPC server [Ref 2]. 
 Ref 1: 
 
 Ref 2: 
 
 Next on the client 1, we are calling tff.framework.RemoteExecutor that connects to the gRPC server. 
 
 Our understanding based on the above is that the Remote Executor runs on the client which connects to the gRPC server. 
 Assuming the above is correct, how can we send a 
 
 tff.tf_computation 
 
 from the server to the client and print the output on the client side to ensure the whole setup works well. 
",44119.64722
402,64398484,manipulate client gradient tensorflow federate sgd,"manipulate client gradient tensorflow federate sgd   I m follow   get start tensorflow federate . aim run federate sgd ( not federate avg ) manipulation client gradient value send server .    before move forward , briefly reiterate federate sgd process , turn client send compute gradient ( not update weight ) server , server aggregate broadcast update model client .    now I ve gather far , use function   instead    mention tutorial perform federate sgd way describe above .    where I m lose be , need clip client gradient add noise ( independently generate gradient value ) send gradient server I m sure it . generate noise straightforward enough , function modify / implement able apply noise gradient ?","How to manipulate client gradients in tensorflow federated sgd  Im following  to get started with tensorflow federated. My aim is to run federated sgd (not federated avg) with some manipulations on client gradient values before they are sent to the server. 
 Before moving forward, to briefly reiterate the federated sgd process, for each turn clients will send their computed gradients (not updated weights) to the server, the server aggregates them and broadcasts the updated model to the clients. 
 Now from what Ive gathered so far, I can use the function  instead of   in the mentioned tutorial to perform federated sgd the way described above. 
 Where Im lost is, I need to clip the client gradients and add some noise to them (independently generated for each gradient value) before sending the gradients to the server and Im not sure how to do it. Generating the noise is straightforward enough, but which function should I modify/implement to be able to do apply the noise to the gradients? 
",44121.10625
403,64698402,tff trainer.next callable,"tff trainer.next callable   I try run tff example code . example code link tff website     but get problem , bug follow      when follow tutorial learn , its right way meet      its problem next callable .    please help , thank much ! ! !","TFF trainer.next is not callable  I try to run the tff example code.
This is the example code link in tff website  
 But i get some problem, bug as follows 
 
 When i following the tutorials to learn,its on the right way until i meet 
 
 Its the same problem next is not callable. 
 Please help me ,thank you very much!!! 
",44140.56875
404,64698895,function instantiation undefined input shape index : 116 outer inference context,"function instantiation undefined input shape index : 116 outer inference context   I use TFF 0.12.0    each client train 38 image test 16 image , 4 client ,    I write simple code federate learning :      I can not understand find line execution :      know change Resnet50 VGG16 , line disappear . help please ! ! mean ?","Function instantiation has undefined input shape at index: 116 in the outer inference context  I use TFF 0.12.0 
 each client has in train 38 images and in test 16 images, I have 4 clients, 
 I write a simple code of federated learning : 
 
 I cant understand why I find those lines in execution: 
 
 Knowing that If I change Resnet50 with VGG16, those lines disappear.
Help please !! what does this mean ? 
",44140.58889
405,64714113,difference tff.learning.from_compiled_keras_model tff.learning.from_keras_model,"difference tff.learning.from_compiled_keras_model tff.learning.from_keras_model   in federated learn task , find two method :      and      I would like know well influence result ( accuracy , loss ) ? thank","difference between tff.learning.from_compiled_keras_model and tff.learning.from_keras_model  In federated learning task, I found those two method: 
 
 and 
 
 I would like to know which is better  and if it can influence on result (accuracy, loss) ?
Thanks 
",44141.49167
406,64750708,training loss test loss ?,"training loss test loss ?   in order manipulate metric model , would like know , see loss    loss    ? read :      training loss look much well evaluation loss : use Federated Averaging ( the optimization algorithm use Federated Learning Image Classification tutorial ) one need careful interpret metric nuance difference centralized model training . especially train loss , average many sequence step batch . mean one round , client may fit model local datum well ( obtain high accuracy ) , average update global model global model may still far away "" good "" , result low test accuracy . additionally , 10 round may few ; one original academic paper Federated Learning demonstrate least 20 round 99 % accuracy ( McMahan 2016 ) iid datum , 100 round non - iid datum .      so would like know well evaluation metrcis use code :      or one :      thank","Training loss or test loss?  In order to manipulate metrics of my model , I would like to know, I saw loss on   or loss on   ?
I read this : 
 
 Training loss looks much better than evaluation loss: when using Federated Averaging (the optimization algorithm used in the Federated Learning for Image Classification tutorial) one needs to be careful interpreting metrics as they have nuanced differences from centralized model training. Especially training loss, which is the average over many sequence steps or batches. This means after one round, each client may have fit the model to their local data very well (obtaining a high accuracy), but after averaging these updates into the global model the global model may still be far away from ""good"", resulting in a low test accuracy. Additionally, 10 rounds may be too few; one of the original academic papers on Federated Learning demonstrated at least 20 rounds until 99% accuracy (McMahan 2016) with IID data, and more than 100 rounds in with non-IID data. 
 
 So I would like to know which is better for evaluation metrcis using this code : 
 
 Or this one : 
 
 Thanks 
",44144.47361
407,64760396,load Fashion MNIST dataset tensorflow fedarate ?,"load Fashion MNIST dataset Tensorflow Fedarated ?   I work project Tensorflow federate . manage use library provide TensorFlow Federated Learning simulation order load , train , test dataset .    for example , load emnist dataset      and get data set return load_data ( ) instance tff.simulation . ClientData . interface allow iterate client ids allow select subset datum simulation .      I try load fashion_mnist dataset Keras perform federate operation :      but get error      because Keras return Tuple Numpy array instead tff.simulation . clientdata like before :      to sum up ,      be way create tuple element    Keras Tuple Numpy array ?      another solution come mind use    load manually appropriate file a format    order get   , problem can not find url fashion_mnist    file format mean something like train test :          my final goal make fashion_mnist dataset work TensorFlow federate learning .","How to load Fashion MNIST dataset in Tensorflow Fedarated?  I am working on a project with Tensorflow federated. I have managed to use the libraries provided by TensorFlow  Federated Learning simulations in order to load,  train, and test some datasets. 
 For example, i load the emnist dataset 
 
 and it got the data sets returned by load_data() as instances of tff.simulation.ClientData. This is an interface that allows me to iterate over client ids and allow me to select subsets of the data for simulations. 
 
 I am trying to load the fashion_mnist dataset with Keras to perform some federated operations: 
 
 but I get this error 
 
 because Keras returns a Tuple of Numpy arrays instead of a tff.simulation.ClientData like before: 
 
 To sum up, 
 
 Is any way to create tuple elements of   from Keras Tuple Numpy arrays? 
 
 Another solution that comes to my mind is to use the
  and load
manually the appropriate files in a format   in order to get the  , but my problem is that i cant find the url for fashion_mnist    file format i mean something like that for both train and test: 
 
 
 
 My final goal is to make the fashion_mnist dataset work with the TensorFlow federated learning. 
",44144.95278
408,74830029,limit usage thread pool TensorFlow - Federated ?,"limit usage thread pool TensorFlow - Federated ?   tff   start new thread , usage ( as TFF 0.42.0 ) optional ThreadPool parameter implementation single executor . case ?","Why is there only limited usage of thread pools in TensorFlow-Federated?  TFFs  start a new thread from , and the only usage (as of TFF 0.42.0) of the optional ThreadPool parameter is in the implementation of a single executor. Why is this the case? 
",44911.90486
409,74886418,can not install import tensorflow_federated colab,"can not install import tensorflow_federated colab   I want try simple federate learn example python . it , need import tensorflow_federated package .      here stack trace      how resolve error ?   btw , read forum problem might resolve update python version , however still exist despite update v3.9   full stack trace follow ( I submit screenshot misinterpret stackoverflow quote code right format )","Cannot install and import tensorflow_federated in colab  I want to try a simple federated learning example in python. For it, I need to import tensorflow_federated package. 
 
 Here is the stack trace 
 
 How should I resolve this error? 
BTW, I read in a forum that the problem might be resolved by updating the python version, however it still exists despite I updated it to v3.9 
The full stack trace is as follows (I had to submit a screenshot of it was misinterpreted by stackoverflow as some quotes and codes that are not in the right format)
 
",44917.3875
410,74985672,typeerror import tensorflow_federate,"typeerror import tensorflow_federate   I ve try import tensorflow_federate stumble across error . extensively search internet yet find anyone encounter same :      the return follow , anyone experience anything similar :  ","TypeError when importing tensorflow_federated  Ive been trying to import TensorFlow_federated but have stumbled across an error. After extensively searching the Internet I am yet to find anyone who has encountered the same: 
 
 The above returns the following, has anyone experienced anything similar: 
 
",44928.75139
411,64791796,Linear regression use tf.data federate core api datum remote execution client,"Linear regression use tf.data federate core api datum remote execution client   I m try demonstration federate learn tff . I ve get far error message get confusing . important part want demostrate datum remote engine , use    could find anything similar tutorial . I ve manage mini experiment datum read remote site , can not get large example work .    currently complain p = x w + b , believe x federated_value . I ve try many many variation can not get work . Salary.csv tutorial   ","Linear regression using tf.data with federated core API and data on remote execution client  Im trying to do a demonstration of federated learning with tff. And Ive got this far but the error messages I get are just too confusing. The important part is that I want to demostrate that the data is in the remote engine, which is why I use the   and I could not find anything similar in any tutorial. Ive managed to do a mini experiment where data was read in the remote site, but I cant get this larger example to work. 
 Currently it complains about p = x * w + b, I believe because x is not a federated_value. But Ive tried many many variations and just cant get it to work. The Salary.csv is from a tutorial here  
 
",44146.75417
412,64959332,write proper dataset_fn tff.simulation . fileperuserclientdata ?,"write proper dataset_fn tff.simulation . fileperuserclientdata ?   I m currently implement federate learning use   .    because dataset large , split many npy file , I m currently put dataset together use .    this I m try do      however , seem work well ,    callback function tensor dtype string . value    be :     instead contain path   , tensor seem contain error message ? something wrong ? write proper dataset_fn    use npy file ?    EDIT : error log . error really related question I m ask , find call function :  ","How to write a proper dataset_fn in tff.simulation.FilePerUserClientData?  Im currently implementing federated learning using  . 
 Because the dataset is very large, we split it into many npy files, and Im currently putting the dataset together using . 
 This is what Im trying to do 
 
 However, it doesnt seem to work well, the   in the callback function has is a tensor with dtype of string. The value of   is:  
 Instead of containing a path in  , the tensor seems to contains error messages? Am I doing something wrong? How can I write a proper dataset_fn for   using npy files? 
 EDIT :
Here is the error log. The error itself is not really related to the question Im asking, but you can find the called functions: 
 
",44157.8625
413,64962547,convert CSV file datum federate datum,convert CSV file datum federate datum   I try convert CSV dataset federate datum . please find code error get run code    code : import collection      error : ---------------------------------------------------------------------------  ,"Converting CSV file data into federated data  I am trying to convert my CSV dataset into a federated data. Please find the code and the error I am getting while I am running my code 
 code: import collections 
 
 Error: --------------------------------------------------------------------------- 
 
",44158.18472
414,64970504,TensorFlow federate : tune non - iidness federate dataset ?,"TensorFlow federate : tune non - iidness federate dataset ?   I test algorithm TensorFlow Federated ( TFF ) . regard , would like test compare federate dataset different "" level "" datum heterogeneity , i.e. non - iidness .    hence , would like know whether way control tune "" level "" non - iidness specific federate dataset , automatic semi - automatic fashion , e.g. mean TFF APIs traditional TF API ( maybe inside Dataset util ) .    to practical : instance , emnist federate dataset provide TFF 3383 client one handwritten character . however , local dataset seem quite balanced term number local example term represent class ( all class be , less , represent locally ) . would like federate dataset ( e.g. , start TFFs EMNIST one ) be :      patologically non - iid , example client hold one class N class ( always refer classification task ) . purpose    . so , use federate dataset one already provide TFF ? ;    Unbalanced term amount local example ( e.g. , one client 10 example , another one 100 example ) ;    both possibility ;      how proceed inside TFF framework prepare federate dataset characteristic ?    should stuff hand ? advice automate process ?    an additional question : paper , Hsu et al . , exploit Dirichlet distribution synthesize population non - identical client , use   concentration parameter   control identicalness among client . seem wasy - to - tune way produce dataset different level heterogeneity . advice implement strategy ( or similar one ) inside tff framework , TensorFlow ( Python ) consider simple dataset EMNIST , would useful too .    thank lot .","TensorFlow Federated: How to tune non-IIDness in federated dataset?  I am testing some algorithms in TensorFlow Federated (TFF). In this regard, I would like to test and compare them on the same federated dataset with different ""levels"" of data heterogeneity, i.e. non-IIDness. 
 Hence, I would like to know whether there is any way to control and tune the ""level"" of non-IIDness in a specific federated dataset, in an automatic or semi-automatic fashion, e.g. by means of TFF APIs or just traditional TF API (maybe inside the Dataset utils). 
 To be more practical: for instance, the EMNIST federated dataset provided by TFF has 3383 clients with each one of them having their handwritten characters. However, these local dataset seems to be quite balanced in terms of number of local examples and in terms of represented classes (all classes are, more or less, represented locally).
If I would like to have a federated dataset (e.g., starting by the TFFs EMNIST one) that is: 
 
 Patologically non-IID, for example having clients that hold only one class out of N classes (always referring to a classification task). Is this the purpose of   . If so, how should I use it from a federated dataset such as the ones already provided by TFF?; 
 Unbalanced in terms of the amount of local examples (e.g., one client has 10 examples, another one has 100 examples); 
 Both the possibilities; 
 
 how should I proceed inside the TFF framework to prepare a federated dataset with those characteristics? 
 Should I do all the stuff by hand? Or do some of you have some advices to automate this process? 
 An additional question: in this paper , by Hsu et al., they exploit the Dirichlet distribution to synthesize a population of non-identical clients, and they use a  concentration parameter  to control the identicalness among clients. This seems an wasy-to-tune way to produce datasets with different levels of heterogeneity. Any advice about how to implement this strategy (or a similar one) inside the TFF framework, or just in TensorFlow (Python) considering a simple dataset such as the EMNIST, would be very useful too. 
 Thank you a lot. 
",44158.60833
415,65071335,tensorflow - federate 0.17.0 totally GPU GPU CPU ?,"tensorflow - federate 0.17.0 totally GPU GPU CPU ?   I would like know new version TFF ( 0.17.0 ) completely GPU ? old version , find TFF run CPU GPU .","Tensorflow-federated 0.17.0 is totally GPU or GPU and CPU?  I would like to know if new version of TFF (0.17.0) is completely GPU ? because on old version, I find that TFF run CPU and GPU . 
",44165.41181
416,65178310,customized aggregation algorithm gradient update tensorflow federate,"customized aggregation algorithm gradient update tensorflow federate   I try implement   . basically want sum per client loss compare previous epoch . constituent layer model compare KL divergence weight server client model get layer specific parameter update softmax decide whether adaptive update normal FedAvg approach need .    the algorithm follows-     I try make use code   build custom federate avg process . get basic understanding tf.computation tff.computation involve . get need make change orchestration logic run_one_round function basically manipulate client output adaptive averaging instead vanilla federate averaging .   tf.computation function basically return value need i.e weights_delta ( can use client base model weight ) , model_output(which use calculate loss ) .    but sure exactly make change .      I want make use server model weight use server_state object . want calculate KL divergence weight server model client model per layer . use relative weight aggregate client weight instead vanilla federate averaging . instead use tff.federated_mean wish use different strategy basically adaptive one base algorithm above .    need suggestion go implement this . basically want :   1)sum value client loss .   2)calculate KL divergence per layerbasis client server determine whether use adaptive optimization FedAvg .     also way manipulate value python value helpful debugging purpose ( try use tf.print helpful either ) . thank !","Customized aggregation algorithm for gradient updates in tensorflow federated  I have been trying to implement this  . Basically what I want to do is sum the per client loss and compare the same with previous epoch. Then for each constituent layer of the model compare the KL divergence between the weights of the server and the client model to get the layer specific parameter updates and then doing a softmax and  to decide whether an adaptive update or a normal FedAvg approach is needed. 
 The algorithm is as follows-
 
 I tried to make use of the code   to build a custom federated avg process. I got the basic understanding that there are some tf.computations and some tff.computations which are involved. I get that I need to make changes in the orchestration logic in the run_one_round function and basically manipulate the client outputs to do adaptive averaging instead of the vanilla federated averaging. The   tf.computation function  basically returns all the values that I need i.e the weights_delta (can be used for client based model weights), model_output(which can be used to calculate the loss). 
 But I am not sure where exactly I should make the changes. 
 
 I want to make use of the server model weights using server_state object.
I want to calculate the KL divergence between the weights of server model and each clients model per layer. Then use a relative weight to aggregate the client weights instead of vanilla federated averaging.
Instead of using tff.federated_mean I wish to use a different strategy basically an adaptive one based on the algorithm above.
 
So I needed some suggestions on how to go about implementing this.
Basically what I want to do is : 
1)Sum all the values of client losses. 
2)Calculate the KL divergence per layerbasis of all the clients with server and then determine whether to use adaptive optimization or FedAvg.  
 Also is there a way to manipulate this value as a python value which will be helpful for debugging purposes( I tried to use tf.print but that was not helpful either). Thanks! 
",44172.35625
417,65273151,initialize model certain weight ?,"initialize model certain weight ?   I use example "" stateful_client "" tensorflow - federate example . want use pretraine model weight initialize model . use function   . seem work . validation accuracy first round still low . solve problem ?  ","How to initialize the model with certain weights?  I am using the example ""stateful_clients"" in tensorflow-federated examples. I want to use my pretrained model weights to initialize the model. I use the function  . But it seems that it doesnt work. The validation accuracy in the first round is still low. How can I solve the problem? 
 
",44178.29028
418,65274580,load serverstate.optimizer_state continue train Tensorflow Federated,"load serverstate.optimizer_state continue train Tensorflow Federated   do tff way save load optimizer state similar model weight . model weight      function , way save load optimizer state especially use server side optimizer SGD .    I could find anything save load state optimizer .","How to load ServerState.optimizer_state to continue training in Tensorflow Federated  Does TFF have any way to save and load optimizer state similar to model weights. For model weights there are   and   functions, Is there a way to save and load optimizer state especially when using server side optimizer other than SGD. 
 I could not find anything to save and load state of optimizer. 
",44178.43958
419,65411118,possible send different subset weight different client ?,"possible send different subset weight different client ?   I m try use tensorflow - federate select different subset weight server send client . client would train send back train weight . server aggregate result start new communication round .    the main problem can not access numpy version weight therefore know access subset layer . try use tf.gather_nd tf.tensor_scatter_nd_update perform selection update , work tensor , list tensor ( as server_state tensorflow - federate ) .    do anyone hint solve problem ? even possible send   different   weight client ?","Is it possible to send different subset of weights to different clients?  Im trying to use tensorflow-federated to select different subset of weights at the server and send them to the clients. The clients then would train and send back the trained weights. The server aggregates the results and starts a new communication round. 
 The main problem is that I cannot access the numpy version of the weights and therefore I dont know how to access a subset of them for each layer. I tried using tf.gather_nd and tf.tensor_scatter_nd_update to perform selection and update, but they only work for tensors, and not lists of tensors (as the server_state is in tensorflow-federated). 
 Does anyone have any hint to solve this problem? Is it even possible to send  different  weights to each client? 
",44187.63194
420,65434193,Multi - GPU TFF simulation error detect dataset reduce op multi - GPU TFF simulation,"Multi - GPU TFF simulation error detect dataset reduce op multi - GPU TFF simulation   I run code emotion detection model use Tensorflow Federated simulation . code work perfectly fine use cpu only . however , receive error trying run TFF GPU .      what error fix it ? try search many place find answer .    here call stack help . long pasted link :     EDIT :    here code contain iterative_process      here code make_federated_data  ","Multi-GPU TFF simulation errors Detected dataset reduce op in multi-GPU TFF simulation  I ran my code for an emotion detection model using Tensorflow Federated simulation. My code work perfectly fine using CPUs only. However, I received this error when trying to run TFF with GPU. 
 
 What is this error about and how can I fix it? I tried to search many places but found no answer. 
 Here is the call stack if it help. It is very long so I pasted into this link:  
 EDIT: 
 Here is the code containing iterative_process 
 
 Here is the code for make_federated_data 
 
",44189.21042
421,65447819,add metric compute performance,"add metric compute performance   I use TFF version 0.12.0 order compute performance model , would like add ( with accuracy ) sensitivity specificity metric ,      I find error :      so add metric tensorflow federate thank","Add other metrics to compute performance  I use TFF version 0.12.0
In order to compute performance of model, I would like to add (with accuracy ) sensitivity and specificity metrics, 
 
 I found this error: 
 
 So how can I add metrics  in Tensorflow federated
Thanks 
",44190.49306
422,65458032,TFF : split datum client,"TFF : split data client   why federated learn task , split dataset train , test validation , make train test .","TFF: How split data of each client  Why in the federated learning task, we dont split our dataset to train, test and validation, we make only train and test . 
",44191.65486
423,65471612,tensorflow_federate attribute namedtupletype,"tensorflow_federate attribute namedtupletype   I follow code   try run file same_OR.py    I also place input file "" initial_model_parameters.txt "" datum folder "" MNIST_data "" folder      I instal tensor flow federate command      and line also underlie red color      when tried execute go error      file "" same_OR.py "" , line 94 , BATCH_TYPE = tff . namedtupletype ( [ AttributeError : module tensorflow_federate attribute NamedTupleType      where problem ? anyone help ?","tensorflow_federated has no attribute NamedTupleType  I am following this code  and trying to run the file same_OR.py 
 I also place input file ""initial_model_parameters.txt""  and data folder ""MNIST_data"" in same folder 
 
 I installed tensor flow federated with this command 
 
 and this line is also underlied with red color 
 
 when i tried to execute go this error 
 
 File ""same_OR.py"", line 94, in 
BATCH_TYPE = tff.NamedTupleType([ AttributeError: module tensorflow_federated has no attribute NamedTupleType 
 
 where is the problem? anyone can help? 
",44192.99792
424,65481370,size mismatch tensorflow_federate eager executor,"size mismatch tensorflow_federate eager executor   I follow code   try run file same_OR.py    there problem    tf show unable import "" tensorflow.compat.v1 "" file "" sameOR.py ""      and list error .. anyone help ?      Traceback ( most recent call last ): File "" samOR.py "" , line 331 , local_model = federated_train(model , learning_rate , federated_train_data ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\utils\function_utils.py "" , line 561 ,   call   return context.invoke(self , arg ) file "" c:\users\aw\anaconda3\lib\site - packages\retrying.py "" , line 49 , wrapped_f return Retrying(*dargs , * * dkw).call(f , * args , * * kw ) file "" c:\users\aw\anaconda3\lib\site - packages\retrying.py "" , line 206 , call return attempt.get(self._wrap_exception ) file "" c:\users\aw\anaconda3\lib\site - packages\retrying.py "" , line 247 , get six.reraise(self.value[0 ] , self.value[1 ] , self.value[2 ] ) file "" c:\users\aw\anaconda3\lib\site - packages\six.py "" , line 703 , reraise raise value file "" c:\users\aw\anaconda3\lib\site - packages\retrying.py "" , line 200 , call attempt = attempt(fn(*args , * * kwargs ) , attempt_number , False ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\execution_context.py "" , line 213 , invoke arg = event_loop.run_until_complete ( file "" c:\users\aw\anaconda3\lib\asyncio\base_events.py "" , line 616 , run_until_complete return future.result ( ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 388 , _ wrap return await coro File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\execution_context.py "" , line 99 , _ ingest ingest = await asyncio.gather(*ingeste ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\execution_context.py "" , line 104 , _ ingest return await executor.create_value(val , type_spec ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py "" , line 286 , create_value return referenceresolvingexecutorvalue(await File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\caching_executor.py "" , line 245 , create_value await cached_value.target_future File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py "" , line 110 , create_value return await self._delegate ( file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py "" , line 105 , _ delegate result_value = await _ delegate_with_trace_ctx(coro , self._event_loop ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 388 , _ wrap return await coro File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn ( fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\federating_executor.py "" , line 383 , create_value return await self._strategy.compute_federated_value(value , type_spec ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\federated_resolving_strategy.py "" , line 272 , compute_federated_value result = await asyncio.gather ( [ file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py "" , line 281 , create_value val = await asyncio.gather ( file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py "" , line 286 , create_value return referenceresolvingexecutorvalue(await File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\caching_executor.py "" , line 245 , create_value await cached_value.target_future File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py "" , line 110 , create_value return await self._delegate ( file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py "" , line 105 , _ delegate result_value = await _ delegate_with_trace_ctx(coro , self._event_loop ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 388 , _ wrap return await coro File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py "" , line 200 , async_trace result = await fn(*fn_args , * * fn_kwargs ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py "" , line 464 , create_value return EagerValue(value , self._tf_function_cache , type_spec , self._device ) file "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py "" , line 366 ,   init   File "" c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py "" , line 326 , to_representation_for_type raise TypeError ( TypeError : apparent type float32[10 ] tensor [ -0.9900856 -0.9902875 -0.99910086 -0.9972545 -0.99561495 -0.99766624 -0.9964327 -0.99897027 -0.9960221 -0.99313617 ] match expect type float32[784,10 ] . ERROR : asyncio : task destroy pende ! task : < task pende name = task-7 coro=<trace .. async_trace ( ) run c:\users\aw\anaconda3\lib\site - packages\tensorflow_federated\python\common_libs\tracing.py:200 > wait_for=<future pende cb=[_chain_future .. _call_check_cancel ( ) c:\users\aw0000282f4dfe3d0 > ( ) ] >  ","Size mismatch in tensorflow_federated eager executor  I am following this code  and trying to run the file same_OR.py 
 there is a problem in   as tf its show that unable to import "" tensorflow.compat.v1"" File ""sameOR.py"" 
 
 and these are list of errors .. can anyone help? 
 
 Traceback (most recent call last):   File ""samOR.py"", line 331, in

local_models = federated_train(model, learning_rate, federated_train_data)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\utils\function_utils.py"",
line 561, in  call 
return context.invoke(self, arg)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py"", line 49, in
wrapped_f
return Retrying(*dargs, **dkw).call(f, *args, **kw)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py"", line 206, in
call
return attempt.get(self._wrap_exception)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py"", line 247, in
get
six.reraise(self.value[0], self.value[1], self.value[2])   File ""C:\Users\Aw\Anaconda3\lib\site-packages\six.py"", line 703, in reraise
raise value   File ""C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py"", line 200, in
call
attempt = Attempt(fn(*args, **kwargs), attempt_number, False)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py"",
line 213, in invoke
arg = event_loop.run_until_complete(   File ""C:\Users\Aw\Anaconda3\lib\asyncio\base_events.py"", line 616, in
run_until_complete
return future.result()   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 388, in _wrapped
return await coro   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py"",
line 99, in
_ingest
ingested = await asyncio.gather(*ingested)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py"",
line 104, in _ingest
return await executor.create_value(val, type_spec)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py"",
line 286, in create_value
return ReferenceResolvingExecutorValue(await   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py"",
line 245, in create_value
await cached_value.target_future   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py"",
line 110, in create_value
return await self._delegate(   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py"",
line 105, in _delegate
result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 388, in _wrapped
return await coro   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn( fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federating_executor.py"",
line 383, in create_value
return await self._strategy.compute_federated_value(value, type_spec)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federated_resolving_strategy.py"",
line 272, in compute_federated_value
result = await asyncio.gather( [   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py"",
line 281, in create_value
vals = await asyncio.gather(   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py"",
line 286, in create_value
return ReferenceResolvingExecutorValue(await   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py"",
line 245, in create_value
await cached_value.target_future   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py"",
line 110, in create_value
return await self._delegate(   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py"",
line 105, in _delegate
result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 388, in _wrapped
return await coro   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py"",
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File ""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py"",
line 464, in create_value
return EagerValue(value, self._tf_function_cache, type_spec, self._device)   File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py"",
line 366, in  init    File
""C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py"",
line 326, in to_representation_for_type
raise TypeError( TypeError: The apparent type float32[10] of a tensor [-0.9900856  -0.9902875  -0.99910086 -0.9972545  -0.99561495
-0.99766624  -0.9964327  -0.99897027 -0.9960221  -0.99313617] does not match the expected type float32[784,10]. ERROR:asyncio:Task was
destroyed but it is pending! task: <Task pending name=Task-7
coro=<trace..async_trace() running at
C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py:200>
wait_for=<Future pending
cb=[_chain_future.._call_check_cancel() at
C:\Users\Aw0000282F4DFE3D0>()]> 
 
",44193.71806
425,65491416,Resnet50 TFF give good result,"Resnet50 TFF give good result   I use tff 0.12.0 image dataset dog cat(2 label ) , test VGG16 , Ifind accuracy 0.9 change resnet50 , accuracy decrease 0.4 , write :      but accuracy exceed 0.46 even 100 round . part result :      help please ! ! !","Why Resnet50 with TFF does not give good results  I use TFF 0.12.0 and image dataset for dog and cat(2 labels), If I test with VGG16, Ifind accuracy 0.9 but If I change to ResNet50, accuracy decrease to 0.4, Here is what I write: 
 
 but accuracy does not exceed 0.46 even after 100 rounds. here is a part of the result : 
 
 Help Please!!! 
",44194.47917
426,75171118,resolve module attribute entropy_decode_index error ubuntu TFF ?,"resolve module attribute entropy_decode_index error ubuntu TFF ?   I get "" module 0b1a516c7ccf3157373118bcf0f434168745c8a4 attribute entropy_decode_index error clean intall tensorflow federate ( TFF ) Ubuntu 22.04 . system : AMD 6900HS , Nvidia3050ti . first "" import tensorflow_federated "" line fail .    there even single entry google concern error message shock .    the detailed error message be : file "" /home / egosis / venv / lib / python3.9 / site - package / tensorflow_compression / python / ops/ init .py "" , line 17 ,       AttributeError : module 0b1a516c7ccf3157373118bcf0f434168745c8a4 attribute entropy_decode_index    every answer gladly appreciate .    I try instal TFF v0.46.0 , v0.45.0 v0.44.0 tff help .","How to resolve module has no attribute entropy_decode_index error in ubuntu for TFF?  I got ""module 0b1a516c7ccf3157373118bcf0f434168745c8a4 has no attribute entropy_decode_index error after a clean intall of tensorflow federated (TFF) on Ubuntu 22.04. System: AMD 6900HS, Nvidia3050ti. The first ""import tensorflow_federated"" line fails. 
 There is not even a single entry on google concerning this error message and I am shocked. 
 The detailed error message is:
File ""/home/egosis/venv/lib/python3.9/site-packages/tensorflow_compression/python/ops/ init .py"", line 17, in  
 
 AttributeError: module 0b1a516c7ccf3157373118bcf0f434168745c8a4 has no attribute entropy_decode_index 
 Every answer is gladly appreciated. 
 I tried installing TFF v0.46.0, v0.45.0 and v0.44.0 of tff but it did not help. 
",44945.45069
427,75205546,transferring model two pc via PostgresSQL database,"transferring model two pc via PostgresSQL database   I two pc want share tensorflow model "" hdf5 format "" federate learn manner via PostgresSQL database .    the model train locally machine , transfer database along training history . transfer do multiple cycle specific schedule .    I search online solution transfer file via PostgresSQL database , solution suggest tabulate data transfer , e.g. csv file datum , arbitrary file extension , like hdf5 .    can anyone help I , even roadmap , solution ? tutorial example similar scenario would suggest , would also appreciate .    thank help advance !","Transferring models between two PCs via PostgresSQL database  I have two PCs that want to share tensorflow models ""hdf5 format"" in a federated learning manner via a PostgresSQL database. 
 The models will be trained locally on both machines, and then transferred to the database along with the training history. The transfer will be done for multiple cycles in a specific schedule. 
 I searched online for solutions to transfer the files via PostgresSQL database, but all solutions suggest a tabulated data transfer, e.g. csv file data, not arbitrary file extensions, like hdf5. 
 Can anyone help me, even with a roadmap, for the solution?
If any tutorials or examples for similar scenarios would be suggested, that would be also appreciated. 
 Thanks for your help in advance! 
",44949.1625
428,75409716,compatibility issue Tensorflow federate Google colab,"compatibility issue Tensorflow federate Google colab   TypeError Traceback ( most recent call last ) 5 import numpy np 6 import tensorflow tf ---- > 7 import tensorflow_federate tff    14 frame /usr / lib / python3.8 / typing.py _ type_check(arg , msg , is_argument ) 147 return arg 148 callable(arg ): -- > 149 raise TypeError(f""{msg } got { arg!r:.100 } . "" ) 150 return arg 151    TypeError : callable[[arg , ... ] , result ] : arg must type . Got Ellipsis .    I m get error try import tensorflow_federate Colab .    I try instal low compatible version tensorflow tensorflow_federate , nothing work . someone else also face problem ? anyone know fix it ?","compatibility issues for Tensorflow federated in Google colab  TypeError                                 Traceback (most recent call last)
 in 
5 import numpy as np
6 import tensorflow as tf
----> 7 import tensorflow_federated as tff 
 14 frames
/usr/lib/python3.8/typing.py in _type_check(arg, msg, is_argument)
147         return arg
148     if not callable(arg):
--> 149         raise TypeError(f""{msg} Got {arg!r:.100}."")
150     return arg
151 
 TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis. 
 Im getting this error while trying to import tensorflow_federated in Colab. 
 I have tried installing lower compatible versions of tensorflow and tensorflow_federated, but nothing works. Can someone else also faced this problem? and Do anyone know how to fix it? 
",44967.42917
429,75614269,save tensorflow federated model,save tensorflow federate model   I tensorflow federate model see below :      where state state server encapsulate model .    printing have :      which server state .   access model parameter with :      which list .   would like save reload future .   ideally would like update future state process ( each federate iteration return new state ) model .   idea ?    P.S. also find   thread everything seem deprecate .,"Saving a tensorflow federated model  I have a tensorflow federated model  as seen below: 
 
 where state is the state of the server encapsulating the model. 
 Printing it we have: 
 
 which is the server state. 
I can access the models parameters with: 
 
 which is a list. 
What i would like to do is save this and reload it in the future. 
Ideally i would like to update a future state of the process (each federated iteration returns a new state) with this model. 
Any ideas? 
 P.S. i also found  SO thread but everything there seems to be deprecated. 
",44987.44167
430,75636817,use tensorflow_federate Google Colab ?,"use tensorflow_federate Google Colab ?   I try everything , even command , nothing work !      can somebody explain give step begin use tensorflow - federate without error Google Colab only ?","How to use tensorflow_federated in Google Colab?  I tried everything, even the below commands, but nothing is working! 
 
 Can somebody explain it or give the steps from the beginning on how to use tensorflow-federated without any errors on Google Colab only? 
",44989.6625
431,75800724,error instal TensorFlow Federated Learning . ( error : module tensorflow attribute contrib ),"error instal TensorFlow Federated Learning . ( error : module tensorflow attribute contrib )   I try install tensorflow federate use command : pip install tensorflow_federated installation complete successfuly , import package use command import tensorflow_federate tff get error :    Traceback ( most recent call last ): File "" "" , line 1 , File "" /home / dgholam/.local / lib / python3.10 / site - package / tensorflow_federated/ init .py "" , line 25 , tensorflow_federated.python import File "" /home / dgholam/.local / lib / python3.10 / site - package / tensorflow_federate / python/ init .py "" , line 25 , tensorflow_federated.python.core import File "" /home / dgholam/.local / lib / python3.10 / site - package / tensorflow_federate / python / core/ init .py "" , line 21 , tensorflow_federated.python.core import util File "" /home / dgholam/.local / lib / python3.10 / site - package / tensorflow_federate / python / core / utils/ init .py "" , line 26 , tensorflow_federated.python.core.utils.computation_util import IterativeProcess File "" /home / dgholam/.local / lib / python3.10 / site - package / tensorflow_federate / python / core / util / computation_utils.py "" , line 21 , tensorflow_federated.python.core import api tff File "" /home / dgholam/.local / lib / python3.10 / site - package / tensorflow_federate / python / core / api/ init .py "" , line 22 , tensorflow_federated.python.core.api.computation_types import FederatedType File "" /home / dgholam/.local / lib / python3.10 / site - package / tensorflow_federate / python / core / api / computation_types.py "" , line 26 , tensorflow_federated.python.common_libs import anonymous_tuple file "" /home / dgholam/.local / lib / python3.10 / site - package / tensorflow_federate / python / common_libs / anonymous_tuple.py "" , line 28 , nest = tf.contrib.framework.nest AttributeError : module tensorflow attribute contrib    I appreciate you , help issue . Python : 3.10.2 tensorflow - federate 0.1.0 tensorflow 2.11.0    I try install python 3.9.2 3.9.7 get another error installation . seem tensorflow - federate need tensorflow 2 tensorflow 2 contrib anymore . ( contrib belong tensforlow 1.x.x )","Error when I am installing TensorFlow Federated Learning. (error: module tensorflow has no attribute contrib)  I am trying to install tensorflow federated using command: pip install tensorflow_federated
The installation completes successfuly, but when I am import the package using command
import tensorflow_federated as tff
I get below error: 
 Traceback (most recent call last):
File """", line 1, in 
File ""/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/ init .py"", line 25, in 
from tensorflow_federated.python import *
File ""/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/ init .py"", line 25, in 
from tensorflow_federated.python.core import *
File ""/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/core/ init .py"", line 21, in 
from tensorflow_federated.python.core import utils
File ""/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/core/utils/ init .py"", line 26, in 
from tensorflow_federated.python.core.utils.computation_utils import IterativeProcess
File ""/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/core/utils/computation_utils.py"", line 21, in 
from tensorflow_federated.python.core import api as tff
File ""/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/core/api/ init .py"", line 22, in 
from tensorflow_federated.python.core.api.computation_types import FederatedType
File ""/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/core/api/computation_types.py"", line 26, in 
from tensorflow_federated.python.common_libs import anonymous_tuple
File ""/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/common_libs/anonymous_tuple.py"", line 28, in 
nest = tf.contrib.framework.nest
AttributeError: module tensorflow has no attribute contrib 
 I will appreciate to you, if you can help me with this issue.
Python: 3.10.2
tensorflow-federated  0.1.0
tensorflow  2.11.0 
 I tried to install it with python 3.9.2 and 3.9.7 but I got another errors during installation. It seems tensorflow-federated needs tensorflow 2 and in tensorflow 2 there no contrib anymore. (contrib belongs to tensforlow 1.x.x) 
",45006.48681
432,75874823,Federated learn Differential Privacy - bad test performance,"Federated learn Differential Privacy - bad test performance   I ve play time FL + dp thesis . use TFF case someone wonder .    I load datum as :      and set q sampling ratio      give define dp parameter :      Noise = 0.5    q = 0.015    n_clients_per_round = int(q*len(train_data.client_id ) )      I define aggregation factory :      and iterative process :      my training happen round follow :      the main issue training metric look good model learn slow steady rate   the test metric horrendous . look like model overfitte use dp ( know regulariser ) . absolutely confused .     I ve try several change noise learn structure modify internal round training batch size . start model train well without dp later add dp .    any idea happen ?    good regard ,","Federated learning with Differential Privacy - Bad test performance  Ive been playing for some time with FL + DP for my thesis.
I am using TFF in case someone is wondering. 
 I load my data as: 
 
 And I set Q as sampling ratio 
 
 Given this I define my DP parameters: 
 
 Noise = 0.5 
 Q = 0.015 
 n_clients_per_round = int(Q*len(train_data.client_ids)) 
 
 I define my aggregation factory: 
 
 And the iterative process: 
 
 My training happens in rounds as follows: 
 
 The main issue here is that the training metrics looks good and the model learns at a slow but steady rate but  the test metrics are horrendous . It looks like the model is overfitting while using DP (known to be a regulariser). I am absolutely confused.
 
 Ive tried several changes in the noise and learning structure so as modifying the internal rounds of training and the batch size.
I started with a model that trains well without DP to later add DP. 
 Any ideas why this is happening? 
 Best regards, 
",45014.35278
433,65498670,"expect TensorFlow computation , find intrinsic","expect TensorFlow computation , find intrinsic   I follow code   try run file    require change        I get error . need suggestion .    I use     Python 3.8.3 version","Expected a TensorFlow computation, found intrinsic  I am following this code  and trying to run the file   with some required changes 
 
 
 I got these errors. I need suggestions. 
 I am using   
 Python 3.8.3 version 
",44194.87222
434,65553960,build federated_averaging_process custom federate dataset load CSV file,build federated_averaging_process custom federate dataset load CSV file   my problem continue question     I manage load federate dataset give csv file load train test datum .    my question reproduce work example build iterative process perform custom federate averaging datum .    here code work :      this error get think problem error . wrong ? ?        thnx @Zachary Garrett solve error help add line code      my problem throw    this      what miss again ? maybe something layer sequential here  ,"How to build federated_averaging_process from custom federated dataset that loads from CSV file  My problem is a continue to this question  
 i manage to load a federated dataset from a given csv file and load both the train and the test data. 
 My question now is how to reproduce a working example to build an iterative process that performs a custom federated averaging on this data. 
 Here is my code but its not working: 
 
 This is the error that I got but I think my problem is more than this error. what I am doing wrong here ?? 
 
 
 thnx to @Zachary Garrett
i solve the above error with his help by adding these line of code 
 
 My problem now that is throwing in the   is this 
 
 what i miss again? maybe something in the layer sequential here 
 
",44199.80764
435,65578020,make prediction TFF ?,"make prediction TFF ?   my question : predict label image Tensorflow Federated ?    after complete evaluation model , would like predict label give image . like Keras :      output :      here state model_fn create :      I find error :      thank","How to make prediction with TFF?  My question is : How can I predict a label of such image with Tensorflow Federated ? 
 After completing the evaluation of the model, I would like to predict the label of a given image. Like in Keras we do this : 
 
 Output: 
 
 here is how state and model_fn was created: 
 
 I find this error : 
 
 Thanks 
",44201.47847
436,65578498,"tff : valueerror : Shapes ( none , 1 ) ( none , ) incompatible","tff : valueerror : Shapes ( none , 1 ) ( none , ) incompatible   I use TFF dataset binary_mode class , declare input :      here sample_batch :      and add layer model      when run code , find error :      I think problem sample_batch take label bainary mode . resolve problem thank","TFF : ValueError: Shapes (None, 1) and (None,) are incompatible  I use TFF and My dataset has a binary_mode class,  this is how I declared my inputs : 
 
 Here is my sample_batch : 
 
 and I add this layer in my model 
 
 When running my code, I find this error : 
 
 I think the problem is that sample_batch does not take label with bainary mode.
How can I resolve this problem
Thanks 
",44201.50139
437,65637227,get ValueError build fedAvg multi - output keras model,get ValueError build fedAvg multi - output keras model   I m try federate keras model multiple output . two separate dense layer perform binary classification multi - class classification . get follow ValueError try build federate averaging process     . follow code snippet error information . unable understand go wrong resolve it .      my model_fn ( ) look like this :      where build_model ( ) create keras model :      and input_specification look like this      how build tff fedavg process use model ?,"Getting ValueError for building fedAvg from multi-output keras model  Im trying to federate a keras model which has multiple outputs. There are two separate dense layers that perform a binary classification and a multi-class classification. I am getting the following ValueError when I try to build my federated averaging process   from  . Following are the code snippets and error information. I am unable to understand what is going wrong and how to resolve it. 
 
 My model_fn() looks like this: 
 
 where build_model() creates the keras model: 
 
 And input_specification that looks like this 
 
 How can I build my TFF fedAvg process using such a model? 
",44204.93403
438,65772509,collect weight return client without aggregate,"collect weight return client without aggregate   I would like know easy way create model , broadcast tensorflow federate , run cycle collect weight return client without aggregate fedavg .","Collecting the weights returned by clients without aggregating them  I would like to know the easiest way to create a model, broadcast it with tensorflow federated, run a cycle and collect the weights returned by clients without aggregating them with the fedavg. 
",44214.42639
439,65794925,inspect client model update Tensorflow Federated,"inspect client model update Tensorflow Federated   I ve learn   framework recently run problem . I d like look train client weight send central server aggregation .    for example ,   tutorial , access state variable :      the state variable hold weight central model ( create aggregate client weight ) . anyway inspect weight send client prior aggregation TensorFlow Federated ?    thank , help appreciate .","How to inspect client model updates in Tensorflow Federated  Ive been learning the  framework recently but have run into a problem. Id like to look at the trained client weights sent to the central server before aggregation. 
 For example, in  tutorial, I have access to the state variable: 
 
 The state variables holds the weights of the central model (created by aggregating client weights). Is there anyway to inspect the weights that were sent by the clients prior to aggregation in TensorFlow Federated? 
 Thanks, any help appreciated. 
",44215.66111
440,65828005,Question tff.simulation.datasets.stackoverflow.load_data(cache_dir = none ),"Question tff.simulation.datasets.stackoverflow.load_data(cache_dir = None )   I ve use function load datum stackoverflow data_set . however , one problem occur every time use function set cache_dir location kera / dataset location cache , still try download tar internet(even already 8.5 g tar file download local ) . simple way avoid download internet access local ?    I ve also try write save load function , seem can not apply HDF5ClientData type .","Question about tff.simulation.datasets.stackoverflow.load_data(cache_dir = None)  Ive been using this function to load data from stackoverflow data_set. However, one problem occurs that every time I use this function and set cache_dir to the location of the keras/dataset or the location of the cache, it still tries to download the tar from the internet(Even when I have already the 8.5G tar file download in local). Is there a simple way to avoid downloading from the internet and access by local? 
 Ive also tried to write the save and load function, but it seems they cannot be applied to HDF5ClientData type. 
",44217.54236
441,65830370,TensorFlow Federated Compression : implement stateful encoder use tff build_federated_averaging_process ?,"TensorFlow Federated Compression : implement stateful encoder use tff build_federated_averaging_process ?   in Tensorflow Federated ( TFF ) , pass       , embed customize encoder e.g. apply custom compression .    get point question , try implement encoder sparsify model update / model weight .    I try build encoder implement   ,   . however , struggle implement ( local ) state accumulate zeroed - out coordinate model update / model weight round round . note state communicate , need maintain locally ( so    helpful ) . general , question maintain local state inside Encoder pass fedavg process .    I attach code encoder implementation ( that , besides state would like add , work fine stateless expect ) . attach excerpt code use encoder implementation . decomment comment part   stateful_encoding_stage_topk.py   code work : can not figure manage state ( that tensor ) TF non eager mode .    stateful_encoding_stage_topk.py      fedavg_with_sparsification.py      I use :      tensorflow 2.4.0    tensorflow - federate 0.17.0  ","TensorFlow Federated Compression: How to implement a stateful encoder to be used in in TFFs build_federated_averaging_process?  In Tensorflow Federated (TFF), you can pass to the   a   and an  , which can embed customized encoders e.g. to apply custom compressions. 
 Getting to the point of my question, I am trying to implement an encoder to sparsify model updates/model weights. 
 I am trying to build such an encoder by implementing the  , from  .
However, I am struggling to implement a (local) state to accumulate the zeroed-out coordinates of model updates/model weights round by round. Note that this state should not be communicated, and just need to be maintained locally (so the   should not be helpful). In general, the question is how to maintain a local state inside an Encoder to be then passed to the fedavg process. 
 I attach the code of my encoder implementation (that, besides the state I would like to add, works fine as stateless as expected).
I then attach the excerpt of my code where I use the encoder implementation.
If I decomment the commented parts in  stateful_encoding_stage_topk.py  the code does not work: I cant figure out how manage the state (that is a Tensor) in TF non eager mode. 
 stateful_encoding_stage_topk.py 
 
 fedavg_with_sparsification.py 
 
 I am using: 
 
 tensorflow 2.4.0 
 tensorflow-federated 0.17.0 
 
",44217.63681
442,65871666,Memory ( OOM ) error Tensorflow Federated learning simulation set federate client 12,"Memory ( OOM ) error Tensorflow Federated learning simulation set federate client 12   I OOM error trying run Federated Learning simulation Tensorflow Federated . want train model multiclass text classification , follow   change model , prepared dataset federate learning dataset . server running simulation 1 gpu available .    --I try allow memory growth , batch size power two , many suggestion find online nothing work now .    --I try set    parameter ( as suggest ) seem expect keyword argument . code use be :      and error get be :      I believe problem model , maybe big :      do suggestion ?    currently , get OOM error run federate learn less 12 client .    log :  ","Out of Memory (OOM) error in Tensorflow Federated learning simulation when I set federated clients more than 12  I am having an OOM error while trying to run a Federated Learning simulation with Tensorflow Federated.
I want to train a model for multiclass text classification, I follow the  and changed the model, and prepared my dataset to be a federated learning dataset.
The server I am running my simulations has 1 GPU available. 
 --I tried the allow memory growth, having a batch size in the power of two, and many other suggestions I found online but nothing worked for me until now. 
 --I am trying now to set the   parameter (as it is suggested) but it seems that is not an expected keyword argument.
the code I use is: 
 
 and the error I get is: 
 
 I believe that the problem is with the model, maybe its too big: 
 
 Do you have any suggestions? 
 Currently, I dont get the OOM error only when I run federated learning with less than 12 clients. 
 Logs: 
 
",44220.59653
443,65935511,valueerror : Layer Model invalid state . upgrade tensorflow federate 0.17.0 0.16.1,"valueerror : Layer Model invalid state . upgrade tensorflow federate 0.17.0 0.16.1   I run error upgrade TFF 0.17.0 . code work perfectly TFF 0.16.1 . training work fine version however try copy weight FL state model evaluate test dataset , get follow error :      below keras_evaluate method :      self.state state return tff.learning.build_federated_averaging_process i.e tff.template . IterativeProcess , test_dataset type tf.data . dataset self.model tf.kera . Model type i.e keras functional model . one custom layer however super ( ) method point 2 error mislead I .    any help appreciate .","ValueError: Your Layer or Model is in an invalid state. after upgrading to tensorflow federated 0.17.0 from 0.16.1  I am running into an error after upgrading to TFF 0.17.0. The same code works perfectly in TFF 0.16.1. The training works just fine in both versions however when I try to copy weights from the FL state to model to evaluate it on test dataset, I get the following error: 
 
 Below is my keras_evaluate method: 
 
 self.state is the state returned by tff.learning.build_federated_averaging_process i.e tff.templates.IterativeProcess, test_dataset is of type tf.data.Dataset and self.model is tf.keras.Model type i.e keras functional model. I have one custom layer however it does have super() method so point 2 in the error is misleading me. 
 Any help will be appreciated. 
",44224.44792
444,76106294,solve error get training client flower framework federate learning ?,"solve error get training client flower framework federate learning ?   I try implement Federated Learning use Flower framework python . get follow error start process .    here try ,      in code cid refer clientID ,","How do I solve the error which I get during training the clients in flower framework for federated learning?  I am trying to implement Federated Learning using Flower framework in python. I get the following error when I start the process. 
 Here is what I tried, 
 
 In the above code cid refers to the clientID, 
",45042.00972
445,76132039,unable install tensorflow_federate venv,"unable install tensorflow_federate venv   try install tensorflow_federated venv . always give error        try resolve update Python 3.11.3 pip 23.1.2 , delete venc create new venv , also update setuptool also instal ez_setup none help still unable install tensorflow_federate .    os : Windows 11 Editor : VSCode","Unable to install tensorflow_federated in venv  Trying to install tensorflow_federated in venv. But it always gives an error 
 
 
 tried to resolve it by Updating Python to 3.11.3 and pip to 23.1.2, deleted the venc then again created new venv, also updated setuptools and also installed ez_setup but none of that helps and still unable to install tensorflow_federated. 
 OS: Windows 11
Editor: VSCode 
",45044.7375
446,65943395,track privacy guarantee federate learn process dp - query,"track privacy guarantee federate learn process dp - query   I m bit new TFF , check github follow EMNIST example train differentially private federate model use    algorithm . mainly do attach      train federate model .    I question please :    1 . give attach    aggregation process would result participant - level central - dp , would track privacy guarantee ( eps , delta ) training ?    below code snippet differentially private federate model set 100 participant ,      set 100      I come across several method compute epsilon delta TF - Privacy , seem meant track privacy guarantee traditional    algorithm expect receive parameter   ,       thank lot advance","Track privacy guarantees in a federated learning process with DP-query  Im a bit new to TFF, I have checked github and followed the EMNIST example to train a differentially private federated model using   algorithm. Mainly this is done by attaching a   to the   then train the federated model. 
 I have a question please: 
 1. Given that attaching a   to the aggregation process would result in a participant-level Central-DP ,  How would I track the privacy guarantee (eps, delta) during training ? 
 below is a code snippet where a differentially private federated model is set up with 100 participants, that is why both   and   are set to 100 
 
 I came across several methods to compute epsilon and delta in TF-Privacy, but it seems they are meant to track privacy guarantee of the traditional   algorithm and expect to receive parameters such as  ,    and  
 Thanks a lot in advance 
",44224.78264
447,65987943,tff serializalize function another library ?,"tff serializalize function another library ?   I m plan TFF scheme client send sever datum besides weight , like hardware information ( e.g cpu frequency ) . achieve that , need call function third - party python librarie , like psutil . possible serialize ( use   ) kind function ? not , could solution achieve objective scenario I m use remote executor set grpc ?","Does TFF serializalize functions of another library?  Im planning a TFF scheme in which the clients send to the sever data besides the weights, like their hardware information (e.g CPU frequency). To achieve that, I need to call functions of third-party python libraries, like psutils. Is it possible to serialize (using  ) such kind of functions?
If not, what could be a solution to achieve this objective in a scenario where Im using a remote executor setting through gRPC? 
",44228.25833
448,66042534,accuracy non IID well accuracy iid datum,"accuracy non IID well accuracy IID datum   I work TFF 0.12.0 , architecture resnet50 , execute example iid dataset , example non - iid dataset , find accuracy non - iid dataset well ( high ) accuracy iid dataset especially first round .","Accuracy of non IID is better than accuracy of IID data  I work with TFF 0.12.0, with the same architecture of ResNet50, I execute an example of IID dataset, and an example with non-IID dataset, but I find that accuracy of non-IID dataset is better (high) than accuracy of IID dataset especially in the first rounds. 
",44231.38333
449,66073393,add layer neural network,"add layer neural network   I want add layer neural network customize code ? one suggest well way    in model layer one layer .. part , define weight ? should add layer would make sense      then batch loss function multiply order get predict y .. that s simply add one layer ..      the full code here  ","Adding more layers to neural network  I want to add more layers in neural network how can I customize this code ? can any one suggest a better way 
 in model layer there is only one layer .. in this part , I can define other weights ?should I add other layers there but it would make no sense 
 
 then in batch loss function they multiply by them in order to get the predicted y.. thats simply adding one layer.. 
 
 The full code is here 
 
",44233.15903
450,66088323,extract 20 % descend loss code ?,"extract 20 % descend loss code ?   I follow code :      in code , want average sort 20 % item correspond loss descend order .      how extract loss sort client ?","How can I extract 20% descending loss in this code?  I have the following code: 
 
 In this code, I want to average by sorting 20% of the items corresponding to the loss in descending order. 
 
 How can I extract loss for sorting clients? 
",44234.54861
451,66182614,tensorflow Federated tutorial Google Colab give error initialization code snippet,tensorflow Federated tutorial Google Colab give error initialization code snippet   here cell need run start tutorial .      it give follow error :      need help resolve this . much familiar library class tensorflow .,"Tensorflow Federated tutorial in Google Colab giving errors in the initialization code snippet  Here is the cell that needs to be run before starting the tutorial. 
 
 It is giving out following errors: 
 
 Need help resolving this. I am not much familiar with libraries and classes on Tensorflow. 
",44240.29167
452,66206118,"typeerror : expect tensorflow.python.framework.tensor_spec . TensorSpec , find numpy.ndarray","typeerror : expect tensorflow.python.framework.tensor_spec . TensorSpec , find numpy.ndarray   I get follow error would like migrate TFF 0.12.0 TFF 0.18.0 , know image dataset , sample_batch      so modifiy sample_batch correct version ? please help ! ! thank","TypeError: Expected tensorflow.python.framework.tensor_spec.TensorSpec, found numpy.ndarray  I am getting the following error when i would like to migrate from TFF 0.12.0 to TFF 0.18.0,
Knowing that I have an image dataset, Here is my sample_batch 
 
 So how can I modifiy my sample_batch to be correct with this version ? please Help !! thanks 
",44242.425
453,66223590,tff : necessity .repeat ( ),"tff : necessity .repeat ( )   when read   tensorflow federate image classification , find   , would like understand necessity preprocess function , especially increase number   , simulation take lot time . so , necessary make    , what number epoch choose ?","TFF : What is the necessity of .repeat()  When I read this  of tensorflow federated for image classification, I find  , I would like to understand the necessity of this preprocess function, especially when I increase the number in  , simulation takes a lot of time. So, if it is necessary to make   ,what number of epoch we can choose ? 
",44243.48125
454,66259690,tff : test accuracy fluctuate,"tff : test accuracy fluctuate   I train resnet50 model TFF , use test accuracy test data evaluation , find many fluctuation show figure below , please avoid fluctuation ?  ","TFF : test accuracy fluctuate  I train a ResNet50 model with TFF, I use test accuracy on test data for evaluation, but I find many fluctuations as shown in the figure below, So please how can I avoid this fluctuation ? 
 
",44245.50694
455,66265109,"Federated Learning Tensorflow Federated , way apply early stop client side ?","Federated Learning Tensorflow Federated , way apply early stop client side ?   I use Tensorflow Federated train text classification model federate learn approach . way apply early Stopping client - side ? option cross - validation api ? thing able find evaluation :      which apply model end federate training round .    be miss something ?","Federated Learning in Tensorflow Federated, is there any way to apply Early stopping on the client side?  I am using Tensorflow Federated to train a text classification model with the federated learning approach.
Is there any way to apply Early Stopping on the client-side? Is there an option for cross-validation in the API?
The only thing I was able to find is the evaluation: 
 
 Which is applied to the model by the end of a federated training round. 
 Am I missing something? 
",44245.72986
456,66277072,tff : increase size dataset proportional increase number round ?,"tff : increase size dataset proportional increase number round ?   Lets suppose start train image dataset 500 image . so , would like know time increase database , increase number round achieve good performance ?    thank give opinion .","TFF : Is the increase in the size of the dataset proportional to the increase in number of rounds?  Lets suppose that we started our training with an image dataset of 500 images. So, I would like to know each time we increase the database, we have to increase the number of rounds to achieve good performance? 
 Thanks for giving me your opinions. 
",44246.49375
457,66277912,validation accuracy get low number worker increase Federated Learning non - iid dataset,"validation accuracy get low number worker increase Federated Learning non - iid dataset   I use human activity recognition ( HAR ) dataset 6 class use federate learning ( FL ) . case , implement non - iid dataset assign ( 1 ) class dataset different 6 worker , ( 2 ) two class 3 different worker , ( 3 ) three class 2 different worker .    when run FL process , validation accuracy scenario ( 3 ) > ( 2 ) > ( 1 ) . expect scenario obtain almost validation accuracy . scenario , use hyperparameter setting include batch size , shuffle buffer , model configuration .    be common FL non - iid dataset problem result ?","The validation accuracy gets lower when the number of workers increases in Federated Learning with non-IID dataset  I use human activity recognition (HAR) dataset with 6 classes using federated learning (FL). In this case, I implement the non-IID dataset by assigning (1) each class dataset to different 6 workers, (2) two classes to 3 different workers, and (3) three classes to 2 different workers. 
 When I run the FL process, the validation accuracy for scenario (3) > (2) > (1). I expect that all scenarios will obtain almost the same validation accuracy. For each scenario, I use the same hyperparameter settings including batch size, shuffle buffer, and the model configuration. 
 Is it common in FL with the non-IID dataset or is there any problem with my result? 
",44246.53542
458,66288387,construct function client selection ?,"construct function client selection ?   I try customize average weight client selecete client base client sort loss sum .      I m try use   for sort    averaging . work(typerror , ValueError ... ) . construct    convert tensor Federatedtype ? ? ?","How can I construct function for client selection?  I am trying to customize to average the weights of the clients by seleceting some of the clients based on each clients sorted loss sum in this . 
 
 Im trying to use  for sorting and   for averaging.
But It doesnt work(TypError, ValueError...).
How can I construct   and How to convert tensor to Federatedtype??? 
",44247.23472
459,66304067,error execute federate learn text generation tutorial Colab,error execute federate learn text generation tutorial Colab   I try follow   federate learn TensorFlow execute line get error :      the error :    ,"Error while executing federated learning text generation tutorial in Colab  I am trying to follow this  on federated learning TensorFlow and when executing this line I get an error: 
 
 The error: 
 
 
",44248.65486
460,66309222,access value sequence type ?,"access value sequence type ?   there follow attribute       after that , make    form sequence     in   . declare `      in . process average server , want average    select client small loss value . try access via    work .","How can I access value in sequence type?  There are the following attributes in  
 
 After that, I made the   in the form of a sequence through
  and  in  . and I declared
` 
 
 in . In the process of averaging on the server, I want to average the   by selecting some of the clients with a small loss value. So I try to access it via   but it doesnt work. 
",44249.09444
461,66331850,create FL algorithm use weight client ?,"create FL algorithm use weight client ?   base   try write new way FL algorithm . train client send model parameter client server , server weight average model parameter 30 % client aggregation process . criterion select model parameter 30 % client , want weight average use    30 % client less    client .    the code modify code .      there follow attribute       after that , make    form sequence     in   .      also , follow code add   implement    function .      I sure correct write code way . try various way , mainly    get error .    I wonder sequence type    access client    sort they , also wonder method use calculate weight average    apply .","How do I create an FL algorithm that uses the weights of a few clients?  Based on this  I am trying to write a new way of FL algorithm. I train all clients and send the model parameters of all clients to the server, and the server will weight average only the model parameters of 30% of all clients during the aggregation process. As a criterion for selecting model parameters of 30% of clients, I want to do a weighted average by using   of 30% of clients with less   of clients. 
 The code below is a modified code for this . 
 
 There are the following attributes in  
 
 After that, I made the   in the form of a sequence through
  and  in  . 
 
 Also, the following code is added  to implement the   function. 
 
 I am not sure if it is correct to write the code in the above way.
I tried in various ways, but mainly   I get this error. 
 I wonder how the sequence type   accesses each clients   and sorts them, and also wonders what method to use when calculating the weighted average with   applied. 
",44250.45833
462,66354417,tff : difference two type ?,"tff : difference two type ?     . please refer   detailed code .    my question difference part mark red photo . term FL algorithm , think    individual client output        combine . correct ? guess correct ,    set individual client member   ?","TFF: What is difference between two type?  
 .
Please refer to this  for detailed code. 
 My question is the difference between the parts marked in red on the photo. In terms of the FL algorithm, I think   is a individual client output and   is   because each   is combined. Is this correct? If my guess is correct, is   a set of individual client members with  ? 
",44251.66597
463,66395599,use federate learn object detection,"use federate learn object detection   I plan use federate learn object detection algorithm already develop detect weed . research , see federate tensorflow example Image classification . like follow link :     my question use federate learn federate tensorflow object detection algorithm ? yes , would please provide link example ?","Using federated learning for object detection  I plan to use federated learning for an object detection algorithm I already developed for detecting weeds.
As I research, I see federated tensorflow examples on Image classification. Like the following link:
 
 My question is can we use federated learning and federated tensorflow for object detection algorithms?
If yes, would you please provide me with some links and examples? 
",44254.18611
464,66413948,per example clip TensorFlow Federated dp - fedavg,"per example clip TensorFlow Federated dp - FedAvg   I m try train differentially private federate model use emnist dataset , attach     . moreover , I m resemble    algorithm use    client server optimizer server learning rate set 1 .    the query be :      what type clip query perform ,   batch clip ,   per example clip ?    in   , option use per example clip set      default   .    how something similar here , switch batch clip per example clip Federated setting ?","Per example clipping in TensorFlow Federated with DP-FedAvg  Im trying to train a differentially private federated model using EMNIST dataset, I have attached the   to the  . Moreover, Im resembling the   algorithm by using   as both client and server optimizer with server learning rate set to 1. 
 The query is: 
 
 What type of clipping does this query perform, is it  batch clipping , or  per example clipping ? 
 In  , the option to use the per example clipping was to set the   to   so it defaults to the  . 
 How can I do something similar here, and switch between the batch clipping and per example clipping in Federated settings? 
",44255.88958
465,76192353,get new function module tensorflow_federated.python.learning attribute assign_weights_to_keras_model,get new function module tensorflow_federated.python.learning attribute assign_weights_to_keras_model   can anybody help replace function ? get error code :  ,"Couldnt get any new function for module tensorflow_federated.python.learning has no attribute assign_weights_to_keras_model  Can anybody help me to replace this function? I am getting error for these code: 
 
",45053.23542
466,76232799,get error install tensorflow federate Colab like IndexError,"get error install tensorflow federate Colab like IndexError   I try install Tensorflow Federated Google Colab get error . surprisingly , open new notebook , install Tensorflow Federated . anyone please help I ?    however use    too .  ","Getting error to install tensorflow federated on Colab like IndexError  I am trying to install Tensorflow Federated on Google Colab but am getting error. Surprisingly, if I open new notebook, I can install Tensorflow Federated. Can anyone please help me? 
 However I used   too. 
 
",45058.11181
467,76407619,tensorflow federate increase default_serialization_limit_byte,tensorflow federate increase default_serialization_limit_byte   I m federate learn tensorflow federate      this code give error      I try follow code increase limit function exist anymore tensorflow federate version 0.58  ,"Tensorflow federated increase default_serialization_limit_bytes  Im doing federated learning with tensorflow federated 
 
 this is my code and its give this error 
 
 I have try the following code to increase the limit but the function doesnt exist anymore in the tensorflow federated version 0.58 
 
",45082.61528
468,76450661,tensorflow Federated - can not install,"tensorflow Federated - can not install   I try install   Tensorflow federate   install    by use    Command Prompt start download version 0.48.0 say trying find compatible version start download version 0.17.0 ,    rise    I python 3.10.11(no anaconda similar app )    anybody know do ?  ","Tensorflow Federated - cant install  i try to install  Tensorflow federated  but it wont install 
 by using   in Command Prompt it start to download version 0.48.0
but it says its trying to find a compatible version and starts to download all version down to 0.17.0, then   will rise 
 i have python 3.10.11(no anaconda or similar app) 
 anybody knows what should i do? 
 
",45088.55625
469,76716812,extract Federated Reconstruction Model Weights,"extract Federated Reconstruction Model Weights   so I m create recommendation system use Federated Reconstruction tutorial Tensorflow Federated . want use extract model modelweight run problem . get attribute error whenever try save model modelweight say ModelWeights save function etc . anyway save model weight build onto DNN Sequential Model ?    Source Code :     I try model.save ( ) , model_weights.save_weight ( ) , model.save_weight ( )","Extracting a Federated Reconstruction Model and its Weights  So Im creating a recommendation system using this Federated Reconstruction tutorial on Tensorflow Federated. I want to use and extract the model and the modelweights but I run into some problems. I get attribute errors whenever I try saving a model or modelweight saying ModelWeights doesnt have save function etc. Is there anyway I can save the model weights so I can build it onto a DNN or Sequential Model? 
 Source Code:  
 I tried model.save(), model_weights.save_weights(), model.save_weights() 
",45125.92292
470,66451298,federate learn process poisson subsample participant,"federate learn process poisson subsample participant   I m perform experiment   . one , would like sample participate client train around accord    client sample probability     at round ,    perform list    fill   unique id   equal number   .      be well way perform   , especially subsample apply   ,    yield accurate privacy analysis result ?    what would good strategy set value      value ?","Federating learning process with poisson subsampling of participants  Im performing few experiments with  . In this one, I would like to sample the participating clients at each training around according to   where each client is sampled with a probability of  
 At each round,   is performed until the list   is filled with  unique ids  equal to the number of  . 
 
 Is there a better way of performing  , especially if the subsampling is applied in  , so that the   yields accurate privacy analysis results ? 
 What would be the best strategy to set the value of   other than   values ? 
",44258.23056
471,66472157,Federated average implementation python,"Federated averaging implementation python   I work federate learning . use global server define cnn base classifier . global server compile model hyper - parameter send edge(client ) , currently use two client . client use local datum ( for use datum , model client ) . training model , client 95 percent accuracy , precision recall local model . client send train local model server . server get model get weight receive model compute average accord . code write implement formula python . set average weight model try predict , accuracy , recall precision fall 20 % .    be something wrong implementation ?  ","Federated averaging implementation in python  I am working with federated learning. I am using a global server where I defined a cnn based classifier. The global server compiles the model with hyper-parameters and send it to the edge(clients), currently I am using two clients. Each client uses its local data (for now I am using same data, and model on each client). After training model, each client has above 95 percent accuracy, precision and recall in their local models. clients sends their trained  local model to the server. The server gets the model and and gets the weights from each received model and computes average according to . Below is the code I wrote to implement this formula in python. when I set the average weights to  models and try to predict, the accuracy, recall and precision fall below 20%. 
 Am I doing something wrong in implementation? 
 
",44259.39375
472,76750150,library get weight local model every round Federated Learning ?,"library get weight local model every round Federated Learning ?   in federated learning , want get weight local model every round , cluster local client base weight , use training_process.get_model_weights(train_state ) get global weight only .    I use training_process.get_model_weights(train_state ) get global weight , find library function get weight client yet .","Is there an library to get weights of each local model every round of Federated Learning?  In federated learning, I want to get weights of each local model every round, then I will cluster local clients based on their weights, but I can just use training_process.get_model_weights(train_state) to get global weights only. 
 I did use training_process.get_model_weights(train_state) to get global weights, but I havent found any library or function to get weights of each clients yet. 
",45130.84444
473,76827472,"obtain f1score , Recall , Confusion Matrix precison","obtain f1score , Recall , Confusion Matrix precison   how obtain f1score , Recall , Confusion Matrix precison code . I use compile obtain accuracy do not know write code obtain metric model . I would thankful te help I . comm_round range(comms_round ):      also want graph performance model train test set record training use line plot , one loss classification accuracy .","Obtain F1score, Recall, Confusion Matrix and precison  How can I obtain F1score, Recall, Confusion Matrix and precison in this code.I have used compile and obtained accuracy but i dont know how write the code to obtain these metrics from my model.I would be thankful te help me.
for comm_round in range(comms_round): 
 
 Also I want to graph the performance of the model on the train and test sets recorded during training using a line plot, one for each of the loss and the classification accuracy. 
",45141.45972
474,77116019,attributeerror : module tensorflow_federated.python.learning attribute from_keras_model,"attributeerror : module tensorflow_federated.python.learning attribute from_keras_model   attempt run federate learn tff however , encounter follow :    AttributeError : module tensorflow_federated.python.learning attribute from_keras_model    Code : trainer = tff.learning.algorithms.build_weighted_fed_avg ( model_fn , client_optimizer_fn = lambda : tf.keras.optimizer . Adam ( ) , server_optimizer_fn = lambda : tf.keras.optimizer . Adam ( ) )    state = trainer.initialize ( ) train_hist = [ ] range(EPOCHS ): state , metric = trainer.next(state , train_data ) train_hist.append(metric )      Environment : use Google collab python - 3.10.12 TensorFlow Federated version : 0.61.0    any help appreciate .    attempt downgrade version TFF","AttributeError: module tensorflow_federated.python.learning has no attribute from_keras_model  Attempting to run federated learning on tff however, encountering the following: 
 AttributeError: module tensorflow_federated.python.learning has no attribute from_keras_model 
 Code:
trainer = tff.learning.algorithms.build_weighted_fed_avg(
model_fn,
client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),
server_optimizer_fn=lambda: tf.keras.optimizers.Adam()
) 
 state = trainer.initialize()
train_hist = []
for i in range(EPOCHS):
state, metrics = trainer.next(state, train_data)
train_hist.append(metrics) 
 
 Environment:
Using Google collab
python - 3.10.12
TensorFlow Federated version: 0.61.0 
 Any help appreciated. 
 Attempted to downgrade version of TFF 
",45185.05556
475,77244883,unsuccessfully run tensorflow federate hello world example,"unsuccessfully run tensorflow federated hello world example   I try execute tensorflow federate "" hello world "" jupyter notebook Visual Studio Code , however code freeze display anything .    here code :      output look something like :      below package version detail :      python : 3.9.16    tensorflow_federate : 0.48.0    tensorflow : 2.11.1    notebook : 7.0.4      can anyone suggest correct ?","Unsuccessfully running tensorflow federated Hello world example  I am trying to execute tensorflow federated ""Hello world"" in jupyter notebook on Visual Studio Code, however the code freezes and doesnt display anything. 
 Here is the code: 
 
 Output looks something like: 
 
 Below are package version details: 
 
 python: 3.9.16 
 tensorflow_federated: 0.48.0 
 tensorflow: 2.11.1 
 notebook: 7.0.4 
 
 Can anyone suggest how can this be corrected? 
",45205.5625
476,66546336,initialize computation construct server state,"initialize computation construct server state   in federated learning context , like   show , initial weight global model ( at server level ) initialize randomly :   . want hand put initial weight download another model ( ) . please proceed , I m new TFF . thank","the initialize computation to construct the server state  In the federated learning context, and like this  shows, initial weights of global model (at server level) are initialized randomly with :  . I want to have the hand to put these initial weights by downloading them from another model ( ). So please how can I proceed, Im newer in TFF.
Thanks 
",44264.49306
477,66557738,explode memory consumption training FL model vary number participant per round,"explode memory consumption training FL model vary number participant per round   I m run FL algorithm follow   tutorial . number participant vary round accord predefine list participant number .      the federated datum preprocesse batch start training .      participant randomly sample    round accord   ,    execute   .      the problem    usage quickly explode round , reach    round   , keep increase approx rate    training eventually crash round    vram reach      python thread create .    error message below      # # # troubleshoot # # #    reduce      allow training complete , memory consumption still huge growing .    run code fix number participant per round , memory consumption fine total approx    VRAM throughout entire training .      extra detail :      be normal memory behaviour   ? refactoring / hint optimize memory consumption ?","Exploding memory consumption when training FL model with varying number of participants per round  Im running FL algorithm following the  tutorial. The number of participants vary at each round according to a predefined list of participants number. 
 
 The federated data is preprocessed and batched before starting the training. 
 
 Participants are randomly sampled from   at each round according to the  , then the   is executed for  . 
 
 The problem is that the   usage quickly explodes after few rounds, it reaches   at round  , and keeps increasing with an approx rate of   until the training eventually crashes at round   where the VRAM reaches   with   python threads created. 
 Error message below 
 
 ### Troubleshooting ### 
 Reducing the   to   allows the training to complete, but the memory consumption was still huge and growing. 
 Running the same code with fixed number of participants per round, memory consumption was fine with total of approx   VRAM throughout the entire training. 
 
 Extra details: 
 
 Is this a normal memory behaviour or a  ? Are there any refactoring/hints to optimize memory consumption ? 
",44265.125
478,66579541,state = iterative_process.initialize ( ) dow Federated learning,"state = iterative_process.initialize ( ) dow Federated learning   I m new Federated learning , try implement code FL image classification , can not understand line :   , Weights affected server ?","What state = iterative_process.initialize() dow in Federated learning  Im new in Federated learning, I tried to implement the code of FL for image classification, but I cant understand this line :  , Weights affected to the server from where ? 
",44266.3875
479,66581075,WARNING : tensorflow : AutoGraph could transform    0x7fca141a6d08 > run as - be,"WARNING : tensorflow : AutoGraph could transform    0x7fca141a6d08 > run as - be   I implement code TFF image classification . TFF version 0.18.0 , write :      but find warning :      so please avoid warn . thank","WARNING:tensorflow:AutoGraph could not transform   at 0x7fca141a6d08> and will run it as-is  I implement the code of TFF of image classification. TFF version 0.18.0,
I write this : 
 
 But I find this warning: 
 
 So please how can I avoid this warning. Thanks 
",44266.45208
480,66705900,tensorflow Federated instal Apple Silicon M1 ?,"tensorflow Federated instal Apple Silicon M1 ?   I want install Tensorflow Federated macos Apple Silicon M1 .    I try instal Python 3.9.1 pyenv create virtual environment . instal package .      some error raise dependency conflict instal Tensorflow Federated . see partial error log below :      I guess happen require package ready satisfy Apple Silicon M1 arm architecture ? right ?    be solution install Tensorflow Federated macos Apple Silicon M1 now ?      Edited Mar 20 , 2021 :    thank   user .    the problem numpy solve follow .    but dependency conflict still here .  ","Can Tensorflow Federated be installed on Apple Silicon M1?  I want install Tensorflow Federated in a macOS with Apple Silicon M1. 
 I have tried installing Python 3.9.1 with pyenv and create a virtual environment. Then I installed the package. 
 
 Some errors raised because of dependency conflict when installed Tensorflow Federated. You can see partial of error logs below: 
 
 I guess it happened because some required packages is not ready to satisfy the Apple Silicon M1 with the ARM architecture? Am I right? 
 Is there any solution to install Tensorflow Federated in a macOS with Apple Silicon M1 now? 
 
 Edited on Mar 20, 2021: 
 Thanks for the  from the user . 
 The problem of numpy is solved by following . 
 But the dependency conflict is still here. 
 
",44274.40903
481,66776030,proper way save client federate dataset,"proper way save client federate dataset   I would like train two independent    model use    dataset . model train    distinct participant randomly draw dataset .    Code below      try save dataset      the warning generate . however , save complete .      the problem occur upon load dataset try inspect content      Error below      try method     , result error below      be good way save newly create dataset ?","Proper way of saving clients federated datasets  I would like to train two independent   models using   dataset. Each model should train on a   distinct participants randomly drawn from the dataset. 
 Code below 
 
 Trying to save the dataset 
 
 the warning below is generated. However, the save is completed. 
 
 The problem occurs upon loading the dataset and trying to inspect its contents 
 
 Error below 
 
 Trying other methods such as   and  , all resulted in error below 
 
 Is there any good way to save the newly created datasets ? 
",44279.28681
482,77352499,tensorflow federate installation give error,tensorflow federate installation give error   iâ´m try install Tensorflow Federated run pip install tensorflow - federate new Anaconda environment Python 3.11 Windows give error :      IÂ´ve try install version python work Python 3.8 point version librarie old work come compatability issue .    would appreciate help !    and thank time !,"Tensorflow federated installation giving error  IÂ´m trying to install Tensorflow Federated by running pip install tensorflow-federated in a new Anaconda environment with Python 3.11 in Windows but it gives me this error: 
 
 IÂ´ve tried to install it in other versions of python but it only works on Python 3.8 and at that point some versions of libraries are to old to work and comes up with compatability issues. 
 Would appreciate some help! 
 And thanks for your time! 
",45223.56181
483,77547784,can not import tensorflow_federate,can not import tensorflow_federate   an attribute Error raise import tensorflow_federated colab though install it .          -- > import tensorflow_federated tff : AttributeError : module numpy attribute _ no_nep50_warne    how solve it ? thank you !      ,"Cant import tensorflow_federated  An attribute Error raised when importing tensorflow_federated on colab though I did install it. 
 
 
 
 --> import tensorflow_federated as tff : AttributeError: module numpy has no attribute _no_nep50_warning 
 how can I solve it?
Thank you! 
 
 
 
",45255.50417
484,77732938,training federate model bert resnet pre - train model,training federate model bert resnet pre - train model   I want train multi - modal model federate learning environment . model definition .      this    code   . want train model get error .   load datum use generator . value error  ,"training federated model by bert and resnet pre-train model  I want to train a multi-modal model in the federated learning environment.
this is my model definition. 
 
 this is my   code  .
When I want to train the model I got this error. 
I load my data by using the generator.
and this is my value error 
 
",45289.67847
485,77858001,attributeerror : module tensorflow_federated.python.core.backends.native attribute set_remote_python_execution_context,"attributeerror : module tensorflow_federated.python.core.backends.native attribute set_remote_python_execution_context   I follow code :      when run part code get error :      I know    deprecate , fix this ?    I try use    execution base    release - note , none exactly   .","AttributeError: module tensorflow_federated.python.core.backends.native has no attribute set_remote_python_execution_context  I have the following code: 
 
 when I run this part of code I got this error: 
 
 I know   is deprecated,
but how can I fix this? 
 I tried to use   executions based on   released-notes, but none of them didnt exactly same as  . 
",45313.27153
486,77876217,perform Federated Learning different dataset file output feature different input feature ?,"perform Federated Learning different dataset file output feature different input feature ?   Iâ€ ™ m apply federate learn several dataset , have similar output feature different input feature , cany that . feature mean column dataset . want know even possible do ? please provide comprehensive answer ?","How can I perform Federated Learning on different dataset files having same output feature but different input feature?  Iâ€™m apply federated learning on several datasets,having similar output feature but different input features, how cany I do that. By feature I mean columns in the dataset. I want to know is this even possible to do? Please provide a comprehensive answer? 
",45315.87917
487,66778069,tensorflow Federated c++,"tensorflow Federated C++   I m try find way utilise Tensorflow Federated C++ . know possible regular Tensorflow Core api , however can not find way federate . possible suggestion workaround would highly appreciate !","Tensorflow Federated in C++  Im trying to find a way to utilise Tensorflow Federated in C++. I know its possible to do it for the regular Tensorflow with the Core API, however I cant find a way for Federated. If its not possible suggestions for workarounds would be highly appreciated! 
",44279.39167
488,67053731,error use update_struct function TensorFlow Federated,"error use update_struct function TensorFlow Federated   I m attempt run   TensorFlow Federated GitHub repository receive follow error server_update function :    AttributeError : module tensorflow_federated.python.common_libs.structure attribute update_struct    I old TensorFlow Federated code use update_state function tff.util package place update_struct ( ) accord commit GitHub package empty now . I m use TensorFlow Federated version 0.18.0 also problem try Google CoLab .    my question fix error ?    thank , help appreciate .","Error using update_struct function in TensorFlow Federated  Im attempting to run the  from the TensorFlow Federated GitHub repository but receiving the following error in the server_update function: 
 AttributeError: module tensorflow_federated.python.common_libs.structure has no attribute update_struct 
 I have some old TensorFlow Federated code that uses the update_state function from the tff.utils package in place of update_struct() but according to a commit on GitHub this package is empty now. Im using TensorFlow Federated version 0.18.0 and I also had the same problem trying on Google CoLab. 
 My question is how can I fix this error? 
 Thanks, any help appreciated. 
",44298.28125
489,67057583,tff : modify process include initialization iterate computation,tff : modify process include initialization iterate computation   what write code :  ,"TFF : Modify the process that includes an initialization and iterated computation  what can I write in this code : 
 
",44298.47917
490,67077757,tensorflow Federated Python package source google colab,tensorflow Federated Python package source google colab   hello try install tensorflow_federate scratch source code google colab instruction   order execute example test source code    I instal bazel google colab follow command      and type      the output seem fine    but try install tensorflow federate instruction mention get error    more particularly type      I get follow output      and want import tensorflow federate get output      can somebody help ? thank advance,"TensorFlow Federated Python package from source in google colab  Hello I am trying to install tensorflow_federated from scratch by its source code in google colab with the instructions from  in order to execute the examples and the tests from the source code 
 I installed bazel in google colab with the following commands 
 
 and when i type 
 
 the output seems fine 
 But when I try to install tensorflow federated with instructions mentioned above i get an error 
 more particularly when i type 
 
 I get the following output 
 
 And when i want to import tensorflow federated i get this output 
 
 Can somebody help me  ?
Thank you in advance 
",44299.63889
491,67077765,MODEL_SPEC Federated Learning ( use Tensorflow Federated Core ),"MODEL_SPEC Federated Learning ( use Tensorflow Federated Core )   I try use Federated code build federate learning algorithm . meet one problem . official tutorial , define Model Spec like follow :          I wonder require input model OrderedDict . could input model trainable Keras model ?    thank !","MODEL_SPEC in Federated Learning (Using Tensorflow Federated Core)  I am trying to use Federated code to build my own federated learning algorithm. But I met one problem. In the official tutorial, it define the Model Spec like following: 
 
 
 
 I am wondering if it is required to input the model as an OrderedDict. Could I input the model as a trainable Keras model? 
 Thanks! 
",44299.63958
492,67101197,datum augmentation tensorflow federate ?,"datum augmentation tensorflow federate ?   I m hope explore datum augmentation work federate learning , I m currently use tff implement it . notice dataset provide tff compose tensor , tensor can not adjust directly , naive idea would change numpy array augmentation . try     provide numpy array , get problem try pass preprocess function . do :     where preprocess define as      I would get follow error :      which seem mean   _ IterableDataset   object numpy array can not apply method .    and try wrap    method   , end error :      be way solve problem ? could augmentation datum provide ?    update    it would enough use    function want convert sample dataset augment one . however , want add new sample dataset(e.g . add sample different label ) , it ? since can not modify client dataset directly , think convert numpy array make processing , yet do :       client dataset , get      seem    apply process . way convert dataset back acceptable   ? well way kind augmentation ?    Update 2    I try use generator GAN model generate new image augment dataset . pretraine GAN ( write tf.keras ) , write datagenerator wrap model augment client dataset . however , fed - avg training , follow error occur :      here    keras model generation . suspect tff computation graph different one use create instance generator model . code training like toturial .      but point strange thing happen uncomment two line go loop . time training could go smoothly , still report bug go loop . therefore guess first time preprocess do , tff use different graph ? possible solution it ?","How to do data augmentation with tensorflow federated?  Im hoping to explore how data augmentation work on federated learning, and Im currently using tff to implement it. I notice that the datasets provide by tff is composed of tensors, and tensors cannot be adjusted directly, so a naive idea would be to change it to numpy arrays and then do augmentation. I tried 
 
and it did provided me with numpy arrays, but I got problems when trying to pass it to preprocess functions. If I do:
 
 where preprocess is defined as 
 
 I would get the following error: 
 
 which seems to mean that this  _IterableDataset  object of numpy arrays cannot be applied for these methods. 
 And I tried wrapping   method as  , but it ends up with this error: 
 
 Is there any way to solve this problem? Or could I do augmentation just on the data it provides? 
 Updates 
 It would be enough to just use   function if I only want to convert each sample in the dataset to a augmented one. However, if I want to add new samples to the dataset(e.g. adding samples of different labels), how can I do it? Since we cant modify the client dataset directly, I was thinking converting it to a numpy array and make further processing, yet if I do: 
 
where   is a client dataset, I got 
 
 Seems this   couldnt be applied to the process. Is there a way that I can convert this dataset back to what is acceptable by  ? Or is there a better way to do this kind of augmentation? 
 Update 2 
 I was trying to use a generator from a GAN model to generate new images to augment the dataset.  I have a pretrained GAN (written by tf.keras), and I wrote a dataGenerator to wrap this model for augmenting the client datasets. However, when I do the fed-avg training, the following error occurred: 
 
 Here   is just the keras model for generation. I suspect this is because in tff the computation graph is different from the one I used to create an instance of the generator model. The code for training is just like the toturial . 
 
 But at this point strange things happen if I uncomment the two lines before going into the loop. This time the training could go smoothly, but still reports the same bug after going into the loop. Therefore I guess after the first time this preprocess is done, tff is using some different graph? Is there any possible solution to it? 
",44301.07986
493,67138338,unable interpret argument type tensorflow.python.data.ops.dataset_op . PrefetchDataset TFF value iterative process,"unable interpret argument type tensorflow.python.data.ops.dataset_op . PrefetchDataset TFF value iterative process   I m try run classification simulation tff , I m get error :      here code I m use      I m use creditcard dataset :     the    list   , like tutorial Tensorflow Federated website .","Unable to interpret an argument of type tensorflow.python.data.ops.dataset_ops.PrefetchDataset as a TFF value in iterative process  Im trying to run a classification simulation in tff, but Im getting this error: 
 
 Here is the code Im using 
 
 Im using this creditcard dataset:  
 The   is a list of  , just like the tutorial from the Tensorflow Federated website . 
",44303.53125
494,67147951,tensorflow_federated.python.simulation attribute FromTensorSlicesClientData use tff - nightly,"tensorflow_federated.python.simulation attribute FromTensorSlicesClientData use tff - nightly   I using    create client datum stable version tff , work fine . switch tff - nightly , call give error :      Heres section code , error throw :      should different way ?","tensorflow_federated.python.simulation has no attribute FromTensorSlicesClientData when using tff-nightly  I was using   to create clients data with the stable version of tff, and it was working fine. I had to switch to tff-nightly, and now calling this gives me an error: 
 
 Heres the section of my code, where the error is thrown: 
 
 Should I be doing this a different way? 
",44304.47361
495,67213520,TFF : tff support model except neurel network ?,"TFF : tff support model except neurel network ?   I m try make comparison different federate learn framework . look TFF site , could find information model support . look   talk weight , ...    be miss something TFF use model except neural network ?","TFF: Does TFF support any other models except neurel networks?  Im trying to make a comparison between different federated learning frameworks.
When looking on the TFF site, I could not find any information about which models are supported.
Looking at the  they only talked about weights,... 
 Am I missing something or can TFF not be used for other models except neural networks? 
",44308.52847
496,67384361,use Homomorphic Encryption tensorflow - federate,use Homomorphic Encryption tensorflow - federate   I use tensorflow - federated(TFF ) develop federate aggregation method . wonder use homomorphic encryption(he ) tensorflow - federate . notice TFF use tff.federated_mean ( ) aggregate gradient every client . TFF provide similar api interface implement he ? thank much .,"How to use Homomorphic Encryption in tensorflow-federated  I am using tensorflow-federated(TFF) to develop my own federated aggregation method. I wonder if I can use Homomorphic Encryption(HE) in tensorflow-federated. I notice that TFF uses tff.federated_mean() to aggregate the gradients from every clients. Does TFF provide a similar API or interface to implement HE? Thank you very much. 
",44320.5
497,78158329,face error Learning Attribute work Tensorflow federate,"face error Learning Attribute work Tensorflow federate   I m use NBIOT dataset select provision_pt_737e_security_camera dataset benign , mirai gagfyt attack .    the error be :      am right way ? improve I m do ?  ","Facing error in Learning Attribute while working in Tensorflow federated  Im using NBIOT dataset where i have selected only Provision_PT_737E_Security_Camera dataset of benign, mirai and gagfyt attacks. 
 The error is: 
 
 Am I doing it the right way? or how to improve what im doing? 
 
",45365.23264
498,78177521,"run example code tensorflow documentation , pertain Tensorflow - Federated , result AttributeError","run example code tensorflow documentation , pertain Tensorflow - Federated , result AttributeError   I try run code give tensorflow official documentation , pertain Tensorflow - Federated . code follow :      however , get follow error :      AttributeError : module tensorflow_federated.python.learning attribute from_keras_model      be something wrong documentation wrong ?","Running example code from Tensorflow documentation, pertaining to Tensorflow-Federated, results in AttributeError  I am trying to run the code given by Tensorflow in their official documentation, pertaining to Tensorflow-Federated. The code is as follows: 
 
 However, I am getting the following error: 
 
 AttributeError: module tensorflow_federated.python.learning has no attribute from_keras_model 
 
 Am I doing something wrong or is the documentation wrong? 
",45369.04375
499,78181211,extend TensorFlow Federated,extend TensorFlow Federated   I m new Federated Learning please bear I . I m work university project I d like build decentralized peer - to - peer network train model without datum sharing without need aggregator ( a central server joint model ) . idea take TensorFlow Federated add client state possibly use Gossip protocol enable client talk other . know possible / feasible TensorFlow Federated . I d appreciate feedback this !    I try look example online find anything .,"Extending TensorFlow Federated  Im new to Federated Learning so please bear with me. Im working on a university project where Id like to build a decentralized peer-to-peer network so that I can train models without data sharing and without the need for an aggregator (a central server with a joint model). The idea is to take TensorFlow Federated and add some client state and possibly use Gossip protocol to enable clients to talk to each other. I dont know if its possible/feasible with TensorFlow Federated. Id appreciate any feedback on this! 
 I tried looking for examples online but didnt find anything. 
",45369.63958
500,78212508,convert frame feature frame mask single variable datum ?,"convert frame feature frame mask single variable datum ?   I try convert dataset tensorflow tensor . however , let so . follow keras video classification tutorial ( ) . tutorial convert train video datum frame feature frame mask feed model training .      I try convert frame feature frame mask single tensorflow tensor feed datum federate learn training . however work . apply tf.ragged.constant luck that .","How to convert frame features and frame mask as a single variable data?  I was trying to convert a dataset as tensorflow tensor. However, it is not letting me to do so. I followed the keras video classification tutorial (). The tutorial converts training video data into frame features and frame mask and then feeds both for model training. 
 
 I tried to convert the frame features and frame masks into a single tensorflow tensor so that I can feed the data into a federated learning training. However it is not working. I applied  tf.ragged.constant but no luck on that. 
",45374.88542
501,78277626,python 3.10 error install tensorflow_federate,"python 3.10 error install tensorflow_federate     python version : 3.10    pip version : 24.0      I use env . TFF require : Python < 3.12 , > = 3.9    when pip install tensorflow_federated terminal ( env on ) receive problem :      how fix it ?    run : pip install tensorflow_federated terminal notice :      runtimeerror : Python version 2.7 3.4 + require .      my python version : 3.10 . do ?","python 3.10 and error when install tensorflow_federated  
 python version: 3.10 
 pip version: 24.0 
 
 I use env.
TFF required: Python <3.12, >=3.9 
 when I pip install tensorflow_federated in terminal (env is on) and received this problem: 
 
 How do I fix it? 
 run: pip install tensorflow_federated in terminal and noticed: 
 
 RuntimeError: Python version 2.7 or 3.4+ is required. 
 
 my python version: 3.10.
what should I do? 
",45387.15
502,78302946,save state(tff.learning.template . learningalgorithmstate ) load resume training process,save state(tff.learning.template . learningalgorithmstate ) load resume training process   this evaluate function federate learning :      I need save state 10 round need load state resume 11th round . it ? help I ...,"How to save the State(tff.learning.templates.LearningAlgorithmState) and again load it to resume the training process  This is my evaluate function for federated learning: 
 
 I need to save the state after 10 rounds and need to load the state and resume from the 11th round.
How to do it? Help me... 
",45392.34028
