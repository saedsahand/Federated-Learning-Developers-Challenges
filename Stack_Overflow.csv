Id,PostTypeId,AcceptedAnswerId,ParentId,CreationDate,DeletionDate,Score,ViewCount,Body,OwnerUserId,OwnerDisplayName,LastEditorUserId,LastEditorDisplayName,LastEditDate,LastActivityDate,Title,Tags,AnswerCount,CommentCount,FavoriteCount,ClosedDate,CommunityOwnedDate,ContentLicense
59430106,1,,,43819.78742,,1,145,"<p>I have read all the documents on the tensorflow federated available at tensorflow.org, but I am not sure how to implement my own federated algorithm. For example, I have a compiled keras model, I know how to convert this to tff.computation. It seems that in order to build a federated algorithm one should build an iterative_process. Can anyone help me in this regard? </p>

<p>Thank you so much, </p>
",12572107,,730754,,44163.45777,44163.45777,How to implement my own federated algorithm Usinsg tensorflow federated,<tensorflow><tensorflow-federated><federated-learning>,2,0,,,,CC BY-SA 4.0
59481435,1,59481825,,43824.82839,,1,604,"<p>Let's consider, I have four models following as M1 (client 1), M2 (client 2), M3 (client 3), and M4 (client 4). Each model has a similar structure. </p>

<p><a href=""https://i.sstatic.net/FXst1.jpg"" rel=""nofollow noreferrer"">Model Structure</a></p>

<p>After training for each client model. I have aggregated these models together and create a new model which is let's say ""EnsModel"". After that, I have used this ensemble model to retrain new data for each client again. However, when I tried to ensemble the updated models again, I faced this problem that says
""ValueError: The name ""Sequential"" is used 4 times in the model. All the layer names should be unique?""</p>

<p>Can anybody help me out? I also have one question. Is there any way that I can model modify the ensemble model structure for each client?</p>

<p>Thank you.</p>
",4615728,,730754,,44163.45749,44163.45749,"ValueError: The name ""Sequential"" is used 4 times in the model. All the layer names should be unique?",<machine-learning><keras><ensemble-learning><federated-learning>,1,0,,,,CC BY-SA 4.0
59484278,1,,,43825.23825,,1,414,"<p>I am trying a Linear Regression algorithm with Federated learning using Pytorch and I face the following error. I am implementing it on Colab. According to me this error might be due to some code line in the train() function. Kindly help is you have worked with Pysyft and have faced such error before. </p>

<pre><code>RuntimeError: invalid argument 8: lda should be at least max(1, 0), but have 0 at /pytorch/aten/src/TH/generic/THBlas.cpp:363
</code></pre>

<p>And the following is the code:</p>

<pre><code>#import the necessasry packages
import torch
from torch.autograd import Variable
import torch.nn as nn
import torch.nn.functional as F
import syft as sy

#create target and data variables as tensors
x_data=Variable(torch.Tensor([[1.0],[0.0],[1.0],[0.0]]))
y_data=Variable(torch.Tensor([[0.0],[0.0],[1.0],[1.0]]))

#Create virtual Workers
hook = sy.TorchHook(torch)
bob = sy.VirtualWorker(hook, id=""bob"")
alice = sy.VirtualWorker(hook, id=""alice"")

data_bob = x_data[0:2]
target_bob = y_data[0:2]
data_alice = x_data[2:0]
target_alice = y_data[2:0]

#creating a class that does Linear Regression
class LinearRegression (nn.Module):

  def __init__(self):
    super(LinearRegression,self). __init__ ()
    self.linear = torch.nn.Linear(1,1)

  def forward(self, x):
    y_pred = self.linear(x)
    return y_pred

#assign the function to the variable name 'Model'
model=LinearRegression()

#send the data to the virtual worker pointers
data_bob = data_bob.send(bob)
data_alice = data_alice.send(alice)

target_bob = target_bob.send(bob)
target_alice = target_alice.send(alice)

# organize pointers into a list
datasets = [(data_bob,target_bob),(data_alice,target_alice)]

#create optimizer and calculate the loss
opt = torch.optim.SGD(params=model.parameters(),lr=0.1)
criterion = torch.nn.MSELoss(size_average=False)

def train():
  opt = torch.optim.SGD(params=model.parameters(),lr=0.1)
  for epoch in range (20):
    model.train()
    print(""Training started.."")

    for x_data,y_data in datasets:

      model.send(x_data.location) 

      opt.zero_grad()

       #forwardpass
       #the model here is the linear regression model
      y_pred = model(x_data)

      #ComputeLoss
      loss=criterion(y_pred,y_data)

      #BackwardPass
      loss.backward()

      opt.step()

      model.get() 

      print(loss.get())

train()
</code></pre>
",9204090,,730754,,44163.46495,44163.46495,"PureFrameworkTensorFoundError, Runtime error -FedeartedLearning",<python><pytorch><federated-learning><pysyft>,1,0,,,,CC BY-SA 4.0
59622300,1,,,43837.19944,,1,629,"<p>I tried to customize the model in ""Image classification"" tutorial in Tensorflow Federated. (It originally used a sequential model)
I use Keras ResNet50 but when it began to train, there is always an error ""Incompatible shapes""</p>

<p>Here are my codes:</p>

<pre><code>NUM_CLIENTS = 4
NUM_EPOCHS = 10
BATCH_SIZE = 2
SHUFFLE_BUFFER = 5

def create_compiled_keras_model():
  model = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', 
                                                input_tensor=tf.keras.layers.Input(shape=(100, 
                                                300, 3)), pooling=None)

  model.compile(
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      optimizer=tf.keras.optimizers.SGD(learning_rate=0.02),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
  return model


def model_fn():
  keras_model = create_compiled_keras_model()
  return tff.learning.from_compiled_keras_model(keras_model, sample_batch)

iterative_process = tff.learning.build_federated_averaging_process(model_fn)
</code></pre>

<p>Error information:
<a href=""https://i.sstatic.net/n7Ctu.png"" rel=""nofollow noreferrer"">enter image description here</a></p>

<p>I feel that the shape is incompatible because the epoch and clients information were somehow missing. Would be very thankful if someone could give me a hint.</p>

<p><strong>Updates:</strong></p>

<p>The Assertion error happened during <code>tff.learning.build_federated_averaging_process</code></p>

<pre><code>---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
&lt;ipython-input-164-dac26193d9d8&gt; in &lt;module&gt;()
----&gt; 1 iterative_process = tff.learning.build_federated_averaging_process(model_fn)
      2 
      3 # iterative_process = build_federated_averaging_process(model_fn)

13 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/federated_averaging.py in build_federated_averaging_process(model_fn, server_optimizer_fn, client_weight_fn, stateful_delta_aggregate_fn, stateful_model_broadcast_fn)
    165   return optimizer_utils.build_model_delta_optimizer_process(
    166       model_fn, client_fed_avg, server_optimizer_fn,
--&gt; 167       stateful_delta_aggregate_fn, stateful_model_broadcast_fn)

/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py in build_model_delta_optimizer_process(model_fn, model_to_client_delta_fn, server_optimizer_fn, stateful_delta_aggregate_fn, stateful_model_broadcast_fn)
    349   # still need this.
    350   with tf.Graph().as_default():
--&gt; 351     dummy_model_for_metadata = model_utils.enhance(model_fn())
    352 
    353   # ===========================================================================

&lt;ipython-input-159-b2763ace8e5b&gt; in model_fn()
      1 def model_fn():
      2   keras_model = model
----&gt; 3   return tff.learning.from_compiled_keras_model(keras_model, sample_batch)

/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/keras_utils.py in from_compiled_keras_model(keras_model, dummy_batch)
    211   # Model.test_on_batch() once before asking for metrics.
    212   if isinstance(dummy_tensors, collections.Mapping):
--&gt; 213     keras_model.test_on_batch(**dummy_tensors)
    214   else:
    215     keras_model.test_on_batch(*dummy_tensors)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in test_on_batch(self, x, y, sample_weight, reset_metrics)
   1007         sample_weight=sample_weight,
   1008         reset_metrics=reset_metrics,
-&gt; 1009         standalone=True)
   1010     outputs = (
   1011         outputs['total_loss'] + outputs['output_losses'] + outputs['metrics'])

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in test_on_batch(model, x, y, sample_weight, reset_metrics, standalone)
    503       y,
    504       sample_weights=sample_weights,
--&gt; 505       output_loss_metrics=model._output_loss_metrics)
    506 
    507   if reset_metrics:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    568         xla_context.Exit()
    569     else:
--&gt; 570       result = self._call(*args, **kwds)
    571 
    572     if tracing_count == self._get_tracing_count():

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    606       # In this case we have not created variables on the first call. So we can
    607       # run the first trace but we should fail if variables are created.
--&gt; 608       results = self._stateful_fn(*args, **kwds)
    609       if self._created_variables:
    610         raise ValueError(""Creating variables on a non-first call to a function""

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   2407     """"""Calls a graph function specialized to the inputs.""""""
   2408     with self._lock:
-&gt; 2409       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   2410     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2411 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2765 
   2766       self._function_cache.missed.add(call_context_key)
-&gt; 2767       graph_function = self._create_graph_function(args, kwargs)
   2768       self._function_cache.primary[cache_key] = graph_function
   2769       return graph_function, args, kwargs

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2655             arg_names=arg_names,
   2656             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 2657             capture_by_value=self._capture_by_value),
   2658         self._function_attributes,
   2659         # Tell the ConcreteFunction to clean up its graph once it goes out of

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--&gt; 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

AssertionError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py:345 test_on_batch  *
        with backend.eager_learning_phase_scope(0):
    /usr/lib/python3.6/contextlib.py:81 __enter__
        return next(self.gen)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py:425 eager_learning_phase_scope
        assert ops.executing_eagerly_outside_functions()

    AssertionError: 

</code></pre>
",12665683,,730754,,44163.45722,44163.45722,ResNet model in Tensorflow Federated,<tensorflow><resnet><tensorflow-federated><federated-learning>,2,4,,,,CC BY-SA 4.0
59741397,1,,,43844.85674,,2,1537,"<p>here is the code of my federated learning test</p>

<pre><code>from __future__ import absolute_import, division, print_function
import os
import collections
import warnings
from six.moves import range
import numpy as np
import six
import tensorflow as tf
import tensorflow_federated as tff
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import PIL


#pretrain

train_datagen1 = tf.keras.preprocessing.image.ImageDataGenerator(vertical_flip=True)
training_set1= train_datagen1.flow_from_directory('folder1/train',target_size=(200, 200), batch_size=32)



)




</code></pre>

<p>Now when I want to create sample_batch like the tutorial in the tensorflow federtaed for image classification</p>

<p>I write this line and it find this error</p>

<pre><code>example_dataset = training_set1.create_tf_dataset_for_client(training_set1.client_ids[0])
</code></pre>

<p>the error</p>

<hr>

<p>TypeError                                 Traceback (most recent call last)
 in 
      1 training_set1.element_type_structure
----> 2 example_dataset = training_set1.create_tf_dataset_for_client(training_set1.client_ids[0])</p>

<p>TypeError: 'abstractproperty' object does not support indexing</p>

<hr>

<p>Can you tell me how I must do to create dummy_batch in order to convert keras model into tff.learning.from_compiled_keras_model(model, dummy_batch)</p>
",12682667,,730754,,44163.68706,44163.68706,Federated learning : convert my own image dataset into tff simulation Clientdata,<python><tensorflow><keras><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
59835749,1,,,43851.29477,,4,584,"<p>(I have posted the question on <a href=""https://github.com/tensorflow/federated/issues/793"" rel=""nofollow noreferrer"">https://github.com/tensorflow/federated/issues/793</a> and maybe also here!)</p>

<p>I have customized my own data and model to federated interfaces and the training converged. But I am confused about an issue that in an images classification task, the whole dataset is extreme large and it can't be stored in a single <code>federated_train_data</code> nor be imported to memory for one time. So I need to load the dataset from the hard disk in batches to memory real-timely and use <code>Keras model.fit_generator</code> instead of <code>model.fit</code> during training, the approach people use to deal with large data.</p>

<p>I suppose in <code>iterative_process</code> shown in image classification tutorial, the model is fitted on a fixed set of data. Is there any way to adjust the code to let it fit to a data generator?I have looked into the source codes but still quite confused. Would be incredibly grateful for any hints.</p>
",12752740,,730754,,44163.45678,44163.45678,Implement data generator in federated training,<tensorflow><keras><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
60198252,1,,,43873.96762,,0,823,"<p>I implemented Resnet34 model in federated images classification tutorial. After 10 rounds the training accuracy can be higher than 90%, however, the evaluation accuracy using the last round's <code>state.model</code> is always around 50%.</p>

<pre><code>    evaluation = tff.learning.build_federated_evaluation(model_fn)
    federated_test_data = make_federated_data(emnist_test, sample_clients)
    test_metrics = evaluation(state.model, federated_test_data)
    str(test_metrics)
</code></pre>

<p>I am very confused what's possibly wrong with the evaluation part? Also, I printed the untrainable variables (mean and variance in BatchNorm) of the server's model, which are 0 and 1 with no updates/averaging after those rounds. Should they be like that or that could be the problem?
Thanks very much! </p>

<p><strong>Updates:</strong> </p>

<p>The codes to prepare training data and printed results:</p>

<pre><code>len(emnist_train.client_ids)
4

emnist_train.element_type_structure
OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int64, name=None)),('pixels',TensorSpec(shape=(256, 256, 3), dtype=tf.float32, name=None))])


NUM_CLIENTS = 4
NUM_EPOCHS = 1
BATCH_SIZE = 30
SHUFFLE_BUFFER = 500

def preprocess(dataset):
  def element_fn(element):
    return collections.OrderedDict([
        ('x', element['pixels']),
        ('y', tf.reshape(element['label'], [1])),
    ])
  return dataset.repeat(NUM_EPOCHS).map(element_fn).shuffle(
      SHUFFLE_BUFFER).batch(BATCH_SIZE)



sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]

federated_train_data = make_federated_data(emnist_train, sample_clients)

preprocessed_example_dataset = preprocess(example_dataset)

sample_batch = tf.nest.map_structure(
    lambda x: x.numpy(), iter(preprocessed_example_dataset).next())

def make_federated_data(client_data, client_ids):
      return [preprocess(client_data.create_tf_dataset_for_client(x))
          for x in client_ids]



len(federated_train_data), federated_train_data[0]
(4,&lt;BatchDataset shapes: OrderedDict([(x, (None, 256, 256, 3)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int64)])&gt;)
</code></pre>

<p>The training and evaluation codes:</p>

<pre><code> def create_compiled_keras_model():
  base_model = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', input_shape=(256,256,3,))
  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
  prediction_layer = tf.keras.layers.Dense(2, activation='softmax')

  model = tf.keras.Sequential([
                               base_model,
                               global_average_layer,
                               prediction_layer
                               ])
  model.compile(optimizer = tf.keras.optimizers.SGD(lr = 0.001, momentum=0.9), loss = tf.keras.losses.SparseCategoricalCrossentropy(), metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])
  return model

def model_fn():
  keras_model = create_compiled_keras_model()
  return tff.learning.from_compiled_keras_model(keras_model, sample_batch)
iterative_process = tff.learning.build_federated_averaging_process(model_fn)
state = iterative_process.initialize()
for round_num in range(2, 12):
  state, metrics = iterative_process.next(state, federated_train_data)
  print('round {:2d}, metrics={}'.format(round_num, metrics, state))


evaluation = tff.learning.build_federated_evaluation(model_fn)
federated_test_data = make_federated_data(emnist_test, sample_clients)

len(federated_test_data), federated_test_data[0]
(4,
 &lt;BatchDataset shapes: OrderedDict([(x, (None, 256, 256, 3)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int64)])&gt;)

test_metrics = evaluation(state.model, federated_test_data)
str(test_metrics)
</code></pre>

<p>The training and evaluations results after each round:</p>

<pre><code>round  1, metrics=&lt;sparse_categorical_accuracy=0.5089045763015747,loss=0.7813001871109009,keras_training_time_client_sum_sec=0.008826255798339844&gt;

&lt;sparse_categorical_accuracy=0.49949443340301514,loss=8.0671968460083,keras_training_time_client_sum_sec=0.0&gt;


round  2, metrics=&lt;sparse_categorical_accuracy=0.519825279712677,loss=0.7640910148620605,keras_training_time_client_sum_sec=0.011750459671020508&gt;

&lt;sparse_categorical_accuracy=0.49949443340301514,loss=8.0671968460083,keras_training_time_client_sum_sec=0.0&gt;


round  3, metrics=&lt;sparse_categorical_accuracy=0.5099126100540161,loss=0.7513422966003418,keras_training_time_client_sum_sec=0.0039823055267333984&gt;

&lt;sparse_categorical_accuracy=0.49949443340301514,loss=8.0671968460083,keras_training_time_client_sum_sec=0.0&gt;


round  4, metrics=&lt;sparse_categorical_accuracy=0.5278897881507874,loss=0.7905193567276001,keras_training_time_client_sum_sec=0.0010638236999511719&gt;

&lt;sparse_categorical_accuracy=0.49949443340301514,loss=8.0671968460083,keras_training_time_client_sum_sec=0.0&gt;


round  5, metrics=&lt;sparse_categorical_accuracy=0.5199933052062988,loss=0.7782396674156189,keras_training_time_client_sum_sec=0.012729644775390625&gt;

&lt;sparse_categorical_accuracy=0.49949443340301514,loss=8.0671968460083,keras_training_time_client_sum_sec=0.0&gt;
</code></pre>
",12752740,,730754,,44163.45652,44168.26734,Low evaluation accuracy of Resnet in TensorFlow Federated,<tensorflow><tf.keras><resnet><tensorflow-federated><federated-learning>,2,0,,,,CC BY-SA 4.0
60202610,1,60292206,,43874.31501,,1,1155,"<p>I am trying to run a federated learning from pysyft (<a href=""https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/advanced/websockets-example-MNIST-parallel/Asynchronous-federated-learning-on-MNIST.ipynb"" rel=""nofollow noreferrer"">https://github.com/OpenMined/PySyft/blob/dev/examples/tutorials/advanced/websockets-example-MNIST-parallel/Asynchronous-federated-learning-on-MNIST.ipynb</a>) that creates remote workers and connect to them via websockets. however I am getting an error in folllowing evaluation step.</p>

<pre><code>future: &lt;Task finished coro=&lt;WebsocketServerWorker._producer_handler() done, defined at C:\Users\Public\Anaconda\lib\site-packages\syft\workers\websocket_server.py:95&gt; exception=AttributeError(""'dict' object has no attribute 'owner'"")&gt;
Traceback (most recent call last):
  File ""C:\Users\Public\Anaconda\lib\site-packages\syft\generic\frameworks\hook\hook_args.py"", line 663, in register_response
    register_response_function = register_response_functions[attr_id]
KeyError: 'evaluate'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Public\Anaconda\lib\site-packages\syft\workers\websocket_server.py"", line 113, in _producer_handler
    response = self._recv_msg(message)
  File ""C:\Users\Public\Anaconda\lib\site-packages\syft\workers\websocket_server.py"", line 124, in _recv_msg
    return self.recv_msg(message)
  File ""C:\Users\Public\Anaconda\lib\site-packages\syft\workers\base.py"", line 310, in recv_msg
    response = self._message_router[type(msg)](msg.contents)
  File ""C:\Users\Public\Anaconda\lib\site-packages\syft\workers\base.py"", line 457, in execute_command
    command_name, response, list(return_ids), self
  File ""C:\Users\Public\Anaconda\lib\site-packages\syft\generic\frameworks\hook\hook_args.py"", line 672, in register_response
    new_response = register_response_function(response, response_ids=response_ids, owner=owner)
  File ""C:\Users\Public\Anaconda\lib\site-packages\syft\generic\frameworks\hook\hook_args.py"", line 766, in &lt;lambda&gt;
    return lambda x, **kwargs: f(lambdas, x, **kwargs)
  File ""C:\Users\Public\Anaconda\lib\site-packages\syft\generic\frameworks\hook\hook_args.py"", line 522, in two_fold
    return lambdas[0](args[0], **kwargs), lambdas[1](args[1], **kwargs)
  File ""C:\Users\Public\Anaconda\lib\site-packages\syft\generic\frameworks\hook\hook_args.py"", line 744, in &lt;lambda&gt;
    else lambda i, **kwargs: register_tensor(i, **kwargs)
  File ""C:\Users\Public\Anaconda\lib\site-packages\syft\generic\frameworks\hook\hook_args.py"", line 712, in register_tensor
    tensor.owner = owner
AttributeError: 'dict' object has no attribute 'owner'
</code></pre>

<p>There are no clear answer from their forum. does anyone have any clue as to what the issue is in this script.</p>

<p>My syft version:</p>

<pre><code>syft : 0.2.3a1
syft-proto : 0.1.1a1.post12
torch : 1.4.0
</code></pre>
",6294565,,730754,,44163.4605,44163.4605,"Pysyft Federated learning, Error with Websockets",<python><websocket><pytorch><federated-learning><pysyft>,1,0,,,,CC BY-SA 4.0
68691256,1,68692289,,44415.41198,,1,873,"<p>I am new to machine learning and was trying out the &quot;federated learning for image classification&quot; code by Tensorflow (<a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification</a>). I ran the code on Google Colab and did not modify anything.</p>
<pre><code>#@test {&quot;skip&quot;: true}

# tensorflow_federated_nightly also bring in tf_nightly, which
# can causes a duplicate tensorboard install, leading to errors.
!pip uninstall --yes tensorboard tb-nightly

!pip install --quiet --upgrade tensorflow-federated-nightly
!pip install --quiet --upgrade nest-asyncio
!pip install --quiet --upgrade tb-nightly  # or tensorboard, but not both

import nest_asyncio
nest_asyncio.apply()

%load_ext tensorboard
</code></pre>
<p>The above works well. (no errors)
But when it comes to the below:</p>
<pre><code>import collections

import numpy as np
import tensorflow as tf
import tensorflow_federated as tff

np.random.seed(0)

tff.federated_computation(lambda: 'Hello, World!')()
</code></pre>
<p>I got an error on the <code>import tensorflow_federated as tff</code> line:</p>
<pre><code>AttributeError: module 'tensorflow_privacy' has no attribute 'DPQuery'
</code></pre>
<p>I've searched for solutions like <code>pip install -U TensorFlow-privacy</code> but none works.</p>
<p>Please help.
Thanks in advance!</p>
",16612378,,,,,44415.51106,AttributeError: module 'tensorflow_privacy' has no attribute 'DPQuery',<tensorflow><google-colaboratory><attributeerror><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
69385064,1,,,44469.06617,,0,202,"<p>I went through the source for the CIFAR-100 inbuilt dataset and decided to create a compatible version for the FairFace dataset in order to be able to leverage the other built-in functions without many modifications everywhere once I convert FairFace into a structure very similar to CIFAR-100.</p>
<p>I did search around but was unable to find how the CIFAR-100 SQLite database was created - specifically how the images were converted into BLOB for storage. After a bit of trial and error, I tried doing it this way:</p>
<pre class=""lang-py prettyprint-override""><code>sample = getDatabyIndex(train_labels, index)
example = tf.train.Example(features=tf.train.Features(feature={
  'image' : bytes_feature(sample[0].tobytes()),
  'label' : int64_feature(sample[1])
}))
example = example.SerializeToString()
cur.execute(&quot;insert into examples('split_name','client_id','serialized_example_proto') values(?,?,?)&quot;, ('train', i, sqlite3.Binary(example)))
</code></pre>
<p>Executing this for each sample in the train data and similarly for test data. I am able to load it using this decoding method:</p>
<pre class=""lang-py prettyprint-override""><code>def parse_proto(tensor_proto):
  parse_spec = {
    'image': tf.io.FixedLenFeature(shape=(), dtype=tf.string),
    'label': tf.io.FixedLenFeature(shape=(), dtype=tf.int64),
  }
  decoded_example = tf.io.parse_example(tensor_proto, parse_spec)
  return collections.OrderedDict(
            image=tf.reshape(tf.io.decode_raw(decoded_example['image'], tf.uint8), (224,224,3)),
            label=decoded_example['label'])
</code></pre>
<p>What I noticed, however, is that the final sqlite.lzma compressed archive is 6.4 GB in size whereas the source archive for the dataset was 555 MB. I am guessing that due to the way I am storing the images, compression is not working as well as it could if they were stored in a more compatible manner. I see from the CIFAR-100 code that the images are loaded directly as FixedLenFeatures of shape (32,32,3) which means that they were stored as such but I have been unable to find a way to store my images as such. The only method that worked for me was the bytes_feature route.</p>
<p>What would be the best/recommended way to go about this?</p>
",8357000,,14692,,44559.95073,44559.96353,What is the best way to create a custom federated image dataset for TFF in SQLite format?,<tensorflow><image-classification><tensorflow-federated><federated-learning>,1,1,,,,CC BY-SA 4.0
60866002,1,,,43916.47017,,1,471,"<p>This question is with regards to my project on federated learning using the pysyft library, but those with the knowledge of websockets can help too since pysyft uses websockets for the server and client interaction.</p>

<p>To start off, i have an issue regarding server and client interaction. I have created a dashboard to launch a pysyft server and a pysyft client which connects to the aforementioned server. However, i have a scenario where i want to have the client disconnect from the server from time to time (manual disconnection) so as to perform changes in model parameters.</p>

<p>My solution was to perform a close() on the pysyft websocketClientWorker which calls the shutdown() function on the websocket object. Doing which, i presume, will close the connection between the client and the server. After whatever changes to the model parameters have been done. I will recreate the pysyft websocketClientWorker object again and perform the model training all over again. However, i am faced with the issue of : <strong>websocket._exceptions.WebSocketConnectionClosedException: socket is already closed.</strong> This exception is being thrown (despite the successful connection to the server) during the iteration of the dataloader.</p>

<p>Perhaps there's a better way to go about this scenario, or am i missing certain fundamental understanding of websockets. Any help will be appreciated. Thank you :)</p>
",13128141,,730754,,44163.45951,44163.45951,Pysyft client and server,<websocket><federated-learning><pysyft>,1,0,,,,CC BY-SA 4.0
60996324,1,,,43923.68262,,3,652,"<p>I am trying to build a federated learning model. In my scenario, I have 3 workers and an orchestrator. The workers start the training and at the end of each training round, the models are being sent to the orchestrator, the orchestrator calculates the federated average and sends back the new model, the workers train on that new model etc. The custom network is an AutoEncoder that I have built from scratch.</p>

<p>Unfortunately I am getting this error message from the workers: <strong>RuntimeError: forward() is missing value for argument 'inputs'. Declaration: forward(ClassType self, Tensor inputs, Tensor outputs) -> (Tensor)</strong> which is weird because my forward function is defined as follows, inside the AE class:</p>

<pre><code>class AutoEncoder(nn.Module):

    def __init__(self, code_size):
        super().__init__()
        self.code_size = code_size

        # Encoder specification
        self.enc_cnn_1 = nn.Conv2d(3, 10, kernel_size=5)
        self.enc_cnn_2 = nn.Conv2d(10, 20, kernel_size=5)
        self.enc_linear_1 = nn.Linear(53 * 53 * 20, 50)
        self.enc_linear_2 = nn.Linear(50, self.code_size)

        # Decoder specification
        self.dec_linear_1 = nn.Linear(self.code_size, 160)
        self.dec_linear_2 = nn.Linear(160, IMAGE_SIZE)

    def forward(self, images):
        code = self.encode(images)
        out = self.decode(code)
        return out, code

    def encode(self, images):
        code = self.enc_cnn_1(images)
        code = F.selu(F.max_pool2d(code, 2))

        code = self.enc_cnn_2(code)
        code = F.selu(F.max_pool2d(code, 2))
        code = code.view([images.size(0), -1])
        code = F.selu(self.enc_linear_1(code))

        code = self.enc_linear_2(code)
        return code

    def decode(self, code):
        out = F.selu(self.dec_linear_1(code))
        out = F.sigmoid(self.dec_linear_2(out))
        out = out.view([code.size(0), 3, IMAGE_WIDTH, IMAGE_HEIGHT])
        return out


Loss function (cross entropy)

```
@torch.jit.script
def loss_fn(inputs, outputs):
    return torch.nn.functional.mse_loss(input=inputs, target=outputs)


def set_gradients(model, finetuning):
    """"""Helper function to exclude all gradients from training
    used for transfer learning in feature extract mode; See: https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html

    Args:
        model (torch.nn.Module): model object.
        finetuning (bool):  if true, nothing will be changed; transfer learning will be used in finetuning mode, i.e., all gradients are trained;
                            if false, all gradients get excluded from training, used in feature extract mode
    """"""

    if not finetuning:
        for param in model.parameters():
            param.requires_grad = False
```


```
def initialize_model():
    model = AutoEncoder(code_size)
    set_gradients(model, False)
    return model
async def train_model_on_worker(
    worker: websocket_client.WebsocketClientWorker,
    traced_model: torch.jit.ScriptModule,
    dataset_key: str,
    batch_size: int,
    curr_round: int,
    lr: float,
):

    traced_model.train()
    print(""train mode on"")
    train_config = sy.TrainConfig(
        model=traced_model,
        loss_fn=loss_fn,
        batch_size=batch_size,
        shuffle=True,
        epochs=1,
        optimizer=""Adam"",
        optimizer_args={""lr"": lr}
    )
logger.info(worker.id + "" send trainconfig"")
    train_config.send(worker)
    print(""Model sent to the worker"")
    logger.info(worker.id + "" start training"")
    await worker.async_fit(dataset_key=DATASET_KEY, return_ids=[0])
    logger.info(worker.id + "" training done"")
    results = dict()
logger.info(worker.id + "" get model"")
    model = train_config.model_ptr.get().obj

    results[""worker_id""] = worker.id
    results[""model""] = model

    return results
def validate_model(identifier, model, dataloader, criterion):
model.eval() # changes the mode of the model, in evaluation mode we don't have dropout

    loss = []
    for i, (inputs,_) in enumerat(dataloader):
        print(""validation mode on"")
        #with torch.set_grad_enabled(False):
        outputs, code  = model(Variable(inputs)) #a tensor with 2 values: one for leak and one for no leak
        loss = criterion(outputs, inputs)

        loss = loss.sqrt()
        loss.append(loss.item())
    print(""Loss = %.3f"" % loss.data)
async def main():
    args = define_and_get_arguments()
    hook = sy.TorchHook(torch) #with this we can override some pytorch methods with pysyft

    # Create WebsocketClientWorkers using IDs, Ports and IP addresses from arguments
    worker_instances = []
    for i in range(len(args.workers) // 3):
        j = i * 3
        worker_instances.append(websocket_client.WebsocketClientWorker(
            id=args.workers[j], port=args.workers[j + 1], host=args.workers[j + 2], hook=hook, verbose=args.verbose))

    model = initialize_model()

    # optional loading of predefined model weights (= dictionary):
    if args.basic_model:
        model.load_state_dict(torch.load(args.basic_model))

    # model serialization (creating an object of type ScriptModule):
    model.eval()
    traced_model = torch.jit.trace(model, torch.rand([1, 3, 224, 224], dtype=torch.float)) #we need to change the form of the model in order to make it 
    #serialisable and send it to the workers

    # Data / picture transformation:
    data_transforms = transforms.Compose([
        transforms.Resize(INPUT_SIZE),
        transforms.CenterCrop(INPUT_SIZE),
        transforms.ToTensor()
        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # Create validation dataset and dataloader
    validation_dataset = datasets.ImageFolder(os.path.join(args.dataset_path, 'val'), data_transforms)
    validation_dataloader = torch.utils.data.DataLoader(validation_dataset, batch_size=args.test_batch_size, shuffle=True, num_workers=4)

    # Create test dataset and dataloader
    test_dataset = datasets.ImageFolder(os.path.join(args.dataset_path, 'test'), data_transforms)
    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=args.test_batch_size, shuffle=True, num_workers=4)

    # Lists to plot loss and acc after training
    train_loss_values = []
    train_acc_values = []
    val_loss_values = []
    val_acc_values = []

    np.set_printoptions(formatter={""float"": ""{: .0f}"".format})

    for curr_round in range(1, args.training_rounds + 1):
        logger.info(""Training round %s/%s"", curr_round, args.training_rounds)
        print(""entered training "")
        # reduce learn rate every 5 training rounds (adaptive learnrate)
        lr = args.lr * (0.1 ** ((curr_round - 1) // 5))
        completed, pending = await asyncio.wait(
            [
                *[
                    train_model_on_worker(
                        worker=worker,
                        traced_model=traced_model,
                        dataset_key=DATASET_KEY,
                        batch_size=args.batch_size,
                        curr_round=curr_round,
                        lr=lr,
                    )
                    for worker in worker_instances
                ]
            ],
            timeout=40
        )

        results = []
        for entry in completed:
            print(""entry"")
            print(entry)
            results.append(entry.result())

        for entry in pending:
            entry.cancel()

        new_worker_instances = []
        for entry in results:
            for worker in worker_instances:
                if (entry[""worker_id""] == worker.id):
                    new_worker_instances.append(worker)

        worker_instances = new_worker_instances


        # Setup the loss function
        criterion = torch.nn.functional.mse_loss()
        #optimizer = optimizer_cls(autoencoder.parameters(), lr=lr)

        # Federate models (note that this will also change the model in models[0]
        models = {}
        for worker in results:
            if worker[""model""] is not None:
                models[worker[""worker_id""]] = worker[""model""]

        logger.info(""aggregation"")
        traced_model = utils.federated_avg(models)
        logger.info(""aggregation done"")

        # Evaluate federated model
        logger.info(""Validate.."")
        loss = validate_model(""Federated"", traced_model, validation_dataloader, criterion)
        logger.info(""Validation done"")
        val_loss_values.append(loss)
        #val_acc_values.append(acc)
if __name__ == ""__main__"":
    # Logging setup
    date_time = datetime.now().strftime(""%m-%d-%Y_%H:%M:%S"")
    FORMAT = ""%(asctime)s | %(message)s""
    logging.basicConfig(filename='logs/orchestrator_' + date_time + '.log', format=FORMAT)
    logger = logging.getLogger(""orchestrator"")
    logger.setLevel(level=logging.INFO)

    asyncio.get_event_loop().run_until_complete(main())

The code of the workers:
def load_dataset(dataset_path):
    """"""Helper function for setting up the local datasets.

    Args:
        dataset_path (string):  path to dataset, images must be arranged in this way
                                dataset_path/train/class1/xxx.jpg
                                dataset_path/train/class2/yyy.jpg
    """"""

    data_transform = transforms.Compose([
        transforms.RandomResizedCrop(INPUT_SIZE),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor()
        #transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    dataset = datasets.ImageFolder(os.path.join(dataset_path, 'train'), data_transform)

    return dataset


def start_websocket_server(id, port, dataset, verbose):
    """"""Helper function for spinning up a websocket server.

    Args:
        id (str or id): the unique id of the worker.
        port (int): the port on which the server should be run.
        dataset: dataset, which the worker should provide.
        verbose (bool): a verbose option - will print all messages sent/received to stdout.
    """"""

    hook = sy.TorchHook(torch)
    server = WebsocketServerWorker(id=id, host=""0.0.0.0"", port=port, hook=hook, verbose=verbose)
    server.add_dataset(dataset, key=DATASET_KEY)
    server.start()

    return server

    def _fit(self, model, dataset_key, loss_fn):
        logger = logging.getLogger(""worker"")
        logger.info(dataset_key)
        print(""dataset key"")
        model.train()
        data_loader = torch.utils.data.DataLoader(dataset, batch_size=args.test_batch_size, shuffle=True, num_workers=4)
        #data_loader = self._create_data_loader(
            #dataset_key=dataset_key, shuffle=self.train_config.shuffle
        #)
        print(""worker"")
        print(data_loader)

        loss = None
        iteration_count = 0

        for _ in range(self.train_config.epochs):
            for data in enumerate(data_loader):
                # Set gradients to zero
                self.optimizer.zero_grad()

                # Update model
                output,code = model(data)
                logger.info(data)
                logger.info(output)
                loss = loss_fn(data, output)
                loss.backward()
                self.optimizer.step()

                # Update and check interation count
                iteration_count += 1
                if iteration_count &gt;= self.train_config.max_nr_batches &gt;= 0:
                    break

        return model



if __name__ == ""__main__"":

    # Parse args
    args = define_and_get_arguments()

    # Logging setup
    date_time = datetime.now().strftime(""%m-%d-%Y_%H:%M:%S"")
    FORMAT = ""%(asctime)s %(levelname)s %(filename)s(l:%(lineno)d, p:%(process)d) - %(message)s""
    logging.basicConfig(filename='logs/worker_' + args.id + '_' + date_time + '.log', format=FORMAT)
    logger = logging.getLogger(""worker"")
    logger.setLevel(level=logging.INFO)

    # Load train dataset
    dataset = load_dataset(args.dataset_path)

    # Start server
    server = start_websocket_server(
        id=args.id,
        port=args.port,
        dataset=dataset,
        verbose=args.verbose,
    )
</code></pre>

<pre><code>Does anybody know what the problem is?
</code></pre>
",10823595,,730754,,44163.46233,44163.46233,Federated learning using custom model in Pytorch/Pysyft,<python><pytorch><federated-learning><pysyft>,0,2,,,,CC BY-SA 4.0
61243073,1,,,43937.21503,,1,470,"<p>Does tensorflow-federated support assigning different batch-size for different simulated devices, and changing batch-size for different epoch?</p>
",4616724,,730754,,44163.45602,44163.45602,Does tensorflow-federated support dynamic batch size?,<tensorflow><tensorflow2.0><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
61520938,1,,,43951.42334,,0,111,"<p>While training the model federated learning with keras on syft,to start workers on different system as client workers, particular line of command to be exectued on terminal.</p>

<pre><code>python -m tf_encrypted.player --config /tmp/tfe.config client name
</code></pre>

<p>this command should be executed on system which is one of my client workers.when executing the code</p>

<pre><code>(PySyft) C:\Users\mades&gt;python -m tf_encrypted.player --config /tmp/tfe.config server1
Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was 'C:\Users\mades\AppData\Roaming\Python\Python37\site-packages\tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.2.so'
WARNING:tensorflow:From C:\Users\mades\AppData\Roaming\Python\Python37\site-packages\tf_encrypted\session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

Traceback (most recent call last):
  File ""C:\Users\mades\Anaconda3\envs\PySyft\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""C:\Users\mades\Anaconda3\envs\PySyft\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\mades\AppData\Roaming\Python\Python37\site-packages\tf_encrypted\player\__main__.py"", line 22, in &lt;module&gt;
    config = RemoteConfig.load(args.config)
  File ""C:\Users\mades\AppData\Roaming\Python\Python37\site-packages\tf_encrypted\config.py"", line 221, in load
    with open(filename, 'r') as f:
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tfe.config'
</code></pre>

<p>how to prepare the config file for federated learning on this system?</p>
",12118247,,730754,,44163.4638,44163.4638,tf_encrypted.player how to config?,<python-3.x><keras><pytorch><federated-learning><pysyft>,1,0,,,,CC BY-SA 4.0
69499432,1,69530100,,44477.71072,,3,569,"<p>I am a newbie in federated learning and just getting to know TensorFlow Federated TFF framework. I have some questions in my mind I would be really appreciated it if anybody can clarify them:</p>
<ol>
<li>Does Federated Averaging algorithm the only aggregation algorithm supported in TFF? and how it differs from Federated Stochastic Gradient Descent?</li>
<li>Dose Federated Averaging require each client to be trained with the Neural Networks? or it is possible for local data to be trained with any machine learning algorithm?</li>
<li>I have big data, and I am planning to partition my data into smaller datasets and simulated each part as one client? does this work in TFF? and does it consider horizontal or vertical federated learning?</li>
</ol>
<p>Thanks in advance</p>
",3088939,,,,,44480.71751,Federated Averaging and TensorFlow,<tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
69525476,1,,,44480.47816,,1,737,"<p>I was trying to implement <a href=""https://github.com/tensorflow/federated/tree/main/tensorflow_federated/python/examples/simple_fedavg"" rel=""nofollow noreferrer"">tensorflow-federated simple fedavg</a> with <a href=""https://github.com/ozgurcelik/stackoverflowQuestion"" rel=""nofollow noreferrer"">cifar10 dataset and resnet18</a>. Also this is the <a href=""https://colab.research.google.com/drive/1GpZpRfKWzBk4IzIt77kXf-Ut-HzYE1b2?usp=sharing"" rel=""nofollow noreferrer"">pytorch implementation</a>. Just like trainable ones, I have aggregated non-trainable parameters of batch-normalization to server and averaged them. I have used 5 clients and dataset was divided to 5 randomly, 50k/5=10k training samples for each client, so there is no gross skewed distribution. I have tested each client, after training, with the full test dataset,10k samples, that I also use to test server. The problem is after first training round despite each client had 20-25% accuracy, the server has 10% accuracy and basically makes nearly the same predictions for each input. This is the only the case  for first round since after that round server has almost always better accuracy than any client had in that round. For example</p>
<pre><code>Round 0 training loss: 3.0080783367156982
Round 0 client_id: 0 eval_score: 0.2287999987602234
Round 0 client_id: 1 eval_score: 0.2614000141620636
Round 0 client_id: 2 eval_score: 0.22040000557899475
Round 0 client_id: 3 eval_score: 0.24799999594688416
Round 0 client_id: 4 eval_score: 0.2565999925136566
Round 0 validation accuracy: 10.0
Round 1 training loss: 1.920640230178833
Round 1 client_id: 0 eval_score: 0.25220000743865967
Round 1 client_id: 1 eval_score: 0.32199999690055847
Round 1 client_id: 2 eval_score: 0.32580000162124634
Round 1 client_id: 3 eval_score: 0.3513000011444092
Round 1 client_id: 4 eval_score: 0.34689998626708984
Round 1 validation accuracy: 34.470001220703125
Round 2 training loss: 1.65810227394104
Round 2 client_id: 0 eval_score: 0.34369999170303345
Round 2 client_id: 1 eval_score: 0.3138999938964844
Round 2 client_id: 2 eval_score: 0.35580000281333923
Round 2 client_id: 3 eval_score: 0.39649999141693115
Round 2 client_id: 4 eval_score: 0.3917999863624573
Round 2 validation accuracy: 45.0
Round 3 training loss: 1.4956902265548706
Round 3 client_id: 0 eval_score: 0.46380001306533813
Round 3 client_id: 1 eval_score: 0.388700008392334
Round 3 client_id: 2 eval_score: 0.39239999651908875
Round 3 client_id: 3 eval_score: 0.43700000643730164
Round 3 client_id: 4 eval_score: 0.430400013923645
Round 3 validation accuracy: 50.62000274658203
Round 4 training loss: 1.3692104816436768
Round 4 client_id: 0 eval_score: 0.510200023651123
Round 4 client_id: 1 eval_score: 0.42739999294281006
Round 4 client_id: 2 eval_score: 0.4223000109195709
Round 4 client_id: 3 eval_score: 0.45080000162124634
Round 4 client_id: 4 eval_score: 0.45559999346733093
Round 4 validation accuracy: 54.83000183105469
</code></pre>
<p>To solve the issue with first round I tried to repeat the dataset but it didnt help. After that I tried to use all the cifar10 training samples for each client meaning instead of creating 5 different datasets of 10k samples for each client I used all 50k samples as the dataset.</p>
<pre><code>Round 0 training loss: 1.9335068464279175
Round 0 client_id: 0 eval_score: 0.4571000039577484
Round 0 client_id: 1 eval_score: 0.4514000117778778
Round 0 client_id: 2 eval_score: 0.4738999903202057
Round 0 client_id: 3 eval_score: 0.4560000002384186
Round 0 client_id: 4 eval_score: 0.4697999954223633
Round 0 validation accuracy: 10.0
Round 1 training loss: 1.4404207468032837
Round 1 client_id: 0 eval_score: 0.5945000052452087
Round 1 client_id: 1 eval_score: 0.5909000039100647
Round 1 client_id: 2 eval_score: 0.5864999890327454
Round 1 client_id: 3 eval_score: 0.5871999859809875
Round 1 client_id: 4 eval_score: 0.5684000253677368
Round 1 validation accuracy: 59.57999801635742
Round 2 training loss: 1.0174440145492554
Round 2 client_id: 0 eval_score: 0.7002999782562256
Round 2 client_id: 1 eval_score: 0.6953999996185303
Round 2 client_id: 2 eval_score: 0.6830999851226807
Round 2 client_id: 3 eval_score: 0.6682999730110168
Round 2 client_id: 4 eval_score: 0.6754000186920166
Round 2 validation accuracy: 72.41999816894531
Round 3 training loss: 0.7608759999275208
Round 3 client_id: 0 eval_score: 0.7621999979019165
Round 3 client_id: 1 eval_score: 0.7608000040054321
Round 3 client_id: 2 eval_score: 0.7390000224113464
Round 3 client_id: 3 eval_score: 0.7301999926567078
Round 3 client_id: 4 eval_score: 0.7303000092506409
Round 3 validation accuracy: 78.33000183105469
Round 4 training loss: 0.5893330574035645
Round 4 client_id: 0 eval_score: 0.7814000248908997
Round 4 client_id: 1 eval_score: 0.7861999869346619
Round 4 client_id: 2 eval_score: 0.7804999947547913
Round 4 client_id: 3 eval_score: 0.7694000005722046
Round 4 client_id: 4 eval_score: 0.758400022983551
Round 4 validation accuracy: 81.30000305175781
</code></pre>
<p>Clients obviously had the same initialization but i guess due to gpu use there were some minor accuracy differences yet each had 45+% accuracy. But as you can see even this didnt help with the first round. When using a simple cnn, such as the one available in the &quot;.main&quot;, with suitable parameters this problem doesnt exist. And using</p>
<pre><code>learning_rate=0.01 or momentum=0
</code></pre>
<p>instead of</p>
<pre><code>learning_rate=0.1 and momentum=0.9
</code></pre>
<p>reduces this for problem the first round but it has overall worse performance and i am trying to reproduce a paper that used the latter parameters.</p>
<p>I have also tried the same with pytorch and got the very similar results. <a href=""https://colab.research.google.com/drive/1GpZpRfKWzBk4IzIt77kXf-Ut-HzYE1b2?usp=sharing"" rel=""nofollow noreferrer"">Colab for pytorch code</a> The results for both are available in github.</p>
<p>I am very confused with that. Especially when I used entire training dataset and when each client had 45% accuracy. Also why get good results for following rounds? What changed between first round and the others? Every time clients had the same initialization with each other, same loss function, and same optimizer with the same parameters. The only thing that changed is the actual initialization between rounds.</p>
<p>So is there a special initialization that solves this first round problem or am I missing something?</p>
<p><em><strong>Edit:</strong></em></p>
<p>When the entire cifar10 training set is used for each client and dataset.repeat is used to repeat data.</p>
<pre><code>Pre-training validation accuracy: 9.029999732971191
Round 0 training loss: 1.6472676992416382
Round 0 client_id: 0 eval_score: 0.5931000113487244
Round 0 client_id: 1 eval_score: 0.5042999982833862
Round 0 client_id: 2 eval_score: 0.5083000063896179
Round 0 client_id: 3 eval_score: 0.5600000023841858
Round 0 client_id: 4 eval_score: 0.6104999780654907
Round 0 validation accuracy: 10.0
</code></pre>
<p>What catches my attention here is the client accuracy here is actually very similar to second round (round 1) accuracy of clients when dataset wasnt repeated(previous results). so eventhough server had 10% accuracy it didnt affect much the results of the next round.</p>
<p>This is how it works with a simple cnn (defined in the main.py in github)</p>
<pre><code>With the training set divided to 5
Pre-training validation accuracy: 9.489999771118164
Round 0 training loss: 2.1234841346740723
Round 0 client_id: 0 eval_score: 0.30250000953674316
Round 0 client_id: 1 eval_score: 0.2879999876022339
Round 0 client_id: 2 eval_score: 0.2533999979496002
Round 0 client_id: 3 eval_score: 0.25999999046325684
Round 0 client_id: 4 eval_score: 0.2897999882698059
Round 0 validation accuracy: 31.18000030517578

Entire training set for all the clients
Pre-training validation accuracy: 9.489999771118164
Round 0 training loss: 1.636365532875061
Round 0 client_id: 0 eval_score: 0.47850000858306885
Round 0 client_id: 1 eval_score: 0.49470001459121704
Round 0 client_id: 2 eval_score: 0.4918000102043152
Round 0 client_id: 3 eval_score: 0.492900013923645
Round 0 client_id: 4 eval_score: 0.4043000042438507
Round 0 validation accuracy: 50.62000274658203
</code></pre>
<p>As we can see when a simple cnn is used server accuracy is better than the best client accuracy, and definitely better than the average, beginning from the very first round. I am trying to understand why the resnet fails to do that and makes the same predictions regardless of input. After the first round the predictions look like</p>
<pre><code>[[0.02677999 0.02175025 0.10807421 0.25275248 0.08478505 0.20601839
  0.16497472 0.09307405 0.01779539 0.02399557]
 [0.04087764 0.03603332 0.09987792 0.23636964 0.07425722 0.19982725
  0.13649824 0.09779423 0.03454168 0.04392283]
 [0.02448712 0.01900426 0.11061406 0.25295085 0.08886322 0.20792796
  0.17296027 0.08762561 0.01570844 0.01985822]
 [0.01790532 0.01536059 0.11237497 0.2519772  0.09357632 0.20954111
  0.18946911 0.08571784 0.01004946 0.01402805]
 [0.02116687 0.02263201 0.10294028 0.25523028 0.08544692 0.21299754
  0.17604835 0.088608   0.01438032 0.02054946]
 [0.01598492 0.01457187 0.10899033 0.25493488 0.09417254 0.20747423
  0.19798534 0.08387674 0.0089481  0.01306108]
 [0.01432306 0.01214803 0.11237216 0.25138852 0.09796435 0.2036258
  0.20656979 0.08344456 0.00726837 0.01089529]
 [0.01605278 0.0135905  0.11161591 0.25388476 0.09531546 0.20592561
  0.19932476 0.08305667 0.00873495 0.01249863]
 [0.02512863 0.0238647  0.10465285 0.24918261 0.08625458 0.21051233
  0.16839236 0.09075507 0.01765386 0.02360307]
 [0.05418856 0.05830322 0.09909651 0.20211859 0.07324574 0.18549475
  0.11666768 0.0990423  0.05081367 0.06102907]]
</code></pre>
<p>They all return 3rd label.</p>
",16428078,,16428078,,44480.99883,44833.38229,"Federated Averaging (fedavg) with resnet 18 that has batch_normalization makes the same prediction after first round, but in no other rounds",<tensorflow><pytorch><tensorflow-federated><federated-learning>,1,1,,,,CC BY-SA 4.0
69538510,1,,,44481.41464,,0,137,"<p>I would like to deploy TFF in a way, where I have one central (aggregation) server on a VM in a cloud and two different VMs with nodes, that train the model. Is this possible with TFF? Does it have the protocols necessary to communicate over the internet etc. or is it more of a Tensorflow with FL algorithms that can be used with different frameworks that provide the architecture?</p>
<p>Thank you</p>
",9334092,,,,,44481.76948,Does TFF support deployment across different devices and clouds?,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
69596586,1,69627599,,44485.61047,,1,114,"<p>I'm trying to understand how Tensorflow Federated Works, using the simple_fedavg as example.</p>
<p>I still don't understand how to change what the client send to the server, for example.</p>
<p>I don't want to send all the weights of the update, i want to send a list formed like this:</p>
<pre><code>  test[index] = test_stc.stc_compression(test[index], sparsification_rate)
</code></pre>
<p>Where <code>test_stc.stc_compression(test[index], sparsification_rate)</code> return 5 values: <code>negatives, positives, average, original_shape, new_shape</code>, then i would like to access those information on the server side before running the  <code>round_model_delta = tff.federated_mean(client_outputs.weights_delta, weight=weight_denom)</code> for creating the weights that i will use for the <code>tff.federated_mean</code>.</p>
<p>So, basically, i would like to change <code>client_update</code> to send a list that i have created instead of all the weights and then, on the server create a custom list of weights using the information that the client sent. Only after the creation of the new custom list of weight i would like the server to update the model.</p>
<p>I actually tried to change the <code>return ClientOutput(test, client_weight, loss_sum / client_weight)</code> of the <code>client_update</code>, but then i don't know how to access the <code>test</code> variable on the server and in which procedure/function i would need to do it.</p>
<p>I hope that i made myself clear enough since my main language is not english.</p>
",12749028,,,,,44488.36016,How to change the update that the client send to the server Tensorflow Federated,<python><tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
69841983,1,71239893,,44504.65671,,0,83,"<p>I am trying to run my notebook (that works fine on google colab or other similar platforms) on Intel OpenFL, the new framework for FL of Intel.
I am using MNIST with this transformation:</p>
<pre><code>trf = transforms.Compose(
     [transforms.Resize(32),
      transforms.RandomHorizontalFlip(),
      transforms.ToTensor(),
     ]) 
</code></pre>
<p>and this is my net:</p>
<pre><code>class Net(nn.Module):
     def __init__(self):
         super(Net, self).__init__()

        # calculate same padding:
        # (w - k + 2*p)/s + 1 = o
        # =&gt; p = (s(o-1) - w + k)/2

         self.block_1 = nn.Sequential(
            nn.Conv2d(in_channels=1,
                      out_channels=64,
                      kernel_size=(3, 3),
                      stride=(1, 1),
                      # (1(32-1)- 32 + 3)/2 = 1
                      padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.Conv2d(in_channels=64,
                      out_channels=64,
                      kernel_size=(3, 3),
                      stride=(1, 1),
                      padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=(2, 2),
                         stride=(2, 2))
         )

         self.block_2 = nn.Sequential(
            nn.Conv2d(in_channels=64,
                      out_channels=128,
                      kernel_size=(3, 3),
                      stride=(1, 1),
                      padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.Conv2d(in_channels=128,
                      out_channels=128,
                      kernel_size=(3, 3),
                      stride=(1, 1),
                      padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=(2, 2),
                         stride=(2, 2))
         )   

         self.block_3 = nn.Sequential(
            nn.Conv2d(in_channels=128,
                      out_channels=256,
                      kernel_size=(3, 3),
                      stride=(1, 1),
                      padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Conv2d(in_channels=256,
                      out_channels=256,
                      kernel_size=(3, 3),
                      stride=(1, 1),
                      padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.Conv2d(in_channels=256,
                      out_channels=256,
                      kernel_size=(3, 3),
                      stride=(1, 1),
                      padding=1),
            nn.BatchNorm2d(256),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=(2, 2),
                         stride=(2, 2))
         )

         self.block_4 = nn.Sequential(
            nn.Conv2d(in_channels=256,
                      out_channels=512,
                      kernel_size=(3, 3),
                      stride=(1, 1),
                      padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.Conv2d(in_channels=512,
                      out_channels=512,
                      kernel_size=(3, 3),
                      stride=(1, 1),
                      padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.Conv2d(in_channels=512,
                      out_channels=512,
                      kernel_size=(3, 3),
                      stride=(1, 1),
                      padding=1),
            nn.BatchNorm2d(512),
            nn.ReLU(),
            nn.MaxPool2d(kernel_size=(2, 2),
                         stride=(2, 2))
         )   
          
         self.classifier = nn.Sequential(
            nn.Linear(2048, 4096),
            nn.ReLU(True),
            nn.Dropout(p=0.65),
            nn.Linear(4096, 4096),
            nn.ReLU(True),
            nn.Dropout(p=0.65),
            nn.Linear(4096, classes) 
        )

         for m in self.modules():
            if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):
                nn.init.kaiming_uniform_(m.weight, mode='fan_in', nonlinearity='leaky_relu')
#                 nn.init.xavier_normal_(m.weight)
                if m.bias is not None:
                    m.bias.detach().zero_()

        # self.avgpool = nn.AdaptiveAvgPool2d((7, 7))

     def forward(self, x):

        x = self.block_1(x)
        x = self.block_2(x)
        x = self.block_3(x)
        x = self.block_4(x)
        # x = self.avgpool(x)
        x = x.view(x.size(0), -1)
        x = self.classifier(x)
        return x
</code></pre>
<p>But I have this error:</p>
<pre><code>---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
/var/folders/pm/nj7yy3px76n6b62knyrn8r_40000gn/T/ipykernel_10337/666012611.py in &lt;module&gt;
----&gt; 1 final_model = fx.run_experiment(collaborators,{'aggregator.settings.rounds_to_train':5})

/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/openfl/native/native.py in run_experiment(collaborator_dict, override_config)
    282         for col in plan.authorized_cols:
    283             collaborator = collaborators[col]
--&gt; 284             collaborator.run_simulation()
    285 
    286     # Set the weights for the final model

/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/openfl/component/collaborator/collaborator.py in run_simulation(self)
    170                 self.logger.info(f'Received the following tasks: {tasks}')
    171                 for task in tasks:
--&gt; 172                     self.do_task(task, round_number)
    173                 self.logger.info(f'All tasks completed on {self.collaborator_name} '
    174                                  f'for round {round_number}...')

/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/openfl/component/collaborator/collaborator.py in do_task(self, task, round_number)
    245             round_num=round_number,
    246             input_tensor_dict=input_tensor_dict,
--&gt; 247             **kwargs)
    248 
    249         # Save global and local output_tensor_dicts to TensorDB

/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/openfl/federated/task/runner_pt.py in validate(self, col_name, round_num, input_tensor_dict, use_tqdm, **kwargs)
    106                 data, target = pt.tensor(data).to(self.device), pt.tensor(
    107                     target).to(self.device, dtype=pt.int64)
--&gt; 108                 output = self(data)
    109                 # get the index of the max log-probability
    110                 pred = output.argmax(dim=1, keepdim=True)

/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
    887             result = self._slow_forward(*input, **kwargs)
    888         else:
--&gt; 889             result = self.forward(*input, **kwargs)
    890         for hook in itertools.chain(
    891                 _global_forward_hooks.values(),

/var/folders/pm/nj7yy3px76n6b62knyrn8r_40000gn/T/ipykernel_10337/3611293808.py in forward(self, x)
    125         # x = self.avgpool(x)
    126         x = x.view(x.size(0), -1)
--&gt; 127         x = self.classifier(x)
    128         return x

/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
    887             result = self._slow_forward(*input, **kwargs)
    888         else:
--&gt; 889             result = self.forward(*input, **kwargs)
    890         for hook in itertools.chain(
    891                 _global_forward_hooks.values(),

/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/container.py in forward(self, input)
    117     def forward(self, input):
    118         for module in self:
--&gt; 119             input = module(input)
    120         return input
    121 

/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
    887             result = self._slow_forward(*input, **kwargs)
    888         else:
--&gt; 889             result = self.forward(*input, **kwargs)
    890         for hook in itertools.chain(
    891                 _global_forward_hooks.values(),

/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/modules/linear.py in forward(self, input)
     92 
     93     def forward(self, input: Tensor) -&gt; Tensor:
---&gt; 94         return F.linear(input, self.weight, self.bias)
     95 
     96     def extra_repr(self) -&gt; str:

/opt/anaconda3/envs/my_env/lib/python3.7/site-packages/torch/nn/functional.py in linear(input, weight, bias)
   1751     if has_torch_function_variadic(input, weight):
   1752         return handle_torch_function(linear, (input, weight), input, weight, bias=bias)
-&gt; 1753     return torch._C._nn.linear(input, weight, bias)
   1754 
   1755 

RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x512 and 2048x4096)
</code></pre>
<p>However, exactly the same network works well on Google Colab. Probably I am missing something about OpenFL.</p>
",11590027,,,,,44615.6505,Intel OpenFL - RuntimeError: mat1 and mat2 shapes cannot be multiplied (128x512 and 2048x4096),<neural-network><runtime-error><intel><openfl><federated-learning>,1,0,,,,CC BY-SA 4.0
69891610,1,69891789,,44509.03748,,2,310,"<p>I am implementing federated learning through tensorflow-federated. The tutorial and all other material available compared the accuracy of the federated (global) model after each communication round. Is there a way I can compute the accuracy of each local model to compare against federated (global) model.</p>
<p>Summary:
Total number of clients: 15
For each communication round: Local vs Federated Model performance</p>
<p>References:</p>
<ol>
<li>(<a href=""https://colab.research.google.com/github/tensorflow/federated/blob/main/docs/tutorials/federated_learning_for_image_classification.ipynb#scrollTo=blQGiTQFS9_r"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/tensorflow/federated/blob/main/docs/tutorials/federated_learning_for_image_classification.ipynb#scrollTo=blQGiTQFS9_r</a>)</li>
</ol>
",8354239,,,,,44644.1362,Local Model performance in Tensorflow Federated,<tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
69965649,1,,,44514.7415,,0,1308,"<p>I am trying to work on this example of Federated Learning.
<a href=""https://towardsdatascience.com/federated-learning-3097547f8ca3"" rel=""nofollow noreferrer"">https://towardsdatascience.com/federated-learning-3097547f8ca3</a>
I have installed the PySyft package but I am getting this error.</p>
<pre><code>ModuleNotFoundError                       Traceback (most recent call 
last)
~\AppData\Local\Temp/ipykernel_10416/238857884.py in &lt;module&gt;
     9 import numpy as np
     10 import syft as sy
---&gt; 11 from syft.frameworks.torch.federated import utils
     12 from syft.workers.websocket_client import WebsocketClientWorker

   ModuleNotFoundError: No module named 'syft.frameworks'
</code></pre>
",7841674,,,,,44698.30589,ModuleNotFoundError: No module named 'syft.frameworks',<python><iot><federated-learning><pysyft>,1,2,,,,CC BY-SA 4.0
70196914,1,,,44532.39226,,2,108,"<p>I would like to Fine-tune the pre-trained model  with Federated Learning, So I do this:</p>
<pre class=""lang-py prettyprint-override""><code>def create_keras_model():
    baseModel = tf.keras.models.load_model(path\to\model)
    headModel = baseModel.output
    model_output = tf.keras.layers.Dense(3)(headModel)
    model = tf.keras.Model(inputs=baseModel.input, outputs=model_output)
    for layer in baseModel.layers:
        layer.trainable = False
    return model

state = iterative_process.initialize()
keras_model = create_keras_model()
state = tff.learning.state_with_new_model_weights(
    state,
    trainable_weights=[v.numpy() for v in keras_model.trainable_weights],
    non_trainable_weights=[
        v.numpy() for v in keras_model.non_trainable_weights
    ])

evaluation = tff.learning.build_federated_evaluation(model_fn)
</code></pre>
<p>And here is the training loop :</p>
<pre class=""lang-py prettyprint-override""><code>for round_num in range(1, NUM_ROUNDS):
    state, _ = iterative_process.next(state, train_data)
    test_metrics = evaluation(state.model, test_data)
    print(test_metrics))
</code></pre>
<p>The problem is that test accuracy still constant and does not increase after all round  :</p>
<pre class=""lang-py prettyprint-override""><code>round  1, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.8680933)])
round  2, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.836558)])
round  3, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.82953715)])
round  4, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.82713753)])
round  5, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.82613766)])
round  6, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.8256878)])
round  7, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.82548285)])
round  8, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.825384)])
round  9, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.825332)])
</code></pre>
<p>I would like to understand the reason, If there is another way to do this? Knowing that my dataset is an image dataset with 3 class.</p>
",14253961,,14253961,,44564.33804,44564.33804,TFF: finetune with pretrained network : Test accuracy still constant after all rounds,<tensorflow><tensorflow-federated><federated-learning>,0,2,,,,CC BY-SA 4.0
70333328,1,,,44543.4451,,1,32,"<p>To improve this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#training_the_model_on_federated_data"" rel=""nofollow noreferrer"">tutorial</a> and test other things, I was pretrained the network with a centralized way in EMNIST database. Then I would like to Fine tune the pretrained network with a federated code above.
So, I only added:</p>
<pre><code>def create_keras_model():
  return tf.keras.models.Sequential([
      tf.keras.models.load_model(path/to/model, compile=False)
      tf.keras.layers.Dense(10, kernel_initializer='zeros'),
      tf.keras.layers.Softmax(),
  ])
</code></pre>
<p>The problem is that I find same test accuracy values compared to test accuracy values without fine tuning a pretrained network.
Can you please give me solution.</p>
",14253961,,,,,44543.4451,TFF : change the code have no effect in changing test accuracy values,<tensorflow-federated><federated-learning>,0,1,,,,CC BY-SA 4.0
70338012,1,70544437,,44543.69638,,1,98,"<p>I have a problem with training using <code>tff.simulation.FilePerUserClientData</code> - I am quickly running out of RAM after 5-6 rounds with 10 clients per round.
The RAM usage is steadily increasing with each round.
I tried to narrow it down and realized that the issue is not the actual iterative process but the creation of the client datasets.
Simply calling <code>create_tf_dataset_for_client(client)</code> in a loop causes the problem.</p>
<p>So this is a minimal version of my code:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import tensorflow_federated as tff
import numpy as np
import pickle

BATCH_SIZE = 16
EPOCHS = 2
MAX_SEQUENCE_LEN = 20
NUM_ROUNDS = 100
CLIENTS_PER_ROUND = 10

def decode_fn(record_bytes):
    return tf.io.parse_single_example(
        record_bytes,
        {&quot;x&quot;: tf.io.FixedLenFeature([MAX_SEQUENCE_LEN], dtype=tf.string),
         &quot;y&quot;: tf.io.FixedLenFeature([MAX_SEQUENCE_LEN], dtype=tf.string)}
    )

def dataset_fn(path):
    return tf.data.TFRecordDataset([path]).map(decode_fn).padded_batch(BATCH_SIZE).repeat(EPOCHS)

def sample_client_data(data, client_ids, sampling_prob):
    clients_total = len(client_ids)
    x = np.random.uniform(size=clients_total)
    sampled_ids = [client_ids[i] for i in range(clients_total) if x[i] &lt; sampling_prob]
    data = [train_data.create_tf_dataset_for_client(client) for client in sampled_ids]
    return data
    
with open('users.pkl', 'rb') as f:
    users = pickle.load(f)
    
train_client_ids = users[&quot;train&quot;]
client_id_to_train_file = {i: &quot;reddit_leaf_tf/&quot; + i for i in train_client_ids}

train_data = tff.simulation.datasets.FilePerUserClientData(
    client_ids_to_files=client_id_to_train_file,
    dataset_fn=dataset_fn
)

sampling_prob = CLIENTS_PER_ROUND / len(train_client_ids)

for round_num in range(0, NUM_ROUNDS):
    print('Round {r}'.format(r=round_num))
    participants_data = sample_client_data(train_data, train_client_ids, sampling_prob)
    print(&quot;Round Completed&quot;)
</code></pre>
<p>I am using tensorflow-federated 19.0.</p>
<p>Is there something wrong with the way I create the client datasets or is it somehow expected that the RAM from the previous round is not freed?</p>
",17667231,,14692,,44559.92255,44561.72934,Running Out of RAM using FilePerUserClientData,<tensorflow-datasets><tensorflow-federated><federated-learning>,1,2,,,,CC BY-SA 4.0
70590588,1,,,44566.39806,,0,1212,"<p>I use TFF v:0.18
I would like to load a pretrained network in the inside of <code>create_keras_model()</code> So I write this :</p>
<pre class=""lang-py prettyprint-override""><code>def create_keras_model():
    baseModel = tf.keras.models.load_model(model_path, compile=False)
    headModel = baseModel.output
    model_output = tf.keras.layers.Dense(3, activation=&quot;softmax&quot;, name=&quot;output&quot;)(headModel)
    model = tf.keras.Model(inputs=baseModel.input, outputs=model_output)
    return model
new_iterproc = tff.templates.IterativeProcess(intialize_fn=server_init_tff, next_fn=old_iterproc.next)
state = new_iterproc.initialize()
</code></pre>
<p>But I find this error:</p>
<pre class=""lang-py prettyprint-override""><code>    new_iterproc = tff.templates.IterativeProcess(intialize_fn=server_init_tff, next_fn=old_iterproc.next)
TypeError: __init__() got an unexpected keyword argument 'intialize_fn'
</code></pre>
<p>I don't believe that the syntax is error,</p>
",14253961,,14253961,,44566.81969,44566.81969,TypeError: __init__() got an unexpected keyword argument 'intialize_fn',<tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
70825390,1,71004238,,44584.77785,,1,458,"<p>I just started studying federated learning and want to apply it to a certain dataset, and there are some questions that have risen up.</p>
<p>My data is containing records of 3 categories, each of which is having 3 departments. I am planning to have 3 different federated learning models for each category and treat the three department of this category as the distributed clients.</p>
<p>Is this possible? or building federated learning models requires having thousands of clients?</p>
<p>Thanks</p>
",17534198,,,,,44598.19286,Limited number of clients used in federated learning,<tensorflow-federated><federated><federated-learning>,1,1,,,,CC BY-SA 4.0
70990386,1,70991107,,44596.72353,,1,783,"<p>I'm working in  <a href=""https://www.kaggle.com/xainano/handwrittenmathsymbols"" rel=""nofollow noreferrer"">Handwritten Math's symbol Classification</a> using Federated Learning. I have preprocessed the image from <code>keras.preprocessing.image.ImageDataGenerator</code> and also obtained the labels of each images.</p>
<pre><code>from keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)
train_dataset = train_datagen.flow_from_directory(
        'train_test_data/train/',
        target_size=(45,45),
        batch_size=32,
        class_mode='categorical')
</code></pre>
<p>For obtaining labels:</p>
<pre><code>import os
# make label list '!/exp87530.jpg'
def make_labels(train_dataset):
  labels = train_dataset.filenames
  label = []
  for l in labels:
    l = l.split(os.path.sep)[0]
    label.append(l)
  return label 
</code></pre>
<p>How could I make a tuple of flattened Image and label that needs to send to the clients ?
As seen from tensorflow tutorial <a href=""https://www.tensorflow.org/federated/tutorials/building_your_own_federated_learning_algorithm"" rel=""nofollow noreferrer"">Building Your Own Federated Learning Algorithm</a></p>
<p>From tutorial:</p>
<pre><code>import 
emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()

NUM_CLIENTS = 10
BATCH_SIZE = 20

def preprocess(dataset):

  def batch_format_fn(element):
    &quot;&quot;&quot;Flatten a batch of EMNIST data and return a (features, label) tuple.&quot;&quot;&quot;
    return (tf.reshape(element['pixels'], [-1, 784]), 
            tf.reshape(element['label'], [-1, 1]))

  return dataset.batch(BATCH_SIZE).map(batch_format_fn)
</code></pre>
",11628726,,9657861,,44596.76459,44596.76459,"How to flatten test image dataset and create a batch of tuple of (flattened image , labels)?",<python><tensorflow><jupyter-notebook><tensorflow-datasets><federated-learning>,1,4,,,,CC BY-SA 4.0
71006411,1,,,44598.45249,,0,274,"<p>I know one use can be using Checkpoint and CheckpointManager tensorflow classes to save and resume training the GAN.</p>
<p>I am looking for a way to save the Generator (G) , Discriminator(D) and their optimisation states such that I can manipulate the model weights (for G and D). One use case for me is average the weights of different Generator in Federated Learning for GAN.</p>
<p>I found no way do to this using Keras or tensorflow.</p>
",6603215,,6603215,,44600.46603,44600.46603,Keras: How to save GAN model with optimiser state?,<python><tensorflow><keras><generative-adversarial-network><federated-learning>,0,2,,,,CC BY-SA 4.0
71043010,1,,,44601.06898,,2,656,"<p>I want to set weights to an existing model, such as VGG 16. However, I only want to set weights to the model <strong>excluding the last (fully connected) layer</strong>. I have tried to use <code>model.layers[:-1].set_weights(weights[:-1])</code>, it will cause the error of</p>
<pre><code>File &quot;server.py&quot;, line 114, in evaluate                                                                                   
model.layers[:-1].set_weights(weights[:-1])          
AttributeError: 'list' object has no attribute 'set_weights'  
</code></pre>
<p>There is one solution used the for loop to set the weight, but it is inefficient.</p>
<pre><code>weights_list = model.get_weights()
for i, weights in enumerate(weights_list[0:9]):
    model.layers[i].set_weights(weights)
</code></pre>
<p>Is there a way to set the weight to some layers of the model? Thanks!</p>
",14649072,,,,,44601.06898,Keras - how to set weights to some layers,<tensorflow><keras><federated-learning>,0,2,,,,CC BY-SA 4.0
71167600,1,71178429,,44610.08726,,3,406,"<p>I am working to build a federated learning model using TFF and I have some questions:</p>
<ol>
<li><p>I am preparing the dataset, I have separate files of data, with same features and different samples. I would consider each of these files as a single client. How can I maintain this in TFF?</p>
</li>
<li><p>The data is not balanced, meaning, the size of data varies in each file. Is this affecting the modeling process?</p>
</li>
<li><p>The size of the data is a bit small, one file (client) is having 300 records and another is 1500 records, is it suitable to build a federated learning model?</p>
</li>
</ol>
<p>Thanks in advance</p>
",17534198,,17534198,,44610.09435,44611.03425,How to build federated learning model of unbalanced and small dataset,<machine-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
62040659,1,,,43978.42641,,2,147,"<p>I'm currently researching with TFF and image classification (Federated Learning for Image Classification) emnist.</p>

<p>I'm looking at hyper parameters for the model learning rate and optimizer. Is grid search a good approach here ? . In a real world scenario would you simply sample clients/devices from the overall domain and if so if I was to do a grid search would I have to fix my client samples 1st. In which case does it make sense to do the grid search. </p>

<p>What would be a typical real world way of selecting parameters, ie is this more a heuristic approach. ?</p>

<p>Colin . . .</p>
",13626403,,730754,,44163.45519,44163.45519,Grid Search Applicable for TFF and FL.?,<grid-search><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
62083380,1,,,43980.41752,,1,1504,"<p>I new in python and machine learning. I tried to implement the following code for federated learning with the MNIST dataset but it doesn't work !! it tried to train a model in a distributed way in local workers. the jpeg version of the MNIST data set is using here. It consists of 42000 digit images with each class kept in a separate folder. I will load the data into memory using this code snippet and keep 10% of the data for testing the trained global model later on.
<strong>The following error appears when i implement the following fl_implemetation.py</strong></p>

<pre><code>(base) C:\python1&gt;fl_implemetation.py

  File ""C:\python1\fl_implemetation.py"", line 112
    global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)SGD_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(y_train)).batch(320)
                                                                                  ^
SyntaxError: invalid syntax
 there are two python files, first **fl_implemetation.py**.
</code></pre>

<p>The original code I am using can be found here: 
<a href=""https://github.com/datafrick/tutorial"" rel=""nofollow noreferrer"">https://github.com/datafrick/tutorial</a></p>

<pre><code>import NumPy as np
import random
import cv2
import os
from imutils import paths
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score

import TensorFlow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import SGD
from tensorflow.keras import backend as K

from fl_mnist_implementation_tutorial_utils import *

#declear path to your mnist data folder
img_path = '/path/to/your/training/dataset'

#get the path list using the path object
image_paths = list(paths.list_images(img_path))

#apply our function
image_list, label_list = load(image_paths, verbose=10000)

#binarize the labels
lb = LabelBinarizer()
label_list = lb.fit_transform(label_list)

#split data into training and test set
X_train, X_test, y_train, y_test = train_test_split(image_list, 
                                                    label_list, 
                                                    test_size=0.1, 
                                                    random_state=42)

#create clients
clients = create_clients(X_train, y_train, num_clients=10, initial='client')

#process and batch the training data for each client
clients_batched = dict()
for (client_name, data) in clients.items():
    clients_batched[client_name] = batch_data(data)

#process and batch the test set  
test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))

comms_round = 100

#create optimizer
lr = 0.01 
loss='categorical_crossentropy'
metrics = ['accuracy']
optimizer = SGD(lr=lr, 
                decay=lr / comms_round, 
                momentum=0.9
               ) 

#initialize global model
smlp_global = SimpleMLP()
global_model = smlp_global.build(784, 10)

#commence global training loop
for comm_round in range(comms_round):

    # get the global model's weights - will serve as the initial weights for all local models
    global_weights = global_model.get_weights()

    #initial list to collect local model weights after scalling
    scaled_local_weight_list = list()

    #randomize client data - using keys
    client_names= list(clients_batched.keys())
    random.shuffle(client_names)

    #loop through each client and create new local model
    for client in client_names:
        smlp_local = SimpleMLP()
        local_model = smlp_local.build(784, 10)
        local_model.compile(loss=loss, 
                      optimizer=optimizer, 
                      metrics=metrics)

        #set local model weight to the weight of the global model
        local_model.set_weights(global_weights)

        #fit local model with client's data
        local_model.fit(clients_batched[client], epochs=1, verbose=0)

        #scale the model weights and add to list
        scaling_factor = weight_scalling_factor(clients_batched, client)
        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)
        scaled_local_weight_list.append(scaled_weights)

        #clear session to free memory after each communication round
        K.clear_session()

    #to get the average over all the local model, we simply take the sum of the scaled weights
    average_weights = sum_scaled_weights(scaled_local_weight_list)

    #update global model 
    global_model.set_weights(average_weights)

    #test global model and print out metrics after each communications round
    for(X_test, Y_test) in test_batched:
        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)SGD_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(y_train)).batch(320)
smlp_SGD = SimpleMLP()
SGD_model = smlp_SGD.build(784, 10) 

SGD_model.compile(loss=loss, 
              optimizer=optimizer, 
              metrics=metrics)

# fit the SGD training data to model
_ = SGD_model.fit(SGD_dataset, epochs=100, verbose=0)

#test the SGD global model and print out metrics
for(X_test, Y_test) in test_batched:
        SGD_acc, SGD_loss = test_model(X_test, Y_test, SGD_model, 1)
</code></pre>

<p>and second <strong>fl_mnist_implementation_tutorial_utils.py</strong></p>

<pre><code>import NumPy as np
import random
import cv2
import os
from imutils import paths
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from sklearn.metrics import accuracy_score

import TensorFlow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import SGD
from tensorflow.keras import backend as K

def load(paths, verbose=-1):
    '''expects images for each class in separate dir, 
    e.g all digits in 0 class in the directory named 0 '''
    data = list()
    labels = list()
    # loop over the input images
    for (i, imgpath) in enumerate(paths):
        # load the image and extract the class labels
        im_gray = cv2.imread(imgpath, cv2.IMREAD_GRAYSCALE)
        image = np.array(im_gray).flatten()
        label = imgpath.split(os.path.sep)[-2]
        # scale the image to [0, 1] and add to list
        data.append(image/255)
        labels.append(label)
        # show an update every `verbose` images
        if verbose &gt; 0 and i &gt; 0 and (i + 1) % verbose == 0:
            print(""[INFO] processed {}/{}"".format(i + 1, len(paths)))
    # return a tuple of the data and labels
    return data, labels


def create_clients(image_list, label_list, num_clients=10, initial='clients'):
    ''' return: a dictionary with keys clients' names and value as 
                data shards - tuple of images and label lists.
        args: 
            image_list: a list of numpy arrays of training images
            label_list:a list of binarized labels for each image
            num_client: number of fedrated members (clients)
            initials: the clients'name prefix, e.g, clients_1 

    '''

    #create a list of client names
    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]

    #randomize the data
    data = list(zip(image_list, label_list))
    random.shuffle(data)

    #shard data and place at each client
    size = len(data)//num_clients
    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]

    #number of clients must equal number of shards
    assert(len(shards) == len(client_names))

    return {client_names[i] : shards[i] for i in range(len(client_names))}



def batch_data(data_shard, bs=32):
    '''Takes in a clients data shard and create a tfds object off it
    args:
        shard: a data, label constituting a client's data shard
        bs:batch size
    return:
        tfds object'''
    #seperate shard into data and labels lists
    data, label = zip(*data_shard)
    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))
    return dataset.shuffle(len(label)).batch(bs)


class SimpleMLP:
    @staticmethod
    def build(shape, classes):
        model = Sequential()
        model.add(Dense(200, input_shape=(shape,)))
        model.add(Activation(""relu""))
        model.add(Dense(200))
        model.add(Activation(""relu""))
        model.add(Dense(classes))
        model.add(Activation(""softmax""))
        return model


def weight_scalling_factor(clients_trn_data, client_name):
    client_names = list(clients_trn_data.keys())
    #get the bs
    bs = list(clients_trn_data[client_name])[0][0].shape[0]
    #first calculate the total training data points across clinets
    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs
    # get the total number of data points held by a client
    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs
    return local_count/global_count


def scale_model_weights(weight, scalar):
    '''function for scaling a models weights'''
    weight_final = []
    steps = len(weight)
    for i in range(steps):
        weight_final.append(scalar * weight[i])
    return weight_final



def sum_scaled_weights(scaled_weight_list):
    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''
    avg_grad = list()
    #get the average grad accross all client gradients
    for grad_list_tuple in zip(*scaled_weight_list):
        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)
        avg_grad.append(layer_mean)

    return avg_grad


def test_model(X_test, Y_test,  model, comm_round):
    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
    #logits = model.predict(X_test, batch_size=100)
    logits = model.predict(X_test)
    loss = cce(Y_test, logits)
    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))
    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))
    return acc, loss
</code></pre>
",13084453,,730754,,44163.45497,44163.45497,federated learning implementing,<python><machine-learning><federated-learning>,1,2,,43980.52722,,CC BY-SA 4.0
62398875,1,,,43998.0002,,1,430,"<pre><code>def create_keras_model():
model = Sequential([
    Conv2D(16, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Conv2D(32, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Conv2D(64, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Flatten(),
    Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.load_weights('/content/drive/My Drive/localmodel/weights')
return model
</code></pre>

<p>Tried something like this in Colab, but I get errno 21, is a directory.</p>

<p>Then I tried another method as shown below,  </p>

<pre><code>tff_model = create_keras_model() #now this function doesnt load weights, just returns a Sequential model   
tff.learning.assign_weights_to_keras_model(tff_model, model_with_weights)
</code></pre>

<p>Just like assign_weights_to_keras_model() transfers weights from tff_model to keras model, I want to transfer weights from keras model to tff_model. How can this be done?</p>
",9799778,,730754,,44163.4547,44163.4547,How to transfer weights from baseline model to federated model?,<tensorflow><tensorflow-federated><federated-learning>,2,4,,,,CC BY-SA 4.0
62803219,1,,,44020.85693,,-1,548,"<p>1:
when attempting to perfrom a pytorch training sequence using batch sizes, my loss function appears to error when the nn output and a batch are put through a MSEloss function.</p>
<p>2:
have tried to search about nn padding, however this is not a covnet but rather an autoencoder, similar stack over flow issues have not yielded results.</p>
<p>3:
the NN:</p>
<pre><code>class Net(nn.Module):
    def __init__(self, input_dim=10):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, int(0.75 * input_dim))
        self.fc2 = nn.Linear(int(0.75 * input_dim), int(0.5 * input_dim))
        self.fc3 = nn.Linear(int(0.5 * input_dim), int(0.33 * input_dim))
        self.fc4 = nn.Linear(int(0.33 * input_dim), int(0.25 * input_dim))
        self.fc5 = nn.Linear(int(0.25 * input_dim), int(0.33 * input_dim))
        self.fc6 = nn.Linear(int(0.33 * input_dim), int(0.5 * input_dim))
        self.fc7 = nn.Linear(int(0.5 * input_dim), int(0.75 * input_dim))
        self.fc8 = nn.Linear(int(0.75 * input_dim), input_dim)

    def forward(self, x):
        x = torch.tanh(self.fc1(x))
        x = torch.tanh(self.fc2(x))
        x = torch.tanh(self.fc3(x))
        x = torch.tanh(self.fc4(x))
        x = torch.tanh(self.fc5(x))
        x = torch.tanh(self.fc6(x))
        x = torch.tanh(self.fc7(x))
        x = self.fc8(x)
        return torch.softmax(x, dim=1)
</code></pre>
<p>the train method:</p>
<pre><code>def train(net, x_train, x_opt, BATCH_SIZE, EPOCHS, input_dim):
    outputs = 0
    mse = 0
    optimizer = optim.SGD(net.parameters(), lr=0.001)
    loss_function = nn.MSELoss()

    for epoch in range(EPOCHS):
        for i in tqdm(range(0, len(x_train), BATCH_SIZE)):
            batch_x = x_train[i:i + BATCH_SIZE]
            # print(&quot;bx&quot;, batch_x.size())

            batch_y = x_opt[i:i + BATCH_SIZE]
            # print(&quot;by&quot;, batch_y.size())
            net.zero_grad()
            # batch_x.view(batch_y.shape[0])
            outputs = net(batch_x)
            # print('out', outputs)

            loss = loss_function(outputs, batch_y)
            loss.backward()
            optimizer.step()  # Does the update

        print(f&quot;Epoch: {epoch}. Loss: {loss}&quot;)
</code></pre>
<p>error:</p>
<pre><code> 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1452/1466 [00:02&lt;00:00, 718.09it/s]B:\tools and software\Anaconda\envs\pysyft-pytorch\lib\site-packages\torch\nn\modules\loss.py:431: UserWarning: Using a target size (torch.Size([39, 10])) that is different to the input size (torch.Size([38, 10])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1465/1466 [00:02&lt;00:00, 718.36it/s]
Traceback (most recent call last):
  File &quot;&lt;input&gt;&quot;, line 1, in &lt;module&gt;
  File &quot;B:\tools and software\PyCharm 2020.1\plugins\python\helpers\pydev\_pydev_bundle\pydev_umd.py&quot;, line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File &quot;B:\tools and software\PyCharm 2020.1\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py&quot;, line 18, in execfile
    exec(compile(contents+&quot;\n&quot;, file, 'exec'), glob, loc)
  File &quot;B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/pytorch_conversion.py&quot;, line 154, in &lt;module&gt;
    input_dim=input_dim)
  File &quot;B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/pytorch_conversion.py&quot;, line 64, in train
    loss = loss_function(outputs, batch_y)
  File &quot;B:\tools and software\Anaconda\envs\pysyft-pytorch\lib\site-packages\torch\nn\modules\module.py&quot;, line 532, in __call__
    result = self.forward(*input, **kwargs)
  File &quot;B:\tools and software\Anaconda\envs\pysyft-pytorch\lib\site-packages\torch\nn\modules\loss.py&quot;, line 431, in forward
    return F.mse_loss(input, target, reduction=self.reduction)
  File &quot;B:\tools and software\Anaconda\envs\pysyft-pytorch\lib\site-packages\torch\nn\functional.py&quot;, line 2215, in mse_loss
    expanded_input, expanded_target = torch.broadcast_tensors(input, target)
  File &quot;B:\tools and software\Anaconda\envs\pysyft-pytorch\lib\site-packages\torch\functional.py&quot;, line 52, in broadcast_tensors
    return torch._C._VariableFunctions.broadcast_tensors(tensors)
RuntimeError: The size of tensor a (38) must match the size of tensor b (39) at non-singleton dimension 0
</code></pre>
",13716568,,730754,,44163.46334,44163.46334,Tensor Size Miss match on loss function,<numpy><machine-learning><pytorch><federated-learning><pysyft>,1,0,,,,CC BY-SA 4.0
63589819,1,,,44069.12439,,0,397,"<p>When I using pysyft to do some Federated Learning task, there is an error:</p>
<p><strong>AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset'</strong></p>
<pre><code>def start_websocket_server_worker(id, host, port, hook, verbose, training, dataset, dataset_labels):
    server = websocket_server.WebsocketServerWorker(id=id, host=host, port=port, hook=hook, verbose=verbose)
    # change dataset to tensor
    x_values_tensor = dataset.reshape(dataset.shape[0], dataset.shape[2], dataset.shape[1], 1).astype(float)

    y_values_tensor = dataset_labels.astype(float)
    one_HARdataset = HARdataset(x_values=x_values_tensor, y_values=y_values_tensor, transform=transforms.Compose([
                        ToTensor()
                        ]))

    server.add_dataset(one_HARdataset, key=&quot;har_dataset&quot;)
    print(&quot;datasets: %s&quot;, server.datasets)
    server.start()
    return server
</code></pre>
<p>the error:</p>
<pre><code>Traceback (most recent call last):
  File &quot;run_websocket_server.py&quot;, line 166, in &lt;module&gt;
    dataset_labels=data_sep_worker_labels[work_dic[args.id]]
  File &quot;run_websocket_server.py&quot;, line 122, in start_websocket_server_worker
    server.add_dataset(one_HARdataset, key=&quot;har_dataset&quot;)
AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset'
Traceback (most recent call last):
  File &quot;run_websocket_server.py&quot;, line 166, in &lt;module&gt;
    dataset_labels=data_sep_worker_labels[work_dic[args.id]]
  File &quot;run_websocket_server.py&quot;, line 122, in start_websocket_server_worker
    server.add_dataset(one_HARdataset, key=&quot;har_dataset&quot;)
AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset'
Traceback (most recent call last):
  File &quot;run_websocket_server.py&quot;, line 166, in &lt;module&gt;
    dataset_labels=data_sep_worker_labels[work_dic[args.id]]
  File &quot;run_websocket_server.py&quot;, line 122, in start_websocket_server_worker
    server.add_dataset(one_HARdataset, key=&quot;har_dataset&quot;)
AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset'
Traceback (most recent call last):
  File &quot;run_websocket_server.py&quot;, line 166, in &lt;module&gt;
    dataset_labels=data_sep_worker_labels[work_dic[args.id]]
  File &quot;run_websocket_server.py&quot;, line 122, in start_websocket_server_worker
    server.add_dataset(one_HARdataset, key=&quot;har_dataset&quot;)
AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset'
</code></pre>
<p>I don't know how to solve it :(</p>
",14167342,,730754,,44163.46594,44163.46594,AttributeError: 'WebsocketServerWorker' object has no attribute 'add_dataset',<python><machine-learning><federated-learning><pysyft>,1,0,,,,CC BY-SA 4.0
71209010,1,71305362,,44613.64897,,1,239,"<p>I am working on Federated Learning experiments using Intel OpenFL. I want to distribute my dataset (MNIST) using different non-iidness scenarios.
I am following their official documentation: <a href=""https://openfl.readthedocs.io/en/latest/source/utilities/splitters_data.html"" rel=""nofollow noreferrer"">https://openfl.readthedocs.io/en/latest/source/utilities/splitters_data.html</a></p>
<p>This is my original working code:</p>
<pre><code>&quot;&quot;&quot;Mnist Shard Descriptor.&quot;&quot;&quot;

import logging
import os
from typing import List

import numpy as np
import requests

from openfl.interface.interactive_api.shard_descriptor import ShardDataset
from openfl.interface.interactive_api.shard_descriptor import ShardDescriptor

logger = logging.getLogger(__name__)


class MnistShardDataset(ShardDataset):
    &quot;&quot;&quot;Mnist Shard dataset class.&quot;&quot;&quot;

    def __init__(self, x, y, data_type, rank=1, worldsize=1):
        &quot;&quot;&quot;Initialize MNISTDataset.&quot;&quot;&quot;
        self.data_type = data_type
        self.rank = rank
        self.worldsize = worldsize
        self.x = x[self.rank - 1::self.worldsize]
        self.y = y[self.rank - 1::self.worldsize]

    def __getitem__(self, index: int):
        &quot;&quot;&quot;Return an item by the index.&quot;&quot;&quot;
        return self.x[index], self.y[index]

    def __len__(self):
        &quot;&quot;&quot;Return the len of the dataset.&quot;&quot;&quot;
        return len(self.x)


class MnistShardDescriptor(ShardDescriptor):
    &quot;&quot;&quot;Mnist Shard descriptor class.&quot;&quot;&quot;

    def __init__(
            self,
            rank_worldsize: str = '1, 1',
            **kwargs
    ):
        &quot;&quot;&quot;Initialize MnistShardDescriptor.&quot;&quot;&quot;
        self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
        (x_train, y_train), (x_test, y_test) = self.download_data()
        self.data_by_type = {
            'train': (x_train, y_train),
            'val': (x_test, y_test)
        }

    def get_shard_dataset_types(self) -&gt; List[str]:
        &quot;&quot;&quot;Get available shard dataset types.&quot;&quot;&quot;
        return list(self.data_by_type)

    def get_dataset(self, dataset_type='train'):
        &quot;&quot;&quot;Return a shard dataset by type.&quot;&quot;&quot;
        if dataset_type not in self.data_by_type:
            raise Exception(f'Wrong dataset type: {dataset_type}')
        return MnistShardDataset(
            *self.data_by_type[dataset_type],
            data_type=dataset_type,
            rank=self.rank,
            worldsize=self.worldsize
        )

    @property
    def sample_shape(self):
        &quot;&quot;&quot;Return the sample shape info.&quot;&quot;&quot;
        return ['28', '28', '1']

    @property
    def target_shape(self):
        &quot;&quot;&quot;Return the target shape info.&quot;&quot;&quot;
        return ['28', '28', '1']

    @property
    def dataset_description(self) -&gt; str:
        &quot;&quot;&quot;Return the dataset description.&quot;&quot;&quot;
        return (f'Mnist dataset, shard number {self.rank}'
                f' out of {self.worldsize}')

    def download_data(self):
        &quot;&quot;&quot;Download prepared dataset.&quot;&quot;&quot;
        local_file_path = 'mnist.npz'
        mnist_url = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'
        response = requests.get(mnist_url)
        with open(local_file_path, 'wb') as f:
            f.write(response.content)

        with np.load(local_file_path) as f:
            x_train, y_train = f['x_train'], f['y_train']
            x_test, y_test = f['x_test'], f['y_test']
            #x_train = np.reshape(x_train, (-1, 784))
            #x_test = np.reshape(x_test, (-1, 784))

        os.remove(local_file_path)  # remove mnist.npz
        print('Mnist data was loaded!')
        return (x_train, y_train), (x_test, y_test)
</code></pre>
<p>Basically, I changed the MnistShardDescriptor class in both my 2 nodes of the federation in this way:</p>
<pre><code>...
class MnistShardDescriptor(ShardDescriptor):
    &quot;&quot;&quot;Mnist Shard descriptor class.&quot;&quot;&quot;

    def __init__(
            self,
            rank_worldsize: str = '1, 1',
            **kwargs
    ):
        &quot;&quot;&quot;Initialize MnistShardDescriptor.&quot;&quot;&quot;
        self.rank, self.worldsize = tuple(int(num) for num in rank_worldsize.split(','))
        (x_train, y_train), (x_test, y_test) = self.download_data()
        train_splitter = RandomNumPyDataSplitter()
        test_splitter = RandomNumPyDataSplitter()
        train_idx = train_splitter.split(y_train, self.worldsize)[self.rank]
        test_idx = test_splitter.split(y_test, self.worldsize)[self.rank]
        x_train_shard = x_train[train_idx]
        x_test_shard = x_test[test_idx]
        self.data_by_type = {
            'train': (x_train, y_train),
            'val': (x_test, y_test)
        }
...
</code></pre>
<p>I have this error at the line <code>train_idx</code>:<code>IndexError: list index out of range</code> but only in one of the 2 nodes. I do not know why, because the code are exactly the same on both nodes of my federation.</p>
<p>EDIT: I changed the position of the code I have written above, and in particular I wrote in the class MnistShardDataset rather than MnistShardDescriptor:</p>
<pre><code>class MnistShardDataset(ShardDataset):
    &quot;&quot;&quot;Mnist Shard dataset class.&quot;&quot;&quot;
    def __init__(self, x, y, data_type, rank=1, worldsize=1):
        &quot;&quot;&quot;Initialize MNISTDataset.&quot;&quot;&quot;
        self.data_type = data_type
        self.rank = rank
        self.worldsize = worldsize
        self.x = x[self.rank - 1::self.worldsize]
        self.y = y[self.rank - 1::self.worldsize]
        
        train_splitter = RandomNumPyDataSplitter()
        #test_splitter = RandomNumPyDataSplitter()
        train_idx = train_splitter.split(self.y, self.worldsize)[self.rank]
        #test_idx = test_splitter.split(self.y, self.worldsize)[self.rank]
        x_train_shard = self.x[train_idx]
        #x_test_shard = self.x[test_idx]
        self.x = x_train_shard
</code></pre>
<p>With this I am able to create the federation and, in the same node of the director, the clients start training, and the split is truly random because I ran the experiment 2 times, and each time the envoy had a different number of samples. However in the other node (because I am using 2 nodes, one for each envoy) with the envoy (openFL calls envoy the worker on a client) I have the same error of Index out of rangeâ€¦</p>
<p>EDIT2: here is an example of data split using openFL: <a href=""https://github.com/intel/openfl/blob/develop/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/kvasir_shard_descriptor_with_data_splitter.py"" rel=""nofollow noreferrer"">https://github.com/intel/openfl/blob/develop/openfl-tutorials/interactive_api/PyTorch_Kvasir_UNet/envoy/kvasir_shard_descriptor_with_data_splitter.py</a></p>
<p>However my dataset is different, and I am not succeeding in adapting this solution. Any other example can you suggest to me, about sharding a dataset like MNIST? A tutorial to follow?</p>
<p>Entire error:</p>
<pre><code>  File &quot;/home/lmancuso/envoymnist/mnist_shard_descriptor_with_data_splitter.py&quot;, line 61, in __init__
    train_idx = train_splitter.split(y_train, self.worldsize)[self.rank]
IndexError: list index out of range
</code></pre>
<p>EDIT: interesting point: If I change the dimension of my federation, increasing from 2 to 3 the rank_worldsize inside the envoy_config.yaml, training starts (and the dataset is divided in a random way, so it works, because each node has different number of samples). However it works only because I have 2 nodes, but I created a federation of 3 without the 3 node. Indeed the samples are 8064 for one node and 9856 for another node. However considering that I have 60000 training samples in MNIST, all the remaining samples got lost, because they are supposed to be in the last node (which does not exist).</p>
",11590027,,11590027,,44616.67367,44955.8155,MNIST Shard Descriptor: IndexError: list index out of range,<deep-learning><sharding><mnist><federated-learning>,1,0,,,,CC BY-SA 4.0
71285825,1,71287281,,44619.62471,,2,474,"<p>I am preparing a dataset for federation settings, in the code below, I have multiple CSV files and used each is considered a single client.</p>
<pre><code>dataset_paths = {
  'client_0': '/content/drive/ds1.csv',
  'client_1': '/content/drive/ds2.csv',
  'client_2': '/content/drive/ds3.csv',
  'client_3': '/content/drive/ds4.csv',
  'client_4': '/content/drive/ds5.csv',
}
## Defining the Dtyps for each columns in the datasets 
record_defaults = [int(), int(), int(), int(), float(),float(),float(),float(),float(),float(), int(), int()]

@tf.function
def create_tf_dataset_for_client_fn(dataset_path):
   return tf.data.experimental.CsvDataset(
     dataset_path, record_defaults=record_defaults, header=True )

source = tff.simulation.datasets.FilePerUserClientData(
  dataset_paths, create_tf_dataset_for_client_fn) 
</code></pre>
<p>I wanted to access the data so I can determine the <code>features</code> and <code>label</code> column. so I typed:</p>
<pre><code>for x in source.create_tf_dataset_for_client('client_1'):
  print(x)  
&gt;&gt;&gt; (&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2145209674&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=14&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=64.17&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=70.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=80.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=30.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=270.14&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=7&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2143677297&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=9&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=60.83&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=14.89&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=75.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=42.5&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=184.72&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=8&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2138537298&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=11&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.83&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=18.82&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=70.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=85.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=30.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=295.14&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=7&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2103817421&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=9&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=77.5&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=8.8&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=75.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=90.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=64.58&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=6&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2081702335&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=10&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=75.83&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=9.7&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=77.5&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=90.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=78.47&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=6&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2067936920&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=11&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=80.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=10.95&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=77.5&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=95.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=100.0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=6&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2065922700&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=11&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.83&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=3.76&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=70.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=60.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=11.81&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=6&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=3&gt;)
</code></pre>
<p><em>there are more rows since I have a big size of data</em>
So I can access these data as they are tensor objects,
<strong>Question1</strong> how can I state that <code>DataFrame.iloc[1:-1] #Features</code>
and <code>DataFrame.iloc[:-1] #Label</code>
<strong>Question2</strong> How can I split each file to training and testing sets to start the training process?</p>
",17534198,,17534198,,44622.95799,44622.95799,Using create_tf_dataset_for_client() to define the training examples in the dataset,<python><tensorflow><tensorflow-datasets><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
71441870,1,71514340,,44631.69721,,-2,915,"<p>While I am studying Federated Learning, I have some questions that popped up in my mind that needed some clarification.</p>
<ol>
<li>We first have defined clients, each client will be split into training and testing sets. The training data are used to train the local models. Now, what testing data are used for? are they used to test the global model? or to test each local model?</li>
<li>when training the global model, we first calculate the resulted weight of each local model, and then send it to the global model. In modeling the local clients, is there any validity check on the model itself before sending to the global model or it is sent anyway and then it will be updated by the global model.</li>
</ol>
<p>Are there any papers explaining these points?</p>
",17534198,,17534198,,44632.53961,45119.21214,Training the global and local model in federated learning,<tensorflow><machine-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
71470160,1,,,44634.63968,,1,39,"<p>I work with TFF, here is a part of my code :</p>
<pre><code>def create_keras_model():
    
    baseModel = tf.keras.applications.ResNet50(include_top=False, weights=None, input_tensor=tf.keras.Input(shape=(224, 224, 3)))

    for layer in baseModel.layers:
        layer.trainable = False
    return model
</code></pre>
<p>With this model I find test-accuracy value = <code>0.8</code>
Now, I would like to change <code>layer.trainable = True</code>, but the test-accuracy value decrease to <code>0.2</code> and loss becomes <code>12 </code>. which is not normal, can anyone tell why.</p>
",14253961,,14253961,,44686.31782,44686.31782,TFF: 'trainable=True ' causes decrinsing of accuracy,<tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
71496155,1,,,44636.4708,,1,91,"<p>The state object returned by iterative_process.initialize() is typically a Python container (tuple, collections.OrderedDict, etc) that contains numpy arrays. I would like that the value of state is not random, instead it begin from loaded model.
As the beginning, I write this :</p>
<pre><code>def create_keras_model():   
  Model = tf.keras.models.load_model(path)
  return Model
def model_fn(): 
    keras_model = create_keras_model()   
    return tff.learning.from_keras_model(keras_model..)
iterative_process = tff.learning.build_federated_averaging_process(model_fn=model_fn..)
state = iterative_process.initialize()
</code></pre>
<p>But test accuracy result does not change at all comparing by the normal case(if I don't load an external model).</p>
<p>That's why, I try this solution:</p>
<pre><code># initialize_fn() function
@tff.tf_computation
def server_init():
    model = model_fn()
    return model.trainable_variables

@tff.federated_computation
def initialize_fn():
    return tff.federated_value(server_init(), tff.SERVER) 

iterative_process = tff.templates.IterativeProcess(initialize_fn, next_fn)
state = iterative_process.initialize()
state['model'] = create_keras_model()
</code></pre>
<p>But I find this error:</p>
<pre><code>NameError: name 'next_fn' is not defined
</code></pre>
<p>So in my case, how can I define next_fn ?
Thanks</p>
",12682667,,12682667,,44636.55381,44636.55381,TFF : Modify the value of state,<tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
71630891,1,,,44646.78374,,1,92,"<p>I use tensorflow fedprox to implement federated learning.(tff.learning.algorithms.build_unweighted_fed_prox)</p>
<pre class=""lang-py prettyprint-override""><code>def model_fn():
    keras_model = create_keras_model()
    return tff.learning.from_keras_model(
        keras_model,
        input_spec=preprocessed_example_dataset.element_spec,
        loss=tf.keras.losses.SparseCategoricalCrossentropy(),
        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]
    )

iterative_process = tff.learning.algorithms.build_unweighted_fed_prox(
    model_fn, 0.001,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.001),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)
)

import nest_asyncio
nest_asyncio.apply()

state = iterative_process.initialize()

for round in range(3, 11):
    state = iterative_process.next(state.state, federated_train_data)
    print('round {:2d}, metrics={}'.format(round, state.metrics))
</code></pre>
<p>and the result of training is:</p>
<p>round  3, 'sparse_categorical_accuracy'= 0.6435834</p>
<p>round  4, 'sparse_categorical_accuracy'= 0.6955319</p>
<p>round  5, 'sparse_categorical_accuracy'= 0.74295634</p>
<p>round  6, 'sparse_categorical_accuracy'= 0.78176934</p>
<p>round  7, 'sparse_categorical_accuracy'= 0.80838746</p>
<p>round  8, 'sparse_categorical_accuracy'= 0.8300672</p>
<p>round  9, 'sparse_categorical_accuracy'= 0.8486338</p>
<p>round 10, 'sparse_categorical_accuracy', 0.86639416</p>
<hr />
<p>but when I want to evaluate my model on test data I get error:</p>
<pre><code>evaluation = tff.learning.build_federated_evaluation(model_fn)
test_metrics = evaluation(state.state, federated_test_data)

TypeError: Mismatched number of elements between type spec and value in `to_representation_for_type`. Type spec has 2 elements, value has 5.
</code></pre>
<p>How do I fix it?</p>
",17945316,,1779532,,44648.19003,44648.19003,"Mismatched number of elements between type spec and value in `to_representation_for_type`. Type spec has 2 elements, value has 5",<python><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
71680438,1,,,44650.66448,,1,118,"<p>I have designed the Federated Learning model with TensorFlow Federated framework. Defined the iterative process as below,</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.9))
</code></pre>
<p>I have 2 remote workers running the tffruntime remote executor service and the context for running computation is defined as <code>tff.backends.native.set_remote_python_execution_context(channels)</code>. When the model is broadcasted to the client with <code>iterative_process.next(state, train_data)</code>, how can we identify that the client metrics is aggregated and applied to the server model. Is the single api <code>build_federated_averaging_process</code> is enough to get the metrics from clients, aggregate and then update the server model? If means how can we identify that the server model is updated? Can anyone please help me to understand this.</p>
",18428250,,17534198,,44658.24053,44663.62755,How the centralized server model is updated with aggregated client metrics in TensorflowFederated,<tensorflow><machine-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
71687929,1,,,44651.27546,,0,797,"<ol>
<li>I am trying to use federated learning framework flower with TensorFlow. My code seems to compile fine but It's not showing federated loss and accuracy. What am I doing wrong?</li>
</ol>
<p>ServerSide Code :</p>
<pre><code>import flwr as fl
import sys
import numpy as np

class SaveModelStrategy(fl.server.strategy.FedAvg):
    def aggregate_fit(
        self,
        rnd,
        results,
        failures
    ):
        aggregated_weights = super().aggregate_fit(rnd, results, failures)
        &quot;&quot;&quot;if aggregated_weights is not None:
            # Save aggregated_weights
            print(f&quot;Saving round {rnd} aggregated_weights...&quot;)
            np.savez(f&quot;round-{rnd}-weights.npz&quot;, *aggregated_weights)&quot;&quot;&quot;
        return aggregated_weights

# Create strategy and run server
strategy = SaveModelStrategy()

# Start Flower server for three rounds of federated learning
fl.server.start_server(
        server_address = 'localhost:'+str(sys.argv[1]),
        #server_address = &quot;[::]:8080&quot; ,
        config={&quot;num_rounds&quot;: 2} ,
        grpc_max_message_length = 1024*1024*1024,
        strategy = strategy
)
</code></pre>
<p>Server Side:
<a href=""https://i.sstatic.net/6IqNN.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/6IqNN.png"" alt=""enter image description here"" /></a></p>
",13335476,,14692,,44651.49041,44651.49041,Flower Framework is not showing federated loss,<deep-learning><federated-learning>,1,0,,,,CC BY-SA 4.0
71767784,1,71768601,,44657.56674,,0,363,"<p>I am using the OpenFL framework for doing Federated Learning experiments. I run their tutorial notebooks without problems, so for example I am able to run classification on MNIST and everything is ok.
Now I am using 2 clients with 2 different datasets. However, my accuracy is around 0% for a binary classification problem.
So, I have 2 classes, &quot;neg&quot; and &quot;pos&quot; for both datasets. Images of the first dataset are 3000x2951 while images of the second are 4892x4020. I resize both to 256x256. My network is a ResNet9 without any sigmoid at the end, because I am using BCEWithLogitsLoss(). Here a bit of code, to check if everything is ok:</p>
<pre><code>optimizer_adam = optim.Adam(params_to_update, lr=1e-4)

def cross_entropy(output, target):
    &quot;&quot;&quot;Binary cross-entropy metric
    &quot;&quot;&quot;
    target = target.unsqueeze(1)
    criterion = nn.BCEWithLogitsLoss()
    loss = criterion(output, target.float())
    return loss
</code></pre>
<pre><code>def train(net_model, train_loader, optimizer, device, loss_fn=cross_entropy, some_parameter=None):
    torch.manual_seed(0)
    device='cpu'
    function_defined_in_notebook(some_parameter)
    
    train_loader = tqdm.tqdm(train_loader, desc=&quot;train&quot;)
    net_model.train()
    net_model.to(device)

    losses = []

    for data, target in train_loader:
        data, target = torch.tensor(data).to(device), torch.tensor(
            target).to(device, dtype=torch.int64)
        optimizer.zero_grad()
        #data = data.type(torch.LongTensor)
        #target = target.type(torch.LongTensor)
        output = net_model(data)
        loss = loss_fn(output=output, target=target)
        loss.backward()
        optimizer.step()
        losses.append(loss.detach().cpu().numpy())
    
    return {'train_loss': np.mean(losses),}


@task_interface.register_fl_task(model='net_model', data_loader='val_loader', device='device')     
def validate(net_model, val_loader, device):
    torch.manual_seed(0)
    device = torch.device('cpu')
    net_model.eval()
    net_model.to(device)
    
    val_loader = tqdm.tqdm(val_loader, desc=&quot;validate&quot;)
    val_score = 0
    total_samples = 0

    with torch.no_grad():
        for data, target in val_loader:
            samples = target.shape[0]
            total_samples += samples
            data, target = torch.tensor(data).to(device), \
                torch.tensor(target).to(device, dtype=torch.int64)
            output = net_model(data)
            
            pred = (output &gt;= 0.5).long() # Binarize predictions to 0 and 1
            val_score = (pred == target).sum().cpu().item()/data.size(0)
            
            #val_score += pred.eq(target).sum().cpu().numpy()
            
    return {'acc': val_score / total_samples,}
</code></pre>
<p>I think that all this is correct. So the only part that can be wrong is when I import the data because in this federated learning framework is a bit tricky. Basically my datasets are organized both in this way: /Dataset1(2)/Train(Test)/neg(pos)/images.png. I want to extract x_train, y_train, x_test and y_test because I am following exactly the structure of a tutorial that works. So this is my proposed solution:</p>
<pre><code>def download_data(self):
        &quot;&quot;&quot;Download prepared dataset.&quot;&quot;&quot;
        image_list_train = []
        image_list_test = []
        x_train = []
        y_train = []
        x_test = []
        y_test = []
        base_dir_train = 'Montgomery_real_splitted/TRAIN/'
        base_dir_test = 'Montgomery_real_splitted/TEST/'
        for f in sorted(os.listdir(base_dir_train)):
            if os.path.isdir(base_dir_train+f):
                print(f&quot;{f} is a target class&quot;)
                for i in sorted(os.listdir(base_dir_train+f)):
                    y_train.append(f)
                    im = Image.open(base_dir_train+f+'/'+i)
                    x_train.append(im)
        for f in sorted(os.listdir(base_dir_test)):
            if os.path.isdir(base_dir_test+f):
                print(f&quot;{f} is a target class&quot;)
                for i in sorted(os.listdir(base_dir_test+f)):
                    y_test.append(f)
                    imt=Image.open(base_dir_test+f+'/'+i)
                    x_test.append(imt)
        y_train = np.array(y_train)
        y_test = np.array(y_test)
        
        for i in range(len(y_train)):
            if y_train[i]==&quot;neg&quot;:
                y_train[i]=0
            else:
                y_train[i]=1
        y_train = y_train.astype(np.uint8)
        
        for i in range(len(y_test)):
            if y_test[i]==&quot;neg&quot;:
                y_test[i]=0
            else:
                y_test[i]=1
        y_test = y_test.astype(np.uint8)    


        print('Mont-china data was loaded!')
        return (x_train, y_train), (x_test, y_test)
</code></pre>
<p>This code above is in a python script needed to load the data. Then, inside the Jupyter notebook I have these cells in order to import the dataset:</p>
<pre><code>normalize = T.Normalize(
    mean=[0.1307],
    std=[0.3081]
)

augmentation = T.RandomApply(
    [T.RandomHorizontalFlip(),
     T.RandomRotation(10)], 
    p=.8
)

training_transform = T.Compose(
    [T.Resize((256,256)),
     augmentation,
     T.ToTensor()]
)

valid_transform = T.Compose(
    [T.Resize((256,256)),
     T.ToTensor()]
)


class TransformedDataset(Dataset):

    def __init__(self, dataset, transform=None, target_transform=None):
        &quot;&quot;&quot;Initialize Dataset.&quot;&quot;&quot;
        self.dataset = dataset
        self.transform = transform
        self.target_transform = target_transform

    def __len__(self):
        &quot;&quot;&quot;Length of dataset.&quot;&quot;&quot;
        return len(self.dataset)

    def __getitem__(self, index):
        img, label = self.dataset[index]
        label = self.target_transform(label) if self.target_transform else label
        img = self.transform(img) if self.transform else img
        return img, label


class MontChinaDataset(DataInterface):
    def __init__(self, **kwargs):
        self.kwargs = kwargs
    
    @property
    def shard_descriptor(self):
        return self._shard_descriptor
        
    @shard_descriptor.setter
    def shard_descriptor(self, shard_descriptor):
        &quot;&quot;&quot;
        Describe per-collaborator procedures or sharding.

        This method will be called during a collaborator initialization.
        Local shard_descriptor  will be set by Envoy.
        &quot;&quot;&quot;
        self._shard_descriptor = shard_descriptor
        
        self.train_set = TransformedDataset(
            self._shard_descriptor.get_dataset('train'),
            transform=training_transform
        )
        self.valid_set = TransformedDataset(
            self._shard_descriptor.get_dataset('val'),
            transform=valid_transform
        )
        
    def get_train_loader(self, **kwargs):
        &quot;&quot;&quot;
        Output of this method will be provided to tasks with optimizer in contract
        &quot;&quot;&quot;
        generator=torch.Generator()
        generator.manual_seed(0)
        return DataLoader(
            self.train_set, batch_size=self.kwargs['train_bs'], shuffle=True, generator=generator
            )

    def get_valid_loader(self, **kwargs):
        &quot;&quot;&quot;
        Output of this method will be provided to tasks without optimizer in contract
        &quot;&quot;&quot;
        return DataLoader(self.valid_set, batch_size=self.kwargs['valid_bs'])

    def get_train_data_size(self):
        &quot;&quot;&quot;
        Information for aggregation
        &quot;&quot;&quot;
        return len(self.train_set)

    def get_valid_data_size(self):
        &quot;&quot;&quot;
        Information for aggregation
        &quot;&quot;&quot;
        return len(self.valid_set)
    

fed_dataset = MontChinaDataset(train_bs=16, valid_bs=16)
</code></pre>
<p>The strange thing is that the loss decreases, while the accuracy remains 0 or around 0.</p>
<pre><code>[12:29:44] METRIC   Round 0, collaborator env_one train result train_loss:  0.673127                                                           experiment.py:116
[12:29:53] METRIC   Round 0, collaborator env_one locally_tuned_model_validate result acc:  0.000000                                           experiment.py:116
[12:29:56] METRIC   Round 0, collaborator env_one aggregated_model_validate result acc:     0.000000                                           experiment.py:116
[12:30:49] METRIC   Round 0, collaborator env_two train result train_loss:  0.562856                                                           experiment.py:116
[12:31:14] METRIC   Round 0, collaborator env_two locally_tuned_model_validate result acc:  0.000000                                           experiment.py:116
[12:31:19] METRIC   Round 0, collaborator env_two aggregated_model_validate result acc:     0.000000                                           experiment.py:116
[12:31:21] METRIC   Round 0, collaborator Aggregator train result train_loss:       0.581464                                                   experiment.py:116
           METRIC   Round 0, collaborator Aggregator locally_tuned_model_validate result acc:       0.000000                                   experiment.py:116
[12:31:22] METRIC   Round 0, collaborator Aggregator aggregated_model_validate result acc:  0.000000                                           experiment.py:116
[12:31:39] METRIC   Round 1, collaborator env_one train result train_loss:  0.637785                                                           experiment.py:116
[12:31:41] METRIC   Round 1, collaborator env_one locally_tuned_model_validate result acc:  0.000000                                           experiment.py:116
[12:31:44] METRIC   Round 1, collaborator env_one aggregated_model_validate result acc:     0.000000                                           experiment.py:116
[12:31:55] METRIC   Round 1, collaborator env_two train result train_loss:  0.432979                                                           experiment.py:116
[12:32:00] METRIC   Round 1, collaborator env_two locally_tuned_model_validate result acc:  0.000000                                           experiment.py:116
[12:32:05] METRIC   Round 1, collaborator env_two aggregated_model_validate result acc:     0.000000                                           experiment.py:116
[12:32:08] METRIC   Round 1, collaborator Aggregator train result train_loss:       0.467540                                                   experiment.py:116
           METRIC   Round 1, collaborator Aggregator locally_tuned_model_validate result acc:       0.000000                                   experiment.py:116
           METRIC   Round 1, collaborator Aggregator aggregated_model_validate result acc:  0.000000   
</code></pre>
<p>And this goes on for several rounds</p>
",11590027,,,,,44657.60266,Accuracy 0% for binary classification,<deep-learning><pytorch><loss><cross-entropy><federated-learning>,1,0,,,,CC BY-SA 4.0
71883746,1,,,44666.49896,,0,1817,"<p>I tried to implement federated learning based on the LSTM approach.</p>
<pre><code>def create_keras_model():
    model = Sequential()
    model.add(LSTM(32, input_shape=(3,1)))
    model.add(Dense(1))
    return model

def model_fn():
    keras_model = create_keras_model()
    return tff.learning.from_keras_model(
      keras_model,
      input_spec=(look_back, 1),
      loss=tf.keras.losses.mean_squared_error(),
      metrics=[tf.keras.metrics.mean_squared_error()])
</code></pre>
<p>but I got this error when I want to define iterative_process.</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.001),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

TypeError: Missing required positional argument
</code></pre>
<p>How do I fix it?</p>
",17945316,,,,,45001.8655,Missing required positional argument:,<python><tensorflow><lstm><tensorflow-federated><federated-learning>,1,1,,,,CC BY-SA 4.0
71885781,1,,,44666.63595,,1,150,"<p>Hi i'm a student and i'm working on a Federated Learning problem, but before doing that with the proper tools like OpenFL or Flower, I started a little experiment to try in local to train using this technique.</p>
<p>I managed to train multiple models using IID data, now I'm struggling with the  <code>local_update()</code> function that should collect the models and then i need to take all the weights of these models and compute their mean. I read some documentation of Keras and Tensorflow that I'm using for my work, and i found some functions but i can't get it to work properly.</p>
<p>Currently this is my  <code>local_update() </code> that's not working</p>
<pre><code>def local_update(self, models):

       
       weights = []
       #Take the weights of the models and compute the mean then return the weights to an updated model

       for model in models:
           for layer in model.layers:
               weights = layer.get_weights()
       
       #Compute the mean of weights  
       weights = np.mean(weights, axis=0)


       for layer in self.model.layers:
           self.model.set_weights(weights)     


       return self.model
</code></pre>
<p>In TensorFlow/Keras there are many way to do this but what is the best and simplest one?</p>
<p>Thank you in advance for the help!</p>
",13842080,,,,,44666.63595,How to compute the mean of weights of multiple models?,<tensorflow><keras><neural-network><mean><federated-learning>,0,0,,,,CC BY-SA 4.0
72076723,1,72077739,,44682.521,,1,3285,"<p>I'm testing this tutorial with non-IID distribution for federated learning:
<a href=""https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression</a></p>
<p>In this posted question <a href=""https://stackoverflow.com/questions/64970504/tensorflow-federated-how-to-tune-non-iidness-in-federated-dataset"">TensorFlow Federated: How to tune non-IIDness in federated dataset?</a> it suggested to use tff.simulation.datasets.build_single_label_dataset() as a way to produce a non-IID distribution for the dataset.</p>
<p>I tried to apply that first (see the code) and got an error !</p>
<pre><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(
    only_digits=False)
emnist_train1 = tff.simulation.datasets.build_single_label_dataset(
  emnist_train.create_tf_dataset_from_all_clients(),
  label_key='label', desired_label=1)

print(emnist_train1.element_spec)
</code></pre>
<blockquote>
<blockquote>
<p>OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)), ('pixels', TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])</p>
</blockquote>
</blockquote>
<pre><code>print(next(iter(emnist_train1))['label'])
</code></pre>
<blockquote>
<blockquote>
<p>tf.Tensor(1, shape=(), dtype=int32)</p>
</blockquote>
</blockquote>
<pre><code>MAX_CLIENT_DATASET_SIZE = 418

CLIENT_EPOCHS_PER_ROUND = 1
CLIENT_BATCH_SIZE = 20
TEST_BATCH_SIZE = 500

def reshape_emnist_element(element):
  return (tf.expand_dims(element['pixels'], axis=-1), element['label'])

def preprocess_train_dataset(dataset):
  return (dataset
          .shuffle(buffer_size=MAX_CLIENT_DATASET_SIZE)
          .repeat(CLIENT_EPOCHS_PER_ROUND)
          .batch(CLIENT_BATCH_SIZE, drop_remainder=False)
          .map(reshape_emnist_element))

emnist_train1 = emnist_train1.preprocess(preprocess_train_dataset)

&gt;&gt; ---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-17-cda96c33a0f6&gt; in &lt;module&gt;()
     15           .map(reshape_emnist_element))
     16 
---&gt; 17 emnist_train1 = emnist_train1.preprocess(preprocess_train_dataset)

AttributeError: 'MapDataset' object has no attribute 'preprocess'
</code></pre>
<p>Since dataset is filtered, it is not able to preprocess!
So, in this case, it is filtered based on what label?</p>
<pre><code>... label_key='label', desired_label=1)
</code></pre>
<p><strong>the desired label = 1 for which label in EMNIST?</strong></p>
<p><strong>My Question is:</strong></p>
<p>How can I apply this function tff.simulation.datasets.build_single_label_dataset()
to get non-IID dataset <em><strong>(different number of samples for each client)</strong></em> in this specific tutorial ! <a href=""https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression</a> in details without error regarding the filtered dataset!</p>
<p>Appreciate any help!</p>
<p>Thanks a lot!</p>
",18969005,,,,,44682.61709,AttributeError: 'MapDataset' object has no attribute 'preprocess' in tensorflow_federated tff,<python><tensorflow><google-colaboratory><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
63723006,1,,,44077.49108,,1,183,"<p>How can I easily save a Tensorflow Federated model? (state)</p>
<p>A few months ago I was using this solution after importing <strong>ServerState</strong> and <strong>FileCheckPointManager</strong> and it worked:</p>
<pre><code># Create the checkpoint Manager
ckpt_manager = FileCheckpointManager(root_dir=checkpoint_dir)
# Save checkpoint for round N
ckpt_manager.save_checkpoint(ServerState.from_tff_result(state), round_num=NUM_ROUNDS)
</code></pre>
<p>But now this solution no longer works because <a href=""https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/flars/flars_fedavg.py#L54"" rel=""nofollow noreferrer"">ServerState</a> does not contain <strong><code>from_tff_result</code></strong> methotd anymore.</p>
<pre><code>AttributeError: type object 'ServerState' has no attribute 'from_tff_result'
</code></pre>
<p>Also using the old version of ServerState where the metohd was included i get:</p>
<pre><code>TypeError: Expected tensorflow_federated.python.common_libs.structure.Struct, found tensorflow_federated.python.learning.model_utils.ModelWeights.
</code></pre>
<p>How can I easly save my federated model?</p>
",6941941,,730754,,44163.4544,44163.4544,How to save Tensorflow Federated Model,<python><tensorflow><federated-learning>,1,0,,,,CC BY-SA 4.0
63878853,1,,,44088.25146,,2,146,"<p>I try to train a image classification (cifar10) with pysyft. My trainsetup has 10 workers where every worker gets betwen 800 and 1200 images of the dataset.</p>
<p>My Problem is that after about 250-300 epochs, the train loss is at about 0.005 and the model stops improving though the test accuracy is just at about 45% with an increasing loss 1.5 -&gt; 8.5.
I tried the same with 100 workers on 500 images where it stoped at 32%.
Furthrmore the implementation is part of a comparison between models and FL Frameworks and therefor the model can't be changed and the data will be loaded localy and transformed into a Dataloader.
Hence I'm very unexperienced with Pytorch and PySyft it might be that I made some mistakes when training the model though i tried to stay as close as possible with the example.</p>
<p>I trained the model without PySyft and it reached about 85% so I think my dataloader and model should be not the problem. For me it looks like the workers overfit on their own data during the training.</p>
<p>Is there a way to prevent workers to overfit or calculate a loss for the global model instead of the workers?</p>
<p>Trainer:</p>
<pre class=""lang-py prettyprint-override""><code>    
def fl_train(args, model, device, federated_train_loader, optimizer, epoch, log):
    model.train()
    results = []
    metrics = []
    t1 = time.time()
    cel = nn.CrossEntropyLoss()
    for batch_idx, (data, target) in enumerate(federated_train_loader): # &lt;-- now it is a distributed dataset
        t2 = time.time()
        model.send(data.location) # &lt;-- NEW: send the model to the right location
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target.long())
        loss.backward()
        optimizer.step()
        model.get() # &lt;-- NEW: get the model back
        if batch_idx % args.log_interval == 0:
            loss = loss.get() # &lt;-- NEW: get the loss back
            results.append(loss.item())
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * BATCH_SIZE, len(federated_train_loader) * BATCH_SIZE,
                100. * batch_idx / len(federated_train_loader), loss.item()))
</code></pre>
<p>Model:</p>
<pre><code>class CNN(nn.Module):

    def __init__(self):
        super(CNN, self).__init__()

        self.conv_layer = nn.Sequential(

            # Conv Layer block 1
            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.MaxPool2d((2,2)),

            # Conv Layer block 2
            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),
            nn.ReLU(inplace=True),
            nn.MaxPool2d((2,2)),

            # Conv Layer block 3
            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3),
            nn.ReLU(inplace=True),
        )

        self.fc_layer = nn.Sequential(
            nn.Linear(1024, 64),
            nn.ReLU(inplace=True),
            nn.Linear(64, 10)
        )


    def forward(self, x):
        # CNN layers
        x = self.conv_layer(x)

        # flatten
        x = x.view(-1, 1024)

        # NN layer
        x = self.fc_layer(x)
        return F.log_softmax(x, dim=1)
</code></pre>
<p>Main:</p>
<pre><code>model = CNN().to(device)
optimizer = optim.SGD(model.parameters(), lr=0.02) # TODO momentum is not supported at the moment
log = {}
for epoch in range(1, args.epochs + 1):
    log = fl_train(args, model, device, f_dataloader, optimizer, epoch, log)
    if epoch % 20 == 0:
      log = test(args, model, device, test_loader, epoch, log)
    if epoch % 100 == 0:
      store_results(log, model)
</code></pre>
<p>Log:</p>
<pre><code>....
Train Epoch: 317 [0/10400 (0%)] Loss: 0.005194
Train Epoch: 317 [3000/10400 (29%)] Loss: 0.003882
Train Epoch: 317 [6000/10400 (58%)] Loss: 0.003100
Train Epoch: 317 [9000/10400 (87%)] Loss: 0.004298
Train Epoch: 318 [0/10400 (0%)] Loss: 0.007426
Train Epoch: 318 [3000/10400 (29%)] Loss: 0.002255
Train Epoch: 318 [6000/10400 (58%)] Loss: 0.003835
Train Epoch: 318 [9000/10400 (87%)] Loss: 0.005277
Train Epoch: 319 [0/10400 (0%)] Loss: 0.006207
Train Epoch: 319 [3000/10400 (29%)] Loss: 0.003562
Train Epoch: 319 [6000/10400 (58%)] Loss: 0.001904
Train Epoch: 319 [9000/10400 (87%)] Loss: 0.002644
Train Epoch: 320 [0/10400 (0%)] Loss: 0.007491
Train Epoch: 320 [3000/10400 (29%)] Loss: 0.003794
Train Epoch: 320 [6000/10400 (58%)] Loss: 0.002643
Train Epoch: 320 [9000/10400 (87%)] Loss: 0.002981
Test set: Average loss: 9.1279, Accuracy: 458/1000 (46%)

Train Epoch: 321 [0/10400 (0%)] Loss: 0.007153
Train Epoch: 321 [3000/10400 (29%)] Loss: 0.004265
Train Epoch: 321 [6000/10400 (58%)] Loss: 0.002708
Train Epoch: 321 [9000/10400 (87%)] Loss: 0.002518
Train Epoch: 322 [0/10400 (0%)] Loss: 0.006285
Train Epoch: 322 [3000/10400 (29%)] Loss: 0.002357
Train Epoch: 322 [6000/10400 (58%)] Loss: 0.002465
Train Epoch: 322 [9000/10400 (87%)] Loss: 0.002406
Train Epoch: 323 [0/10400 (0%)] Loss: 0.005361
Train Epoch: 323 [3000/10400 (29%)] Loss: 0.004807
Train Epoch: 323 [6000/10400 (58%)] Loss: 0.001903
Train Epoch: 323 [9000/10400 (87%)] Loss: 0.003711
Train Epoch: 324 [0/10400 (0%)] Loss: 0.006609
....
</code></pre>
",10228129,,730754,,44163.46024,44163.46024,PySyft Worker overfitting,<python><machine-learning><pytorch><federated-learning><pysyft>,0,0,,,,CC BY-SA 4.0
64037971,1,64039982,,44098.01984,,0,591,"<p>I&quot;m looking at converting a dart package (<a href=""https://pub.dev/packages/sounds"" rel=""nofollow noreferrer"">https://pub.dev/packages/sounds</a>) to a federated model using pigeon.</p>
<p>The documentation around combing these two pieces is a little sparse.</p>
<p>Looking at the video_player sample (<a href=""https://github.com/flutter/plugins/tree/master/packages/video_player/video_player_platform_interface"" rel=""nofollow noreferrer"">https://github.com/flutter/plugins/tree/master/packages/video_player/video_player_platform_interface</a>) seems to suggest a federated model as the web platform is separate.</p>
<p>However both the android and ios packages are part of the main package.</p>
<p>Is this just an historical artefact or do the ios and android packages still need to be part of the main plugin?</p>
<p>If they can be separated out what is the correct package(s) structure?</p>
<p>Are then any open source plugins that use pigeon in a fully federated model that could be used as samples?</p>
",8994998,,730754,,44163.45416,44541.66213,Using dart pigeon in a federated model,<dart><plugins><federated-learning>,2,0,,,,CC BY-SA 4.0
64050391,1,,,44098.67729,,3,741,"<p>i can't understand how in function train() below, the variable (data, target) are choosen.</p>
<pre><code>def train(args, model, device, federated_train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(federated_train_loader): # &lt;-- now it is a distributed dataset
        model.send(data.location) # &lt;-- NEW: send the model to the right location`
</code></pre>
<p>i guess they are 2 tensor representing 2 random images of dataset train, but then the loss function</p>
<pre><code>loss = F.nll_loss(output, target)
</code></pre>
<p>is calculated at every interaction with different target?</p>
<p>Also i have different question: i trained the network with images of cats, then i test it with images of cars and the accuracy reached is 97%. How is this possible? is a proper value or i'm doing something wrong?</p>
<p>here is the entire code:</p>
<pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms

import syft as sy  # &lt;-- NEW: import the Pysyft library
hook = sy.TorchHook(torch)  # &lt;-- NEW: hook PyTorch ie add extra functionalities to support Federated Learning
bob = sy.VirtualWorker(hook, id=&quot;bob&quot;)  # &lt;-- NEW: define remote worker bob
alice = sy.VirtualWorker(hook, id=&quot;alice&quot;)  # &lt;-- NEW: and alice

class Arguments():
    def __init__(self):
        self.batch_size = 64
        self.test_batch_size = 1000
        self.epochs = 2
        self.lr = 0.01
        self.momentum = 0.5
        self.no_cuda = False
        self.seed = 1
        self.log_interval = 30
        self.save_model = False

args = Arguments()

use_cuda = not args.no_cuda and torch.cuda.is_available()

torch.manual_seed(args.seed)

device = torch.device(&quot;cuda&quot; if use_cuda else &quot;cpu&quot;)

kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}

federated_train_loader = sy.FederatedDataLoader( # &lt;-- this is now a FederatedDataLoader
    datasets.MNIST(&quot;C:\\users...\\train&quot;, train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((bob, alice)), # &lt;-- NEW: we distribute the dataset across all the workers, it's now a FederatedDataset
    batch_size=args.batch_size, shuffle=True, **kwargs)

test_loader = torch.utils.data.DataLoader(
    datasets.MNIST(&quot;C:\\Users...\\test&quot;, train=False, download=True, transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ])),
    batch_size=args.test_batch_size, shuffle=True, **kwargs)


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5, 1)
        self.conv2 = nn.Conv2d(20, 50, 5, 1)
        self.fc1 = nn.Linear(4*4*50, 500)
        self.fc2 = nn.Linear(500, 10)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2, 2)
        x = x.view(-1, 4*4*50)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)

def train(args, model, device, federated_train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data, target) in enumerate(federated_train_loader): # &lt;-- now it is a distributed dataset
        model.send(data.location) # &lt;-- NEW: send the model to the right location
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        model.get() # &lt;-- NEW: get the model back
        if batch_idx % args.log_interval == 0:
            loss = loss.get() # &lt;-- NEW: get the loss back
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                epoch, batch_idx * args.batch_size, len(federated_train_loader) * args.batch_size,
                100. * batch_idx / len(federated_train_loader), loss.item()))

def test(args, model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss
            pred = output.argmax(1, keepdim=True) # get the index of the max log-probability
            correct += pred.eq(target.view_as(pred)).sum().item()

    test_loss /= len(test_loader.dataset)

    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        100. * correct / len(test_loader.dataset)))


model = Net().to(device)
optimizer = optim.SGD(model.parameters(), lr=args.lr) # TODO momentum is not supported at the moment

for epoch in range(1, args.epochs + 1):
    train(args, model, device, federated_train_loader, optimizer, epoch)
    test(args, model, device, test_loader)

if (args.save_model):
    torch.save(model.state_dict(), &quot;mnist_cnn.pt&quot;)   
</code></pre>
",5736757,,730754,,44163.46547,44991.56067,"how ""data"" and ""target"" are choosen in a federated learning? (PySyft)",<python><pytorch><federated-learning><pysyft>,1,0,,,,CC BY-SA 4.0
64760396,1,64770354,,44144.95304,,4,1267,"<p>I am working on a project with Tensorflow federated. I have managed to use the libraries provided by TensorFlow  Federated Learning simulations in order to load,  train, and test some datasets.</p>
<p>For example, i load the emnist dataset</p>
<pre><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()
</code></pre>
<p>and it got the data sets returned by load_data() as instances of tff.simulation.ClientData. This is an interface that allows me to iterate over client ids and allow me to select subsets of the data for simulations.</p>
<pre><code>len(emnist_train.client_ids)

3383


emnist_train.element_type_structure


OrderedDict([('pixels', TensorSpec(shape=(28, 28), dtype=tf.float32, name=None)), ('label', TensorSpec(shape=(), dtype=tf.int32, name=None))])


example_dataset = emnist_train.create_tf_dataset_for_client(
    emnist_train.client_ids[0])
</code></pre>
<p>I am trying to load the fashion_mnist dataset with Keras to perform some federated operations:</p>
<pre><code>fashion_train,fashion_test=tf.keras.datasets.fashion_mnist.load_data()
</code></pre>
<p>but I get this error</p>
<pre><code>AttributeError: 'tuple' object has no attribute 'element_spec'
</code></pre>
<p>because Keras returns a Tuple of Numpy arrays instead of a tff.simulation.ClientData like before:</p>
<pre><code>def tff_model_fn() -&gt; tff.learning.Model:
    return tff.learning.from_keras_model(
        keras_model=factory.retrieve_model(True),
        input_spec=fashion_test.element_spec,
        loss=loss_builder(),
        metrics=metrics_builder())

iterative_process = tff.learning.build_federated_averaging_process(
    tff_model_fn, Parameters.server_adam_optimizer_fn, Parameters.client_adam_optimizer_fn)
server_state = iterative_process.initialize()
</code></pre>
<p>To sum up,</p>
<ol>
<li><p>Is any way to create tuple elements of <code>tff.simulation.ClientData</code> from Keras Tuple Numpy arrays?</p>
</li>
<li><p>Another solution that comes to my mind is to use the
<code>tff.simulation.HDF5ClientData</code> and load
manually the appropriate files in a<code>HDF5</code>format <code>(train.h5,   test.h5)</code> in order to get the <code>tff.simulation.ClientData</code>, but my problem is that i cant find the url for fashion_mnist  <code>HDF5</code> file format i mean something like that for both train and test:</p>
<pre><code>      fileprefix = 'fed_emnist_digitsonly'
      sha256 = '55333deb8546765427c385710ca5e7301e16f4ed8b60c1dc5ae224b42bd5b14b'
      filename = fileprefix + '.tar.bz2'
      path = tf.keras.utils.get_file(
          filename,
          origin='https://storage.googleapis.com/tff-datasets-public/' + filename,
          file_hash=sha256,
          hash_algorithm='sha256',
          extract=True,
          archive_format='tar',
          cache_dir=cache_dir)

      dir_path = os.path.dirname(path)
      train_client_data = hdf5_client_data.HDF5ClientData(
          os.path.join(dir_path, fileprefix + '_train.h5'))
      test_client_data = hdf5_client_data.HDF5ClientData(
          os.path.join(dir_path, fileprefix + '_test.h5'))

      return train_client_data, test_client_data
</code></pre>
</li>
</ol>
<p>My final goal is to make the fashion_mnist dataset work with the TensorFlow federated learning.</p>
",3163824,,730754,,44163.6865,44163.6865,How to load Fashion MNIST dataset in Tensorflow Fedarated?,<python><tensorflow><keras><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72086887,1,,,44683.53041,,1,125,"<p>I'm testing this tutorial with non-IID distribution for federated learning: <a href=""https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression</a>, and using <code>tff.simulation.datasets.build_single_label_dataset()</code> as a way to produce a non-IID distribution for the dataset.</p>
<p>But I faced an error regarding keras values in the <code>input_spec</code>.</p>
<p>The code:</p>
<pre><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(
    only_digits=False)

emnist_train1 = tff.simulation.datasets.build_single_label_dataset(
  emnist_train.create_tf_dataset_from_all_clients(),
  label_key='label', desired_label=1)

MAX_CLIENT_DATASET_SIZE = 418

CLIENT_EPOCHS_PER_ROUND = 1
CLIENT_BATCH_SIZE = 20
TEST_BATCH_SIZE = 500

def reshape_emnist_element(element):
  return (tf.expand_dims(element['pixels'], axis=-1), element['label'])

def preprocess_train_dataset(dataset):
  return (dataset
          .shuffle(buffer_size=MAX_CLIENT_DATASET_SIZE)
          .repeat(CLIENT_EPOCHS_PER_ROUND)
          .batch(CLIENT_BATCH_SIZE, drop_remainder=False)
          .map(reshape_emnist_element))

emnist_train1 = preprocess_train_dataset(emnist_train1)

import random
NUM_CLIENTS = 100

client_datasets = [
   emnist_train1.take(random.randint(1, CLIENT_BATCH_SIZE))
   for _ in range(NUM_CLIENTS)
]

emnist_train1 = client_datasets

def create_original_fedavg_cnn_model(only_digits=True):
  &quot;&quot;&quot;The CNN model used in https://arxiv.org/abs/1602.05629.&quot;&quot;&quot;
  data_format = 'channels_last'

  max_pool = functools.partial(
      tf.keras.layers.MaxPooling2D,
      pool_size=(2, 2),
      padding='same',
      data_format=data_format)
  conv2d = functools.partial(
      tf.keras.layers.Conv2D,
      kernel_size=5,
      padding='same',
      data_format=data_format,
      activation=tf.nn.relu)

  model = tf.keras.models.Sequential([
      tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),
      conv2d(filters=32),
      max_pool(),
      conv2d(filters=64),
      max_pool(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(512, activation=tf.nn.relu),
      tf.keras.layers.Dense(10 if only_digits else 62),
      tf.keras.layers.Softmax(),
  ])

  return model

input_spec = emnist_train.create_tf_dataset_for_client(
    emnist_train.client_ids[0]).element_spec

def tff_model_fn():
  keras_model = create_original_fedavg_cnn_model()
  return tff.learning.from_keras_model(
      keras_model=keras_model,
      input_spec=input_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

federated_averaging = tff.learning.build_federated_averaging_process(
    model_fn=tff_model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-11-7661a3b7dc92&gt; in &lt;module&gt;()
      3     model_fn=tff_model_fn,
      4     client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
----&gt; 5     server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

6 frames
/usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/learning/keras_utils.py in from_keras_model(keras_model, loss, input_spec, loss_weights, metrics)
    176           'The `input_spec` is a collections.abc.Mapping (e.g., a dict), so it '
    177           'must contain an entry with key `\'{}\'`, representing the input(s) '
--&gt; 178           'to the Keras model.'.format(model_lib.MODEL_ARG_NAME))
    179     if model_lib.MODEL_LABEL_NAME not in input_spec:
    180       raise ValueError(
</code></pre>
<blockquote>
<p>ValueError: The <code>input_spec</code> is a collections.abc.Mapping (e.g., a dict), so it must contain an entry with key <code>'x'</code>, representing the input(s) to the Keras model.</p>
</blockquote>
<p>What does that mean? How can I solve it?</p>
",18969005,,4621513,,44683.65646,44683.65646,"ValueError: The `input_spec` is a collections.abc.Mapping (e.g., a dict), so it must contain an entry with key `'x'`, representing the input(s)",<python><keras><google-colaboratory><tensorflow-federated><federated-learning>,0,1,,,,CC BY-SA 4.0
72121192,1,,,44686.09213,,0,274,"<p>I tried to implement federated learning. (Using TensorFlow federated core)</p>
<pre><code>def create_keras_model():
    model = Sequential()
    model.add(Conv2D(16, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(226,232,1)))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    
    model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    
    model.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    
    model.add(Flatten())

    model.add(Dense(128, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(10, activation='softmax'))
    return model



def model_fn():
      keras_model = create_keras_model()
      return tff.learning.from_keras_model(
          keras_model,
          input_spec=federated_train_data[0].element_spec,
          loss=tf.keras.losses.SparseCategoricalCrossentropy(),
          metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

def initialize_fn():
  model = model_fn()
  return model.trainable_variables

def next_fn(server_weights, federated_dataset):
  # Broadcast the server weights to the clients.
  server_weights_at_client = broadcast(server_weights)

  # Each client computes their updated weights.
  client_weights = client_update(federated_dataset, server_weights_at_client)

  # The server averages these updates.
  mean_client_weights = mean(client_weights)

  # The server updates its model.
  server_weights = server_update(mean_client_weights)

  return server_weights


@tf.function
def client_update(model, dataset, server_weights, client_optimizer):
  &quot;&quot;&quot;Performs training (using the server model weights) on the client's dataset.&quot;&quot;&quot;
  # Initialize the client model with the current server weights.
  client_weights = model.trainable_variables
  # Assign the server weights to the client model.
  tf.nest.map_structure(lambda x, y: x.assign(y),
                        client_weights, server_weights)

  # Use the client_optimizer to update the local model.
  for batch in dataset:
    with tf.GradientTape() as tape:
      # Compute a forward pass on the batch of data
      outputs = model.forward_pass(batch)

    # Compute the corresponding gradient
    grads = tape.gradient(outputs.loss, client_weights)
    grads_and_vars = zip(grads, client_weights)

    # Apply the gradient using a client optimizer.
    client_optimizer.apply_gradients(grads_and_vars)

  return client_weights

@tf.function
def server_update(model, mean_client_weights):
  &quot;&quot;&quot;Updates the server model weights as the average of the client model weights.&quot;&quot;&quot;
  model_weights = model.trainable_variables
  # Assign the mean client weights to the server model.
  tf.nest.map_structure(lambda x, y: x.assign(y),
                        model_weights, mean_client_weights)
  return model_weights

@tff.federated_computation(tff.FederatedType(tf.float32, tff.CLIENTS))
def get_average_temperature(client_temperatures):
  return tff.federated_mean(client_temperatures)

@tff.tf_computation(tf.float32)
def add_half(x):
  return tf.add(x, 0.5)


@tff.federated_computation(tff.FederatedType(tf.float32, tff.CLIENTS))
def add_half_on_clients(x):
  return tff.federated_map(add_half, x)


@tff.tf_computation
def server_init():
  model = model_fn()
  return model.trainable_variables


@tff.federated_computation
def initialize_fn():
  return tff.federated_value(server_init(), tff.SERVER)


whimsy_model = model_fn()
tf_dataset_type = tff.SequenceType(whimsy_model.input_spec)


model_weights_type = server_init.type_signature.result


@tff.tf_computation(tf_dataset_type, model_weights_type)
def client_update_fn(tf_dataset, server_weights):
  model = model_fn()
  client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)
  return client_update(model, tf_dataset, server_weights, client_optimizer)


@tff.tf_computation(model_weights_type)
def server_update_fn(mean_client_weights):
  model = model_fn()
  return server_update(model, mean_client_weights)


federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)
federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)

@tff.federated_computation(federated_server_type, federated_dataset_type)
def next_fn(server_weights, federated_dataset):
  # Broadcast the server weights to the clients.
  server_weights_at_client = tff.federated_broadcast(server_weights)

  # Each client computes their updated weights.
  client_weights = tff.federated_map(
      client_update_fn, (federated_dataset, server_weights_at_client))

  # The server averages these updates.
  mean_client_weights = tff.federated_mean(client_weights)

  # The server updates its model.
  server_weights = tff.federated_map(server_update_fn, mean_client_weights)

  return server_weights,client_weights


federated_algorithm = tff.templates.IterativeProcess(
    initialize_fn=initialize_fn,
    next_fn=next_fn
)


server_state = federated_algorithm.initialize()
</code></pre>
<p>and save server_state (weights) after each round:</p>
<pre><code>for round in range(3,15):
  server_state,client_weights = federated_algorithm.next(server_state, federated_train_data)
  FileCheckpointManager(root_dir= '/content/drive/MyDrive',prefix='fed_per_',step= 1,keep_total= 1,keep_first= True).save_checkpoint(state=server_state,round_num=round)
</code></pre>
<p>now I want to use this pre_trained model for a new federated learning case where the weights of the CNN layer are fixed and only the weights of the 3 last layers are changed.</p>
<p>could someone help me with how I can do this?</p>
",17945316,,,,,44686.31314,How can I use transfer learning in federated learning?,<python><tensorflow><transfer-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72146421,1,,,44687.8049,,2,525,"<p>I'm trying to test a compression technique in federated learning with <strong>non-IID</strong> using this API tff.simulation.datasets.build_single_label_dataset(), following these posts:</p>
<ul>
<li><a href=""https://stackoverflow.com/questions/64970504/tensorflow-federated-how-to-tune-non-iidness-in-federated-dataset"">TensorFlow Federated: How to tune non-IIDness in federated dataset?</a></li>
<li><a href=""https://stackoverflow.com/questions/72076723/attributeerror-mapdataset-object-has-no-attribute-preprocess-in-tensorflow/72077739#72077739"">AttributeError: &#39;MapDataset&#39; object has no attribute &#39;preprocess&#39; in tensorflow_federated tff</a></li>
</ul>
<p>But after defining the model and training it, I got <strong>this error</strong> :</p>
<pre><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-16-b04459984716&gt; in &lt;module&gt;()
     10 
     11 train(federated_averaging_process=federated_averaging, num_rounds=10,
---&gt; 12       num_clients_per_round=NUM_CLIENTS, summary_writer=summary_writer)

&lt;ipython-input-15-7157bce2bb0f&gt; in train(federated_averaging_process, num_rounds, num_clients_per_round, summary_writer)
     11       # sample the clients parcitipated in this round.
     12       sampled_clients = np.random.choice(
---&gt; 13           fed_emnist_train.client_ids,
     14           size=num_clients_per_round,
     15           replace=False)

AttributeError: 'MapDataset' object has no attribute 'client_ids'
</code></pre>
<p><strong>The code:</strong></p>
<pre><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(
    only_digits=False)

# for non-IID we use this API tff.simulation.datasets.build_single_label_dataset()
fed_emnist_train = tff.simulation.datasets.build_single_label_dataset(
  emnist_train.create_tf_dataset_from_all_clients(),
  label_key='label', desired_label=1)

MAX_CLIENT_DATASET_SIZE = 418

CLIENT_EPOCHS_PER_ROUND = 1
CLIENT_BATCH_SIZE = 20
TEST_BATCH_SIZE = 500

def reshape_emnist_element(element):
  return (tf.expand_dims(element['pixels'], axis=-1), element['label'])

def preprocess_train_dataset(dataset):
  return (dataset
          .shuffle(buffer_size=MAX_CLIENT_DATASET_SIZE)
          .repeat(CLIENT_EPOCHS_PER_ROUND)
          .batch(CLIENT_BATCH_SIZE, drop_remainder=False)
          .map(reshape_emnist_element))

fed_emnist_train = preprocess_train_dataset(fed_emnist_train)

# for unbalanced dataset
import random
NUM_CLIENTS = 100

client_datasets = [
   fed_emnist_train.take(random.randint(1, CLIENT_BATCH_SIZE))
   for _ in range(NUM_CLIENTS)
]

# defining a model 
def create_original_fedavg_cnn_model(only_digits=False):
  data_format = 'channels_last'

  max_pool = functools.partial(
      tf.keras.layers.MaxPooling2D,
      pool_size=(2, 2),
      padding='same',
      data_format=data_format)
  conv2d = functools.partial(
      tf.keras.layers.Conv2D,
      kernel_size=5,
      padding='same',
      data_format=data_format,
      activation=tf.nn.relu)

  model = tf.keras.models.Sequential([
      tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),
      conv2d(filters=32),
      max_pool(),
      conv2d(filters=64),
      max_pool(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(512, activation=tf.nn.relu),
      tf.keras.layers.Dense(10 if only_digits else 62),
      tf.keras.layers.Softmax(),
  ])

  return model

input_spec = client_datasets[0].element_spec

def tff_model_fn():
  keras_model = create_original_fedavg_cnn_model()
  return tff.learning.from_keras_model(
      keras_model=keras_model,
      input_spec=input_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

# training the model 
federated_averaging = tff.learning.build_federated_averaging_process(
    model_fn=tff_model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

# utility function
def format_size(size):
  size = float(size)
  for unit in ['bit','Kibit','Mibit','Gibit']:
    if size &lt; 1024.0:
      return &quot;{size:3.2f}{unit}&quot;.format(size=size, unit=unit)
    size /= 1024.0
  return &quot;{size:.2f}{unit}&quot;.format(size=size, unit='TiB')

def set_sizing_environment():
  sizing_factory = tff.framework.sizing_executor_factory()
  context = tff.framework.ExecutionContext(executor_fn=sizing_factory)
  tff.framework.set_default_context(context)

  return sizing_factory

# trains the federated averaging process and output metrics
def train(federated_averaging_process, num_rounds, num_clients_per_round, summary_writer):
  # create a environment to get communication cost
  environment = set_sizing_environment()

  # initialize the FedAvg algorithm to get the initial server state
  state = federated_averaging_process.initialize()

  with summary_writer.as_default():
    for round_num in range(num_rounds):
      # sample the clients parcitipated in this round.
      sampled_clients = np.random.choice(
          fed_emnist_train.client_ids,
          size=num_clients_per_round,
          replace=False)
      # create a list of `tf.Dataset` instances from the data of sampled clients
      sampled_train_data = [
          fed_emnist_train.create_tf_dataset_for_client(client)
          for client in sampled_clients
      ]
      
      state, metrics = federated_averaging_process.next(state, sampled_train_data)

      size_info = environment.get_size_info()
      broadcasted_bits = size_info.broadcast_bits[-1]
      aggregated_bits = size_info.aggregate_bits[-1]

      print('round {:2d}, metrics={}, broadcasted_bits={}, aggregated_bits={}'.format(round_num, metrics, format_size(broadcasted_bits), format_size(aggregated_bits)))

      # add metrics to Tensorboard
      for name, value in metrics['train'].items():
          tf.summary.scalar(name, value, step=round_num)

      tf.summary.scalar('cumulative_broadcasted_bits', broadcasted_bits, step=round_num)
      tf.summary.scalar('cumulative_aggregated_bits', aggregated_bits, step=round_num)
      summary_writer.flush()

# first, clean the log directory to avoid conflicts
try:
  tf.io.gfile.rmtree('/tmp/logs/scalars')
except tf.errors.OpError as e:
  pass 

# set up the log directory and writer for Tensorboard.
logdir = &quot;/tmp/logs/scalars/original/&quot;
summary_writer = tf.summary.create_file_writer(logdir)

train(federated_averaging_process=federated_averaging, num_rounds=10,
      num_clients_per_round=NUM_CLIENTS, summary_writer=summary_writer)

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-16-b04459984716&gt; in &lt;module&gt;()
     10 
     11 train(federated_averaging_process=federated_averaging, num_rounds=10,
---&gt; 12       num_clients_per_round=NUM_CLIENTS, summary_writer=summary_writer)

&lt;ipython-input-15-7157bce2bb0f&gt; in train(federated_averaging_process, num_rounds, num_clients_per_round, summary_writer)
     11       # sample the clients parcitipated in this round.
     12       sampled_clients = np.random.choice(
---&gt; 13           fed_emnist_train.client_ids,
     14           size=num_clients_per_round,
     15           replace=False)

AttributeError: 'MapDataset' object has no attribute 'client_ids'
</code></pre>
<p><strong>What does that mean?
Appreciate any help!</strong></p>
",18969005,,18969005,,44687.91807,44688.5231,AttributeError: 'MapDataset' object has no attribute 'client_ids' in tensorflow_federated TFF,<python><tensorflow><google-colaboratory><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72179718,1,72190334,,44691.05253,,3,555,"<p>I'm trying to test this tutorial <a href=""https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression</a> with <strong>CIFAR100 dataset</strong>, but the <strong>accuracy</strong> is <strong>dropping</strong> each round!</p>
<p><strong>Does my tuning for the hyper parameter is the reason??</strong></p>
<p>Here is my code:</p>
<pre><code>cifar_train, cifar_test = tff.simulation.datasets.cifar100.load_data()

MAX_CLIENT_DATASET_SIZE = 418

CLIENT_EPOCHS_PER_ROUND = 1
CLIENT_BATCH_SIZE = 20
TEST_BATCH_SIZE = 500

def reshape_cifar_element(element):
  return (tf.expand_dims(element['image'], axis=-1), element['label'])

def preprocess_train_dataset(dataset):
  &quot;&quot;&quot;Preprocessing function for the EMNIST training dataset.&quot;&quot;&quot;
  return (dataset
          # Shuffle according to the largest client dataset
          .shuffle(buffer_size=MAX_CLIENT_DATASET_SIZE)
          # Repeat to do multiple local epochs
          .repeat(CLIENT_EPOCHS_PER_ROUND)
          # Batch to a fixed client batch size
          .batch(CLIENT_BATCH_SIZE, drop_remainder=False)
          # Preprocessing step
          .map(reshape_cifar_element))

cifar_train = cifar_train.preprocess(preprocess_train_dataset)

# defining a model 
def create_original_fedavg_cnn_model():
  data_format = 'channels_last'

  max_pool = functools.partial(
      tf.keras.layers.MaxPooling2D,
      pool_size=(2, 2),
      padding='same',
      data_format=data_format)
  conv2d = functools.partial(
      tf.keras.layers.Conv2D,
      kernel_size=5,
      padding='same',
      data_format=data_format,
      activation=tf.nn.relu)

  model = tf.keras.models.Sequential([
      tf.keras.layers.InputLayer(input_shape=(32, 32, 3)),
      conv2d(filters=32),
      max_pool(),
      conv2d(filters=64),
      max_pool(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(512, activation=tf.nn.relu),
      tf.keras.layers.Dense(100, activation=None),
      tf.keras.layers.Softmax(),
  ])
  return model

input_spec = cifar_train.create_tf_dataset_for_client(
    cifar_train.client_ids[0]).element_spec

def tff_model_fn():
  keras_model = create_original_fedavg_cnn_model()
  return tff.learning.from_keras_model(
      keras_model=keras_model,
      input_spec=input_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

# training the model 
federated_averaging = tff.learning.build_federated_averaging_process(
    model_fn=tff_model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.05),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

# utility function
def format_size(size):
  size = float(size)
  for unit in ['bit','Kibit','Mibit','Gibit']:
    if size &lt; 1024.0:
      return &quot;{size:3.2f}{unit}&quot;.format(size=size, unit=unit)
    size /= 1024.0
  return &quot;{size:.2f}{unit}&quot;.format(size=size, unit='TiB')

def set_sizing_environment():
  sizing_factory = tff.framework.sizing_executor_factory()
  context = tff.framework.ExecutionContext(executor_fn=sizing_factory)
  tff.framework.set_default_context(context)

  return sizing_factory

def train(federated_averaging_process, num_rounds, num_clients_per_round, summary_writer):
  environment = set_sizing_environment()

  # Initialize the Federated Averaging algorithm to get the initial server state.
  state = federated_averaging_process.initialize()

  with summary_writer.as_default():
    for round_num in range(num_rounds):
      # Sample the clients parcitipated in this round.
      sampled_clients = np.random.choice(
          cifar_train.client_ids,
          size=num_clients_per_round,
          replace=False)
      # Create a list of `tf.Dataset` instances from the data of sampled clients.
      sampled_train_data = [
          cifar_train.create_tf_dataset_for_client(client)
          for client in sampled_clients
      ]
      state, metrics = federated_averaging_process.next(state, sampled_train_data)

      size_info = environment.get_size_info()
      broadcasted_bits = size_info.broadcast_bits[-1]
      aggregated_bits = size_info.aggregate_bits[-1]

      print('round {:2d}, metrics={}, broadcasted_bits={}, aggregated_bits={}'.format(round_num, metrics, format_size(broadcasted_bits), format_size(aggregated_bits)))

      # Add metrics to Tensorboard.
      for name, value in metrics['train'].items():
          tf.summary.scalar(name, value, step=round_num)

      # Add broadcasted and aggregated data size to Tensorboard.
      tf.summary.scalar('cumulative_broadcasted_bits', broadcasted_bits, step=round_num)
      tf.summary.scalar('cumulative_aggregated_bits', aggregated_bits, step=round_num)
      summary_writer.flush()

# Clean the log directory to avoid conflicts.
try:
  tf.io.gfile.rmtree('/tmp/logs/scalars')
except tf.errors.OpError as e:
  pass  # Path doesn't exist

# Set up the log directory and writer for Tensorboard.
logdir = &quot;/tmp/logs/scalars/original/&quot;
summary_writer = tf.summary.create_file_writer(logdir)

train(federated_averaging_process=federated_averaging, num_rounds=10,
      num_clients_per_round=100, summary_writer=summary_writer)
</code></pre>
<p>And this is the output:</p>
<pre><code>round  0, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0299), ('loss', 15.586388), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=6.56Gibit, aggregated_bits=6.56Gibit
round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0046), ('loss', 16.042076), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=13.13Gibit, aggregated_bits=13.13Gibit
round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0107), ('loss', 15.945647), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=19.69Gibit, aggregated_bits=19.69Gibit
round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0104), ('loss', 15.950482), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=26.26Gibit, aggregated_bits=26.26Gibit
round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0115), ('loss', 15.932754), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=32.82Gibit, aggregated_bits=32.82Gibit
round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0111), ('loss', 15.9391985), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=39.39Gibit, aggregated_bits=39.39Gibit
round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0112), ('loss', 15.937586), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=45.95Gibit, aggregated_bits=45.95Gibit
round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.012), ('loss', 15.924692), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=52.52Gibit, aggregated_bits=52.52Gibit
round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0105), ('loss', 15.948869), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=59.08Gibit, aggregated_bits=59.08Gibit
round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0096), ('loss', 15.963377), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=65.64Gibit, aggregated_bits=65.64Gibit
</code></pre>
<p>Here is the input structure:</p>
<pre><code>OrderedDict([('coarse_label', TensorSpec(shape=(), dtype=tf.int64, name=None)), ('image', TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name=None)), ('label', TensorSpec(shape=(), dtype=tf.int64, name=None))])
</code></pre>
<p>I don't know where is my mistake!</p>
<ul>
<li><p><strong>Are the hyper parameter that are defined in the layers in create_original_fedavg_cnn_model() wrong? or in preprocess_train_dataset()?</strong></p>
</li>
<li><p><strong>How to tune the parameters for the same tutorial for CIFAR100 dataset?</strong></p>
</li>
</ul>
<p>Appreciate any help! Thanks.</p>
",18969005,,,,,44691.70779,How to tune hyper parameters for CIFAR100 in tensorflow_federated TFF without dropping in the accuracy?,<python><tensorflow><google-colaboratory><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72263736,1,,,44697.75595,,2,2135,"<p>I try to install tensorflow federated.</p>
<pre><code>pip install --quiet --upgrade tensorflow_federated_nightly
</code></pre>
<p>but when I want to import tensorflow federated, I get this warning and after that google colab notebook is restarted.</p>
<pre><code>WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.
</code></pre>
<p>Also, I try install tensorflow federated as this way:</p>
<pre><code>pip install --quiet --upgrade tensorflow_federated
</code></pre>
<p>but get error when import tensorflow federated</p>
<pre><code>TypeError: 'type' object is not subscriptable
</code></pre>
<p>how do I fix it?</p>
",19129842,,19129842,,44698.80554,44702.02828,Cant to install tensorflow_federated,<python><tensorflow><google-colaboratory><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72335489,1,,,44703.29574,,2,120,"<p>I want to use pre_trained model in federated learning as following code:</p>
<p>first I build my model and set the weights on model and then I freeze convolutional layers and remove 4 last layer.</p>
<pre><code>def create_keras_model():
    model = Sequential()
    model.add(Conv2D(16, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(226,232,1)))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Flatten())
    model.add(Dense(256, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(10, activation='softmax'))
    return model

keras_model = create_keras_model()

server_state=FileCheckpointManager(root_dir= '/content/drive/MyDrive',
    prefix=  'federated_clustering',
    step= 1,
    keep_total= 1,
    keep_first= True).load_checkpoint(structure=server_state,round_num=10)

keras_model.set_weights(server_state)

for layer in keras_model.layers[:-4]:
  layer.trainable = False

model_pre = Model(inputs=keras_model.input,outputs=keras_model.layers[14].output)
</code></pre>
<p>next, I build new model.</p>
<pre><code>def create_keras_model1():
    model = Sequential()
    model.add(model_pre)
    model.add(Dense(256, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(2, activation='softmax'))
    return model

def model_fn():
  # We _must_ create a new model here, and _not_ capture it from an external
  # scope. TFF will call this within different graph contexts.
  keras_model = create_keras_model1()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=preprocessed_example_dataset.element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>but I get ValueError when I want to use tff.learning.build_federated_averaging_process.</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.001),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

ValueError: Your Layer or Model is in an invalid state. This can happen for the following cases:
 1. You might be interleaving estimator/non-estimator models or interleaving models/layers made in tf.compat.v1.Graph.as_default() with models/layers created outside of it. Converting a model to an estimator (via model_to_estimator) invalidates all models/layers made before the conversion (even if they were not the model converted to an estimator). Similarly, making a layer or a model inside a a tf.compat.v1.Graph invalidates all layers/models you previously made outside of the graph.
2. You might be using a custom keras layer implementation with  custom __init__ which didn't call super().__init__.  Please check the implementation of &lt;class 'keras.engine.functional.Functional'&gt; and its bases.
</code></pre>
<p>please help me to fix it.</p>
",19129842,,19129842,,44703.52468,44704.39737,Get ValueError when apply transfer learning in federated learning (TFF),<python><tensorflow><transfer-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72467705,1,72493791,,44713.8535,,2,365,"<p>I am applying federated learning on multiple files using Tensoflow Federated. The problem is, that the size of data (number of records) in each file is different.</p>
<ol>
<li>Is it a problem in federated learning training to have different sizes for each client? if there is how can I overcome it?</li>
<li>Is there a way that I can see how each client performing while federated computation training?</li>
</ol>
<p><a href=""https://i.sstatic.net/2wRQb.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/2wRQb.png"" alt=""The chart describing the variety of number of records in each client"" /></a></p>
",18358769,,,,,45593.6127,Unbalanced client size in federated learning,<tensorflow><tensorflow-federated><federated-learning>,2,0,,,,CC BY-SA 4.0
72556795,1,72574434,,44721.33969,,1,166,"<p>I was following this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">Image classification tutorial</a> and <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation"" rel=""nofollow noreferrer"">Text Generation tutorial</a>. So I've implemented transfer learning with fine-tuning on my dataset but I don't know how to access labels whenever I am doing predictions.
I transformed my data into the right shape (tf.data.Dataset) so I am using the Keras model for predictions. So for example if I want just to predict one label: <code>keras_model.predict(federated_train_data[0]) </code></p>
<p>federated_train_data consists of following elements:</p>
<pre><code>(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None),
 TensorSpec(shape=(None,), dtype=tf.int64, name=None))
</code></pre>
<p>First Tensor is an image shape and the second one represents encoded labels.</p>
<p>My goal is to illustrate what are true and predicted labels of an image, for example:(<a href=""https://i.sstatic.net/p5KwL.png"" rel=""nofollow noreferrer"">Predicted classes</a>)</p>
<p>TLDR: Is there a way that you can access just labels when you have tf.data.Dataset?</p>
",11776320,,11776320,,44721.67502,44722.52637,How to access labels with TFF,<python-3.x><tensorflow><tensorflow-federated><federated-learning><federated>,1,1,,,,CC BY-SA 4.0
72558094,1,,,44721.40541,,1,50,"<p>for some day's now I try to implement gradient boosted tree's with flwr.
I tried the example given by <a href=""https://github.com/adap/flower/tree/main/examples/sklearn-logreg-mnist"" rel=""nofollow noreferrer"">flwr</a>.
They use a LogisticRegression Model for the classification of MNIST, which works in my setup.</p>
<p>This is where my problem arise:
Simply replacing the sklear.linear_model.LogisticRegression model with the <code>sklearn.ensemble.GradientBoostingClassifier</code> does not work because:</p>
<p>I don't know which values I have to initalize, which are equivalent to the <code>LogistiRegression.coef_</code>. Does anyone has an idea?</p>
<p>If I could make a working version I would try to add it to flwr as reference for anybody.</p>
<p>Thanks in advance</p>
",19305581,,,,,44721.40541,[flwr][sklearn] Trying to use Gradient Boosted Trees,<python><machine-learning><scikit-learn><federated-learning>,0,0,,,,CC BY-SA 4.0
72584612,1,,,44723.5485,,0,1275,"<p>I was trying to use <code>kubeFate</code> with version <code>1.3.0</code> but after I applied the service with its original file as <code>kubectl apply -f ./kubefate.yaml</code>, it pops out the error saying</p>
<pre><code>Error from server (NotFound): Unable to list &quot;extensions/v1beta1, Resource=ingresses&quot;: the server could not find the requested resource (get ingresses.extensions)
</code></pre>
<p>Initially I looked into the <code>kubefate.yaml</code> and changed anything related to <code>extensions/v1beta1</code> in the ingress part as:</p>
<pre><code>apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
   name: kubefate
   namespace: kube-fate
spec:
  ingressClassName: nginx
  rules:
    - host: kubefate.net
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                 name: kubefate
                 port:
                   number: 8080
</code></pre>
<p>Well, after changed, it does not generate the error when I apply but after I use <code>kubectl get all,ingress -n kube-fate</code> to check out the status, the same error shows again...
I have no clue how to solve this. Please someone give me some hint.</p>
",16303646,,,,,44723.56318,"unable to list ""extensions/v1beta1, resource=ingresses",<yaml><kubernetes-ingress><minikube><federated-learning>,1,0,,,,CC BY-SA 4.0
72652038,1,72981298,,44728.89176,,1,367,"<p>I am training a tensorflow federated learning model. I cannot see the output of epochs. Details are as follows:</p>
<pre><code>split = 4
NUM_ROUNDS = 5
NUM_EPOCHS = 10
BATCH_SIZE = 2
PREFETCH_BUFFER = 5
</code></pre>
<pre class=""lang-py prettyprint-override""><code>
for round_num in range(1, NUM_ROUNDS+1):
    state, tff_metrics = iterative_process.next(state, federated_train_data) 
    print('round {:2d}, metrics{}'.format(round_num,tff_metrics['train'].items()))
    
    eval_model = create_keras_model()
    eval_model.compile(optimizer=optimizers.Adam(learning_rate=client_lr),
                       loss=losses.BinaryCrossentropy(),
                       metrics=[tf.keras.metrics.Accuracy()])
    
    #tff.learning.assign_weights_to_keras_model(eval_model, state.model)
    state.model.assign_weights_to(eval_model)
    
    ev_result = eval_model.evaluate(x_val, y_val, verbose=2)
    train_metrics = tff_metrics['train']
      for name, value in tff_metrics['train'].items():
            tf.summary.scalar(name,value, step=round_num)
    
    tff_val_acc.append(ev_result[1])
    tff_val_loss.append(ev_result[0])
</code></pre>
<p>And my output looks as follows:</p>
<pre><code>
    round  1, metrics=odict_items([('accuracy', 0.0), ('loss', 1.2104079)])
    1/1 - 1s - loss: 0.7230 - accuracy: 0.0000e+00 - 1s/epoch - 1s/step
    round  2, metrics=odict_items([('accuracy', 0.0007142857), ('loss', 1.2233553)])
    1/1 - 1s - loss: 0.6764 - accuracy: 0.0000e+00  - 646ms/epoch - 646ms/step
    round  3, metrics=odict_items([('accuracy', 0.0),  ('loss', 1.1939998)])
    1/1 - 1s - loss: 0.6831 - accuracy: 0.0000e+00  - 635ms/epoch - 635ms/step
    round  4, metrics=odict_items([('accuracy', 0.0), ('loss', 1.2829995)])
    1/1 - 1s - loss: 0.6830 - accuracy: 0.0000e+00  - 641ms/epoch - 641ms/step
    round  5, metrics=odict_items([('accuracy', 0.0),  ('loss', 1.2051892)])
    1/1 - 1s - loss: 0.7135 - accuracy: 0.0000e+00 - 621ms/epoch - 621ms/step

</code></pre>
<p>Are these values for global model after each round? How can I plot the curves for validation accuracy of the global model for the 100 epochs (10 rounds, 10 local epochs per round)? (Not in tensorboard)</p>
",10543101,,,,,44756.55963,Why can't I see the local epochs output when training tensorflow federated learning model?,<python-3.x><tensorflow2.0><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72698170,1,72698704,,44733.38506,,-3,733,"<p>I am getting the following error related to this function definition what is wrong?</p>
<p>Convert_to_client_data() is a function in federated learning where I am trying to convert a dataset into the federated dataset.</p>
<p>Here is the declaration of the class Distribute which is used in the function which gives the error</p>
<p>#Declaration of Class Distribute</p>
<pre><code>def partition_list (list_in, n):
    random.shuffle(list_in)
    return [list_in[i::n] for i in range(n)]

class Distribute:
    def __init__(self, data, data_type):

        self.data = data
        self.data_type = data_type.lower()
        self.selected_feature = -1
        self.type = 'iid'
        self.client_no = 10
        self.data_sample_fraction = 0.1
        self.min_user_number = 10
        self.max_user_number = 20
        self.train_data_fraction = 0.9
        self.random_sampling_seed = 4
        self.random_split_seed = 1
        self.split_type = 'sample'

    def __shuffle(self, data, label):
        random.Random(self.random_sampling_seed).shuffle(data)

    def _iid_no_clint(self):
        size = random.randrange(2, len(self.data))
        self.__shuffle(self.data)

        glist = []
        group_size = int(len(self.data) / size)
        for i in range(size):
            glist.append(self.data[group_size * i: group_size * (i + 1)])

        return glist

    def _iid_clint(self, number_of_clients):

        self.__shuffle(self.data)

        glist = []
        group_size = int(len(self.data) / number_of_clients)

        for i in range(number_of_clients):
            glist.append(self.data[group_size * i: group_size * (i + 1)])

        return glist

    def _iid(self, **kwargs):
        number_of_clients = kwargs.get('number_of_clients')
        if number_of_clients:
            return self._iid_clint(number_of_clients)
        else:
            return self._iid_no_clint()

    def _niid(self, **kwargs):

        selected_feature = kwargs.get('selected_feature', self.selected_feature)
        min_user_number = kwargs.get('min_user_number', self.min_user_number)
        max_user_number = kwargs.get('max_user_number', self.max_user_number)
        number_of_clients = kwargs.get('number_of_clients')

        data_type = kwargs.get('data_type')

        if data_type == 'image':
            if number_of_clients:
                if number_of_clients &gt; len(self.data):
                    raise ValueError('Total number of data:', len(self.data),
                                     'is less than total number of clients specified:', number_of_clients)
                else:
                    data = self.__select_feature_image_client(number_of_clients)
            else:
                data = self.__select_feature_image_no_client(min_user_number, max_user_number)

        elif data_type == 'text':
            if number_of_clients:
                if number_of_clients &gt; len(self.data):
                    raise ValueError('Total number of data:', len(self.data),
                                     'is less than total number of clients specified:', number_of_clients)
                else:
                    data = self.__select_feature_text_client(number_of_clients)
            else:
                data = self.__select_feature_text_no_client(min_user_number, max_user_number)

        elif data_type == 'csv':
            if number_of_clients:
                if number_of_clients &gt; len(self.data):
                    raise ValueError('Total number of data:', len(self.data),
                                     'is less than total number of clients specified:', number_of_clients)
                else:
                    data = self.__select_feature_csv_client(number_of_clients)
            else:
                data = self.__select_feature_csv_no_client(min_user_number, max_user_number)
        else:
            raise ValueError(
                f'Given data type: &quot;{data_type}&quot; is not correct, choose between options &quot;text&quot; or &quot;image&quot;.')

        return data

    def distribute_data(self, **kwargs):
        if kwargs.get('dist_type', self.type) == 'iid':
            return self._iid(**kwargs)
        else:
            return self._niid(**kwargs)

    def __select_feature_image_no_client(self, min_user_number, max_user_number):

        client_size = random.randint(min_user_number, max_user_number)
        grouped_data = partition_list (self.data, client_size)

        return grouped_data

    def __select_feature_image_client(self, number_of_clients):

        grouped_data = np.array_split(self.data, number_of_clients)

        return grouped_data

    def __select_feature_text_no_client(self, min_user_number, max_user_number):

        client_size = random.randint(min_user_number, max_user_number)
        grouped_data = partition_list (self.data, client_size)

        return grouped_data

    def __select_feature_text_client(self, number_of_clients):

        grouped_data = np.array_split(self.data, number_of_clients)

        return grouped_data

    def __select_feature_csv_no_client(self, min_user_number, max_user_number):

        client_size = random.randint(min_user_number, max_user_number)
        grouped_data = partition_list (self.data, client_size)

        return grouped_data

    def __select_feature_csv_client(self, number_of_clients):

        grouped_data = np.array_split(self.data, number_of_clients)

        return grouped_data

        
    def split_data(self, x, y, **kwargs):
        train_data_fraction = kwargs.get('train_data_fraction', self.train_data_fraction)
        if kwargs.get('type', self.type) == 'sample':
            return self._sample_split(x, y, train_data_fraction)
        else:
            return self._user_split(train_data_fraction)

    def _user_split(self, train_data_fraction):
        rng_seed = (self.random_split_seed if (self.random_split_seed is not None and self.random_split_seed &gt;= 0)
                    else int(time.time()))
        rng = random.Random(rng_seed)
        # randomly sample from user_files to pick training set users
        num_users = self.client_no
        num_train_users = int(train_data_fraction * num_users)
        indices = [i for i in range(num_users)]
        train_indices = rng.sample(indices, num_train_users)
        train_blist = [False for i in range(num_users)]
        for i in train_indices:
            train_blist[i] = True
        train_user_files = []
        test_user_files = []
        train_labels = []
        test_labels = []

        for i in range(num_users):
            if train_blist[i]:
                train_user_files.append(self.data[i])
                train_labels.append(self.label[i])
            else:
                test_user_files.append(self.data[i])
                test_labels.append(self.label[i])

        return train_user_files, test_user_files, train_labels, test_labels

    def _sample_split(self, x, y, train_data_fraction):
        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=train_data_fraction)
        return x_train, x_test, y_train, y_test


#DATA variable


    data_type = 'text'
    input_path = '/content/drive/MyDrive/Divya-Yasaman/v2/data/text/topics_sample'  # accepts either folder or csv file
    
    obj = Reader(data_type, input_path)
    
    %%time
    data = obj.read_data()
  
</code></pre>
<p>#function DEFINITION which gives the error</p>
<pre><code>def convert_to_client_data(data, data_type, **kwargs):

    distributor_obj = Distribute(data, data_type)

    distributed_data = distributor_obj.distribute_data(data_type=data_type, **kwargs)
    

    client_train_dataset = collections.OrderedDict()

    for i in range(len(distributed_data)):
        client_name = &quot;client_&quot; + str(i)
        data = collections.OrderedDict('data', distributed_data[i])
       # data = collections.OrderedDict( distributed_data[i])
        client_train_dataset[client_name] = data

    print(f'Converting data to {len(distributed_data)} client data...')

    train_dataset = tff.simulation.datasets.TestClientData(client_train_dataset)

    print(f'Data successfully converted to {len(distributed_data)} client data.')

    return train_dataset
</code></pre>
<p>ERROR STATEMENT for the function definition</p>
<pre><code>&lt;decorator-gen-53&gt; in time(self, line, cell, local_ns)

&lt;timed exec&gt; in &lt;module&gt;()

&lt;ipython-input-60-7b390d37230c&gt; in convert_to_client_data(data, data_type, **kwargs)
     13     for i in range(len(distributed_data)):
     14         client_name = &quot;client_&quot; + str(i)
---&gt; 15         data = collections.OrderedDict('data', distributed_data[i])
     16        # data = collections.OrderedDict( distributed_data[i])
     17         client_train_dataset[client_name] = data

TypeError: expected at most 1 arguments, got 2
</code></pre>
",13352824,,13352824,,44733.39515,44733.40986,"TypeError: expected at most 1 arguments, got 2....... data = collections.OrderedDict('data', distributed_data[i])",<python><ordereddictionary><tensorflow-federated><federated-learning><ordereddict>,1,9,,45545.85464,,CC BY-SA 4.0
72713816,1,72981108,,44734.43588,,1,63,"<p>I am currently stuck in a dead end. I am trying to make an image caption generator from a federated approach. My initial idea was to have a different tokenizer for each client. That poses these issues however:</p>
<ol>
<li><p>Every client will have a different sized vocabulary, and thus a
different shape of y, which will cause issues with the global model
configuration.</p>
</li>
<li><p>To counter the above issue, I could make size of y in each client
equivalent to the largest size across all clients, and fill the
extra columns in each client with 0. <strong>Example:</strong> [0,1,1,1] mapped to a size
of 6 would become [0,1,1,1,0,0]</p>
</li>
<li><p>This brings me to the last possible flaw, which is that the same
words in different clients will be having different indices. A word
&quot;rock&quot; in client 1 might have an index of 6, while the same can have
an index of 9 in another client. While training the global model, it
will cause issues since the model is trying to learn different label
indices for the same word, which will impact the accuracy?</p>
</li>
</ol>
<p><strong>This brings me to the final question</strong>: Is it against the idea of Federated Learning to tokenize all the words of all the training clients in a single tokenizer?</p>
",12575770,,,,,44758.07946,Is it against privacy of clients if I have a global tokenizer in Federated Learning (TFF)?,<tensorflow><nlp><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72777309,1,,,44739.80302,,0,104,"<p>I'm trying to switch from a federated setting to centralized learning. I've created a federated dataset, but I want to create a dataset for centralized learning with the <em>create_tf_dataset_from_all_clients</em> function. When I googled the error I found out that maybe versions of NumPy and TensorFlow are not correct for this function, my current versions are :</p>
<ul>
<li>python == 3.9</li>
<li>tensorflow==2.8.2</li>
<li>numpy==1.21.6</li>
<li>tensorflow-federated==0.24.0</li>
</ul>
<p>I haven't found some recent posts about TensorFlow 2.8 and matching NumPy version</p>
<p>Also, the error might come from a function that I used to create the clientData object:</p>
<pre><code> def parse_image(filename):
    parts = tf.strings.split(filename, os.sep)
    label_str = parts[-2]

    label_int = tf.where(labels_tf == label_str)[0][0]

    image = tf.io.read_file(filename)
    image = tf.io.decode_jpeg(image, channels=3)
    image = tf.image.convert_image_dtype(image, tf.float32)
    image = tf.image.resize(image, [32, 32])
    image = tf.keras.applications.resnet50.preprocess_input(image)

    if base_model == &quot;VGG16&quot;:
        print(&quot;-------- preprocessing image for base_model VGG16 --------&quot;)

        image = tf.keras.applications.vgg16.preprocess_input(image)

    elif base_model == &quot;ResNet&quot;:
        print(&quot;-------- preprocessing image for base_model  ResNet --------&quot;)

        image = tf.keras.applications.resnet.preprocess_input(image)

    return image, label_int

def create_dataset(client_id):

    df = train_set

    client_id = int(client_id)

    file = df.loc[df[&quot;client_id&quot;] == client_id]
    # print(file)
    path = file[&quot;path&quot;]

    # print(path)
    list_ds = tf.data.Dataset.list_files(path)

    images_ds = list_ds.map(parse_image)

    return images_ds
</code></pre>
<p>Error:</p>
<pre><code>TypeError                                 Traceback (most recent call last)
Input In [7], in &lt;cell line: 1&gt;()
----&gt; 1 train_dataset = client_data.create_tf_dataset_from_all_clients()

File ~/master_venv/lib/python3.9/site-packages/tensorflow_federated/python/simulation/datasets/client_data.py:231, in ClientData.create_tf_dataset_from_all_clients(self, seed)
    227 nested_dataset = tf.data.Dataset.from_tensor_slices(client_ids)
    228 # We apply serializable_dataset_fn here to avoid loading all client datasets
    229 # in memory, which is slow. Note that tf.data.Dataset.map implicitly wraps
    230 # the input mapping in a tf.function.
--&gt; 231 example_dataset = nested_dataset.flat_map(self.serializable_dataset_fn)
    232 return example_dataset

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2092, in DatasetV2.flat_map(self, map_func, name)
   2058 def flat_map(self, map_func, name=None):
   2059   &quot;&quot;&quot;Maps `map_func` across this dataset and flattens the result.
   2060 
   2061   The type signature is:
   (...)
   2090     Dataset: A `Dataset`.
   2091   &quot;&quot;&quot;
-&gt; 2092   return FlatMapDataset(self, map_func, name=name)

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:5327, in FlatMapDataset.__init__(self, input_dataset, map_func, name)
   5325 &quot;&quot;&quot;See `Dataset.flat_map()` for details.&quot;&quot;&quot;
   5326 self._input_dataset = input_dataset
-&gt; 5327 self._map_func = structured_function.StructuredFunctionWrapper(
   5328     map_func, self._transformation_name(), dataset=input_dataset)
   5329 if not isinstance(self._map_func.output_structure, DatasetSpec):
   5330   raise TypeError(
   5331       &quot;The `map_func` argument must return a `Dataset` object. Got &quot;
   5332       f&quot;{_get_type(self._map_func.output_structure)!r}.&quot;)

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:271, in StructuredFunctionWrapper.__init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)
    264       warnings.warn(
    265           &quot;Even though the `tf.config.experimental_run_functions_eagerly` &quot;
    266           &quot;option is set, this option does not apply to tf.data functions. &quot;
    267           &quot;To force eager execution of tf.data functions, please use &quot;
    268           &quot;`tf.data.experimental.enable_debug_mode()`.&quot;)
    269     fn_factory = trace_tf_function(defun_kwargs)
--&gt; 271 self._function = fn_factory()
    272 # There is no graph to add in eager mode.
    273 add_to_graph &amp;= not context.executing_eagerly()

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2567, in Function.get_concrete_function(self, *args, **kwargs)
   2558 def get_concrete_function(self, *args, **kwargs):
   2559   &quot;&quot;&quot;Returns a `ConcreteFunction` specialized to inputs and execution context.
   2560 
   2561   Args:
   (...)
   2565        or `tf.Tensor` or `tf.TensorSpec`.
   2566   &quot;&quot;&quot;
-&gt; 2567   graph_function = self._get_concrete_function_garbage_collected(
   2568       *args, **kwargs)
   2569   graph_function._garbage_collector.release()  # pylint: disable=protected-access
   2570   return graph_function

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2533, in Function._get_concrete_function_garbage_collected(self, *args, **kwargs)
   2531   args, kwargs = None, None
   2532 with self._lock:
-&gt; 2533   graph_function, _ = self._maybe_define_function(args, kwargs)
   2534   seen_names = set()
   2535   captured = object_identity.ObjectIdentitySet(
   2536       graph_function.graph.internal_captures)

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2711, in Function._maybe_define_function(self, args, kwargs)
   2708   cache_key = self._function_cache.generalize(cache_key)
   2709   (args, kwargs) = cache_key._placeholder_value()  # pylint: disable=protected-access
-&gt; 2711 graph_function = self._create_graph_function(args, kwargs)
   2712 self._function_cache.add(cache_key, cache_key_deletion_observer,
   2713                          graph_function)
   2715 return graph_function, filtered_flat_args

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2627, in Function._create_graph_function(self, args, kwargs)
   2622 missing_arg_names = [
   2623     &quot;%s_%d&quot; % (arg, i) for i, arg in enumerate(missing_arg_names)
   2624 ]
   2625 arg_names = base_arg_names + missing_arg_names
   2626 graph_function = ConcreteFunction(
-&gt; 2627     func_graph_module.func_graph_from_py_func(
   2628         self._name,
   2629         self._python_function,
   2630         args,
   2631         kwargs,
   2632         self.input_signature,
   2633         autograph=self._autograph,
   2634         autograph_options=self._autograph_options,
   2635         arg_names=arg_names,
   2636         capture_by_value=self._capture_by_value),
   2637     self._function_attributes,
   2638     spec=self.function_spec,
   2639     # Tell the ConcreteFunction to clean up its graph once it goes out of
   2640     # scope. This is not the default behavior since it gets used in some
   2641     # places (like Keras) where the FuncGraph lives longer than the
   2642     # ConcreteFunction.
   2643     shared_func_graph=False)
   2644 return graph_function

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1141, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)
   1138 else:
   1139   _, original_func = tf_decorator.unwrap(python_func)
-&gt; 1141 func_outputs = python_func(*func_args, **func_kwargs)
   1143 # invariant: `func_outputs` contains only Tensors, CompositeTensors,
   1144 # TensorArrays and `None`s.
   1145 func_outputs = nest.map_structure(
   1146     convert, func_outputs, expand_composites=True)

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:248, in StructuredFunctionWrapper.__init__.&lt;locals&gt;.trace_tf_function.&lt;locals&gt;.wrapped_fn(*args)
    242 @eager_function.defun_with_attributes(
    243     input_signature=structure.get_flat_tensor_specs(
    244         self._input_structure),
    245     autograph=False,
    246     attributes=defun_kwargs)
    247 def wrapped_fn(*args):  # pylint: disable=missing-docstring
--&gt; 248   ret = wrapper_helper(*args)
    249   ret = structure.to_tensor_list(self._output_structure, ret)
    250   return [ops.convert_to_tensor(t) for t in ret]

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:177, in StructuredFunctionWrapper.__init__.&lt;locals&gt;.wrapper_helper(*args)
    175 if not _should_unpack(nested_args):
    176   nested_args = (nested_args,)
--&gt; 177 ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)
    178 if _should_pack(ret):
    179   ret = tuple(ret)

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:692, in convert.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(*args, **kwargs)
    690 except Exception as e:  # pylint:disable=broad-except
    691   if hasattr(e, 'ag_error_metadata'):
--&gt; 692     raise e.ag_error_metadata.to_exception(e)
    693   else:
    694     raise

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689, in convert.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(*args, **kwargs)
    687 try:
    688   with conversion_ctx:
--&gt; 689     return converted_call(f, args, kwargs, options=options)
    690 except Exception as e:  # pylint:disable=broad-except
    691   if hasattr(e, 'ag_error_metadata'):

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439, in converted_call(f, args, kwargs, caller_fn_scope, options)
    437 try:
    438   if kwargs is not None:
--&gt; 439     result = converted_f(*effective_args, **kwargs)
    440   else:
    441     result = converted_f(*effective_args)

File /var/folders/w2/fcxhc9j52tb9hymgw1b8_dmh0000gn/T/__autograph_generated_filepc7z792y.py:11, in outer_factory.&lt;locals&gt;.inner_factory.&lt;locals&gt;.tf__create_dataset(client_id)
      9 retval_ = ag__.UndefinedReturnValue()
     10 client_id = ag__.converted_call(ag__.ld(int), (ag__.ld(client_id),), None, fscope)
---&gt; 11 files = ag__.ld(df).loc[ag__.ld(df)['client_id'] == ag__.ld(client_id)]
     12 path = ag__.ld(files)['path']
     13 list_ds = ag__.converted_call(ag__.ld(tf).data.Dataset.list_files, (ag__.ld(path),), None, fscope)

File ~/master_venv/lib/python3.9/site-packages/pandas/core/ops/common.py:70, in _unpack_zerodim_and_defer.&lt;locals&gt;.new_method(self, other)
     66             return NotImplemented
     68 other = item_from_zerodim(other)
---&gt; 70 return method(self, other)

File ~/master_venv/lib/python3.9/site-packages/pandas/core/arraylike.py:40, in OpsMixin.__eq__(self, other)
     38 @unpack_zerodim_and_defer(&quot;__eq__&quot;)
     39 def __eq__(self, other):
---&gt; 40     return self._cmp_method(other, operator.eq)

File ~/master_venv/lib/python3.9/site-packages/pandas/core/series.py:5625, in Series._cmp_method(self, other, op)
   5622 with np.errstate(all=&quot;ignore&quot;):
   5623     res_values = ops.comparison_op(lvalues, rvalues, op)
-&gt; 5625 return self._construct_result(res_values, name=res_name)

File ~/master_venv/lib/python3.9/site-packages/pandas/core/series.py:3017, in Series._construct_result(self, result, name)
   3013     return (res1, res2)
   3015 # We do not pass dtype to ensure that the Series constructor
   3016 #  does inference in the case where `result` has object-dtype.
-&gt; 3017 out = self._constructor(result, index=self.index)
   3018 out = out.__finalize__(self)
   3020 # Set the result's name after __finalize__ is called because __finalize__
   3021 #  would set it back to self.name

File ~/master_venv/lib/python3.9/site-packages/pandas/core/series.py:442, in Series.__init__(self, data, index, dtype, name, copy, fastpath)
    440     index = default_index(len(data))
    441 elif is_list_like(data):
--&gt; 442     com.require_length_match(data, index)
    444 # create/copy the manager
    445 if isinstance(data, (SingleBlockManager, SingleArrayManager)):

File ~/master_venv/lib/python3.9/site-packages/pandas/core/common.py:556, in require_length_match(data, index)
    552 def require_length_match(data, index: Index):
    553     &quot;&quot;&quot;
    554     Check the length of data matches the length of the index.
    555     &quot;&quot;&quot;
--&gt; 556     if len(data) != len(index):
    557         raise ValueError(
    558             &quot;Length of values &quot;
    559             f&quot;({len(data)}) &quot;
    560             &quot;does not match length of index &quot;
    561             f&quot;({len(index)})&quot;
    562         )

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:932, in Tensor.__len__(self)
    931 def __len__(self):
--&gt; 932   raise TypeError(f&quot;len is not well defined for a symbolic Tensor &quot;
    933                   f&quot;({self.name}). Please call `x.shape` rather than &quot;
    934                   f&quot;`len(x)` for shape information.&quot;)

TypeError: in user code:

    File &quot;/var/folders/w2/fcxhc9j52tb9hymgw1b8_dmh0000gn/T/ipykernel_2264/3413278942.py&quot;, line 7, in create_dataset  *
        files = df.loc[df['client_id']==client_id]
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/ops/common.py&quot;, line 70, in new_method
        return method(self, other)
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/arraylike.py&quot;, line 40, in __eq__
        return self._cmp_method(other, operator.eq)
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/series.py&quot;, line 5625, in _cmp_method
        return self._construct_result(res_values, name=res_name)
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/series.py&quot;, line 3017, in _construct_result
        out = self._constructor(result, index=self.index)
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/series.py&quot;, line 442, in __init__
        com.require_length_match(data, index)
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/common.py&quot;, line 556, in require_length_match
        if len(data) != len(index):

    TypeError: len is not well defined for a symbolic Tensor (Equal:0). Please call `x.shape` rather than `len(x)` for shape information.
</code></pre>
",11776320,,,,,44749.2152,When switching from federated to centralized dataset -Error may indicate that you're trying to pass a Tensor to a NumPy call,<python><numpy><tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72792770,1,,,44740.85154,,1,135,"<p>I want to save weights only when loss is getting lower and reuse them for evaluation.</p>
<pre><code>lowest_loss = Inf

    if loss[round] &lt; lowest_loss:
        lowest_loss = loss[round]

        model_weights = transfer_learning_iterative_process.get_model_weights(state)



eval_metric = federated_eval(model_weights, [fed_valid_data])
</code></pre>
<p>where:</p>
<pre><code>  federated_eval = tff.learning.build_federated_evaluation(model_fn)
</code></pre>
<p>Is there a possible way to save server weights in hdf5 format or as a checkpoint and reuse it?</p>
",11776320,,,,,44749.2067,How to save weights in tensorflow federated,<python><tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72818097,1,,,44742.62957,,0,164,"<p>I do some some experiments with the tensorflow federated learning API. Actualy I try to train a simple ResNet on 10 Clients. Based on the data and metrics, the training seems to be successful. But the evaluation as well as local and federated fails.</p>
<p>Does  anyone have an advice?</p>
<p>The model:</p>
<pre><code>def create_keras_resnet_model(): 

    inputs = tf.keras.layers.Input(shape=(28,28,1))
    bn0 = tf.keras.layers.BatchNormalization(scale=True)(inputs)

    conv1 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(7,7), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(bn0)
    conv1 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(7,7), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(conv1)
    bn1 = tf.keras.layers.BatchNormalization(scale=True)(conv1)
    max_pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding = 'same')(bn1)


    conv2 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(max_pool1)
    conv2 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(conv2)
    conv2 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(conv2)
    bn2 = tf.keras.layers.BatchNormalization(scale=True)(conv2)

    res1_conv = tf.keras.layers.Conv2D(filters = 32,
                                  kernel_size = (3,3),
                                  padding = 'same',
                                  kernel_initializer='uniform')(max_pool1)
    res1_bn = tf.keras.layers.BatchNormalization(scale=True)(res1_conv)

    add1 = tf.keras.layers.Add()([res1_bn, bn2])


    act1 = tf.keras.layers.Activation('relu')(add1)
    max_pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding = 'same')(act1)

    conv3 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(max_pool2)
    conv3 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(conv3)
    conv3 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(conv3)
    bn2 = tf.keras.layers.BatchNormalization(scale=True)(conv3)

    res2_conv = tf.keras.layers.Conv2D(filters = 32,
                                  kernel_size = (3,3),
                                  padding = 'same',
                                  kernel_initializer='uniform')(max_pool2)
    res2_bn = tf.keras.layers.BatchNormalization(scale=True)(res2_conv)

    add2 = tf.keras.layers.Add()([res2_bn, bn2])

    act2 = tf.keras.layers.Activation('relu')(add2)
    max_pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding = 'same')(act2)

    flatten = tf.keras.layers.Flatten()(max_pool3)

    dense1 = tf.keras.layers.Dense(128, activation='relu')(flatten)

    do = tf.keras.layers.Dropout(0.20)(dense1)
    dense2 = tf.keras.layers.Dense(10, activation='softmax')(do)

    model = tf.keras.models.Model(inputs=[inputs], outputs=[dense2])

    return model
</code></pre>
<p>The model is just a simple ResNet.
For the training I use the Tensorflow Federated Simulation Dataset for emnist and here 10 clients for 10 epochs.
<a href=""https://i.sstatic.net/cykYX.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/cykYX.jpg"" alt=""enter image description here"" /></a></p>
<p>Everything looks fine so far...</p>
<p>I have adjusted the provided function for preparing the data. I have already tested the whole process with a simple CNN and all works quiet well.</p>
<pre><code>def preprocess(dataset):

def batch_format_fn(element):
    return collections.OrderedDict(
        x=tf.reshape(element['pixels'], [-1, 28, 28, 1]),
        y=tf.reshape(element['label'], [-1, 1])
    )
    
return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=42).batch(BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)
</code></pre>
<p>Doing the evaluation process with tensorflow shows a strange result. The accuracy will be at around 11 percent and the loss has something between 7 and 8.</p>
<p>If I copy the weights to a local model and do the evaluation local, the same result. If I try to predict a single image from the test data an exception is thrown:</p>
<pre><code>ValueError: Input 0 of layer dense_10 is incompatible with the layer: expected axis -1 of input shape to have value 512 but received input with shape (None, 128)
</code></pre>
<p>Here the model summaray:</p>
<pre><code>Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           [(None, 28, 28, 1)]  0                                            
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 28, 28, 1)    4           input_13[0][0]                   
__________________________________________________________________________________________________
conv2d_120 (Conv2D)             (None, 28, 28, 32)   1600        batch_normalization_72[0][0]     
__________________________________________________________________________________________________
conv2d_121 (Conv2D)             (None, 28, 28, 32)   50208       conv2d_120[0][0]                 
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 28, 28, 32)   128         conv2d_121[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_36 (MaxPooling2D) (None, 14, 14, 32)   0           batch_normalization_73[0][0]     
__________________________________________________________________________________________________
conv2d_122 (Conv2D)             (None, 14, 14, 32)   25632       max_pooling2d_36[0][0]           
__________________________________________________________________________________________________
conv2d_123 (Conv2D)             (None, 14, 14, 32)   25632       conv2d_122[0][0]                 
__________________________________________________________________________________________________
conv2d_125 (Conv2D)             (None, 14, 14, 32)   9248        max_pooling2d_36[0][0]           
__________________________________________________________________________________________________
conv2d_124 (Conv2D)             (None, 14, 14, 32)   25632       conv2d_123[0][0]                 
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 14, 14, 32)   128         conv2d_125[0][0]                 
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 14, 14, 32)   128         conv2d_124[0][0]                 
__________________________________________________________________________________________________
add_24 (Add)                    (None, 14, 14, 32)   0           batch_normalization_75[0][0]     
                                                                 batch_normalization_74[0][0]     
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 14, 14, 32)   0           add_24[0][0]                     
__________________________________________________________________________________________________
max_pooling2d_37 (MaxPooling2D) (None, 7, 7, 32)     0           activation_24[0][0]              
__________________________________________________________________________________________________
conv2d_126 (Conv2D)             (None, 7, 7, 32)     25632       max_pooling2d_37[0][0]           
__________________________________________________________________________________________________
conv2d_127 (Conv2D)             (None, 7, 7, 32)     25632       conv2d_126[0][0]                 
__________________________________________________________________________________________________
conv2d_129 (Conv2D)             (None, 7, 7, 32)     9248        max_pooling2d_37[0][0]           
__________________________________________________________________________________________________
conv2d_128 (Conv2D)             (None, 7, 7, 32)     25632       conv2d_127[0][0]                 
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 7, 7, 32)     128         conv2d_129[0][0]                 
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 7, 7, 32)     128         conv2d_128[0][0]                 
__________________________________________________________________________________________________
add_25 (Add)                    (None, 7, 7, 32)     0           batch_normalization_77[0][0]     
                                                                 batch_normalization_76[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 7, 7, 32)     0           add_25[0][0]                     
__________________________________________________________________________________________________
max_pooling2d_38 (MaxPooling2D) (None, 4, 4, 32)     0           activation_25[0][0]              
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 512)          0           max_pooling2d_38[0][0]           
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 128)          65664       flatten_12[0][0]                 
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 128)          0           dense_24[0][0]                   
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 10)           1290        dropout_12[0][0]                 
==================================================================================================
Total params: 291,694
Trainable params: 291,372
Non-trainable params: 322
__________________________________________________________________________________________________
</code></pre>
<p>I did not convert the labels with with to_categorical function from the karas util package. But why is the exception, the input of the dense layer is wrong? And why does the training work?</p>
",4828378,,,,,44747.41106,Tensorflow Federated Learning on ResNet failse,<python><tensorflow><machine-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
73024656,1,,,44760.63509,,2,197,"<p>In federated averaging, does the client optimizer have to be 'SGD' only?</p>
<p>In this paper <a href=""https://arxiv.org/abs/2003.00295"" rel=""nofollow noreferrer"">ADAPTIVE FEDERATED OPTIMIZATION</a> it states &quot;One such method is FEDAVG (McMahan et al., 2017), in which clients perform multiple epochs of SGD on their local datasets.&quot;   Based on this statement, if the clients run Adam on their own loss function, it is not federated averaging?</p>
<p>What is the difference between 'federated averaging (FedAvg)' and 'Adaptive federated optimization (FedOpt) (paper linked above)'?</p>
<p>In other words what is the different between <code>tff.learning.algorithms.build_weighted_fed_avg</code> and <code>tff.learning.algorithms.build_weighted_fed_avg_with_optimizer_schedule</code>?</p>
",10543101,,10543101,,44760.6442,44760.6442,In FedAvg what is the client optimizer?,<tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
64962547,1,,,44158.18494,,0,405,"<p>I am trying to convert my CSV dataset into a federated data. Please find the code and the error I am getting while I am running my code</p>
<p>code: import collections</p>
<pre><code>import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_federated as tff

np.random.seed(0)
df = pd.read_csv('path to my csv file')

client_id_colname = 'aratio: continuous.' 
SHUFFLE_BUFFER = 1000
NUM_EPOCHS = 1

client_ids = df[client_id_colname].unique()
train_client_ids = sample(client_ids.tolist(),500)
test_client_ids = [x for x in client_ids if x not in train_client_ids]

def create_tf_dataset_for_client_fn(client_id):
  client_data = df[df[client_id_colname] == client_id]
  dataset = tf.data.Dataset.from_tensor_slices(client_data.to_dict('list'))
  dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)
  return dataset

train_data = tff.simulation.ClientData.from_clients_and_fn(
        client_ids=train_client_ids,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
test_data = tff.simulation.ClientData.from_clients_and_fn(
        client_ids=test_client_ids,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
</code></pre>
<p>Error: ---------------------------------------------------------------------------</p>
<pre><code>NameError                                 Traceback (most recent call last)
&lt;ipython-input-7-9d85508920a8&gt; in &lt;module&gt;
     15 # split client id into train and test clients
     16 client_ids = df[client_id_colname].unique()
---&gt; 17 train_client_ids = sample(client_ids.tolist(),500)
     18 test_client_ids = [x for x in client_ids if x not in train_client_ids]
     19 

NameError: name 'sample' is not defined
</code></pre>
",14689654,,730754,,44163.45279,44163.46686,Converting CSV file data into federated data,<python><pandas><tensorflow><tensorflow-federated><federated-learning>,2,0,,,,CC BY-SA 4.0
65078203,1,,,44165.72321,,1,716,"<p>when I make in python</p>
<pre><code>import syft as sy
import torch

hook = sy.TorchHook(torch)
data = torch.tensor([[1.,1],[0,1],[1,0],[0,0]])
</code></pre>
<p>an error came up that says: 'torch.tensor is not callable'. And I do not know how to solve it.
I have pytorch version 1.4.0.</p>
",14736719,,,,,44165.72321,How can I solve the pytorch/pylint error: torch.tensor is not callable?,<pytorch><pylint><federated-learning>,0,1,,,,CC BY-SA 4.0
65078281,1,,,44165.72675,,0,1009,"<p>does anyone know a solution for this Error? I am trying to switch my PyTorch network to an Federated Learning network but i always get this Error.</p>
<p>I'm using Google Colab an train on GPU. When I print the size of embeds I get 0, but I don't understand why the data is not used there.</p>
<hr />
<pre><code>RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-42-fd4a5223524b&gt; in &lt;module&gt;()
----&gt; 1 model, history = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=10)
      2 #model = train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=10)

6 frames
&lt;ipython-input-41-a386f044d41f&gt; in train_model(model, dataloaders, criterion, optimizer, num_epochs, batch_size)
     68                         # detaching it from its history on the last instance.
     69 
---&gt; 70                         outputs = model(inputs)
     71 
     72                         loss = criterion(outputs, labels)

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--&gt; 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

&lt;ipython-input-36-64e9a7d68b11&gt; in forward(self, sentence)
     11     def forward(self, sentence):
     12         embeds = self.word_embeddings(sentence)
---&gt; 13         lstm_out, (h,t) = self.lstm(embeds)
     14         lstm_out = self.dropout(lstm_out)
     15         tag_space = self.output(lstm_out[:,-1,:])

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--&gt; 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py in forward(self, input, hx)
    554             hx = self.permute_hidden(hx, sorted_indices)
    555 
--&gt; 556         self.check_forward_args(input, hx, batch_sizes)
    557         if batch_sizes is None:
    558             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py in check_forward_args(self, input, hidden, batch_sizes)
    506     def check_forward_args(self, input, hidden, batch_sizes):
    507         # type: (Tensor, Tuple[Tensor, Tensor], Optional[Tensor]) -&gt; None
--&gt; 508         self.check_input(input, batch_sizes)
    509         expected_hidden_size = self.get_expected_hidden_size(input, batch_sizes)
    510 

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py in check_input(self, input, batch_sizes)
    157             raise RuntimeError(
    158                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(
--&gt; 159                     self.input_size, input.size(-1)))
    160 
    161     def get_expected_hidden_size(self, input, batch_sizes):

RuntimeError: input.size(-1) must be equal to input_size. Expected 200, got 0
</code></pre>
<hr />
<pre><code>class LSTM(nn.Module):

def __init__(self, embedding_dim, hidden_layers,vocab_size,num_layers,pretrained_weights):
    super(LSTM, self).__init__()

    self.word_embeddings = nn.Embedding(vocab_size, embedding_dim,_weight=pretrained_weights, padding_idx=0)
    self.lstm = nn.LSTM(embedding_dim, hidden_size=hidden_layers,num_layers=num_layers, batch_first=True)
    self.output = nn.Linear(hidden_layers, vocab_size, bias=False)
    self.dropout = nn.Dropout(0.1)

def forward(self, sentence):
    embeds = self.word_embeddings(sentence)
    lstm_out, (h,t) = self.lstm(embeds)
    lstm_out = self.dropout(lstm_out)
    tag_space = self.output(lstm_out[:,-1,:])

    return tag_space
</code></pre>
<p>The Error throws in this line: lstm_out, (h,t) = self.lstm(embeds)</p>
<pre><code>  for epoch in range(num_epochs):
    print('Epoch {}/{}'.format(epoch, num_epochs - 1))
    print('-' * 10)
    train_loss = 0
    acc_score = 0

    valid_loss = 0
    acc_valid_score = 0

    #Variables to store the losses temporary
    train_loss_result = 0
    acc_score_result = 0
    valid_loss_result = 0
    acc_valid_score_result = 0

    valid_loss_not_decreased = 0

    if valid_loss_not_decreased == 5:
      break

    # Each epoch has a training and validation phase
    for phase in ['train', 'val']:
        if phase == 'train':
            model.train()  # Set model to training mode
        else:
            model.eval()   # Set model to evaluate mode
        

        for inputs,labels in dataloaders[phase]:

            # Location of current batch
            worker = inputs.location  # &lt;---- Where will send the model to
            
            #model.to(device)

            model = model.send(worker)   # &lt;---- for Federated Learning

            inputs, labels = inputs.to(device), labels.to(device)
            
            print(&quot;--------&gt; INPUT: &quot;,inputs)
            print(&quot;--------&gt; LABEL: &quot;,labels)

            # zero the parameter gradients
            optimizer.zero_grad()

            # forward
            # track history if only in train
            with torch.set_grad_enabled(phase == 'train'):
                # Get model outputs and calculate loss

                # backward + optimize only if in training phase
                if phase == 'train':
                    # we need to clear out the hidden state of the LSTM,
                    # detaching it from its history on the last instance.

                    outputs = model(inputs)

                    loss = criterion(outputs, labels)
                    acc = binary_accuracy(outputs,labels)       
                    acc_score = acc_score + acc
                    train_loss = train_loss + loss.item()
                    loss.backward()
                    
                    optimizer.step()
</code></pre>
",14736648,,,,,44779.66907,"RuntimeError: input.size(-1) must be equal to input_size. Expected 200, got 0 ---- PySyft / PyTorch / Federated Learning",<python><pytorch><federated-learning><pysyft>,1,0,,,,CC BY-SA 4.0
65471612,1,65472745,,44192.99811,,2,330,"<p>I am following this code <a href=""https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL"" rel=""nofollow noreferrer"">https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL</a> and trying to run the file same_OR.py</p>
<p>I also place input file &quot;initial_model_parameters.txt&quot;  and data folder &quot;MNIST_data&quot; in same folder</p>
<pre><code>from __future__ import absolute_import, division, print_function
import tensorflow_federated as tff
import tensorflow.compat.v1 as tf
import numpy as np
import time
from scipy.special import comb, perm

import os

# tf.compat.v1.enable_v2_behavior()
# tf.compat.v1.enable_eager_execution()

# NUM_EXAMPLES_PER_USER = 1000
BATCH_SIZE = 100
NUM_AGENT = 5


def get_data_for_digit(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence

def get_data_for_digit_test(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples)):
        output_sequence.append({
            'x': np.array(source[0][all_samples[i]].flatten() / 255.0,
                          dtype=np.float32),
            'y': np.array(source[1][all_samples[i]], dtype=np.int32)})
    return output_sequence

def get_data_for_federated_agents(source, num):
    output_sequence = []

    Samples = []
    for digit in range(0, 10):
        samples = [i for i, d in enumerate(source[1]) if d == digit]
        samples = samples[0:5421]
        Samples.append(samples)

    all_samples = []
    for sample in Samples:
        for sample_index in range(int(num * (len(sample) / NUM_AGENT)), int((num + 1) * (len(sample) / NUM_AGENT))):
            all_samples.append(sample[sample_index])

    # all_samples = [i for i in range(int(num*(len(source[1])/NUM_AGENT)), int((num+1)*(len(source[1])/NUM_AGENT)))]

    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence


BATCH_TYPE = tff.NamedTupleType([
    ('x', tff.TensorType(tf.float32, [None, 784])),
    ('y', tff.TensorType(tf.int32, [None]))])

MODEL_TYPE = tff.NamedTupleType([
    ('weights', tff.TensorType(tf.float32, [784, 10])),
    ('bias', tff.TensorType(tf.float32, [10]))])


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)
def batch_loss(model, batch):
    predicted_y = tf.nn.softmax(tf.matmul(batch.x, model.weights) + model.bias)
    return -tf.reduce_mean(tf.reduce_sum(
        tf.one_hot(batch.y, 10) * tf.log(predicted_y), axis=[1]))


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)
def batch_train(initial_model, batch, learning_rate):
    # Define a group of model variables and set them to `initial_model`.
    model_vars = tff.utils.create_variables('v', MODEL_TYPE)
    init_model = tff.utils.assign(model_vars, initial_model)

    # Perform one step of gradient descent using loss from `batch_loss`.
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    with tf.control_dependencies([init_model]):
        train_model = optimizer.minimize(batch_loss(model_vars, batch))

    # Return the model vars after performing this gradient descent step.
    with tf.control_dependencies([train_model]):
        return tff.utils.identity(model_vars)


LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)


@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)
def local_train(initial_model, learning_rate, all_batches):
    # Mapping function to apply to each batch.
    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)
    def batch_fn(model, batch):
        return batch_train(model, batch, learning_rate)

    l = tff.sequence_reduce(all_batches, initial_model, batch_fn)
    return l


@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)
def local_eval(model, all_batches):
    #
    return tff.sequence_sum(
        tff.sequence_map(
            tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),
            all_batches))


SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER, all_equal=True)
CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)


@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)
def federated_eval(model, data):
    return tff.federated_mean(
        tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))


SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER, all_equal=True)


@tff.federated_computation(
    SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)
def federated_train(model, learning_rate, data):
    l = tff.federated_map(
        local_train,
        [tff.federated_broadcast(model),
         tff.federated_broadcast(learning_rate),
         data])
    return l
    # return tff.federated_mean()


def readTestImagesFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot;\t&quot;)
        for i in p:
            if i != &quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)

def readTestLabelsFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot; &quot;)
        for i in p:
            if i!=&quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)


def getParmsAndLearningRate(agent_no):
    f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    parm_local = []
    learning_rate_list = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0:784]
            learning_rate_list.append(float(line[784].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        else:
            weights_line = line[1:785]
            learning_rate_list.append(float(line[785].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        valid_weights_line = []
        for l in weights_line:
            w_list = l.split(&quot;\t&quot;)
            w_list = w_list[0:len(w_list) - 1]
            w_list = [float(i) for i in w_list]
            valid_weights_line.append(w_list)
        parm_local.append(valid_weights_line)
    f.close()

    f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    bias_local = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0]
        else:
            weights_line = line[1]
        b_list = weights_line.split(&quot;\t&quot;)
        b_list = b_list[0:len(b_list) - 1]
        b_list = [float(i) for i in b_list]
        bias_local.append(b_list)
    f.close()
    ret = {
        'weights': np.asarray(parm_local),
        'bias': np.asarray(bias_local),
        'learning_rate': np.asarray(learning_rate_list)
    }
    return ret


def train_with_gradient_and_valuation(agent_list, grad, bi, lr, distr_type):
    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial_g = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial_g = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()
    model_g = {
        'weights': w_initial_g,
        'bias': b_initial_g
    }
    for i in range(len(grad[0])):
        # i-&gt;è¿­ä»£è½®æ•°
        gradient_w = np.zeros([784, 10], dtype=np.float32)
        gradient_b = np.zeros([10], dtype=np.float32)
        for j in agent_list:
            gradient_w = np.add(np.multiply(grad[j][i], 1/len(agent_list)), gradient_w)
            gradient_b = np.add(np.multiply(bi[j][i], 1/len(agent_list)), gradient_b)
        model_g['weights'] = np.subtract(model_g['weights'], np.multiply(lr[0][i], gradient_w))
        model_g['bias'] = np.subtract(model_g['bias'], np.multiply(lr[0][i], gradient_b))

    test_images = readTestImagesFromFile(False)
    test_labels_onehot = readTestLabelsFromFile(False)
    m = np.dot(test_images, np.asarray(model_g['weights']))
    test_result = m + np.asarray(model_g['bias'])
    y = tf.nn.softmax(test_result)
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.arg_max(test_labels_onehot, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    return accuracy.numpy()


def remove_list_indexed(removed_ele, original_l, ll):
    new_original_l = []
    for i in original_l:
        new_original_l.append(i)
    for i in new_original_l:
        if i == removed_ele:
            new_original_l.remove(i)
    for i in range(len(ll)):
        if set(ll[i]) == set(new_original_l):
            return i
    return -1


def shapley_list_indexed(original_l, ll):
    for i in range(len(ll)):
        if set(ll[i]) == set(original_l):
            return i
    return -1


def PowerSetsBinary(items):
    N = len(items)
    set_all = []
    for i in range(2 ** N):
        combo = []
        for j in range(N):
            if (i &gt;&gt; j) % 2 == 1:
                combo.append(items[j])
        set_all.append(combo)
    return set_all


if __name__ == &quot;__main__&quot;:
    start_time = time.time()

    #data_num = np.asarray([5923,6742,5958,6131,5842])
    #agents_weights = np.divide(data_num, data_num.sum())

    for index in range(NUM_AGENT):
        f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(index)+&quot;.txt&quot;), &quot;w&quot;)
        f.close()
        f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(index) + &quot;.txt&quot;), &quot;w&quot;)
        f.close()
    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()

    DISTRIBUTION_TYPE = &quot;SAME&quot;

    federated_train_data_divide = None
    federated_train_data = None
    if DISTRIBUTION_TYPE == &quot;SAME&quot;:
        federated_train_data_divide = [get_data_for_federated_agents(mnist_train, d) for d in range(NUM_AGENT)]
        federated_train_data = federated_train_data_divide

    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()

    initial_model = {
        'weights': w_initial,
        'bias': b_initial
    }
    model = initial_model
    learning_rate = 0.1
    for round_num in range(50):
        local_models = federated_train(model, learning_rate, federated_train_data)
        print(&quot;learning rate: &quot;, learning_rate)
        #print(local_models[0][0])#ç¬¬0ä¸ªagentçš„weightsçŸ©é˜µ
        #print(local_models[0][1])#ç¬¬0ä¸ªagentçš„biasçŸ©é˜µ
        #print(len(local_models))
        for local_index in range(len(local_models)):
            f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(local_index)+&quot;.txt&quot;),&quot;a&quot;,encoding=&quot;utf-8&quot;)
            for i in local_models[local_index][0]:
                line = &quot;&quot;
                arr = list(i)
                for j in arr:
                    line += (str(j)+&quot;\t&quot;)
                print(line, file=f)
            print(&quot;***&quot;+str(learning_rate)+&quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
            f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(local_index) + &quot;.txt&quot;), &quot;a&quot;, encoding=&quot;utf-8&quot;)
            line = &quot;&quot;
            for i in local_models[local_index][1]:
                line += (str(i) + &quot;\t&quot;)
            print(line, file=f)
            print(&quot;***&quot; + str(learning_rate) + &quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
        m_w = np.zeros([784, 10], dtype=np.float32)
        m_b = np.zeros([10], dtype=np.float32)
        for local_model_index in range(len(local_models)):
            m_w = np.add(np.multiply(local_models[local_model_index][0], 1/NUM_AGENT), m_w)
            m_b = np.add(np.multiply(local_models[local_model_index][1], 1/NUM_AGENT), m_b)
            model = {
                'weights': m_w,
                'bias': m_b
            }
        learning_rate = learning_rate * 0.9
        loss = federated_eval(model, federated_train_data)
        print('round {}, loss={}'.format(round_num, loss))
        print(time.time()-start_time)

    gradient_weights = []
    gradient_biases = []
    gradient_lrs = []
    for ij in range(NUM_AGENT):
        model_ = getParmsAndLearningRate(ij)
        gradient_weights_local = []
        gradient_biases_local = []
        learning_rate_local = []

        for i in range(len(model_['learning_rate'])):
            if i == 0:
                gradient_weight = np.divide(np.subtract(initial_model['weights'], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(initial_model['bias'], model_['bias'][i]),
                                          model_['learning_rate'][i])
            else:
                gradient_weight = np.divide(np.subtract(model_['weights'][i - 1], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(model_['bias'][i - 1], model_['bias'][i]),
                                          model_['learning_rate'][i])
            gradient_weights_local.append(gradient_weight)
            gradient_biases_local.append(gradient_bias)
            learning_rate_local.append(model_['learning_rate'][i])

        gradient_weights.append(gradient_weights_local)
        gradient_biases.append(gradient_biases_local)
        gradient_lrs.append(learning_rate_local)

    all_sets = PowerSetsBinary([i for i in range(NUM_AGENT)])
    group_shapley_value = []
    for s in all_sets:
        group_shapley_value.append(
            train_with_gradient_and_valuation(s, gradient_weights, gradient_biases, gradient_lrs, DISTRIBUTION_TYPE))
        print(str(s)+&quot;\t&quot;+str(group_shapley_value[len(group_shapley_value)-1]))

    agent_shapley = []
    for index in range(NUM_AGENT):
        shapley = 0.0
        for j in all_sets:
            if index in j:
                remove_list_index = remove_list_indexed(index, j, all_sets)
                if remove_list_index != -1:
                    shapley += (group_shapley_value[shapley_list_indexed(j, all_sets)] - group_shapley_value[
                        remove_list_index]) / (comb(NUM_AGENT - 1, len(all_sets[remove_list_index])))
        agent_shapley.append(shapley)
    for ag_s in agent_shapley:
        print(ag_s)
    print(&quot;end_time&quot;, time.time()-start_time)
</code></pre>
<p>I installed tensor flow federated with this command</p>
<pre><code>pip install --upgrade tensorflow_federated
</code></pre>
<p>and this line is also underlied with red color</p>
<pre><code>import tensorflow.compat.v1 as tf
</code></pre>
<p>when i tried to execute go this error</p>
<blockquote>
<p>File &quot;same_OR.py&quot;, line 94, in 
BATCH_TYPE = tff.NamedTupleType([ AttributeError: module 'tensorflow_federated' has no attribute 'NamedTupleType'</p>
</blockquote>
<p>where is the problem? anyone can help?</p>
",7996402,,,,,44193.15117,'tensorflow_federated' has no attribute 'NamedTupleType,<python><tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
65481370,1,65484988,,44193.71836,,1,310,"<p>I am following this code <a href=""https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL"" rel=""nofollow noreferrer"">https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL</a> and trying to run the file same_OR.py</p>
<p>there is a problem in <code>import tensorflow.compat.v1</code> as tf its show that unable to import &quot; tensorflow.compat.v1&quot; File &quot;sameOR.py&quot;</p>
<pre><code>from __future__ import absolute_import, division, print_function
import tensorflow_federated as tff
import tensorflow.compat.v1 as tf
import numpy as np
import time
from scipy.special import comb, perm

import os

# tf.compat.v1.enable_v2_behavior()
# tf.compat.v1.enable_eager_execution()

# NUM_EXAMPLES_PER_USER = 1000
BATCH_SIZE = 100
NUM_AGENT = 5


def get_data_for_digit(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence

def get_data_for_digit_test(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples)):
        output_sequence.append({
            'x': np.array(source[0][all_samples[i]].flatten() / 255.0,
                          dtype=np.float32),
            'y': np.array(source[1][all_samples[i]], dtype=np.int32)})
    return output_sequence

def get_data_for_federated_agents(source, num):
    output_sequence = []

    Samples = []
    for digit in range(0, 10):
        samples = [i for i, d in enumerate(source[1]) if d == digit]
        samples = samples[0:5421]
        Samples.append(samples)

    all_samples = []
    for sample in Samples:
        for sample_index in range(int(num * (len(sample) / NUM_AGENT)), int((num + 1) * (len(sample) / NUM_AGENT))):
            all_samples.append(sample[sample_index])

    # all_samples = [i for i in range(int(num*(len(source[1])/NUM_AGENT)), int((num+1)*(len(source[1])/NUM_AGENT)))]

    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence


BATCH_TYPE = tff.NamedTupleType([
    ('x', tff.TensorType(tf.float32, [None, 784])),
    ('y', tff.TensorType(tf.int32, [None]))])

MODEL_TYPE = tff.NamedTupleType([
    ('weights', tff.TensorType(tf.float32, [784, 10])),
    ('bias', tff.TensorType(tf.float32, [10]))])


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)
def batch_loss(model, batch):
    predicted_y = tf.nn.softmax(tf.matmul(batch.x, model.weights) + model.bias)
    return -tf.reduce_mean(tf.reduce_sum(
        tf.one_hot(batch.y, 10) * tf.log(predicted_y), axis=[1]))


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)
def batch_train(initial_model, batch, learning_rate):
    # Define a group of model variables and set them to `initial_model`.
    model_vars = tff.utils.create_variables('v', MODEL_TYPE)
    init_model = tff.utils.assign(model_vars, initial_model)

    # Perform one step of gradient descent using loss from `batch_loss`.
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    with tf.control_dependencies([init_model]):
        train_model = optimizer.minimize(batch_loss(model_vars, batch))

    # Return the model vars after performing this gradient descent step.
    with tf.control_dependencies([train_model]):
        return tff.utils.identity(model_vars)


LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)


@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)
def local_train(initial_model, learning_rate, all_batches):
    # Mapping function to apply to each batch.
    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)
    def batch_fn(model, batch):
        return batch_train(model, batch, learning_rate)

    l = tff.sequence_reduce(all_batches, initial_model, batch_fn)
    return l


@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)
def local_eval(model, all_batches):
    #
    return tff.sequence_sum(
        tff.sequence_map(
            tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),
            all_batches))


SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER, all_equal=True)
CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)


@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)
def federated_eval(model, data):
    return tff.federated_mean(
        tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))


SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER, all_equal=True)


@tff.federated_computation(
    SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)
def federated_train(model, learning_rate, data):
    l = tff.federated_map(
        local_train,
        [tff.federated_broadcast(model),
         tff.federated_broadcast(learning_rate),
         data])
    return l
    # return tff.federated_mean()


def readTestImagesFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot;\t&quot;)
        for i in p:
            if i != &quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)

def readTestLabelsFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot; &quot;)
        for i in p:
            if i!=&quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)


def getParmsAndLearningRate(agent_no):
    f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    parm_local = []
    learning_rate_list = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0:784]
            learning_rate_list.append(float(line[784].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        else:
            weights_line = line[1:785]
            learning_rate_list.append(float(line[785].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        valid_weights_line = []
        for l in weights_line:
            w_list = l.split(&quot;\t&quot;)
            w_list = w_list[0:len(w_list) - 1]
            w_list = [float(i) for i in w_list]
            valid_weights_line.append(w_list)
        parm_local.append(valid_weights_line)
    f.close()

    f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    bias_local = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0]
        else:
            weights_line = line[1]
        b_list = weights_line.split(&quot;\t&quot;)
        b_list = b_list[0:len(b_list) - 1]
        b_list = [float(i) for i in b_list]
        bias_local.append(b_list)
    f.close()
    ret = {
        'weights': np.asarray(parm_local),
        'bias': np.asarray(bias_local),
        'learning_rate': np.asarray(learning_rate_list)
    }
    return ret


def train_with_gradient_and_valuation(agent_list, grad, bi, lr, distr_type):
    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial_g = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial_g = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()
    model_g = {
        'weights': w_initial_g,
        'bias': b_initial_g
    }
    for i in range(len(grad[0])):
        # i-&gt;è¿­ä»£è½®æ•°
        gradient_w = np.zeros([784, 10], dtype=np.float32)
        gradient_b = np.zeros([10], dtype=np.float32)
        for j in agent_list:
            gradient_w = np.add(np.multiply(grad[j][i], 1/len(agent_list)), gradient_w)
            gradient_b = np.add(np.multiply(bi[j][i], 1/len(agent_list)), gradient_b)
        model_g['weights'] = np.subtract(model_g['weights'], np.multiply(lr[0][i], gradient_w))
        model_g['bias'] = np.subtract(model_g['bias'], np.multiply(lr[0][i], gradient_b))

    test_images = readTestImagesFromFile(False)
    test_labels_onehot = readTestLabelsFromFile(False)
    m = np.dot(test_images, np.asarray(model_g['weights']))
    test_result = m + np.asarray(model_g['bias'])
    y = tf.nn.softmax(test_result)
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.arg_max(test_labels_onehot, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    return accuracy.numpy()


def remove_list_indexed(removed_ele, original_l, ll):
    new_original_l = []
    for i in original_l:
        new_original_l.append(i)
    for i in new_original_l:
        if i == removed_ele:
            new_original_l.remove(i)
    for i in range(len(ll)):
        if set(ll[i]) == set(new_original_l):
            return i
    return -1


def shapley_list_indexed(original_l, ll):
    for i in range(len(ll)):
        if set(ll[i]) == set(original_l):
            return i
    return -1


def PowerSetsBinary(items):
    N = len(items)
    set_all = []
    for i in range(2 ** N):
        combo = []
        for j in range(N):
            if (i &gt;&gt; j) % 2 == 1:
                combo.append(items[j])
        set_all.append(combo)
    return set_all


if __name__ == &quot;__main__&quot;:
    start_time = time.time()

    #data_num = np.asarray([5923,6742,5958,6131,5842])
    #agents_weights = np.divide(data_num, data_num.sum())

    for index in range(NUM_AGENT):
        f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(index)+&quot;.txt&quot;), &quot;w&quot;)
        f.close()
        f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(index) + &quot;.txt&quot;), &quot;w&quot;)
        f.close()
    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()

    DISTRIBUTION_TYPE = &quot;SAME&quot;

    federated_train_data_divide = None
    federated_train_data = None
    if DISTRIBUTION_TYPE == &quot;SAME&quot;:
        federated_train_data_divide = [get_data_for_federated_agents(mnist_train, d) for d in range(NUM_AGENT)]
        federated_train_data = federated_train_data_divide

    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()

    initial_model = {
        'weights': w_initial,
        'bias': b_initial
    }
    model = initial_model
    learning_rate = 0.1
    for round_num in range(50):
        local_models = federated_train(model, learning_rate, federated_train_data)
        print(&quot;learning rate: &quot;, learning_rate)
        #print(local_models[0][0])#ç¬¬0ä¸ªagentçš„weightsçŸ©é˜µ
        #print(local_models[0][1])#ç¬¬0ä¸ªagentçš„biasçŸ©é˜µ
        #print(len(local_models))
        for local_index in range(len(local_models)):
            f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(local_index)+&quot;.txt&quot;),&quot;a&quot;,encoding=&quot;utf-8&quot;)
            for i in local_models[local_index][0]:
                line = &quot;&quot;
                arr = list(i)
                for j in arr:
                    line += (str(j)+&quot;\t&quot;)
                print(line, file=f)
            print(&quot;***&quot;+str(learning_rate)+&quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
            f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(local_index) + &quot;.txt&quot;), &quot;a&quot;, encoding=&quot;utf-8&quot;)
            line = &quot;&quot;
            for i in local_models[local_index][1]:
                line += (str(i) + &quot;\t&quot;)
            print(line, file=f)
            print(&quot;***&quot; + str(learning_rate) + &quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
        m_w = np.zeros([784, 10], dtype=np.float32)
        m_b = np.zeros([10], dtype=np.float32)
        for local_model_index in range(len(local_models)):
            m_w = np.add(np.multiply(local_models[local_model_index][0], 1/NUM_AGENT), m_w)
            m_b = np.add(np.multiply(local_models[local_model_index][1], 1/NUM_AGENT), m_b)
            model = {
                'weights': m_w,
                'bias': m_b
            }
        learning_rate = learning_rate * 0.9
        loss = federated_eval(model, federated_train_data)
        print('round {}, loss={}'.format(round_num, loss))
        print(time.time()-start_time)

    gradient_weights = []
    gradient_biases = []
    gradient_lrs = []
    for ij in range(NUM_AGENT):
        model_ = getParmsAndLearningRate(ij)
        gradient_weights_local = []
        gradient_biases_local = []
        learning_rate_local = []

        for i in range(len(model_['learning_rate'])):
            if i == 0:
                gradient_weight = np.divide(np.subtract(initial_model['weights'], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(initial_model['bias'], model_['bias'][i]),
                                          model_['learning_rate'][i])
            else:
                gradient_weight = np.divide(np.subtract(model_['weights'][i - 1], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(model_['bias'][i - 1], model_['bias'][i]),
                                          model_['learning_rate'][i])
            gradient_weights_local.append(gradient_weight)
            gradient_biases_local.append(gradient_bias)
            learning_rate_local.append(model_['learning_rate'][i])

        gradient_weights.append(gradient_weights_local)
        gradient_biases.append(gradient_biases_local)
        gradient_lrs.append(learning_rate_local)

    all_sets = PowerSetsBinary([i for i in range(NUM_AGENT)])
    group_shapley_value = []
    for s in all_sets:
        group_shapley_value.append(
            train_with_gradient_and_valuation(s, gradient_weights, gradient_biases, gradient_lrs, DISTRIBUTION_TYPE))
        print(str(s)+&quot;\t&quot;+str(group_shapley_value[len(group_shapley_value)-1]))

    agent_shapley = []
    for index in range(NUM_AGENT):
        shapley = 0.0
        for j in all_sets:
            if index in j:
                remove_list_index = remove_list_indexed(index, j, all_sets)
                if remove_list_index != -1:
                    shapley += (group_shapley_value[shapley_list_indexed(j, all_sets)] - group_shapley_value[
                        remove_list_index]) / (comb(NUM_AGENT - 1, len(all_sets[remove_list_index])))
        agent_shapley.append(shapley)
    for ag_s in agent_shapley:
        print(ag_s)
    print(&quot;end_time&quot;, time.time()-start_time)
</code></pre>
<p>and these are list of errors .. can anyone help?</p>
<blockquote>
<p>Traceback (most recent call last):   File &quot;samOR.py&quot;, line 331, in

local_models = federated_train(model, learning_rate, federated_train_data)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\utils\function_utils.py&quot;,
line 561, in <strong>call</strong>
return context.invoke(self, arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 49, in
wrapped_f
return Retrying(*dargs, **dkw).call(f, *args, **kw)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 206, in
call
return attempt.get(self._wrap_exception)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 247, in
get
six.reraise(self.value[0], self.value[1], self.value[2])   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\six.py&quot;, line 703, in reraise
raise value   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 200, in
call
attempt = Attempt(fn(*args, **kwargs), attempt_number, False)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py&quot;,
line 213, in invoke
arg = event_loop.run_until_complete(   File &quot;C:\Users\Aw\Anaconda3\lib\asyncio\base_events.py&quot;, line 616, in
run_until_complete
return future.result()   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py&quot;,
line 99, in
_ingest
ingested = await asyncio.gather(*ingested)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py&quot;,
line 104, in _ingest
return await executor.create_value(val, type_spec)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 286, in create_value
return ReferenceResolvingExecutorValue(await   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py&quot;,
line 245, in create_value
await cached_value.target_future   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 110, in create_value
return await self._delegate(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 105, in _delegate
result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(<em>fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federating_executor.py&quot;,
line 383, in create_value
return await self._strategy.compute_federated_value(value, type_spec)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federated_resolving_strategy.py&quot;,
line 272, in compute_federated_value
result = await asyncio.gather(</em>[   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 281, in create_value
vals = await asyncio.gather(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 286, in create_value
return ReferenceResolvingExecutorValue(await   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py&quot;,
line 245, in create_value
await cached_value.target_future   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 110, in create_value
return await self._delegate(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 105, in _delegate
result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 464, in create_value
return EagerValue(value, self._tf_function_cache, type_spec, self._device)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 366, in <strong>init</strong>   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 326, in to_representation_for_type
raise TypeError( TypeError: The apparent type float32[10] of a tensor [-0.9900856  -0.9902875  -0.99910086 -0.9972545  -0.99561495
-0.99766624  -0.9964327  -0.99897027 -0.9960221  -0.99313617] does not match the expected type float32[784,10]. ERROR:asyncio:Task was
destroyed but it is pending! task: &lt;Task pending name='Task-7'
coro=&lt;trace..async_trace() running at
C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py:200&gt;
wait_for=&lt;Future pending
cb=[_chain_future.._call_check_cancel() at
C:\Users\Aw0000282F4DFE3D0&gt;()]&gt;</p>
</blockquote>
",7996402,,14161847,,44193.92515,44193.9416,Size mismatch in tensorflow_federated eager executor,<python><tensorflow><machine-learning><tensorflow-federated><federated-learning>,1,2,,,,CC BY-SA 4.0
65491416,1,,,44194.47931,,2,115,"<p>I use TFF 0.12.0 and image dataset for dog and cat(2 labels), If I test with VGG16, Ifind accuracy 0.9 but If I change to ResNet50, accuracy decrease to 0.4, Here is what I write:</p>
<pre class=""lang-py prettyprint-override""><code>def create_compiled_keras_model():
   
    baseModel = tf.keras.applications.ResNet50(include_top=False, weights=&quot;imagenet&quot;, input_tensor=tf.keras.Input(shape=(224, 224, 3)))

   resnet_output = baseModel.output
   layer1 = tf.keras.layers.GlobalAveragePooling2D()(resnet_output)
   layer2 = tf.keras.layers.Flatten(name=&quot;flatten&quot;)(layer1)
   layer2 = tf.keras.layers.Dense(units=256, name='nonlinear', activation=&quot;relu&quot;)(layer2)
   dropout_layer = tf.keras.layers.Dropout(0.5)(layer2)
   model_output = tf.keras.layers.Dense(2, activation=&quot;softmax&quot;)(dropout_layer)
   model = tf.keras.Model(inputs=baseModel.input, outputs=model_output)
   for layer in baseModel.layers:
       layer.trainable = False
   model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.001, momentum =0.9), 
            loss=tf.keras.losses.CategoricalCrossentropy(),
             metrics=([tf.keras.metrics.CategoricalAccuracy()]))
   return model

def model_fn():
   keras_model = create_compiled_keras_model()
   return tff.learning.from_compiled_keras_model(keras_model, sample_batch) 

iterative_process = tff.learning.build_federated_averaging_process(model_fn, server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),client_weight_fn=None)

state = iterative_process.initialize()
evaluation = tff.learning.build_federated_evaluation(model_fn)
</code></pre>
<p>but accuracy does not exceed 0.46 even after 100 rounds. here is a part of the result :</p>
<pre class=""lang-py prettyprint-override""><code>round  1, metrics=&lt;categorical_accuracy=0.500249981880188,loss=0.7735000252723694,keras_training_time_client_sum_sec=0.0&gt;
round  2, metrics=&lt;categorical_accuracy=0.47187501192092896,loss=0.7735000252723694,keras_training_time_client_sum_sec=0.0&gt;
....
round 99, metrics=&lt;categorical_accuracy=0.4632812440395355,loss=0.7622881531715393,keras_training_time_client_sum_sec=0.0&gt;
round 100, metrics=&lt;categorical_accuracy=0.46015626192092896,loss=0.7622881531748393,keras_training_time_client_sum_sec=0.0&gt;
</code></pre>
<p>Help Please!!!</p>
",14253961,,14692,,44416.58507,44416.58507,Why Resnet50 with TFF does not give good results,<tensorflow-federated><federated-learning>,0,3,,,,CC BY-SA 4.0
65498670,1,65526829,,44194.87247,,2,350,"<p>I am following this code <a href=""https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL"" rel=""nofollow noreferrer"">https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL</a> and trying to run the file <code>same_OR.py</code> with some required changes</p>
<pre><code>from __future__ import absolute_import, division, print_function
import tensorflow_federated as tff
import tensorflow.compat.v1 as tf
import numpy as np
import time
from scipy.special import comb, perm
import collections
import os

# tf.compat.v1.enable_v2_behavior()
# tf.compat.v1.enable_eager_execution()

# NUM_EXAMPLES_PER_USER = 1000
BATCH_SIZE = 100
NUM_AGENT = 5


def get_data_for_digit(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence

def get_data_for_digit_test(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples)):
        output_sequence.append({
            'x': np.array(source[0][all_samples[i]].flatten() / 255.0,
                          dtype=np.float32),
            'y': np.array(source[1][all_samples[i]], dtype=np.int32)})
    return output_sequence

def get_data_for_federated_agents(source, num):
    output_sequence = []

    Samples = []
    for digit in range(0, 10):
        samples = [i for i, d in enumerate(source[1]) if d == digit]
        samples = samples[0:5421]
        Samples.append(samples)

    all_samples = []
    for sample in Samples:
        for sample_index in range(int(num * (len(sample) / NUM_AGENT)), int((num + 1) * (len(sample) / NUM_AGENT))):
            all_samples.append(sample[sample_index])

    # all_samples = [i for i in range(int(num*(len(source[1])/NUM_AGENT)), int((num+1)*(len(source[1])/NUM_AGENT)))]

    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence


BATCH_TYPE = tff.StructType([
    ('x', tff.TensorType(tf.float32, [None, 784])),
    ('y', tff.TensorType(tf.int32, [None]))])

MODEL_TYPE = tff.StructType([
    ('weights', tff.TensorType(tf.float32, [784, 10])),
    ('bias', tff.TensorType(tf.float32, [10]))])


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)
def batch_loss(model, batch):
    predicted_y = tf.nn.softmax(tf.matmul(batch.x, model.weights) + model.bias)
    return -tf.reduce_mean(tf.reduce_sum(
        tf.one_hot(batch.y, 10) * tf.log(predicted_y), axis=[1]))


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)
def batch_train(initial_model, batch, learning_rate):
    # Define a group of model variables and set them to `initial_model`.
    model_vars = tff.utils.create_variables('v', MODEL_TYPE)
    init_model = tff.utils.assign(model_vars, initial_model)

    # Perform one step of gradient descent using loss from `batch_loss`.
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    with tf.control_dependencies([init_model]):
        train_model = optimizer.minimize(batch_loss(model_vars, batch))

    # Return the model vars after performing this gradient descent step.
    with tf.control_dependencies([train_model]):
        return tff.utils.identity(model_vars)


LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)


@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)
def local_train(initial_model, learning_rate, all_batches):
    # Mapping function to apply to each batch.
    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)
    def batch_fn(model, batch):
        return batch_train(model, batch, learning_rate)

    l = tff.sequence_reduce(all_batches, initial_model, batch_fn)
    return l


@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)
def local_eval(model, all_batches):
    #
    return tff.sequence_sum(
        tff.sequence_map(
            tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),
            all_batches))


SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER, all_equal=True)
CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)


@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)
def federated_eval(model, data):
    return tff.federated_mean(
        tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))


SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER, all_equal=True)


@tff.federated_computation(
    SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)
def federated_train(model, learning_rate, data):
    l = tff.federated_map(
        local_train,
        [tff.federated_broadcast(model),
         tff.federated_broadcast(learning_rate),
         data])
    return l
    # return tff.federated_mean()


def readTestImagesFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot;\t&quot;)
        for i in p:
            if i != &quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)

def readTestLabelsFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot; &quot;)
        for i in p:
            if i!=&quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)


def getParmsAndLearningRate(agent_no):
    f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    parm_local = []
    learning_rate_list = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0:784]
            learning_rate_list.append(float(line[784].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        else:
            weights_line = line[1:785]
            learning_rate_list.append(float(line[785].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        valid_weights_line = []
        for l in weights_line:
            w_list = l.split(&quot;\t&quot;)
            w_list = w_list[0:len(w_list) - 1]
            w_list = [float(i) for i in w_list]
            valid_weights_line.append(w_list)
        parm_local.append(valid_weights_line)
    f.close()

    f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    bias_local = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0]
        else:
            weights_line = line[1]
        b_list = weights_line.split(&quot;\t&quot;)
        b_list = b_list[0:len(b_list) - 1]
        b_list = [float(i) for i in b_list]
        bias_local.append(b_list)
    f.close()
    ret = {
        'weights': np.asarray(parm_local),
        'bias': np.asarray(bias_local),
        'learning_rate': np.asarray(learning_rate_list)
    }
    return ret


def train_with_gradient_and_valuation(agent_list, grad, bi, lr, distr_type):
    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial_g = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial_g = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()
    model_g = {
        'weights': w_initial_g,
        'bias': b_initial_g
    }
    for i in range(len(grad[0])):
        # i-&gt;è¿­ä»£è½®æ•°
        gradient_w = np.zeros([784, 10], dtype=np.float32)
        gradient_b = np.zeros([10], dtype=np.float32)
        for j in agent_list:
            gradient_w = np.add(np.multiply(grad[j][i], 1/len(agent_list)), gradient_w)
            gradient_b = np.add(np.multiply(bi[j][i], 1/len(agent_list)), gradient_b)
        model_g['weights'] = np.subtract(model_g['weights'], np.multiply(lr[0][i], gradient_w))
        model_g['bias'] = np.subtract(model_g['bias'], np.multiply(lr[0][i], gradient_b))

    test_images = readTestImagesFromFile(False)
    test_labels_onehot = readTestLabelsFromFile(False)
    m = np.dot(test_images, np.asarray(model_g['weights']))
    test_result = m + np.asarray(model_g['bias'])
    y = tf.nn.softmax(test_result)
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.arg_max(test_labels_onehot, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    return accuracy.numpy()


def remove_list_indexed(removed_ele, original_l, ll):
    new_original_l = []
    for i in original_l:
        new_original_l.append(i)
    for i in new_original_l:
        if i == removed_ele:
            new_original_l.remove(i)
    for i in range(len(ll)):
        if set(ll[i]) == set(new_original_l):
            return i
    return -1


def shapley_list_indexed(original_l, ll):
    for i in range(len(ll)):
        if set(ll[i]) == set(original_l):
            return i
    return -1


def PowerSetsBinary(items):
    N = len(items)
    set_all = []
    for i in range(2 ** N):
        combo = []
        for j in range(N):
            if (i &gt;&gt; j) % 2 == 1:
                combo.append(items[j])
        set_all.append(combo)
    return set_all


if __name__ == &quot;__main__&quot;:
    start_time = time.time()

    #data_num = np.asarray([5923,6742,5958,6131,5842])
    #agents_weights = np.divide(data_num, data_num.sum())

    for index in range(NUM_AGENT):
        f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(index)+&quot;.txt&quot;), &quot;w&quot;)
        f.close()
        f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(index) + &quot;.txt&quot;), &quot;w&quot;)
        f.close()
    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()

    DISTRIBUTION_TYPE = &quot;SAME&quot;

    federated_train_data_divide = None
    federated_train_data = None
    if DISTRIBUTION_TYPE == &quot;SAME&quot;:
        federated_train_data_divide = [get_data_for_federated_agents(mnist_train, d) for d in range(NUM_AGENT)]
        federated_train_data = federated_train_data_divide

    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()

    initial_model =  collections.OrderedDict(
        'weights': w_initial 
        'bias':b_initial)
    
    model = initial_model
    learning_rate = 0.1
    for round_num in range(50):
        local_models = federated_train(model, learning_rate, federated_train_data)
        print(&quot;learning rate: &quot;, learning_rate)
        #print(local_models[0][0])#ç¬¬0ä¸ªagentçš„weightsçŸ©é˜µ
        #print(local_models[0][1])#ç¬¬0ä¸ªagentçš„biasçŸ©é˜µ
        #print(len(local_models))
        for local_index in range(len(local_models)):
            f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(local_index)+&quot;.txt&quot;),&quot;a&quot;,encoding=&quot;utf-8&quot;)
            for i in local_models[local_index][0]:
                line = &quot;&quot;
                arr = list(i)
                for j in arr:
                    line += (str(j)+&quot;\t&quot;)
                print(line, file=f)
            print(&quot;***&quot;+str(learning_rate)+&quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
            f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(local_index) + &quot;.txt&quot;), &quot;a&quot;, encoding=&quot;utf-8&quot;)
            line = &quot;&quot;
            for i in local_models[local_index][1]:
                line += (str(i) + &quot;\t&quot;)
            print(line, file=f)
            print(&quot;***&quot; + str(learning_rate) + &quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
        m_w = np.zeros([784, 10], dtype=np.float32)
        m_b = np.zeros([10], dtype=np.float32)
        for local_model_index in range(len(local_models)):
            m_w = np.add(np.multiply(local_models[local_model_index][0], 1/NUM_AGENT), m_w)
            m_b = np.add(np.multiply(local_models[local_model_index][1], 1/NUM_AGENT), m_b)
            model = {
                'weights': m_w,
                'bias': m_b
            }
        learning_rate = learning_rate * 0.9
        loss = federated_eval(model, federated_train_data)
        print('round {}, loss={}'.format(round_num, loss))
        print(time.time()-start_time)

    gradient_weights = []
    gradient_biases = []
    gradient_lrs = []
    for ij in range(NUM_AGENT):
        model_ = getParmsAndLearningRate(ij)
        gradient_weights_local = []
        gradient_biases_local = []
        learning_rate_local = []

        for i in range(len(model_['learning_rate'])):
            if i == 0:
                gradient_weight = np.divide(np.subtract(initial_model['weights'], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(initial_model['bias'], model_['bias'][i]),
                                          model_['learning_rate'][i])
            else:
                gradient_weight = np.divide(np.subtract(model_['weights'][i - 1], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(model_['bias'][i - 1], model_['bias'][i]),
                                          model_['learning_rate'][i])
            gradient_weights_local.append(gradient_weight)
            gradient_biases_local.append(gradient_bias)
            learning_rate_local.append(model_['learning_rate'][i])

        gradient_weights.append(gradient_weights_local)
        gradient_biases.append(gradient_biases_local)
        gradient_lrs.append(learning_rate_local)

    all_sets = PowerSetsBinary([i for i in range(NUM_AGENT)])
    group_shapley_value = []
    for s in all_sets:
        group_shapley_value.append(
            train_with_gradient_and_valuation(s, gradient_weights, gradient_biases, gradient_lrs, DISTRIBUTION_TYPE))
        print(str(s)+&quot;\t&quot;+str(group_shapley_value[len(group_shapley_value)-1]))

    agent_shapley = []
    for index in range(NUM_AGENT):
        shapley = 0.0
        for j in all_sets:
            if index in j:
                remove_list_index = remove_list_indexed(index, j, all_sets)
                if remove_list_index != -1:
                    shapley += (group_shapley_value[shapley_list_indexed(j, all_sets)] - group_shapley_value[
                        remove_list_index]) / (comb(NUM_AGENT - 1, len(all_sets[remove_list_index])))
        agent_shapley.append(shapley)
    for ag_s in agent_shapley:
        print(ag_s)
    print(&quot;end_time&quot;, time.time()-start_time)
</code></pre>
<pre><code>File &quot;SameOR-elb.py&quot;, line 352, in &lt;module&gt;
    local_models = federated_train(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\utils\function_utils.py&quot;,
line 561, in __call__
    return context.invoke(self, arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 49, in
wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 206, in
call
    return attempt.get(self._wrap_exception)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 247, in
get
    six.reraise(self.value[0], self.value[1], self.value[2])   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\six.py&quot;, line 703, in reraise
    raise value   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 200, in
call
    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py&quot;,
line 217, in invoke
    return event_loop.run_until_complete(   File &quot;C:\Users\Aw\Anaconda3\lib\asyncio\base_events.py&quot;, line 616, in
run_until_complete
    return future.result()   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
    return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py&quot;,
line 123, in _invoke
    result = await executor.create_call(comp, arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 343, in create_call
    return await comp_repr.invoke(self, arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 155, in invoke
    return await executor._evaluate(comp_lambda.result, new_scope)  # pylint: disable=protected-access   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 513, in _evaluate
    return await self._evaluate_block(comp, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 477, in _evaluate_block
    value = await self._evaluate(loc.value, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 507, in _evaluate
    return await self._evaluate_call(comp, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 446, in _evaluate_call
    return await self.create_call(func, arg=arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 339, in create_call
    return ReferenceResolvingExecutorValue(await   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py&quot;,
line 281, in create_call
    target_value = await cached_value.target_future   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 120, in create_call
    return await self._delegate(self._target_executor.create_call(comp, arg))   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 105, in _delegate
    result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
    return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federating_executor.py&quot;,
line 445, in create_call
    return await self._strategy.compute_federated_intrinsic(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federating_executor.py&quot;,
line 139, in compute_federated_intrinsic
    return await fn(arg)  # pylint: disable=not-callable   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federated_resolving_strategy.py&quot;,
line 453, in compute_federated_map
    return await self._map(arg, all_equal=False)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federated_resolving_strategy.py&quot;,
line 320, in _map
    results = await asyncio.gather(*[   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 343, in create_call
    return await comp_repr.invoke(self, arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 155, in invoke
    return await executor._evaluate(comp_lambda.result, new_scope)  # pylint: disable=protected-access   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 513, in _evaluate
    return await self._evaluate_block(comp, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 477, in _evaluate_block
    value = await self._evaluate(loc.value, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 507, in _evaluate
    return await self._evaluate_call(comp, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 445, in _evaluate_call
    func, arg = await asyncio.gather(func, get_arg())   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 501, in _evaluate
    return await self._evaluate_to_delegate(comp, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 410, in _evaluate_to_delegate
    await self._target_executor.create_value(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py&quot;,
line 245, in create_value
    await cached_value.target_future   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 110, in create_value
    return await self._delegate(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 105, in _delegate
    result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
    return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 464, in create_value
    return EagerValue(value, self._tf_function_cache, type_spec, self._device)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 366, in __init__
    self._value = to_representation_for_type(value, tf_function_cache,   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 287, in to_representation_for_type
    embedded_fn = embed_tensorflow_computation(value, type_spec, device)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 153, in embed_tensorflow_computation
    raise TypeError('Expected a TensorFlow computation, found {}.'.format( TypeError: Expected a TensorFlow computation, found
intrinsic.
</code></pre>
<p>I got these errors. I need suggestions.</p>
<p>I am using  <code>tf 2.2.1</code></p>
<p>Python 3.8.3 version</p>
",7996402,,,user15801675,44425.17824,44425.17824,"Expected a TensorFlow computation, found intrinsic",<python><tensorflow><machine-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
65527210,1,65591930,,44197.16777,,0,302,"<p>hello guys i am new in machine learning. I am implementing federated learning on with <strong>LSTM to predict the next label in a sequence</strong>. my sequence looks like this <em><strong>[2,3,5,1,4,2,5,7]</strong></em>. for example, the intention is predict the 7 in this sequence. So I tried a simple federated learning with keras. I used this approach for another model(Not LSTM) and it worked for me, but here it always overfits on 2. it always predict 2 for any input. I made the input data so balance, means there are almost equal number for each label in last index (here is 7).<strong>I tested this data on simple deep learning and greatly works</strong>. so it seems to me this data mybe is not suitable for LSTM or any other issue. Please help me. This is my Code for my federated learning. Please let me know if more information is needed, I really need it. Thanks</p>
<pre><code>def get_lstm(units):
    &quot;&quot;&quot;LSTM(Long Short-Term Memory)
    Build LSTM Model.

    # Arguments
        units: List(int), number of input, output and hidden units.
    # Returns
        model: Model, nn model.
    &quot;&quot;&quot;
    model = Sequential()
    inp = layers.Input((units[0],1))
    x = layers.LSTM(units[1], return_sequences=True)(inp)
    x = layers.LSTM(units[2])(x)
    x = layers.Dropout(0.2)(x)
    out = layers.Dense(units[3], activation='softmax')(x)

    model = Model(inp, out)



 optimizer = keras.optimizers.Adam(lr=0.01)

seqLen=8 -1;
global_model = Mymodel.get_lstm([seqLen, 64, 64, 15]) # 14 categories we have , array start from 0 but never can predict zero class
global_model.compile(loss=&quot;sparse_categorical_crossentropy&quot;, optimizer=optimizer, metrics=tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1)) 

def main(argv): 



 for comm_round in range(comms_round):
            print(&quot;round_%d&quot; %( comm_round))
            scaled_local_weight_list = list()
            global_weights = global_model.get_weights()
            np.random.shuffle(train) 
            temp_data = train[:]
            
            # data divided among ten users and shuffled
            for user in range(10):
                user_data = temp_data[user * userDataSize: (user+1)*userDataSize]

                X_train = user_data[:, 0:seqLen]
                X_train = np.asarray(X_train).astype(np.float32)
                Y_train = user_data[:, seqLen]    
                Y_train = np.asarray(Y_train).astype(np.float32)
                local_model = Mymodel.get_lstm([seqLen, 64, 64, 15])
                X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
                                                         
                local_model.compile(loss=&quot;sparse_categorical_crossentropy&quot;, optimizer=optimizer, metrics=tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1))
                local_model.set_weights(global_weights)
                

                local_model.fit(X_train, Y_train)
                scaling_factor = 1 / 10 # 10 is number of users
                scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)
                scaled_local_weight_list.append(scaled_weights)
                K.clear_session()

            average_weights = sum_scaled_weights(scaled_local_weight_list)
            global_model.set_weights(average_weights)


predictions=global_model.predict(X_test)
for i in range(len(X_test)):
    print('%d,%d' % ((np.argmax(predictions[i])), Y_test[i]),file=f2 )
</code></pre>
",9137963,,14692,,44197.22049,44202.32102,LSTM sequence prediction overfits on one specific value only,<machine-learning><keras><lstm><federated-learning>,1,0,,,,CC BY-SA 4.0
65553960,1,,,44199.80791,,2,582,"<p>My problem is a continue to this question <a href=""https://stackoverflow.com/questions/58965488/how-to-create-federated-dataset-from-a-csv-file"">How to create federated dataset from a CSV file?</a></p>
<p>i manage to load a federated dataset from a given csv file and load both the train and the test data.</p>
<p>My question now is how to reproduce a working example to build an iterative process that performs a custom federated averaging on this data.</p>
<p>Here is my code but it's not working:</p>
<pre><code>import os

import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_federated as tff
from absl import app
from tensorflow.keras import layers

from src.main import Parameters


def main(args):
    working_dir = &quot;D:/User/Documents/GitHub/TriaBaseMLBackup/input/fakehdfs/nms/ystr=2016/ymstr=1/ymdstr=26&quot;
    client_id_colname = 'counter'
    SHUFFLE_BUFFER = 1000
    NUM_EPOCHS = 1

    for root, dirs, files in os.walk(working_dir):
        file_list = []

        for filename in files:
            if filename.endswith('.csv'):
                file_list.append(os.path.join(root, filename))
        df_list = []
        for file in file_list:
            df = pd.read_csv(file, delimiter=&quot;|&quot;, usecols=[1, 2, 6, 7], header=None, na_values=[&quot;NIL&quot;],
                             na_filter=True, names=[&quot;meas_info&quot;, &quot;counter&quot;, &quot;value&quot;, &quot;time&quot;], index_col='time')
            df_list.append(df[[&quot;value&quot;]])

        if df_list:
            rawdata = pd.concat(df_list)

    client_ids = df.get(client_id_colname)
    train_client_ids = client_ids.sample(frac=0.5).tolist()
    test_client_ids = [x for x in client_ids if x not in train_client_ids]

    def create_tf_dataset_for_client_fn(client_id):
        # a function which takes a client_id and returns a
        # tf.data.Dataset for that client
        client_data = df[df['value'] == client_id]
    features = ['meas_info', 'counter']
    LABEL_COLUMN = 'value'
    dataset = tf.data.Dataset.from_tensor_slices(
        (collections.OrderedDict(client_data[features].to_dict('list')),
         client_data[LABEL_COLUMN].to_list())
    )
    global input_spec
    input_spec = dataset.element_spec
    dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)
    return dataset

    train_data = tff.simulation.ClientData.from_clients_and_fn(
        client_ids=train_client_ids,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
    test_data = tff.simulation.ClientData.from_clients_and_fn(
        client_ids=test_client_ids,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
    example_dataset = train_data.create_tf_dataset_for_client(
        train_data.client_ids[0]
    )
    # split client id into train and test clients
    loss_builder = tf.keras.losses.SparseCategoricalCrossentropy
    metrics_builder = lambda: [tf.keras.metrics.SparseCategoricalAccuracy()]
    tff_model = tf.keras.Sequential([
        layers.Dense(64),
        layers.Dense(1)
    ])

    def retrieve_model():
    model = tf.keras.models.Sequential([
        tf.keras.layers.LSTM(2, input_shape=(1,2), return_sequences=True),
        tf.keras.layers.Dense(256, activation=tf.nn.relu),
        tf.keras.layers.Activation(tf.nn.softmax),
    ])

    return model

    def tff_model_fn() -&gt; tff.learning.Model:
        return tff.learning.from_keras_model(
            keras_model=retrieve_model(),
            input_spec=example_dataset.element_spec,
            loss=loss_builder(),
            metrics=metrics_builder())

    iterative_process = tff.learning.build_federated_averaging_process(
        tff_model_fn, Parameters.server_adam_optimizer_fn, Parameters.client_adam_optimizer_fn)
    server_state = iterative_process.initialize()

    for round_num in range(Parameters.FLAGS.total_rounds):
        sampled_clients = np.random.choice(
            train_data.client_ids,
            size=Parameters.FLAGS.train_clients_per_round,
            replace=False)
        sampled_train_data = [
            train_data.create_tf_dataset_for_client(client)
            for client in sampled_clients
        ]
        server_state, metrics = iterative_process.next(server_state, sampled_train_data)
        train_metrics = metrics['train']
        print(metrics)


if __name__ == '__main__':
    app.run(main)


def start():
    app.run(main)
</code></pre>
<p>This is the error that I got but I think my problem is more than this error. what I am doing wrong here ??</p>
<pre><code>ValueError: The top-level structure in `input_spec` must contain exactly two top-level elements, as it must specify type information for both inputs to and predictions from the model. You passed input spec {'meas_info': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'counter': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'value': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}.
</code></pre>
<p><a href=""https://i.sstatic.net/w1t2L.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/w1t2L.png"" alt=""enter image description here"" /></a></p>
<p>thnx to @Zachary Garrett
i solve the above error with his help by adding these line of code</p>
<pre><code> client_data = df[df['value'] == client_id]
        features = ['meas_info', 'counter']
        LABEL_COLUMN = 'value'
        dataset = tf.data.Dataset.from_tensor_slices(
            (collections.OrderedDict(client_data[features].to_dict('list')),
             client_data[LABEL_COLUMN].to_list())
        )
        global input_spec
        input_spec = dataset.element_spec
        dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)
        return dataset
</code></pre>
<p>My problem now that is throwing in the <code>tff.learning.build_federated_averaging_process</code> is this</p>
<pre><code>ValueError: Layer sequential expects 1 inputs, but it received 2 input tensors. Inputs received: [&lt;tf.Tensor 'batch_input:0' shape=() dtype=float32&gt;, &lt;tf.Tensor 'batch_input_1:0' shape=() dtype=float32&gt;]
</code></pre>
<p>what i miss again? maybe something in the layer sequential here</p>
<pre><code>def retrieve_model():
        model = tf.keras.models.Sequential([
            tf.keras.layers.LSTM(2, input_shape=(1,2), return_sequences=True),
            tf.keras.layers.Dense(256, activation=tf.nn.relu),
            tf.keras.layers.Activation(tf.nn.softmax),
        ])

        return model
</code></pre>
",3163824,,3163824,,44205.55155,44205.55155,How to build federated_averaging_process from custom federated dataset that loads from CSV file,<python><tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
73083132,1,73083287,,44764.66872,,-1,304,"<p>I am using the Flower code example to try POC of Federated Learning but I keep getting the error below when I run the client.py file:</p>
<pre class=""lang-bash prettyprint-override""><code>INFO flower 2022-07-04 15:27:37,301 | connection.py:102 | Opened insecure gRPC connection (no certificates were passed)
DEBUG flower 2022-07-04 15:27:37,323 | connection.py:39 | ChannelConnectivity.IDLE
DEBUG flower 2022-07-04 15:27:37,389 | connection.py:39 | ChannelConnectivity.CONNECTING
DEBUG flower 2022-07-04 15:27:37,708 | connection.py:39 | ChannelConnectivity.READY
Training finished for round 5
DEBUG flower 2022-07-04 15:27:41,178 | connection.py:121 | gRPC channel closed
Traceback (most recent call last):
File &quot;C:\Users\HP\Development\Federated-Learning-sklearn\sklearnff\client.py&quot;, line 52, in
fl.client.start_numpy_client(
File &quot;C:\Users\HP.virtualenvs\sklearnff-UZKgGLZy\lib\site-packages\flwr\client\app.py&quot;, line 173, in start_numpy_client
start_client(
File &quot;C:\Users\HP.virtualenvs\sklearnff-UZKgGLZy\lib\site-packages\flwr\client\app.py&quot;, line 94, in start_client
client_message, sleep_duration, keep_going = handle(
File &quot;C:\Users\HP.virtualenvs\sklearnff-UZKgGLZy\lib\site-packages\flwr\client\grpc_client\message_handler.py&quot;, line 61, in handle
return _fit(client, server_msg.fit_ins), 0, True
File &quot;C:\Users\HP.virtualenvs\sklearnff-UZKgGLZy\lib\site-packages\flwr\client\grpc_client\message_handler.py&quot;, line 117, in _fit
fit_res = client.fit(fit_ins)
File &quot;C:\Users\HP.virtualenvs\sklearnff-UZKgGLZy\lib\site-packages\flwr\client\numpy_client.py&quot;, line 203, in fit
raise Exception(EXCEPTION_MESSAGE_WRONG_RETURN_TYPE_FIT)
Exception:
NumPyClient.fit did not return a tuple with 3 elements.
The returned values should have the following type signature:

Tuple[List[np.ndarray], int, Dict[str, Scalar]]
Example
model.get_weights(), 10, {&quot;accuracy&quot;: 0.95}
</code></pre>
",12221987,,,,,44764.67839,I'm getting an **NumPyClient.fit did not return a tuple with 3 elements.** error when I run client.py file. What could be the problem?,<python><scikit-learn><data-science><flower><federated-learning>,1,0,,44767.39743,,CC BY-SA 4.0
73326892,1,,,44784.87943,,1,254,"<p>I am very interested in federated systems and i was trying one of the pre trained multilingual models such as this notebook <a href=""https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.2_Multi_Lingual_Training_and_models.ipynb"" rel=""nofollow noreferrer"">Multi_Lingual_Training_and_models</a>.</p>
<p>I was looking for any tutorials using TFF or Flower frameworks that handle csv datasets.</p>
<p>So could you suggest any tutorials or github repositories to help me do that with TFF or Flower!</p>
",14208343,,14208343,,44784.88146,45319.37374,How to build a federated system with CSV dataset with SparkNL library?,<tensorflow-federated><flower><federated-learning><johnsnowlabs-spark-nlp>,0,0,,,,CC BY-SA 4.0
73407373,1,,,44791.73873,,1,204,"<p>I want to build a TFF model for speech recognition systems. For this, I use the CNN-GRU model architecture with a CTC loss function. but I got error when I wanted to build_federated_averaging_process and think it's about the ctc_loss function but I cant fix it.</p>
<p>part of my code is:</p>
<pre><code>def CTCLoss(y_true, y_pred):
    # Compute the training-time loss value
    batch_len = tf.cast(tf.shape(y_true)[0], dtype=&quot;int64&quot;)
    input_length = tf.cast(tf.shape(y_pred)[1], dtype=&quot;int64&quot;)
    label_length = tf.cast(tf.shape(y_true)[1], dtype=&quot;int64&quot;)

    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=&quot;int64&quot;)
    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=&quot;int64&quot;)

    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)
    return loss

def create_compiled_keras_model():
    &quot;&quot;&quot;Model similar to DeepSpeech2.&quot;&quot;&quot;
    # Model's input
    input_spectrogram = layers.Input((None, fft_length // 2 + 1), name=&quot;input&quot;)
    # Expand the dimension to use 2D CNN.
    x = layers.Reshape((-1, fft_length // 2 + 1 , 1), name=&quot;expand_dim&quot;)(input_spectrogram)
    # Convolution layer 1
    x = layers.Conv2D(
        filters=32,
        kernel_size=[11, 41],
        strides=[2, 2],
        padding=&quot;same&quot;,
        use_bias=False,
        name=&quot;conv_1&quot;,
    )(x)
    x = layers.BatchNormalization(name=&quot;conv_1_bn&quot;)(x)
    x = layers.ReLU(name=&quot;conv_1_relu&quot;)(x)
    # Convolution layer 2
    x = layers.Conv2D(
        filters=32,
        kernel_size=[11, 21],
        strides=[1, 2],
        padding=&quot;same&quot;,
        use_bias=False,
        name=&quot;conv_2&quot;,
    )(x)
    x = layers.BatchNormalization(name=&quot;conv_2_bn&quot;)(x)
    x = layers.ReLU(name=&quot;conv_2_relu&quot;)(x)
    # Reshape the resulted volume to feed the RNNs layers
    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)
    # RNN layers
    for i in range(1, 2 + 1):
        recurrent = layers.GRU(
            units=128,
            activation=&quot;tanh&quot;,
            recurrent_activation=&quot;sigmoid&quot;,
            use_bias=True,
            return_sequences=True,
            reset_after=True,
            name=f&quot;gru_{i}&quot;,
        )
        x = layers.Bidirectional(
            recurrent, name=f&quot;bidirectional_{i}&quot;, merge_mode=&quot;concat&quot;
        )(x)
        if i &lt; 2:
            x = layers.Dropout(rate=0.5)(x)
    # Dense layer
    x = layers.Dense(units=128 * 2, name=&quot;dense_1&quot;)(x)
    x = layers.ReLU(name=&quot;dense_1_relu&quot;)(x)
    x = layers.Dropout(rate=0.5)(x)
    # Classification layer
    output = layers.Dense(units= output_dim + 1, activation=&quot;softmax&quot;)(x)
    # Model
    model = keras.Model(input_spectrogram, output, name=&quot;DeepSpeech_2&quot;)
    
    return model

def model_fn():
  # We _must_ create a new model here, and _not_ capture it from an external
  # scope. TFF will call this within different graph contexts.
  keras_model = create_compiled_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=layers.Input((None, fft_length // 2 + 1)),
      loss=CTCLoss)
</code></pre>
<p>and I got error in this step :</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda:keras.optimizers.Adam(learning_rate=1e-4))

TypeError: Expected keras.losses.Loss, found function.
</code></pre>
<p>how do I fix it?</p>
",17945316,,,,,44801.19262,"TypeError: Expected keras.losses.Loss, found function",<tensorflow><keras><tensorflow-federated><federated-learning><ctc>,1,0,,,,CC BY-SA 4.0
73431551,1,,,44794.17002,,0,198,"<p>I have two kinds of covid 19 datasets as two clients (the first one ST Scan images and the second is XRays images) and I use federated learning approch.
The question is can I use those dataset as two clients although they have different type to acheive the heterogeneity and try to solve it ?</p>
",19811583,,19811583,,44794.17065,44964.6556,Federated learning,<python><dataset><federated-learning>,1,1,,,,CC BY-SA 4.0
73456900,1,,,44796.42664,,3,736,"<p>I have just started using <code>pysyft</code> to implement federated-learning. While following one of the tutorials, I got stuck on an error:</p>
<p><a href=""https://i.sstatic.net/SbGt4.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/SbGt4.png"" alt=""enter image description here"" /></a></p>
<p>Code which I have used:</p>
<pre><code>import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
import logging
import syft as sy

westside = sy.VirtualMachine(name = &quot;westside&quot;)
grapevine = sy.VirtualMachine(name = &quot;grapevine&quot;)

# Introducing hyperparameters to control the learning process
args = {
    'use_cuda': True,
    'batch_size': 64,
    'test_batch_size': 1000,
    'lr': 0.01,
    'log_interval': 100,
    'epochs': 10
}

# Check to use GPU or not
use_cuda = args['use_cuda'] and torch.cuda.is_available()
device = torch.device('cuda' if use_cuda else 'cpu')

# Create a simple CNN net
class Net(nn.Module):
    
    def __init__(self):
        super(Net, self).__init__()
        
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels = 1, out_channels = 32, kernel_size = 3, stride = 1),
            nn.ReLU(),
            nn.Conv2d(in_channels=32,out_channels = 64, kernel_size = 3, stride = 1),
            nn.ReLU()
        )
        
        self.fc = nn.Sequential(
            nn.Linear(in_features=64*12*12, out_features=128),
            nn.ReLU(),
            nn.Linear(in_features=128, out_features=10),
        )
    
    def forward(self, x):
        x = self.conv(x)
        x = F.max_pool2d(x,2)
        x = x.view(-1, 64*12*12)
        x = self.fc(x)
        x = F.log_softmax(x, dim=1)
        return x

# Load the data and transform it into a federated dataset
federated_train_loader = sy.FederatedDataLoader(
    datasets.MNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate((grapevine, westside)),
    batch_size=args['batch_size'], shuffle=True)
</code></pre>
<p>The tutorial which I am following uses an old version of <code>pysyft</code> so the support for <code>hooks</code> has been deprecated. Also, I had to use <code>syft.VirtualMachine(name=&quot;Some-name&quot;)</code> instead of <code>syft.VirtualWorker(hook, id=&quot;Some-name&quot;)</code>. The purpose of <code>sy.FederatedDataLoader</code> as given in the tutorial is to load data and hence, transform it to <code>federated dataset</code>. This is the link for the <a href=""https://github.com/spmallick/learnopencv/blob/master/Federated-Learning-Intro/Federated_Learning_Tutorial.ipynb"" rel=""nofollow noreferrer"">tutorial</a>. Is there any equivalent function instead of <code>FederatedDataLoader()</code> to load data in the new version?</p>
",17324341,,,,,45275.22238,AttributeError: module 'syft' has no attribute 'FederatedDataLoader',<python><tensorflow><federated-learning><pysyft>,2,0,,,,CC BY-SA 4.0
73502727,1,,,44799.6103,,1,218,"<p>I am planning to use Opacus to implement differential privacy in my federated learning model but I have a very basic doubt that I would love to have cleared before that.</p>
<p>So as far as my understanding goes, using Opacus, we use an optimizer like DPSGD that adds differential noise to each batch of each clientâ€™s dataset while they are in â€œlocal trainingâ€. And in federated learning, we train client models for a few â€œlocal epochsâ€ before sending their weights out to a central server for aggregation, and we add differential noise before sending out the model weights.</p>
<p>So my question is, why do we use DPSGD to add noise to every single batch of every single client dataset during local training when we could just add noise to the local weights before they are sent out? Why do we not let the local training epochs happen as is and simply add noise to the outbound weights at the time of departure? What am I missing?</p>
",1655033,,,,,45313.55887,Noise addition to weights using Opacus in a Federated Learning setting,<pytorch><gradient-descent><privacy><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
65828005,1,,,44217.54271,,1,84,"<p>I've been using this function to load data from stackoverflow data_set. However, one problem occurs that every time I use this function and set cache_dir to the location of the keras/dataset or the location of the cache, it still tries to download the tar from the internet(Even when I have already the 8.5G tar file download in local). Is there a simple way to avoid downloading from the internet and access by local?</p>
<p>I've also tried to write the save and load function, but it seems they cannot be applied to HDF5ClientData type.</p>
",15052242,,,,,44217.54271,Question about tff.simulation.datasets.stackoverflow.load_data(cache_dir = None),<tensorflow><tensorflow-federated><loaddata><federated><federated-learning>,0,1,,,,CC BY-SA 4.0
66259690,1,,,44245.50719,,3,204,"<p>I train a ResNet50 model with TFF, I use test accuracy on test data for evaluation, but I find many fluctuations as shown in the figure below, So please how can I avoid this fluctuation ?</p>
<p><a href=""https://i.sstatic.net/JDtmg.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/JDtmg.png"" alt=""enter image description here"" /></a></p>
",14253961,,14692,,44258.30725,44258.30725,TFF : test accuracy fluctuate,<tensorflow-federated><federated-learning>,2,0,,,,CC BY-SA 4.0
66265109,1,,,44245.73031,,2,561,"<p>I am using Tensorflow Federated to train a text classification model with the federated learning approach.
Is there any way to apply Early Stopping on the client-side? Is there an option for cross-validation in the API?
The only thing I was able to find is the evaluation:</p>
<pre><code>evaluation = tff.learning.build_federated_evaluation(model_fn)
</code></pre>
<p>Which is applied to the model by the end of a federated training round.</p>
<p>Am I missing something?</p>
",9745740,,,,,44247.21334,"Federated Learning in Tensorflow Federated, is there any way to apply Early stopping on the client side?",<tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66277912,1,66288191,,44246.53603,,1,322,"<p>I use human activity recognition (HAR) dataset with 6 classes using federated learning (FL). In this case, I implement the non-IID dataset by assigning (1) each class dataset to different 6 workers, (2) two classes to 3 different workers, and (3) three classes to 2 different workers.</p>
<p>When I run the FL process, the validation accuracy for scenario (3) &gt; (2) &gt; (1). I expect that all scenarios will obtain almost the same validation accuracy. For each scenario, I use the same hyperparameter settings including batch size, shuffle buffer, and the model configuration.</p>
<p>Is it common in FL with the non-IID dataset or is there any problem with my result?</p>
",10988616,,,,,44247.59326,The validation accuracy gets lower when the number of workers increases in Federated Learning with non-IID dataset,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66289113,1,66291126,,44247.31427,,0,151,"<p>I try to use <code>np.array.split</code> to split the dataset into 2 part, but it does not work well</p>
<p>Hope some one can give some advice on this issue</p>
<pre><code>x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (14218, 32, 32, 3), y.shape = (2, 7109, 10)
</code></pre>
<p>Code part</p>
<pre><code>y_train = utils.to_categorical(y_train_data, number_of_classes)  # one-hot encoding
y_test = utils.to_categorical(y_test_data, number_of_classes)   # one-hot encoding
# æŸ¥çœ‹ä¸€ä¸ªç±»åˆ«æ ·æœ¬
print('å¯¹åº”ç±»åˆ«ä¸º7\n', y_train[1])

'''clients_num = 2
X_train = np.array_split(X_train, clients_num)
y_train = np.array_split(y_train, clients_num)
print(np.shape(y_train))'''

input_shape = (img_rows, img_cols, 1)

rgb_batch = np.repeat(X_train_data[..., np.newaxis], 3, -1)
rgb_batch1 = np.repeat(X_test_data[..., np.newaxis], 3, -1)

X_train = tf.image.resize(rgb_batch, (32, 32))
X_test = tf.image.resize(rgb_batch1, (32, 32))

tf.dtypes.cast(X_train, tf.float32)
tf.dtypes.cast(X_test, tf.float32)

X_train /= 255.0
X_test /= 255.0
</code></pre>
",15187453,,,,,44247.48957,"How to split the dataset into train and test based on client number using ""Federated learning""",<python><tensorflow><federated-learning>,1,1,,,,CC BY-SA 4.0
66304067,1,66304876,,44248.65535,,0,173,"<p>I am trying to follow this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation"" rel=""nofollow noreferrer"">tutorial</a> on federated learning TensorFlow and when executing this line I get an error:</p>
<pre><code>train_data, test_data = tff.simulation.datasets.shakespeare.load_data()
</code></pre>
<p>The error:</p>
<pre><code>    Downloading shakespeare.sqlite.lzma:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1048576/1329828 [00:00&lt;00:00, 12187174.26it/s]
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
&lt;ipython-input-12-f8f1fc62c096&gt; in &lt;module&gt;()
----&gt; 1 train_data, test_data = tff.simulation.datasets.shakespeare.load_data()

4 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py in _prewrite_check(self)
     86                                            &quot;File isn't open for writing&quot;)
     87       self._writable_file = _pywrap_file_io.WritableFile(
---&gt; 88           compat.path_to_bytes(self.__name), compat.as_bytes(self.__mode))
     89 
     90   def _prepare_value(self, val):

NotFoundError: /root/.tff/shakespeare.sqlite; No such file or directory
</code></pre>
<p><a href=""https://i.sstatic.net/7OWh2.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
",8421958,,,,,44248.71486,Error while executing federated learning text generation tutorial in Colab,<tensorflow><google-colaboratory><tensorflow-datasets><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66312016,1,,,44249.33734,,0,64,"<pre><code>Epoch 1/8
222/222 [==============================] - 18s 67ms/step - loss: 1.4523 - accuracy: 0.9709 - val_loss: 1.3310 - val_accuracy: 0.9865
Epoch 2/8
222/222 [==============================] - 14s 63ms/step - loss: 1.3345 - accuracy: 0.9747 - val_loss: 1.2312 - val_accuracy: 0.9865
Epoch 3/8
222/222 [==============================] - 14s 64ms/step - loss: 1.1911 - accuracy: 0.9868 - val_loss: 1.1245 - val_accuracy: 0.9887
Epoch 4/8
222/222 [==============================] - 14s 63ms/step - loss: 1.0926 - accuracy: 0.9873 - val_loss: 1.0798 - val_accuracy: 0.9769
Epoch 5/8
222/222 [==============================] - 14s 63ms/step - loss: 1.0622 - accuracy: 0.9760 - val_loss: 1.0887 - val_accuracy: 0.9555
Epoch 6/8
222/222 [==============================] - 14s 63ms/step - loss: 0.9589 - accuracy: 0.9841 - val_loss: 0.9216 - val_accuracy: 0.9814
Epoch 7/8
222/222 [==============================] - 14s 64ms/step - loss: 0.8648 - accuracy: 0.9885 - val_loss: 0.8241 - val_accuracy: 0.9896
Epoch 8/8
222/222 [==============================] - 14s 63ms/step - loss: 0.7993 - accuracy: 0.9908 - val_loss: 0.7694 - val_accuracy: 0.9893
Model: &quot;model_5&quot;
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_6 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
model_1 (Functional)         (None, 10)                3250058   
=================================================================
Total params: 3,250,058
Trainable params: 3,228,170
Non-trainable params: 21,888
_________________________________________________________________
Epoch 1/8
222/222 [==============================] - 18s 66ms/step - loss: 1.4423 - accuracy: 0.9741 - val_loss: 1.3361 - val_accuracy: 0.9839
Epoch 2/8
222/222 [==============================] - 14s 64ms/step - loss: 1.3457 - accuracy: 0.9734 - val_loss: 1.2327 - val_accuracy: 0.9845
Epoch 3/8
222/222 [==============================] - 14s 63ms/step - loss: 1.1927 - accuracy: 0.9893 - val_loss: 1.1287 - val_accuracy: 0.9870
</code></pre>
<p>this is my output, as you can see when I load the model after training, the value of the loss is still the same compared with the value before training. I am really confused about it.</p>
<p>This is my code, I want to use two models (After combining, Final combining), and I use <code>load_mode</code> and <code>model.save</code> . Cuz I want to mimic Federated Learning process.</p>
<p>Hope someone can give me some ideas.</p>
<pre><code>def train2():
  img_input = Input(shape=(32, 32, 3))
  Mobilenet2 = load_model('Final combining.h5')
  output = Mobilenet2(img_input)
  model = Model(img_input, output)
  model.summary()

  # set optimizer
  sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)
  model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

  # start training
  h2 = model.fit(X_train2, y_2_train, batch_size=batch_size,
                  steps_per_epoch=len(X_train2) // batch_size,
                  epochs=epochs1,
                  # callbacks=cbks,
                  validation_data=(X_test, y_test))
                  # callbacks=callbacks                 
  
  model.save('After combining.h5')

def train3():
  img_input = Input(shape=(32, 32, 3))
  Mobilenet1 = load_model('After combining.h5')
  output = Mobilenet1(img_input)
  model = Model(img_input, output)
  model.summary()

  # set optimizer
  sgd = optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)
  model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])

  # start training
  h3 = model.fit(X_train1, y_1_train, batch_size=batch_size,
                  steps_per_epoch=len(X_train1) // batch_size,
                  epochs=epochs1,
                  # callbacks=cbks,
                  validation_data=(X_test, y_test))
                  # callbacks=callbacks   
  
  model.save('Final combining.h5')
</code></pre>
<p>I use the <code>for</code> loop to control the training process, the output is the last iteration... , the value of accuracy and loss is almost the same compared with the first iteration</p>
<pre><code>for _ in range(5):
  num = 0
  if num % 2==0:
    train2()
    num+=1
  else:
    train3()
    num+=1
</code></pre>
",15187453,,15187453,,44249.34689,44249.49919,"Keras load model after saving the model, why start training from the beginningï¼Ÿ",<tensorflow><keras><federated-learning>,1,15,,,,CC BY-SA 4.0
66395599,1,,,44254.18641,,0,405,"<p>I plan to use federated learning for an object detection algorithm I already developed for detecting weeds.
As I research, I see federated tensorflow examples on Image classification. Like the following link:
<a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification</a></p>
<p>My question is can we use federated learning and federated tensorflow for object detection algorithms?
If yes, would you please provide me with some links and examples?</p>
",8617125,,,,,44291.0398,Using federated learning for object detection,<object-detection><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66546336,1,,,44264.49307,,1,151,"<p>In the federated learning context, and like this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">tutorial</a> shows, initial weights of global model (at server level) are initialized randomly with : <code> state = iterative_process.initialize()</code>. I want to have the hand to put these initial weights by downloading them from another model (<code>load_model()</code>). So please how can I proceed, I'm newer in TFF.
Thanks</p>
",14253961,,,,,44299.04198,the initialize computation to construct the server state,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66576677,1,66888033,,44266.20372,,-1,433,"<p>I am working on a federated learning to detect bad clients.</p>
<p>Brief about federated learning - Data is divided into various clients, training is done on client side and the results are then sent by each client to central server where aggregation of the client weights is done and the aggregated model is then again sent to local clients for training.</p>
<p>I am working on detection of client sending malicious updates to central server. I am using base code present <a href=""https://towardsdatascience.com/federated-learning-a-step-by-step-implementation-in-tensorflow-aac568283399"" rel=""nofollow noreferrer"">here</a>.</p>
<p>I wrote a method filter client which will detect if some client is malicious and remove that client from aggregation step. I expected that there will not be much performance difference if one of the client weight is remove from global aggregation but the results are confusing me. I added this piece of code. noisy_client[itr] != 0 will only occur for 1/10 clients and it will occur for the same client in each iteration.</p>
<pre><code>if noisy_client[itr] == 0:
            scaled_local_weight_list.append(scaled_weights)
        
</code></pre>
<p>If this code is not used then the accuracy in each iteration is increasing steadily</p>
<pre><code>0.6102380952380952
0.7195238095238096
0.7723809523809524
0.8014285714285714
0.8195238095238095
0.8314285714285714
0.8397619047619047
0.8438095238095238
0.8516666666666667
0.8545238095238096
0.8573809523809524
0.8602380952380952
0.861904761904762
0.8635714285714285
0.8654761904761905
0.8671428571428571
0.8683333333333333
</code></pre>
<p>But when the code is used accuracy increases for first few iterations and decreases after that for each iteration</p>
<pre><code>0.6883333333333334 0.7373809523809524 0.7552380952380953 0.765 0.763095238095238 0.7559523809523809 0.7497619047619047 0.7414285714285714 0.7323809523809524 0.7221428571428572 0.7154761904761905 0.705952380952381 0.6966666666666667 0.6895238095238095 0.6819047619047619 0.6730952380952381 0.6597619047619048 0.6102380952380952
</code></pre>
<p>I have tried reducing the learning rate from 0.01 to 0.001 and also decreasing the batch size but saw the same behavior after that.
What can be the reason for this and how this can be corrected ?</p>
",12206939,,4685471,,44266.39821,44286.52608,Accuracy decreasing after iteration in federated learning setting,<python><tensorflow><machine-learning><mnist><federated-learning>,1,1,,,,CC BY-SA 4.0
66579541,1,,,44266.38751,,2,259,"<p>I'm new in Federated learning, I tried to implement the code of FL for image classification, but I can't understand this line : <code>state = iterative_process.initialize() </code>, Weights affected to the server from where ?</p>
",14253961,,,,,44290.32794,What state = iterative_process.initialize() dow in Federated learning,<tensorflow-federated><federated-learning>,1,2,,,,CC BY-SA 4.0
66581075,1,,,44266.45271,,2,1607,"<p>I implement the code of TFF of image classification. TFF version 0.18.0,
I write this :</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(model_fn, server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0), client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.001))

state = iterative_process.initialize()
</code></pre>
<p>But I find this warning:</p>
<pre><code>WARNING:tensorflow:AutoGraph could not transform &lt;function &lt;lambda&gt; at 0x7fca141a6d08&gt; and will run it as-is.
Cause: could not parse the source code of &lt;function &lt;lambda&gt; at 0x7fca141a6d08&gt;: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.
Match 0:
(lambda : tf.keras.optimizers.SGD(learning_rate=1.0))

Match 1:
(lambda : tf.keras.optimizers.SGD(learning_rate=0.001))

To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
</code></pre>
<p>So please how can I avoid this warning. Thanks</p>
",14253961,,,,,44291.03126,WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fca141a6d08> and will run it as-is,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66875831,1,,,44285.73458,,0,136,"<p>I am implementing <strong>federated deep Q-learning</strong> by PyTorch, using multiple agents, each running DQN.
My problem is that when I use multiple replay buffers for agents, each appending experiences at the corresponding agent, <strong>two elements of experiences in each agent replay buffer, i. e., &quot;current_state&quot; and &quot;next_state&quot;</strong> becomes the same after the first time slot. I mean in each buffer, we see <strong>the same values for current states and the same values for next states</strong>.
I have included simplified parts of the code and results below. Whay is it changing the current states and next states already exixting in the buffer when doing append? Is there something wrong with defining the buffers as a global variable? or do you have another idea?</p>
<pre><code>&lt;&lt;&lt; time 0 and agent 0:
current_state[0] = [1,2]
next_state[0] = [11,12]
*** experience: (array([ 1., 2.]), 2.0, array([200]), array([ 11., 12.]), 0)
*** buffer: deque([(array([ 1., 2.]), 2.0, array([200]), array([ 11., 12.]), 0)], maxlen=10000)

&lt;&lt;&lt; time 0 and agent 1: 
current_state[1] = [3, 4]
next_state[1] = [13, 14]
*** experience: (array([ 3., 4.]), 4.0, array([400]), array([ 13., 14.]), 0)
*** buffer: deque([(array([ 1., 2.]), 4.0, array([400]), array([ 11., 12.]), 0)], maxlen=10000)

&lt;&lt;&lt; time 1 and agent 0:
current_state = [11,12]
next_state[0] = [110, 120]
*** experience: (array([ 11., 12.]), 6.0, array([600]), array([ 110., 120.]), 0)
*** buffer: deque([(array([ 11., 12.]), 2.0, array([200]), array([ 110., 120.]), 0),(array([ 11., 12.]), 6.0, array([600]), array([ 110., 120.]), 0)], maxlen=10000)

&lt;&lt;&lt; time 1 and agent 1:
current_state = [13, 14]
next_state[1] = [130, 140]
*** experience: (array([ 13., 14.]), 8.0, array([800]), array([ 130., 140.]), 0)
*** buffer: deque([(array([ 13., 14.]), 4.0, array([400]), array([ 130., 140.]), 0),(array([ 13., 14.]), 8.0, array([800]), array([ 130., 140.]), 0)], maxlen=10000)
</code></pre>
<pre><code>class BasicBuffer:
def __init__(self, max_size):
    self.max_size = max_size
    self.buffer = deque(maxlen=10000)

def add(self, current_state, action, reward, next_state, done):
    ## &quot;&quot;&quot;&quot;Add a new experience to buffer.&quot;&quot;&quot;&quot;
    experience = (current_state, action, np.array([reward]), next_state, done)
    self.buffer.append(experience)

def DQNtrain(env, state_size, agent):
for time in range(time_max):
    for e in range(agents_numbers):
       current_state[e,:]
        next_state_edge[e, :] 
        ## &quot;&quot;&quot;&quot;Add a new experience to buffer.&quot;&quot;&quot;&quot;
        replay_buffer_t[e].add(current_state, action, reward, next_state, done)
        current_state[e, :] = next_state[e, :]

if __name__ == '__main__':
   DQNtrain(env, state_size, agent)
   replay_buffer_t = [[] for _ in range(edge_max)]
   for e in range(edge_max):
       replay_buffer_t[e] = BasicBuffer(max_size=agent_buffer_size)
</code></pre>
",11918948,,11918948,,44285.82802,44286.23206,Federated reinforcement learning,<python><pytorch><reinforcement-learning><deque><federated-learning>,1,0,,,,CC BY-SA 4.0
73524856,1,,,44802.26877,,0,133,"<p>In federated/ distributed learning, the server will send initially a global model to clients, and each client will train the model locally and then select the top k values, and send only these values to the server.</p>
<p><strong>How I can select an adaptive k in each client?</strong> rather than set top k value to fixed number (e.g. k=3, which return top 3 values), I want to make the top k values adaptive, for example, some clients will send top 4 values, other may send 6 top values based on a defined feature ( largest value, largest loss , ... etc)</p>
<p>Is there any way to do that?</p>
",18969005,,4685471,,44802.47512,44802.47512,Adaptive top-k selection in machine learning,<python><machine-learning><deep-learning><pytorch><federated-learning>,0,3,,,,CC BY-SA 4.0
74424083,1,,,44878.81113,,0,190,"<p>I would like to add different weights to clients in Federated learning, so in the aggregation stage, each client has a different impact on the global model.</p>
<p>For example:</p>
<pre><code>Client_1 has 2X impact
Client_2 has X impact
</code></pre>
<p>I am looking for suggestions to implement this approach.</p>
",4409800,,4685471,,44878.82537,45078.05578,Federated learning weighted aggregation,<python><machine-learning><data-science><federated-learning>,1,0,,,,CC BY-SA 4.0
74596793,1,,,44893.27203,,3,4386,"<p>Trying to implement the reaserch paper:
<a href=""https://ieeexplore.ieee.org/document/9479786/"" rel=""nofollow noreferrer"">https://ieeexplore.ieee.org/document/9479786/</a>
Training a Monotone Network with architechture:</p>
<pre class=""lang-py prettyprint-override""><code>class Model(nn.Module):
  def __init__(self, q, s):
    self.layer_s_list = [nn.Linear(5, s) for _ in range(q)]
    self.inv_w, self.inv_b = self.get_layer_weights()
      
  def forward(self, x):
    # print(inv_w[0].shape, inv_b[0].shape)
    output_lst = []
    for layer in self.layer_s_list:
      v, id = torch.max(layer(x), 1)
      output_lst.append(v.detach().numpy())
    output_lst = np.array(output_lst)
    output_lst = torch.from_numpy(output_lst)
    out, _ = torch.min(output_lst, 0)
    allo_out = F.softmax(out)
    pay_out = nn.ReLU(inplace = True)(out)
    inv_out_lst = []
    
    for q_idx in range(len(self.inv_w)):
      # print(inv_w[q_idx].shape, pay_out.shape, inv_b[q_idx].shape)
      y, _ = torch.min(torch.linalg.pinv(self.inv_w[q_idx]) * (pay_out - self.inv_b[q_idx]), 0)
      inv_out_lst.append(y.detach().numpy())
    final_out = np.array(inv_out_lst)
    final_out = torch.from_numpy(final_out)
    final_out, _ = torch.max(final_out, 1)
    return final_out, allo_out

  
  def get_layer_weights(self):
    weights_lst = []
    bias_lst = []
    for layer in self.layer_s_list:
      weights_lst.append(layer.state_dict()['weight'])
      bias_lst.append(layer.state_dict()['bias'])
    return weights_lst, bias_lst
</code></pre>
<p>When I initialise the network and run for random inputs:</p>
<pre class=""lang-py prettyprint-override""><code>q = 5
s = 10
x = torch.rand((10, 5), requires_grad = True)
net = Model(q, s)
y, z = net(x)`
</code></pre>
<p>It gives the following error:</p>
<pre><code>AttributeError                            Traceback (most recent call last)
&lt;ipython-input-3-aac6d239df1f&gt; in &lt;module&gt;
      1 x = torch.rand((10, 5), requires_grad = True)
      2 net = Model(5, 10)
----&gt; 3 y = net(x)

1 frames
/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py in __getattr__(self, name)
   1206                 return modules[name]
   1207         raise AttributeError(&quot;'{}' object has no attribute '{}'&quot;.format(
-&gt; 1208             type(self).__name__, name))
   1209 
   1210     def __setattr__(self, name: str, value: Union[Tensor, 'Module']) -&gt; None:

AttributeError: 'Model' object has no attribute '_backward_hooks'
</code></pre>
<p>Please help me understand what this error is and how to fix it.</p>
",12249140,,2847330,,44893.46824,44893.46824,AttributeError: 'Model' object has no attribute '_backward_hooks',<machine-learning><deep-learning><neural-network><data-science><federated-learning>,1,0,,,,CC BY-SA 4.0
67051923,1,,,44298.09855,,1,2595,"<p>I'm on windows but even in google Collab I cant import it.
and I do have proper internet.</p>
<pre class=""lang-py prettyprint-override""><code>from tensorflow_federated import python as tff
</code></pre>
",15607889,,10315163,,44298.1933,44308.54608,No module named 'tensorflow_fedarated',<python-3.x><tensorflow><google-colaboratory><federated-learning>,1,1,,,,CC BY-SA 4.0
67077765,1,,,44299.63994,,1,68,"<p>I am trying to use Federated code to build my own federated learning algorithm. But I met one problem. In the official tutorial, it define the Model Spec like following:</p>
<blockquote>
</blockquote>
<pre><code>MODEL_SPEC = collections.OrderedDict(
            filter1 = tf.TensorSpec(shape=weights[0].shape, dtype=tf.float32),
            bias1 = tf.TensorSpec(shape=weights[1].shape, dtype=tf.float32),
            filter2 = tf.TensorSpec(shape=weights[2].shape, dtype=tf.float32),
            bias2 = tf.TensorSpec(shape=weights[3].shape, dtype=tf.float32),
            weight1 = tf.TensorSpec(shape=weights[4].shape, dtype=tf.float32),
            bias3 = tf.TensorSpec(shape=weights[5].shape, dtype=tf.float32)
        )
        MODEL_TYPE = tff.to_type(MODEL_SPEC)
</code></pre>
<p>I am wondering if it is required to input the model as an OrderedDict. Could I input the model as a trainable Keras model?</p>
<p>Thanks!</p>
",15624043,,,,,44299.65244,MODEL_SPEC in Federated Learning (Using Tensorflow Federated Core),<tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
67567802,1,,,44333.42911,,0,142,"<p>I would like to update state, So here is what i wrote:</p>
<pre><code>def create_keras_model():
...
   return model
iterative_process = tff.learning.build_federated_averaging_process(..)

</code></pre>
<p>My problem is loss increase contrary to the accuracy which makes a small decrease:</p>
<pre><code>round  1, metrics=OrderedDict([('categorical_accuracy', 0.4675926), ('loss', 8.581259)])
round  2, metrics=OrderedDict([('categorical_accuracy', 0.65625), ('loss', 5.4126678)])
round  3, metrics=OrderedDict([('categorical_accuracy', 0.6018519), ('loss', 6.37924)])
round  4, metrics=OrderedDict([('categorical_accuracy', 0.587963), ('loss', 6.5979366)])
round  5, metrics=OrderedDict([('categorical_accuracy', 0.6400463), ('loss', 5.7463913)])
round  6, metrics=OrderedDict([('categorical_accuracy', 0.6909722), ('loss', 4.872179)])
round  7, metrics=OrderedDict([('categorical_accuracy', 0.6469907), ('loss', 5.6218925)])
round  8, metrics=OrderedDict([('categorical_accuracy', 0.7037037), ('loss', 4.723536)])
round  9, metrics=OrderedDict([('categorical_accuracy', 0.7002315), ('loss', 4.774122)])
round 10, metrics=OrderedDict([('categorical_accuracy', 0.7060185), ('loss', 4.6346316)])
round 11, metrics=OrderedDict([('categorical_accuracy', 0.6724537), ('loss', 5.213738)])
round 12, metrics=OrderedDict([('categorical_accuracy', 0.6608796), ('loss', 5.450448)])
</code></pre>
<p>Is there another solution to solve this problem ?
Thanks</p>
",14253961,,14253961,,44336.47571,44336.47571,"loss increase when updating ""State""",<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
67570514,1,,,44333.55565,,1,295,"<p>I'm newer in TFF, I work on this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">tutorial</a>. I would like to replace <code>keras_evaluate</code> function by predefined function of TFF : <code>evaluation = tff.learning.build_federated_evaluation(model)</code></p>
<p>So how can I edit those lines :</p>
<pre class=""lang-py prettyprint-override""><code>def keras_evaluate(state, round_num):
  # Take our global model weights and push them back into a Keras model to
  # use its standard `.evaluate()` method.
  keras_model = load_model(batch_size=BATCH_SIZE)
  keras_model.compile(
      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
      metrics=[FlattenedCategoricalAccuracy()])
  state.model.assign_weights_to(keras_model)
  loss, accuracy = keras_model.evaluate(example_dataset, steps=2, verbose=0)
  print('\tEval: loss={l:.3f}, accuracy={a:.3f}'.format(l=loss, a=accuracy))


for round_num in range(NUM_ROUNDS):
  print('Round {r}'.format(r=round_num))
  keras_evaluate(state, round_num)
  state, metrics = fed_avg.next(state, train_datasets)
  train_metrics = metrics['train']
  print('\tTrain: loss={l:.3f}, accuracy={a:.3f}'.format(
      l=train_metrics['loss'], a=train_metrics['accuracy']))

print('Final evaluation')
keras_evaluate(state, NUM_ROUNDS + 1)
</code></pre>
<p>In this line :</p>
<pre class=""lang-py prettyprint-override""><code>loss, accuracy = keras_model.evaluate(example_dataset, steps=2, verbose=0)
</code></pre>
<p>the function evaluate only on an example of dataset contrary to <code>build_federated_evaluation</code> , it evaluate on <code>federated_test_data</code> totally. So how can I modify this function to evaluate on the totality of <code>federated_test_data</code> like in the other <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">tutorial</a> : <code> test_metrics = evaluation(state.model, federated_test_data)</code></p>
",12682667,,14692,,44339.39968,44339.39968,use tff.learning.build_federated_evaluation instead of keras_evaluate,<tensorflow-federated><federated-learning>,0,2,,,,CC BY-SA 4.0
67602060,1,,,44335.46402,,0,77,"<p>I would like to print (before training) the state of model :
with  <code>print(state['model'])</code>,
I found this error :</p>
<pre><code>TypeError: 'ServerState' object is not subscriptable

</code></pre>
",14253961,,,,,44335.47909,How to print state of model in Federated learning,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
67633859,1,67635068,,44337.37932,,2,156,"<p>I'm training a DP federated learning model using the &quot;DP-FedAvg&quot; algorithm, which is based on below paper:</p>
<p><a href=""https://arxiv.org/abs/1710.06963"" rel=""nofollow noreferrer"">Learning Differentially Private Recurrent Language Models</a></p>
<p>The paper proposes two norm clipping techniques &quot;flat clipping&quot; and &quot;per-layer clipping&quot;, then performs the experiments using &quot;per-layer clipping&quot;.</p>
<p>In case of TFF, when attaching a DP-query and an aggregation process to the federated model, which clipping technique is implemented by default? Is there a way to specify the clipping technique used?</p>
",15092004,,4621513,,44338.7114,44338.7114,Norm clipping technique in TFF,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
67634399,1,,,44337.40288,,1,113,"<p>I practice on this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">tutorial</a>, I would like that each client train a different architecture and different model, Is this possible?</p>
",14253961,,,,,44337.54692,"In FL, can clients train different model architectures?",<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
67678734,1,,,44340.86285,,0,212,"<p>i create a CNN model like this <code>global_model = CNNMnist(args=args)</code>. Then i send it to device, set it to train. Then i train my local models, collect the local_weights and the average them to get updated global_model.
Now i am trying to get the items from the <code>.parameters()</code> function but all i get is <code>None</code> as <code>item.grad</code>. When i do the same thing for the local_models, i get the desired output. What am i doing wrong?</p>
<pre><code>global_model.to(device)
global_model.train()
...................
global_weights = average_weights(local_weights)
global_model.load_state_dict(global_weights)
last_update = []
for item in global_model.parameters():
    last_update.append(copy.deepcopy(item.grad))
    print(item.grad)

Output: None None None None None None None None
</code></pre>
<p>Any help would be appreciated.</p>
",11446390,,,,,44341.21545,The parameters of a CNN model is returning None,<pytorch><conv-neural-network><federated-learning>,1,0,,,,CC BY-SA 4.0
67810671,1,,,44349.77281,,2,80,"<p>I am trying to implement a Differentially private FL binary classification model using gaussian adaptive clipping geometric method.</p>
<pre><code>aggregation_factory = tff.aggregators.DifferentiallyPrivateFactory.gaussian_adaptive(
            noise_multiplier=0.6,
            clients_per_round=10,
            initial_l2_norm_clip=0.1,
            target_unclipped_quantile=0.8,
            learning_rate=0.2)
</code></pre>
<p>I know that the initial_l2_norm_clip is the initial value of clipping norm which is updated based on the target_unclipped_quantile value.</p>
<p>How can we determine the appropriate value of initial_l2_norm_clip for a particular model?</p>
<p>when I set it (initial_l2_norm_clip) to 0.1 I am getting a really low AOC (around 0.4) but when I set it to a higher value of 1.0 I am getting a better AOC value (around 0.8) and in both cases the 'clip' metric which is recorded by the iterative process always increases (i.e it goes from 0.1 to 0.3 and 1.0 to 1.2)</p>
<p>my model is running for 13 rounds with 10 clients per round does this make a difference?</p>
",15995765,,,,,44350.26228,What does intial_clip_norm mean in gaussian adaptive clipping in TFF?,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
67842524,1,,,44351.78103,,0,159,"<p>I am performing Federated learning using pysyft and pytorch. I am using a diabetes dataset.  I got this error while training(element 0 of tensors does not require grad and does not have a grad_fn). I am attaching the screen shots of my error and also the note book file:</p>
<p><img src=""https://i.sstatic.net/UA8J0.png"" alt=""enter image description here"" /></p>
<p>My code:</p>
<pre class=""lang-py prettyprint-override""><code>epochs = 500
final_loss = []
for i in range(epochs):
    i = i + 1
    model.train()
    for batch_idx, (data, target) in enumerate(federated_train_loader): # &lt;-- now it is a distributed dataset
        model.send(data.location) # &lt;-- NEW: send the model to the right location
   
        data, target = data.to(device), target.to(device)
        output = model.forward(data)
        loss = loss_function(output, target)
        final_loss.append(loss)
        if i % 10 == 1:
            print('Epoch number: {} and the loss: {}'.format(i, loss.get()))
        optimizer.zero_grad() ## Clears the gradients of all optimized class
        loss.backward() ## for backward propagation and to find the derivative
        optimizer.step() ## performs a single optimization step.
        model.get()
</code></pre>
<p>My model:</p>
<pre class=""lang-py prettyprint-override""><code>class ANN_Model(nn.Module):
    def __init__(self, input_features = 8, hidden1 = 20, hidden2 = 20, out_features = 2):
        super().__init__()
        self.f_connected1 = nn.Linear(input_features, hidden1)
        self.f_connected2 = nn.Linear(hidden1, hidden2)
        self.out = nn.Linear(hidden2, out_features)
    def forward(self, x):
        x = F.relu(self.f_connected1(x))
        x = F.relu(self.f_connected2(x))
        x = self.out(x)
        return x
</code></pre>
",7623690,,4370109,,44352.72853,44352.72853,Got an error (element 0 of tensors does not require grad and does not have a grad_fn) while performing learning using pytorch with diabates data set,<pytorch><federated-learning><pysyft>,0,2,,,,CC BY-SA 4.0
67971878,1,,,44361.59315,,1,440,"<p>I want to get reproducible results with my Tensorflow Federated code. For that I have implemented some seeds (random, numpy and tensorflow), but they aren't affecting Tensorflow Federated. The data processing steps are all reproducible, it has to be in the code snippet below.</p>
<p>I have read that Tensorflow Federated doesn't provide a global seed function and that my only possibility is to save the state. But I don't understand this argumentation. Is anyone aware of a method/function that can help me out or explain to me why I can't use seeds with Tensorflow Federated?</p>
<p>Appreciate every comment :) Thanks for your help.</p>
<pre><code>nest_asyncio.apply()

seed_value = 0 
random.seed(seed_value)
np.random.seed(seed_value)
tf.random.set_seed(seed_value)

# designing the clients
client_train_data = collections.OrderedDict()

for i in range(1, num_clients+1): 
    client_name = &quot;Client_{}&quot;.format(i)
    size = len(X_train)//num_clients
    start = size * (i-1)
    end = size * i 
    data = collections.OrderedDict(((&quot;label&quot;, y_train[start:end]),
                                    (&quot;features&quot;, X_train[start:end])))
    client_train_data[client_name] = data

train_dataset = tff.simulation.FromTensorSlicesClientData(client_train_data)

def preprocess(dataset): 
    
    def batch_format(element): 
        return collections.OrderedDict(
            x = reshape(element[&quot;features&quot;], [-1, 11]), 
            y = reshape(element[&quot;label&quot;], [-1, 1]))

    return dataset.repeat(num_epochs).shuffle(shuffle_buffer).batch(
        batch_size).map(batch_format).prefetch(prefetch_buffer)

def make_federated_data(client_data, client_ids): 
    return [
        preprocess(client_data.create_tf_dataset_for_client(x))
        for x in client_ids
    ]

fl_train_data = make_federated_data(train_dataset, train_dataset.client_ids)

def create_keras_model(): 
    model = Sequential()
    model.add(Dense(15, input_dim=11, activation=&quot;relu&quot;))
    model.add(Dense(15, activation=&quot;relu&quot;))
    model.add(Dense(1, activation=&quot;sigmoid&quot;))
    return model

def model_fl(): 
    keras_model = create_keras_model()
    return tff.learning.from_keras_model(
        keras_model,
        input_spec=fl_train_data[0].element_spec,
        loss=tf.keras.losses.BinaryCrossentropy(), 
        metrics=[tf.keras.metrics.BinaryAccuracy()])

fl_process = tff.learning.build_federated_averaging_process(
    model_fl,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01), 
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.00))
# initialize federated averaging
state = fl_process.initialize()
# federated rounds
for round in range(1, num_rounds+1):
    state, metrics = fl_process.next(state, fl_train_data)
    print(&quot;Runde {:2d}, metrics={}&quot;.format(round, metrics))
</code></pre>
",16223516,,16223516,,44362.51715,44370.75115,Random Seed for Tensorflow federated?,<tensorflow><machine-learning><random-seed><tensorflow-federated><federated-learning>,1,4,,,,CC BY-SA 4.0
68018178,1,,,44364.46693,,0,662,"<p>I'm new in Federated learning, I tried to implement the code of FL for Image Classification, but I can't understand this line</p>
<p>I am confused in some detail parts. I am trying to build a sequential model in Keras, but when I train the model, I am getting this error, How may I fix it?</p>
<p>please guide me
thank you.</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(model_fn)

TypeError                                 Traceback (most recent call last)
&lt;ipython-input-50-0fdb188570d0&gt; in &lt;module&gt;()
----&gt; 1 iterative_process = tff.learning.build_federated_averaging_process(model_fn)

TypeError: build_federated_averaging_process() missing 1 required positional argument: 'client_optimizer_fn'
</code></pre>
<p><a href=""https://colab.research.google.com/github/tensorflow/federated/blob/v0.12.0/docs/tutorials/federated_learning_for_image_classification.ipynb#scrollTo=sk6mjOfycX5N"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/tensorflow/federated/blob/v0.12.0/docs/tutorials/federated_learning_for_image_classification.ipynb#scrollTo=sk6mjOfycX5N</a></p>
",15416999,,14692,,44366.71067,44366.7149,Federated Learning for Image Classification in colab,<python><machine-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
74886418,1,,,44917.38793,,0,139,"<p>I want to try a simple federated learning example in python. For it, I need to import tensorflow_federated package.</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow_federated as tff
</code></pre>
<p>Here is the stack trace</p>
<pre class=""lang-py prettyprint-override""><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-6-961ae1555cfa&gt; in &lt;module&gt;
----&gt; 1 import tensorflow_federated as tff

14 frames
/usr/lib/python3.8/typing.py in _type_check(arg, msg, is_argument)
    147         return arg
    148     if not callable(arg):
--&gt; 149         raise TypeError(f&quot;{msg} Got {arg!r:.100}.&quot;)
    150     return arg
    151 

TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis.
</code></pre>
<p>How should I resolve this error?<br />
BTW, I read in a forum that the problem might be resolved by updating the python version, however it still exists despite I updated it to v3.9<br />
The full stack trace is as follows (I had to submit a screenshot of it was misinterpreted by stackoverflow as some quotes and codes that are not in the right format)
<a href=""https://i.sstatic.net/Skmez.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Skmez.png"" alt=""enter image description here"" /></a></p>
",3415597,,1910920,,44920.46807,44920.46807,Cannot install and import tensorflow_federated in colab,<python><tensorflow-federated><federated-learning>,0,3,,,,CC BY-SA 4.0
74898751,1,77372309,,44918.44784,,0,439,"<p>I use <a href=""https://flower.dev/"" rel=""nofollow noreferrer"">Flower API</a> for federated learning applications. Is there any way to run the server and clients on different machines for a real-world benchmark?</p>
",12090940,,,,,45226.32069,Flower running the server and clients on different machines,<federated-learning>,1,0,,,,CC BY-SA 4.0
75171118,1,,,44945.45132,,0,46,"<p>I got &quot;module '0b1a516c7ccf3157373118bcf0f434168745c8a4' has no attribute 'entropy_decode_index' error after a clean intall of tensorflow federated (TFF) on Ubuntu 22.04. System: AMD 6900HS, Nvidia3050ti. The first &quot;import tensorflow_federated&quot; line fails.</p>
<p>There is not even a single entry on google concerning this error message and I am shocked.</p>
<p>The detailed error message is:
File &quot;/home/egosis/venv/lib/python3.9/site-packages/tensorflow_compression/python/ops/<strong>init</strong>.py&quot;, line 17, in </p>
<pre><code>from tensorflow_compression.python.ops.gen_ops import *
</code></pre>
<p>AttributeError: module '0b1a516c7ccf3157373118bcf0f434168745c8a4' has no attribute 'entropy_decode_index'</p>
<p>Every answer is gladly appreciated.</p>
<p>I tried installing TFF v0.46.0, v0.45.0 and v0.44.0 of tff but it did not help.</p>
",21042714,,,,,44945.45132,"How to resolve ""module has no attribute 'entropy_decode_index' error in ubuntu for TFF?",<tensorflow><tensorflow-federated><federated-learning>,0,3,,,,CC BY-SA 4.0
75205546,1,,,44949.16278,,0,51,"<p>I have two PCs that want to share tensorflow models &quot;hdf5 format&quot; in a federated learning manner via a PostgresSQL database.</p>
<p>The models will be trained locally on both machines, and then transferred to the database along with the training history. The transfer will be done for multiple cycles in a specific schedule.</p>
<p>I searched online for solutions to transfer the files via PostgresSQL database, but all solutions suggest a tabulated data transfer, e.g. csv file data, not arbitrary file extensions, like hdf5.</p>
<p>Can anyone help me, even with a roadmap, for the solution?
If any tutorials or examples for similar scenarios would be suggested, that would be also appreciated.</p>
<p>Thanks for your help in advance!</p>
",10797562,,10797562,,44950.08953,44950.08953,Transferring models between two PCs via PostgresSQL database,<postgresql><tensorflow-federated><federated-learning>,0,2,,,,CC BY-SA 4.0
75299930,1,,,44957.67259,,0,141,"<p>I was wondering if in a Federated Learning approach I need to split the local dataset in a number of batches equal to the number of communication rounds.
Otherwise I need to update locally on the whole local dataset each round.</p>
<p>Building a federated learning model</p>
",21119389,,,,,44971.52953,"Local dataset in Federated learning: client side, is the local update performed on a different subset of the local dataset each round?",<server><client><federated-learning>,1,0,,,,CC BY-SA 4.0
75480058,1,,,44974.15316,,0,187,"<p>I have deep learning models (tensorflow in hdf5 format), which I want to upload to a PostgreSQL database.
A single model may be up to 500 MBs, and the models need to be updated and uploaded/downloaded from the database frequently (e.g., once every 30 mins).</p>
<p>I'm a begineer to PostgreSQL, so any information/receipes to start with would be appreciated.</p>
",10797562,,,,,44975.08543,Is there a way to upload a deep learning model to a PostgreSQL database?,<postgresql><tensorflow><federated-learning>,2,10,,,,CC BY-SA 4.0
75549595,1,,,44980.82059,,1,179,"<p>I have a PyTorch model that I am trying to integrate federated learning for. In order to do this, I need to send the model weights back and forth between a server and a client. When I get the size of the model weights, it is approximately 6kb, but when I dill/pickle it to send over the network, it ends up being ~65mb, which takes a very long time, especially since this send/receive must be done for many rounds of training. I realize that there is always going to be extra overhead when serializing python objects, but is there a way I might be able to compress the weights further or use a different datastructure to transfer the model weights back and forth?</p>
<p>I tried <code>dill.dumps(self.network.state_dict())</code>, which results in a ~64mb string that must be transferred over internet, which is too large. I'ved tried compression via lzma and blosc, but they yield little compression.</p>
",21275581,,,,,44980.82059,Sending PyTorch model weights over network in a compressed manner,<pytorch><network-programming><pickle><federated-learning>,0,1,,,,CC BY-SA 4.0
75664095,1,,,44992.65313,,1,196,"<p>I got a series of error messages, the last one being the one mentioned first in the title, while I was trying to run <a href=""https://github.com/MenguChen/Federated_object_detection"" rel=""nofollow noreferrer"">this</a> Github repo on my local machine. I need that project as a boilerplate for my own code later.</p>
<p>I have pasted the dependencies and the error at the end.</p>
<p><strong>My Tries to solve it:</strong><br />
I have looked at the answers for a similar error in <a href=""https://stackoverflow.com/questions/41480148/importerror-sys-meta-path-is-none-python-is-likely-shutting-down"">this</a> post, but I could not figure out the solution for my case. I have also looked into answers for the <code>Exception in thread Thread-1</code> and <code>OverflowError: timeout doesn't fit into C timeval</code>  anomalies which were in the same log, but am completely helpless.<br />
I also tried changing from a conda environment to virtualenv environment but I ran into the same error. I also tried with Python v3.9 and 3.10.9 and 3.10.10</p>
<p><strong>Things to look for, while running the cloned project:</strong></p>
<ul>
<li><p>There is no need to prepare the dataset as it already comes with the cloned project. Follow the rest of the steps as in the Readme.</p>
</li>
<li><p>You can look at the logs for the server in the <code>C:\Users\HP\Federated_object_detection\experiments\logs\0307\yolo\street_5 </code> directory.</p>
</li>
<li><p>'I got the error' in the client's log files which are in <code>C:\Users\HP\Federated_object_detection\yolo_task1 </code> and all 4 others.</p>
</li>
<li><p>Remember to download the weights <code>darknet53.conv.74</code> in <code>C:\Users\HP\Federated_object_detection\weights</code></p>
</li>
<li><p>Change the python directory to your conda/virtualenv environment's python, in the <code>run_server</code> and <code>run</code> shell scripts, before running them. 'I ran those scripts in Git Bash.'</p>
</li>
<li><p>The dependencies below should help.</p>
</li>
</ul>
<p><strong>Dependencies</strong></p>
<pre><code>bidict==0.22.1
certifi==2022.12.7
charset-normalizer==3.1.0
click==8.1.3
colorama==0.4.6
contourpy==1.0.7
cupy-cuda11x==11.6.0
cycler==0.11.0
Cython==0.29.33
dnspython==2.3.0
eventlet==0.33.3
fastrlock==0.8.1
Flask==2.0.3
Flask-SocketIO==4.3.2
fonttools==4.39.0
greenlet==2.0.2
idna==3.4
imageio==2.26.0
importlib-metadata==6.0.0
importlib-resources==5.12.0
itsdangerous==2.1.2
Jinja2==3.1.2
jsonpatch==1.32
jsonpointer==2.3
kiwisolver==1.4.4
lazy_loader==0.1
MarkupSafe==2.1.2
matplotlib==3.7.1
networkx==3.0
numpy==1.24.2
packaging==23.0
Pillow==9.4.0
pyparsing==3.0.9
python-dateutil==2.8.2
python-engineio==3.14.2
python-socketio==4.6.1
PyWavelets==1.4.1
requests==2.28.2
scikit-image==0.20.0
scipy==1.9.1
six==1.16.0
sklearn==0.0.post1
socketIO-client==0.7.2
terminaltables==3.1.10
tifffile==2023.2.28
torch==1.13.1
torchnet==0.0.4
torchvision==0.14.1
tornado==6.2
tqdm==4.65.0
typing_extensions==4.5.0
urllib3==1.26.14
visdom==0.2.4
websocket-client==1.5.1
Werkzeug==2.0.3
zipp==3.15.0
</code></pre>
<p><strong>Error</strong></p>
<pre><code>Namespace(gpu=2, config_file='data/task_configs/yolo/street_5/yolo_task2.json', ignore_load='True', port=1234)
client run on 2
{'model_name': 'Yolo', 'model_config': 'data/task_configs/yolo/street_5/yolo_model.json', 'log_filename': 'yolo/street_5/FL_client_2_log', 'train': 'data/street_5/2/train.txt', 'test': 'data/street_5/2/test.txt', 'names': 'data/street_5/classes.names', 'n_cpu': 4, 'local_epoch': 5, 'batch_size': 1}
INFO:client:{'model_name': 'Yolo', 'model_config': 'data/task_configs/yolo/street_5/yolo_model.json', 'log_filename': 'yolo/street_5/FL_client_2_log', 'train': 'data/street_5/2/train.txt', 'test': 'data/street_5/2/test.txt', 'names': 'data/street_5/classes.names', 'n_cpu': 4, 'local_epoch': 5, 'batch_size': 1}
Exception in thread Thread-1:
Traceback (most recent call last):
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\threading.py&quot;, line 980, in _bootstrap_inner
sent wakeup
Traceback (most recent call last):
    self.run()
  File &quot;C:\Users\HP\Federated_object_detection\fl_client.py&quot;, line 266, in &lt;module&gt;
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\heartbeats.py&quot;, line 27, in run
    FederatedClient(&quot;127.0.0.1&quot;, opt.port, opt.config_file, opt.gpu, opt.ignore_load)
  File &quot;C:\Users\HP\Federated_object_detection\fl_client.py&quot;, line 95, in __init__
    self._send_heartbeat()
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\__init__.py&quot;, line 210, in _ping
    self.sio.emit('client_wake_up')
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\__init__.py&quot;, line 433, in emit
    self._transport_instance.send_packet(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\transports.py&quot;, line 94, in send_packet
    self._message(str(socketIO_packet_type) + socketIO_packet_data)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\__init__.py&quot;, line 28, in wrap
    get_response(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\transports.py&quot;, line 176, in get_response
    return f(*args, **kw)
    response = request(*args, stream=True, **kw)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\__init__.py&quot;, line 225, in _message
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 635, in post
    transport.send_packet(engineIO_packet_type, engineIO_packet_data)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\transports.py&quot;, line 94, in send_packet
    return self.request(&quot;POST&quot;, url, data=data, json=json, **kwargs)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 587, in request
    get_response(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\transports.py&quot;, line 176, in get_response
    resp = self.send(prep, **send_kwargs)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 701, in send
    response = request(*args, stream=True, **kw)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 635, in post
    r = adapter.send(request, **kwargs)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\adapters.py&quot;, line 489, in send
    return self.request(&quot;POST&quot;, url, data=data, json=json, **kwargs)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 587, in request
    resp = conn.urlopen(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connectionpool.py&quot;, line 703, in urlopen
    resp = self.send(prep, **send_kwargs)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 701, in send
    httplib_response = self._make_request(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connectionpool.py&quot;, line 434, in _make_request
    r = adapter.send(request, **kwargs)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\adapters.py&quot;, line 489, in send
    conn.sock.settimeout(read_timeout)
OverflowError: timeout doesn't fit into C timeval
    resp = conn.urlopen(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connectionpool.py&quot;, line 703, in urlopen
    httplib_response = self._make_request(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connectionpool.py&quot;, line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connection.py&quot;, line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\http\client.py&quot;, line 1285, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\http\client.py&quot;, line 1331, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\http\client.py&quot;, line 1280, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\http\client.py&quot;, line 1040, in _send_output
    self.send(msg)
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\http\client.py&quot;, line 980, in send
    self.connect()
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connection.py&quot;, line 205, in connect
    conn = self._new_conn()
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connection.py&quot;, line 174, in _new_conn
    conn = connection.create_connection(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\util\connection.py&quot;, line 82, in create_connection
    sock.settimeout(timeout)
OverflowError: timeout doesn't fit into C timeval
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\__init__.py&quot;, line 203, in _close
    self._transport_instance.send_packet(engineIO_packet_type)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\transports.py&quot;, line 94, in send_packet
    get_response(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\transports.py&quot;, line 176, in get_response
    response = request(*args, stream=True, **kw)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 635, in post
    return self.request(&quot;POST&quot;, url, data=data, json=json, **kwargs)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 587, in request
    resp = self.send(prep, **send_kwargs)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 701, in send
    r = adapter.send(request, **kwargs)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\adapters.py&quot;, line 489, in send
    resp = conn.urlopen(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connectionpool.py&quot;, line 703, in urlopen
    httplib_response = self._make_request(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connectionpool.py&quot;, line 398, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connection.py&quot;, line 239, in request
    super(HTTPConnection, self).request(method, url, body=body, headers=headers)
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\http\client.py&quot;, line 1285, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\http\client.py&quot;, line 1331, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\http\client.py&quot;, line 1280, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\http\client.py&quot;, line 1040, in _send_output
    self.send(msg)
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\http\client.py&quot;, line 980, in send
    self.connect()
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connection.py&quot;, line 205, in connect
    conn = self._new_conn()
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\connection.py&quot;, line 174, in _new_conn
    conn = connection.create_connection(
  File &quot;C:\Users\HP\menguv2\lib\site-packages\urllib3\util\connection.py&quot;, line 82, in create_connection
    sock.settimeout(timeout)
OverflowError: timeout doesn't fit into C timeval
Exception ignored in: &lt;function SocketIO.__del__ at 0x000001E2405CB820&gt;
Traceback (most recent call last):
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\__init__.py&quot;, line 372, in __del__
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\__init__.py&quot;, line 417, in disconnect
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\__init__.py&quot;, line 203, in _close
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\transports.py&quot;, line 94, in send_packet
  File &quot;C:\Users\HP\menguv2\lib\site-packages\socketIO_client\transports.py&quot;, line 176, in get_response
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 635, in post
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 573, in request
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\sessions.py&quot;, line 475, in prepare_request
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\cookies.py&quot;, line 556, in merge_cookies
  File &quot;C:\Users\HP\menguv2\lib\site-packages\requests\cookies.py&quot;, line 362, in update
  File &quot;C:\Users\HP\AppData\Local\Programs\Python\Python39\lib\copy.py&quot;, line 92, in copy
ImportError: sys.meta_path is None, Python is likely shutting down
</code></pre>
<p><strong>Previous errors:</strong><br />
Just mentioning it in case it helps. I was facing issues with <a href=""https://stackoverflow.com/questions/66069215/the-client-is-using-an-unsupported-version-of-the-socket-io-or-engine-io-protoco"">this</a> which I solved by installing <code>Flask-SocketIO==4.3.2</code> and other related dependencies.</p>
",17169908,,17169908,,44992.84369,44992.84369,"ImportError: sys.meta_path is None, Python is likely shutting down; OverflowError: timeout doesn't fit into C timeval; Exception in thread Thread-1",<python><sh><yolo><federated-learning>,0,0,,,,CC BY-SA 4.0
75720004,1,,,44998.39292,,1,138,"<p>I am trying to work on a federated learning project and I am just at the beginning. I tried to import a class called &quot;BaseDataset&quot; from the pysyft library as shown in the following.</p>
<pre><code>import syft.frameworks.torch.fl.dataset as st

dataset = st.BaseDataset(train_inputs[:train_idx], train_labels[:train_idx])
</code></pre>
<p>However the follwing error is poping up. I have checked the documentation from <a href=""https://pysyftbenardi.readthedocs.io/en/sphinx_backup/api/syft/frameworks/torch/fl/dataset/index.html?highlight=BaseDataset#syft.frameworks.torch.fl.dataset.BaseDataset"" rel=""nofollow noreferrer"">here</a>Any help will be much appreciated.</p>
<pre><code>ModuleNotFoundError                       Traceback (most recent call last)
&lt;ipython-input-77-f2dbf9acefcc&gt; in &lt;module&gt;
----&gt; 1 import syft.frameworks.torch.fl.dataset as st

ModuleNotFoundError: No module named 'syft.frameworks'
</code></pre>
<p>P.S. I am on pysyft version 0.7.0</p>
<pre><code>Name: syft
Version: 0.7.0
Summary: Perform numpy-like analysis on data that remains in someone elses server
Home-page: https://openmined.github.io/PySyft/
Author: OpenMined
Author-email: info@openmined.org
License: Apache-2.0
Location: /usr/local/lib/python3.9/dist-packages
Requires: ascii-magic, bcrypt, boto3, cachetools, flax, forbiddenfruit, gevent, jax, jaxlib, loguru, matplotlib, names, numpy, packaging, pandas, protobuf, pyarrow, pycapnp, pydantic, pyjwt, pympler, pynacl, redis, requests, requests-toolbelt, sqlalchemy, torch, tqdm, typing-extensions
Required-by: 

</code></pre>
<p>I tried to import a class from the module. However a <code>ModuleNotFoundError</code> error is still persisting.</p>
",17174868,,,,,45130.54176,why is api calls from the pysyft library causing a ModuleNotFoundError?,<python><torch><modulenotfounderror><federated-learning><pysyft>,0,0,,,,CC BY-SA 4.0
75721113,1,,,44998.46705,,1,1462,"<p>Last week iam working with syft==0.2.9 and it was working great!
but this week when i tried to install syft==0.2.9 i have this error
&quot;ERROR: Could not find a version that satisfies the requirement torchvision~=0.5.0 (from syft) (from versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.8.2, 0.9.0, 0.9.1, 0.10.0, 0.10.1, 0.11.0, 0.11.1, 0.11.2, 0.11.3, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1)
ERROR: No matching distribution found for torchvision~=0.5.0&quot;</p>
<p>Then when import the syft library it was undefine</p>
<p>I need to work with TorchHook in federated learning by PyTorch</p>
<p>I use Google Colab.. Also i tried my code in Jypter and kaggle, all showing the same error</p>
<pre><code>!pip install syft==0.2.9
</code></pre>
<pre><code>import syft as sy
hook = sy.TorchHook(torch)
clients = []

for i in range(args.clients):
    clients.append({'hook': sy.VirtualWorker(hook, id=&quot;client{}&quot;.format(i+1))})
</code></pre>
",19625677,,6379197,,45098.82817,45098.82817,ERROR: Could not find a version that satisfies the requirement torchvision~=0.5.0 (from syft),<python><pytorch><google-colaboratory><federated-learning><pysyft>,1,0,,,,CC BY-SA 4.0
68233576,1,,,44380.24225,,0,367,"<p>I am trying to implement that pysyft code for federated learing for my csv data . The tutorial i am following is this <a href=""https://github.com/bt-s/Split-Learning-and-Federated-Learning/blob/master/src/federated_learning.py"" rel=""nofollow noreferrer"">https://github.com/bt-s/Split-Learning-and-Federated-Learning/blob/master/src/federated_learning.py</a>  they used torch library FMNIST data which is iamge . I am having difficulty in customizing this code for my csv data.</p>
<p>This is error i am getting</p>
<blockquote>
<p>File &quot;C:/user/python/PCA/federated_learning.py&quot;, line 175, in 
train_loader = sy.FederatedDataLoader(train_set, transform=data_transformer.federate(workers), train=True,
batch_size=args.batch_size, shuffle=True,  **kwargs) AttributeError:
'Compose' object has no attribute 'federate</p>
</blockquote>
<pre><code># Pysyft needs to be hooked to PyTorch to enable its features
    hook = sy.TorchHook(torch)

    # Define the workers
    alfa    = sy.VirtualWorker(hook, id=&quot;alfa&quot;)
    bravo   = sy.VirtualWorker(hook, id=&quot;bravo&quot;)
    workers = (alfa, bravo)

    device = &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;
    device = torch.device(device)
    kwargs = {'num_workers': 1, 'pin_memory': True} if device==&quot;cuda&quot; else {}

    # Specify required data transformation
    data_transformer = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])

    import pandas as pd
    print(&quot;Loading CSV...&quot;)
    test_set = pd.read_csv(&quot;C:/user/python/PCA/data/test.csv&quot;, encoding = &quot;UTF-8&quot;)
    train_set = pd.read_csv(&quot;C:/user/python/PCA/data/train.csv&quot;, encoding = &quot;UTF-8&quot;)
    train_loader = sy.FederatedDataLoader(train_set, transform=data_transformer.federate(workers), train=True, batch_size=args.batch_size, shuffle=True,  **kwargs)
    test_loader = torch.utils.data.DataLoader(test_set, transform=data_transformer, train=False, batch_size=args.batch_size, shuffle=True,  **kwargs)
    
</code></pre>
",7996402,,7996402,,44380.92999,44380.92999,PySyft AttributeError: 'DataFrame' object has no attribute 'federate' while reading data from csv,<dataframe><pytorch><federated-learning><pysyft>,0,10,,,,CC BY-SA 4.0
68269539,1,,,44383.46751,,0,432,"<p>I am new to Federated Learning, and I am trying to get started with TensorFlow Federated. While working on the tutorial &quot;Federated Learning for Image Classification&quot; on Colab, I tried to install TensorFlow Federated, but was met with these errors:</p>
<pre><code>ERROR: tensorflow 2.5.0 requires tensorboard~=2.5, which is not installed.
ERROR: tensorflow 2.5.0 has requirement grpcio~=1.34.0, but you'll have grpcio 1.37.1 which is incompatible.
ERROR: tensorflow 2.5.0 has requirement keras-nightly~=2.5.0.dev, but you'll have keras-nightly 2.6.0.dev2021062500 which is incompatible.
ERROR: spacy 2.2.4 has requirement tqdm&lt;5.0.0,&gt;=4.38.0, but you'll have tqdm 4.28.1 which is incompatible.
ERROR: pymc3 3.11.2 has requirement cachetools&gt;=4.2.1, but you'll have cachetools 3.1.1 which is incompatible.
ERROR: fbprophet 0.7.1 has requirement tqdm&gt;=4.36.1, but you'll have tqdm 4.28.1 which is incompatible.
ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.
ERROR: tensorflow-privacy 0.6.1 has requirement attrs&gt;=21.2.0, but you'll have attrs 19.3.0 which is incompatible.
</code></pre>
<p>After installing the versions of the libraries mentioned here, I found that there still exist some internal conflicts with the installed libraries. Has anyone else faced this issue? Would be great to get some pointers on this!</p>
",16389426,,14692,,44383.83595,44640.18262,Issues in setting up the environment for TensorFlow Federated on Colab,<tensorflow><tensorflow-federated><federated-learning>,1,3,,,,CC BY-SA 4.0
75874823,1,,,45014.35285,,0,124,"<p>I've been playing for some time with FL + DP for my thesis.
I am using TFF in case someone is wondering.</p>
<p>I load my data as:</p>
<pre><code>train_data = tff.simulation.datasets.ClientData.from_clients_and_fn(
        client_ids=train_data_paths,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )

test_data = tff.simulation.datasets.ClientData.from_clients_and_fn(
        client_ids=test_data_paths,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
</code></pre>
<p>And I set Q as sampling ratio</p>
<pre><code>def get_training_Q(Q):
    size = int(Q*len(train_data.client_ids))
    sampled_clients = np.random.choice(
            train_data.client_ids,
            size=size,
            replace=False)
    
    sampled_train_data = [
            train_data.create_tf_dataset_for_client(client)
            for client in sampled_clients
        ]
    
    return sampled_train_data

def get_test_Q(Q):
    size = int(Q*len(test_data.client_ids))
    sampled_clients = np.random.choice(
            test_data.client_ids,
            size=size,
            replace=False)
    
    ids = [_id.split('/')[-3] for _id in sampled_clients]
    print(ids)
    
    sampled_test_data = [
            test_data.create_tf_dataset_for_client(client)
            for client in sampled_clients
        ]
    return sampled_test_data
</code></pre>
<p>Given this I define my DP parameters:</p>
<ul>
<li>Noise = 0.5</li>
<li>Q = 0.015</li>
<li>n_clients_per_round = int(Q*len(train_data.client_ids))</li>
</ul>
<p>I define my aggregation factory:</p>
<p><code>aggregation_factory = tff.learning.model_update_aggregator.dp_aggregator(noise_multiplier=Noise,clients_per_round=n_clients_per_round)</code></p>
<p>And the iterative process:</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_tff,
    client_optimizer_fn=lambda: keras.optimizers.Adam(),
    server_optimizer_fn=lambda: keras.optimizers.SGD(learning_rate=1),
    model_update_aggregation_factory=aggregation_factory,
    use_experimental_simulation_loop=True)


evaluation = tff.learning.build_federated_evaluation(model_tff,use_experimental_simulation_loop=True)
</code></pre>
<p>My training happens in rounds as follows:</p>
<pre><code>train_set = get_training_Q(Q)
test_set = get_test_Q(Q)

state, metrics = iterative_process.next(state, train_set)
test_metrics = evaluation(state.model, test_set)    
</code></pre>
<p>The main issue here is that the training metrics looks good and the model learns at a slow but steady rate but <strong>the test metrics are horrendous</strong>. It looks like the model is overfitting while using DP (known to be a regulariser). I am absolutely confused.
<a href=""https://i.sstatic.net/NiqxZ.png"" rel=""nofollow noreferrer"">performance plot</a></p>
<p>I've tried several changes in the noise and learning structure so as modifying the internal rounds of training and the batch size.
I started with a model that trains well without DP to later add DP.</p>
<p>Any ideas why this is happening?</p>
<p>Best regards,</p>
",19726243,,19726243,,45014.35816,45021.45876,Federated learning with Differential Privacy - Bad test performance,<python><privacy><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
75918443,1,75919785,,45019.43462,,0,166,"<p>`
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split</p>
<pre><code># Define the deep neural network model
class DNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(DNN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, output_size)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        out = self.sigmoid(out)
        return out

# Load the breast cancer dataset
data = load_breast_cancer()
X = data.data
y = data.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define the number of training rounds and the number of clients
num_rounds = 100
num_clients = 2
batch_size = 10

# Split the data into equal chunks for each client
X_splits = np.array_split(X_train, num_clients)
y_splits = np.array_split(y_train, num_clients)

# Define the loss function and optimizer
criterion = nn.BCELoss()

# Perform federated learning
global_model = DNN(X_train.shape[1], 16, 1)
optimizer = optim.SGD(global_model.parameters(), lr=.01)

for i in range(num_rounds):
    local_models = []
    for j in range(num_clients):
        # Create a local model by copying the current global model
        local_model = DNN(X_train.shape[1], 16, 1)
        local_model.load_state_dict(global_model.state_dict())

        # Create a dataloader for the local client's data
        local_X = torch.tensor(X_splits[j], dtype=torch.float32)
        local_y = torch.tensor(y_splits[j], dtype=torch.float32)
        local_dataset = torch.utils.data.TensorDataset(local_X, local_y)
        local_dataloader = DataLoader(local_dataset, batch_size=batch_size, shuffle=True)

        # Train the local model
        local_optimizer = optim.SGD(local_model.parameters(), lr=0.1)
        for inputs, labels in local_dataloader:
            local_optimizer.zero_grad()
            outputs = local_model(inputs)
            loss = criterion(outputs, labels.view(-1, 1))
            loss.backward()
            local_optimizer.step()

        # Add the trained local model to the list of local models
        local_models.append(local_model)

    # Aggregate the local models to create a global model
    with torch.no_grad():
        for global_param, local_params in zip(global_model.parameters(), zip(*[local_model.parameters() for local_model in local_models])):
            global_param.data += torch.stack(local_params).sum(0) / num_clients

    # Evaluate the global model on the train dataset
    global_model.eval()
    with torch.no_grad():
        global_outputs = global_model(torch.tensor(X_train, dtype=torch.float32))
        global_loss = criterion(global_outputs, torch.tensor(y_train, dtype=torch.float32).view(-1, 1))
        global_pred = (global_outputs &gt; 0.5).int().numpy().flatten()
        accuracy = np.mean(global_pred == y_train)
        print(f&quot;Round {i}, train accuracy:{accuracy}&quot;)
</code></pre>
<p>`</p>
<p>the code works perfectly upto num_rounds=96 but when the numround is given greater then or equal to 97, it shows an error:</p>
<p>`
RuntimeError                              Traceback (most recent call last)</p>
<p> in &lt;cell line: 47&gt;()
79     with torch.no_grad():
80         global_outputs = global_model(torch.tensor(X_train, dtype=torch.float32))
---&gt; 81         global_loss = criterion(global_outputs, torch.tensor(y_train, dtype=torch.float32).view(-1, 1))
82         global_pred = (global_outputs &gt; 0.5).int().numpy().flatten()
83         accuracy = np.mean(global_pred == y_train)</p>
<p>2 frames</p>
<p>/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py in binary_cross_entropy(input, target, weight, size_average, reduce, reduction)
3093         weight = weight.expand(new_size)
3094
-&gt; 3095     return torch._C._nn.binary_cross_entropy(input, target, weight, reduction_enum)
3096
3097</p>
<p>RuntimeError: all elements of input should be between 0 and 1
`</p>
",20543669,,,,,45019.54361,Federated Learning implementation code shows a RuntimeError: all elements of input should be between 0 and 1,<deep-learning><pytorch><runtime-error><pytorch-lightning><federated-learning>,1,0,,,,CC BY-SA 4.0
76106294,1,,,45042.00998,,0,506,"<p>I am trying to implement Federated Learning using Flower framework in python. I get the following error when I start the process.<a href=""https://i.sstatic.net/y9fJU.jpg"" rel=""nofollow noreferrer"">Snapshot of the error</a></p>
<p>Here is what I tried,</p>
<pre><code>NUM_CLIENTS = 10

#function to load data
def load_datasets(num_clients: int, train_loader, test_loader):

    
    # Split training set into `num_clients` partitions to simulate different local datasets
    partition_size = len(train_loader) // num_clients
    lengths = [partition_size] * num_clients
    datasets = random_split(train_loader, lengths, torch.Generator().manual_seed(42))

    # Split each partition into train/val and create DataLoader
    trainloaders = []
    valloaders = []
    for ds in datasets:
        len_val = len(ds) // 10  # 10 % validation set
        len_train = len(ds) - len_val
        lengths = [len_train, len_val]
        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))
        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))
        valloaders.append(DataLoader(ds_val, batch_size=32))
    testloader = DataLoader(test_loader, batch_size=32)
    return trainloaders, valloaders, testloader


trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS ,train_loader,test_loader)



#client function thats been passed to start the server 
def client_fn(cid) -&gt; CardiacClient:
    net = CardiacModel().to(DEVICE)
    trainloader = trainloaders[cid]
    valloader = valloaders[cid]
    return CardiacClient(cid, net, trainloader, valloader)

</code></pre>
<p>In the above code cid refers to the clientID,</p>
",21730317,,,,,45155.6319,How do I solve the error which I get during training the clients in flower framework for federated learning?,<python><machine-learning><tensorflow-federated><flower><federated-learning>,1,0,,,,CC BY-SA 4.0
76140070,1,,,45046.31944,,0,188,"<p>I'm working on federating a UNET semantic segmentation workflow using flower and Pytorch. As of right now I can load the data and run a centralized training but once I try to federate it I see that model parameters are not being loaded properly. I have included a google colab notebook to the code and the log output, to keep the question short.<br />
<a href=""https://colab.research.google.com/drive/1dmlH4QTX_ZwicbSfwVeCw55BXRnV6PY4?usp=sharing"" rel=""nofollow noreferrer"">https://colab.research.google.com/drive/1dmlH4QTX_ZwicbSfwVeCw55BXRnV6PY4?usp=sharing</a></p>
<p>I'm leaving this up here incase someone is trying to implement a similar workflow. Feel free to reach out.</p>
",10368235,,10368235,,45047.30566,45047.30566,Resolved: Model parameters not loading when simulating a federated learning Semantic Segmentation task using Flower and Pytorch,<pytorch><federated-learning><unet-neural-network>,1,0,,,,CC BY-SA 4.0
76178468,1,76182331,,45051.10133,,-1,80,"<p>What are the libraries we can use for federated learning process?
what are the data encryption techniques used to protect datasets?</p>
<p>I studied some articles and blogs but in health sector it's difficult to implement because health organisations are not agree t share data. in other way they have no trust on federated learning that it would support as a protective way</p>
",7053070,,,,,45051.53054,How Federated Learning would help to centralise Hospitals and clinical data cohorts (databases)? Especially Electronic Health Records datasets,<machine-learning><federated-learning><openehr><metadata-repository>,1,0,,,,CC BY-SA 4.0
76288080,1,,,45065.42407,,0,351,"<p>The problem of the given code is:</p>
<pre><code>line 25, in &lt;module&gt; privacy_engine = PrivacyEngine(model, batch_size=64, 
sample_size=60000, alphas=range(2,32), noise_multiplier=1.3, max_grad_norm=1.0)

TypeError: __init__() got an unexpected keyword argument 'batch_size'
</code></pre>
<p><a href=""https://i.sstatic.net/zaqD5.png"" rel=""nofollow noreferrer"">An image of the code is attached in this link </a>.</p>
<p>The code is given below:</p>
<pre class=""lang-py prettyprint-override""><code># Step 1: Importing PyTorch and Opacus
import torch
from torchvision import datasets, transforms
import numpy as np
from opacus import PrivacyEngine
from tqdm import tqdm

# Step 2: Loading MNIST Data
train_loader = torch.utils.data.DataLoader(datasets.MNIST('../mnist', train=True, download=True,
               transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), 
               (0.3081,)),]),), batch_size=64, shuffle=True, num_workers=1, pin_memory=True)

test_loader = torch.utils.data.DataLoader(datasets.MNIST('../mnist', train=False, 
              transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), 
              (0.3081,)),]),), batch_size=1024, shuffle=True, num_workers=1, pin_memory=True)

# Step 3: Creating a PyTorch Neural Network Classification Model and Optimizer
model = torch.nn.Sequential(torch.nn.Conv2d(1, 16, 8, 2, padding=3), torch.nn.ReLU(), torch.nn.MaxPool2d(2, 1),
        torch.nn.Conv2d(16, 32, 4, 2),  torch.nn.ReLU(), torch.nn.MaxPool2d(2, 1), torch.nn.Flatten(), 
        torch.nn.Linear(32 * 4 * 4, 32), torch.nn.ReLU(), torch.nn.Linear(32, 10))

optimizer = torch.optim.SGD(model.parameters(), lr=0.05)

# Step 4: Attaching a Differential Privacy Engine to the Optimizer
privacy_engine = PrivacyEngine(model, batch_size=64, sample_size=60000, alphas=range(2,32), 
                                noise_multiplier=1.3, max_grad_norm=1.0)
</code></pre>
<p>How do I fix this issue in the PrivacyEngine of Opacus for differential privacy?</p>
",10140314,,4685471,,45065.50551,45197.67895,Differential Privacy error in PyTorch using Opacus PrivacyEngine - how to troubleshoot?,<deep-learning><pytorch><federated-learning>,1,0,,,,CC BY-SA 4.0
76658088,1,76658137,,45118.03132,,0,244,"<p>I am trying to use shfl python library. When I import shfl, I get the error <code>ModuleNotFoundError: No module named 'shfl'</code>, and apparently I cannot install it.</p>
<p>I have used three following commands and all are unsuccessful with the errors I mention below (I use conda). My python version is <code>3.10.12</code>. My conda version is <code>23.5.0</code>, and my pip version is <code>23.1.2</code>.</p>
<p>1- <code>pip install shfl</code>(based on <a href=""https://github.com/officialarijit/Federated-Learning-Framework/blob/main/install.md"" rel=""nofollow noreferrer"">this link</a>) ---&gt; I get this error:</p>
<pre><code>ERROR: Could not find a version that satisfies the requirement shfl (from versions: none)
ERROR: No matching distribution found for shfl
</code></pre>
<p>2- <code>pip install shfl==0.1.0</code> (based on <a href=""https://package.wiki/shfl"" rel=""nofollow noreferrer"">this link</a>) ---&gt; I get this error:</p>
<pre><code>ERROR: Could not find a version that satisfies the requirement shfl==0.1.0 (from versions: none)
ERROR: No matching distribution found for shfl==0.1.0
</code></pre>
<p>3- <code>conda install -c conda-forge shfl</code> (because I use conda environment) ---&gt; I get this error:</p>
<pre><code>PackagesNotFoundError: The following packages are not available from current channels:

  - shfl
</code></pre>
",19558213,,,,,45118.04142,Cannot install shfl in python,<python-3.x><pip><anaconda><conda><federated-learning>,1,1,,,,CC BY-SA 4.0
76750150,1,,,45130.84462,,0,91,"<p>In federated learning, I want to get weights of each local model every round, then I will cluster local clients based on their weights, but I can just use training_process.get_model_weights(train_state) to get global weights only.</p>
<p>I did use training_process.get_model_weights(train_state) to get global weights, but I haven't found any library or function to get weights of each clients yet.</p>
",22273170,,,,,45133.0331,Is there an library to get weights of each local model every round of Federated Learning?,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
76772278,1,,,45133.59834,,0,51,"<p>I am trying to implement the following algorithm
<a href=""https://i.sstatic.net/dxqch.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/dxqch.png"" alt=""L2C not the meta-L2C"" /></a>. In step 18, the gradient of the loss with respect to alpha is being computed and when i try to access this .grad atribute for alpha, I get None, which means that there is no gradient computed for alpha</p>
<p>My model is as follow:</p>
<pre><code>class CNNCifar(nn.Module):
    def __init__(self):
        super(CNNCifar, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
        self.alpha = nn.Parameter(torch.randn(100, 100), requires_grad=True)
        self.w = torch.randn((100, 100), requires_grad=True)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return F.log_softmax(x, dim=1)

</code></pre>
<p>with a training loop that goes like this:</p>
<pre><code>k = len(neighbour_sets)
    device = torch.device(&quot;cuda&quot; if not torch.cuda.is_available() else &quot;cpu&quot;)
    model = CNNCifar().to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.1)
    l2c_optimizer = optim.Adam([model.alpha], lr=beta, weight_decay=0.01)

    test_accuracies = [[] for _ in range(k)]

    theta = [model.state_dict().copy() for _ in range(k)]
    theta_half = [model.state_dict().copy() for _ in range(k)]

    # w = torch.randn(k, k, requires_grad=True)
    delta_theta = [model.state_dict().copy() for _ in range(k)]

    with tqdm_output(tqdm(range(T))) as trange:
        for t in trange:
            for i in range(k):
                # Local SGD step
                log.info(f'Started training a Local SGD at node {i + 1}')

                model.load_state_dict(theta[i])
                for m in range(S):
                    for _, data in enumerate(train_loaders[i]):
                        inputs, labels = data
                        inputs, labels = inputs.to(device), labels.to(device)
                        optimizer.zero_grad()
                        outputs = model(inputs)
                        loss = criterion(outputs, labels)
                        loss.backward()
                        optimizer.step()

                log.info(f'Finished training a Local SGD at node {i + 1}')



                # Change capturing
                log.info(f'Computing change capturing at node {i + 1}')
                for name, param in model.named_parameters():
                    delta_theta[i][name] = theta[i][name] - theta_half[i][name]

                log.info(f'Computing mixing weights at node {i + 1}')
                # Mixing weights calculation
                model.w = model.w.clone()
                model.w[i] = compute_mixing_weights(model.alpha[i], neighbour_sets[i])

                # Aggregation
                log.info(f'Aggergating at node {i + 1}')
                theta_next = {}
                for name, param in model.named_parameters():
                    theta_next[name] = theta[i][name].clone()

                for j in neighbour_sets[i]:
                    for name, param in model.named_parameters():
                        theta_next[name] -= model.w[i][j].item() * delta_theta[i][name][j].clone()


                # Update L2C
                log.info(f'Updating L2C at node {i + 1}')
                model.load_state_dict(theta_next)
                model.train()
                # a training loop to find alpha that minimizes the validation loss
                for _, data in enumerate(val_loaders[i]):
                    inputs, labels = data
                    inputs, labels = inputs.to(device), labels.to(device)
                    
                    l2c_optimizer.zero_grad()
                    model.alpha.requires_grad_(True)
                    
                    log.info(f'Forward pass check')
                    outputs = model(inputs)
                    loss = criterion(outputs, labels)
                    model.alpha.retain_grad()
                    loss.backward()
                    print(f'gradient of alpha is {model.alpha.grad}')
                    import pdb; pdb.set_trace()
                    l2c_optimizer.step()

                    # Update Î±[i]
                    # import pdb; pdb.set_trace()
                    # alpha_grad = model.alpha.grad  # Access the computed gradients
                    # model.alpha.data[i] -= beta * alpha_grad[i]
                

                # Remove edges for sparse topology
                if t == T_0:
                    for _ in range(K_0):
                        j = min(neighbour_sets[i], key=lambda x: w[i][x])
                        neighbour_sets[i].delete(j)

                theta[i] = model.state_dict().copy()
                theta_half[i] = model.state_dict().copy()

                # Compute test accuracy for each local model
                test_accuracies = compute_test_acc(model, test_loaders[i], device, test_accuracies, i)
            
        log.info(f'Test accuracies atiteration at Comm_round {t} =  {sum(test_accuracies) / k}')
    
    return theta, test_accuracies
</code></pre>
<p>What is the problem with this implemntation.</p>
<p>I tried different retrain_grad() after the loss computation</p>
",11193114,,,,,45133.59834,"Pytorch: Calculating the loss with respect to alpha, which is a nn.Paramter",<deep-learning><pytorch><autograd><federated-learning><personalization>,0,2,,,,CC BY-SA 4.0
76935633,1,,,45157.60887,,0,67,"<p>I have a federated server (flower framework) running in a docker container in the raspberry pi device in the same network as the client (My laptop). The client is not able to establish a connection with the server.</p>
<p><code>Raspberry pi host ip address: 192.168.0.104 Docker container ip address: 170.17.0.2</code></p>
<p>I enabled port forwarding for the docker container from 8080 to 8000. When I try to connect the client to the serverâ€™s 192.168.0.104:8000 address and port. I get the error</p>
<p><code>status = StatusCode.UNAVAILABLE                                                                                                                                 details = &quot;failed to connect to all addresses; last error: UNAVAILABLE: ipv4:192.168.0.104:8000: WSA Error&quot;                                                     debug_error_string = &quot;UNKNOWN:failed to connect to all addresses; last error: UNAVAILABLE: ipv4:192.168.0.104:8000: WSA Error {created_time:&quot;2023-08-19T13:55:0 7.018340428+00:00&quot;, grpc_status:14}&quot;</code></p>
<p>I have disabled the firewall in the client (my laptop).</p>
<p>I searched whether raspberry pi has any firewall blocking the connection, but I havenâ€™t found any solid information. Am I missing anything, sharing any information or direction in which I must head will be appreciated.</p>
<p>Thank you.</p>
",16168180,,,,,45157.60887,Could not connect to the docker container,<docker><network-programming><raspberry-pi><raspbian><federated-learning>,0,2,,,,CC BY-SA 4.0
77107057,1,,,45183.70968,,0,110,"<p>I am creating <code>num_of_clients</code> threads using the following code:</p>
<pre><code>sockets_thread = []
no_of_client = 1

all_data = b&quot;&quot;
while True:
    try:
        for i in range(no_of_client):
            connection, client_info = soc.accept() 
            print(&quot;\nNew Connection from {client_info}.&quot;.format(client_info=client_info))
            socket_thread = SocketThread(connection=connection,
                                     client_info=client_info, 
                                     buffer_size=1024,
                                     recv_timeout=100)
            sockets_thread.append(socket_thread)
        for i in range(no_of_client):    
            sockets_thread[i].start()
            sockets_thread[i].join()
    except:
        soc.close()
        print(&quot;(Timeout) Socket Closed Because no Connections Received.\n&quot;)
        break
</code></pre>
<p>In the run function, there are several pieces of code, as follows:</p>
<pre><code>class SocketThread(object):
     def run(self):
           while True: 
                received_data, status = self.recv()
                if status == 0:
                    self.connection.close() 
                    break
     
                self.reply(received_data)

     def reply(self, received_data):
        model = SimpleASR()
        #all threads must averge the model before going to next line
        model_instance = self.model_averaging(model, model_instance)
        print(&quot;All threads completed model averging.&quot;)
        #now do rest of the things 
</code></pre>
<p>In the reply function, I have called one function. I want to write this code in such a way that every thread will proceed to the next line after calling this function.</p>
<p>Every thread must average the model and then proceed to the next line. I understood that I have to use Python condition variable. How can I do that?</p>
<p>The following functions must be mutually exclusive.</p>
<pre><code>model_instance = self.model_averaging(model, model_instance)
</code></pre>
<p>Every thread will proceed to the next line after executing this piece of code.</p>
<p>I am writing this code as part of implementing a federated learning algorithm.
<a href=""https://i.sstatic.net/Ta1FY.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Ta1FY.jpg"" alt=""enter image description here"" /></a></p>
",6379197,,6379197,,45183.80169,45183.80169,make model_averaging exclusive in federated learning using Python Threads,<python><multithreading><mutex><condition-variable><federated-learning>,1,8,,,,CC BY-SA 4.0
77136636,1,,,45188.71758,,1,465,"<p>i am facing &quot;AttributeError: module 'syft' has no attribute 'VirtualWorker'&quot; for &quot;# Create VirtualWorkers hook = syft.VirtualWorker(hook, id=&quot;hook&quot;) &quot;</p>
<h1>Create VirtualWorkers</h1>
<p><code>your text</code>hook = syft.VirtualWorker(hook, id=&quot;hook&quot;)
your text<code>bob = syft.VirtualWorker(hook, id=&quot;bob&quot;) your text</code>alice = syft.VirtualWorker(hook, id=&quot;alice&quot;`</p>
<p>i first tried using</p>
<h1>Create a PySyft hook</h1>
<p><code>your text</code>hook = syft.TorchHook(torch)`</p>
<h1>Create virtual workers</h1>
<p><code>your text</code>bob = syft.VirtualWorker(hook, id=&quot;bob&quot;)
your text<code>alice = syft.VirtualWorker(hook, id=&quot;alice&quot;) your text</code>but it was depricated so i used this approach `</p>
",22405366,,14692,,45369.64436,45369.64436,"i am facing ""AttributeError: module 'syft' has no attribute 'VirtualWorker'"" for ""# Create VirtualWorkers hook = syft.VirtualWorker(hook, id=""hook"") """,<federated-learning><pysyft>,0,0,,,,CC BY-SA 4.0
77377438,1,,,45226.96332,,1,216,"<p>I am using flwr framework to send a random array from client to server and then server will merge the array and sends back to each of the clients.</p>
<pre><code>import numpy as np
import flwr as fl
from flwr.server.strategy import Strategy 
from typing import List

class MergeArraysStrategy(fl.server.strategy.FedAvg): 
     
    def aggregate_fit(self, rnd, results, failures):
        
        aggregated_parameters, aggregated_metrics = super().aggregate_fit(rnd, results, failures)
        print(aggregated_parameters, aggregated_metrics)
        # if aggregated_parameters is not None:
        #     # Convert `Parameters` to `List[np.ndarray]`
        #     aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)

        #     # Save aggregated_ndarrays
        #     print(f&quot;Saving round {rnd} aggregated_ndarrays...&quot;)
        #     np.savez(f&quot;round-{rnd}-weights.npz&quot;, *aggregated_ndarrays)

        # return aggregated_parameters, aggregated_metrics
        print(results)
        self.arrays = []
        for result in results:
            self.arrays.append(result.parameters)

        if self.arrays:
            merged_array = np.concatenate(self.arrays)
            self.arrays = []
            return merged_array, {} 
        else:
            # Return some default or empty array if there are no results
            return np.array([]), {} 
        
    def configure_evaluate(self, server_round, parameters, client_manager):
        pass

    def evaluate(self, value, parameters):
        pass


# Create a Flower server
strategy = MergeArraysStrategy(min_available_clients=3, min_fit_clients=3)
client_manager = fl.server.SimpleClientManager()
server = fl.server.Server(client_manager=client_manager, strategy=strategy)

# Start the server
fl.server.start_server(
    server_address=&quot;127.0.0.1:8080&quot;,
    config=fl.server.ServerConfig(num_rounds=2),
    server=server
)
</code></pre>
<p>Client code:</p>
<pre><code> import flwr as fl
import numpy as np
import flwr   

from flwr.common import (
    Code,
    EvaluateIns,
    EvaluateRes,
    FitIns,
    FitRes,
    GetParametersIns,
    GetParametersRes,
    Status,
    ndarrays_to_parameters,
    parameters_to_ndarrays,
)

class Client(fl.client.NumPyClient):

    def __init__(self, array):
        self.array = array 
        print(self.array)
    
    def get_parameters(self, ins: GetParametersIns) -&gt; GetParametersRes:
        #print(f&quot;[Client {self.cid}] get_parameters&quot;)

        # Get parameters as a list of NumPy ndarray's
        ndarrays: np.ndarray  = self.array

        # Serialize ndarray's into a Parameters object
        parameters = ndarrays_to_parameters(ndarrays)

        # Build and return response
        status = Status(code=Code.EVALUATE_NOT_IMPLEMENTED, message=&quot;Success&quot;)
        return GetParametersRes(
            status=status,
            parameters=parameters,
        )

    # def fit(self, parameters):
    #     self.array = parameters
    #     fit_res = flwr.common.FitRes(status=flwr.common.Status(
    #             code=flwr.common.Code.EVALUATE_NOT_IMPLEMENTED ,
    #             message=&quot;Client does not implement `fit`&quot;,
    #         ),
    #         parameters=self.array,
    #         num_examples=len(self.array ),
    #         metrics={})
    #     return fit_res
    
    def fit(self, ins: FitIns) -&gt; FitRes:
        # Deserialize parameters to NumPy ndarray's
        parameters_original = ins.parameters
        self.array = parameters_to_ndarrays(parameters_original)

        # Update the model parameters using your training logic
        # This is where you should perform the model training with the received parameters

        # Serialize updated ndarray's into a Parameters object
        parameters_updated = ndarrays_to_parameters(self.array)

        # Build and return response
        status = Status(code=Code.EVALUATE_NOT_IMPLEMENTED, message=&quot;Success&quot;)  # Change the status code to SUCCESS
        return FitRes(
            status=status,
            parameters=parameters_updated,  # Return the updated model parameters
            num_examples=len(self.array),
            metrics={},
        )
    
    def evaluate(self, parameters):
        pass
 
# Create a Flower client
client = Client(array=np.random.randn(2))

# Connect to the server
fl.client.start_client(server_address=&quot;127.0.0.1:8080&quot;, client=client)

# The server should handle the aggregation logic and return the merged array
# The client can retrieve the merged array from its 'array' attribute
merged_array = client.array
print(merged_array)
</code></pre>
<p><strong>Scenario:</strong>
Suppose two clients have [1, 2] and [3, 4] data. The server will collect these datasets and concatenate them. Then the server will have [1, 2, 3, 4] and send back to each of the clients. So after one round each client will have [1, 2, 3, 4].</p>
<p>But I am getting the result as my expectation. The error log on the server side is as follows:</p>
<pre><code>INFO flwr 2023-10-27 18:55:29,709 | app.py:165 | Starting Flower server, config: ServerConfig(num_rounds=2, round_timeout=None)
INFO flwr 2023-10-27 18:55:29,745 | app.py:179 | Flower ECE: gRPC server running (2 rounds), SSL is disabled
INFO flwr 2023-10-27 18:55:29,746 | server.py:89 | Initializing global parameters
INFO flwr 2023-10-27 18:55:29,746 | server.py:277 | Requesting initial parameters from one random client     
INFO flwr 2023-10-27 18:55:37,053 | server.py:281 | Received initial parameters from one random client
INFO flwr 2023-10-27 18:55:37,054 | server.py:91 | Evaluating initial parameters
None
INFO flwr 2023-10-27 18:55:37,054 | server.py:105 | FL starting
DEBUG flwr 2023-10-27 18:55:47,744 | server.py:228 | fit_round 1: strategy sampled 3 clients (out of 3)
DEBUG flwr 2023-10-27 18:55:47,759 | server.py:242 | fit_round 1 received 0 results and 3 failures
None {}
[]
INFO flwr 2023-10-27 18:55:47,760 | server.py:172 | evaluate_round 1: no clients selected, cancel
DEBUG flwr 2023-10-27 18:55:47,760 | server.py:228 | fit_round 2: strategy sampled 3 clients (out of 3)      
DEBUG flwr 2023-10-27 18:55:47,766 | server.py:242 | fit_round 2 received 0 results and 3 failures
None {}
[]
INFO flwr 2023-10-27 18:55:47,766 | server.py:172 | evaluate_round 2: no clients selected, cancel
INFO flwr 2023-10-27 18:55:47,767 | server.py:154 | FL finished in 10.712144899999998
INFO flwr 2023-10-27 18:55:47,767 | app.py:225 | app_fit: losses_distributed []
INFO flwr 2023-10-27 18:55:47,768 | app.py:226 | app_fit: metrics_distributed_fit {}
INFO flwr 2023-10-27 18:55:47,768 | app.py:227 | app_fit: metrics_distributed {}
INFO flwr 2023-10-27 18:55:47,768 | app.py:228 | app_fit: losses_centralized []
INFO flwr 2023-10-27 18:55:47,769 | app.py:229 | app_fit: metrics_centralized {}    
       
        
         
</code></pre>
",6379197,,6379197,,45226.9673,45393.62713,Why fit_round received failures in flwr framework?,<python><pytorch><federated-learning>,1,0,,,,CC BY-SA 4.0
77513547,1,,,45250.19625,,0,312,"<p>I made a model for detecting seven objects that detect people using YOLOv8 and saved it as .pt.</p>
<p>The dataset is a jpg and txt file consisting of images and labels.</p>
<p>How can I apply Federated Learning to YOLOv8n in a Google colab environment?</p>
<p>I'm a beginner in CV field.</p>
<pre><code>import openfl.native as fx
import torch
from torch.optim import SGD
import torchvision.transforms as T
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from ultralytics import YOLO

# ë¡œì»¬ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
model_files = [
    &quot;/content/drive/MyDrive/runs/detect/local_1_train_result/weights/best.pt&quot;,
    &quot;/content/drive/MyDrive/runs/detect/local_2_train_result/weights/best.pt&quot;,
    &quot;/content/drive/MyDrive/runs/detect/local_3_train_result/weights/best.pt&quot;,
    &quot;/content/drive/MyDrive/runs/detect/local_4_train_result/weights/best.pt&quot;,
    &quot;/content/drive/MyDrive/runs/detect/local_5_train_result/weights/best.pt&quot;,
    &quot;/content/drive/MyDrive/runs/detect/local_6_train_result/weights/best.pt&quot;,
    &quot;/content/drive/MyDrive/runs/detect/local_7_train_result/weights/best.pt&quot;
]

# ë°ì´í„° ê²½ë¡œ
data_path = '/content/drive/MyDrive/local_1_final_all/train'

# YOLOv5 ëª¨ë¸ ë¡œë“œ
def load_yolov8_model():
    model = YOLO(model='yolov8n.pt')
    return model

# ë¡œì»¬ ëª¨ë¸ ë¡œë“œ
local_models = []
global_model = load_yolov8_model()

for i, model_file in enumerate(model_files):
    local_model = load_yolov8_model()
    local_model.load_state_dict(torch.load(model_file))
    local_models.append(local_model)
    global_model.features[i] = local_model.features[i]

# ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
transform = T.Compose([T.ToTensor()])

def custom_collate_fn(batch):
    return tuple(zip(*batch))

dataset = ImageFolder(data_path, transform=transform)
data_loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)

# OpenFL ì´ˆê¸°í™”
fx.init('torch', 'openfl', local_model=global_model)

# ì—°í•© í•™ìŠµì„ ìœ„í•œ ì˜µí‹°ë§ˆì´ì € ì„¤ì •
optimizer = SGD(global_model.parameters(), lr=0.001)

# ì—°í•© í•™ìŠµ ì‹¤í–‰
fx.federated_averaging(
    model=global_model,
    data={'data': dataset},
    server_optimizer=optimizer,
    aggregation='mean',
    rounds=10
)

# ì—°í•© ëª¨ë¸ ì €ìž¥
torch.save(global_model.state_dict(), &quot;/content/drive/MyDrive/federated_model.pt&quot;)

</code></pre>
<p>I tried the above, but I failed all of them.</p>
",22948835,,,,,45250.19625,How can I apply federated learning to YOLOv8 model?,<python><computer-vision><yolov8><federated-learning>,0,0,,,,CC BY-SA 4.0
77534661,1,,,45253.25703,,0,170,"<p>I am using the pysyft library 0.8.2 to implement Federated Learning experiment. At one part of the code I am supposed to send the tensor information over clients established using pysyft commands. But the attributes send() and get() are no longer supported by Pytorch 2.1.0.</p>
<p>import torch
import pysyft as sy</p>
<p>bob = sy.Worker(name='bob')
print(bob)
print(bob.client_cache)
x = torch.tensor([1,2,3])
print(x)
x.send(bob)   # error message: 'Tensor' objects has no attributes 'send'
print(x)</p>
<p>How to overcome this dilemma and send tensors over the clients?</p>
<p>I do not know whether I have to download an older version of pytorch to get send() and get() attributes or there will be another way to send the tensor over pysyft client.</p>
",9959811,,9959811,,45253.25747,45254.17889,'Tensor' object has no attribute 'send',<python><pytorch><federated-learning><pysyft>,0,0,,,,CC BY-SA 4.0
77547784,1,,,45255.50425,,0,277,"<p>An attribute Error raised when importing tensorflow_federated on colab though I did install it.</p>
<p><code>!pip install --quiet --upgrade tensorflow-federated</code></p>
<p><code>import tensorflow as tf</code></p>
<p><code>import tensorflow_federated as tff</code></p>
<p>--&gt; import tensorflow_federated as tff : AttributeError: module 'numpy' has no attribute '_no_nep50_warning'</p>
<p>how can I solve it?
Thank you!</p>
<p><code>!pip install --quiet --upgrade tensorflow-federated</code></p>
<p><code>import tensorflow as tf</code></p>
<p><code>import tensorflow_federated as tff</code></p>
",22982880,,22982880,,45255.50625,45266.42157,Can't import tensorflow_federated,<tensorflow><tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
77732938,1,,,45289.6791,,0,53,"<p>I want to train a multi-modal model in the federated learning environment.
this is my model definition.</p>
<pre><code>num_classes=5
def image_text_model():
  # Define the image input
  image_input = Input(shape=(224, 224, 3), name='image_input')
  # text_input = Input(shape=(tokenizer.model_max_length, ), dtype=tf.int32, name='text_input')

  input_ids = Input(shape=(96,), dtype=tf.int32, name='input_ids')
  token_type_ids = Input(shape=(96,), dtype=tf.int32, name='token_type_ids')
  attention_mask = Input(shape=(96,), dtype=tf.int32, name='attention_mask')


  # Use the base_model to extract features from the image input
  # image_features = img_model()

  resnet_model = ResNet50(weights='imagenet', include_top=False)
  image_output = resnet_model(image_input)
  image_output = GlobalAveragePooling2D()(image_output)

  # Use the BERT model to extract features from the text input
  text_features = bert_model(input_ids, token_type_ids, attention_mask).pooler_output

  # Concatenate the image features and text features
  concatenated = concatenate([image_output,text_features])

  # Add a Dense layer
  x = Dense(units=128, activation='relu')(concatenated)

  # Add the output Dense layer with softmax activation for classification
  output = Dense(num_classes, activation='softmax')(x)

  # Define the model
  model = tf.keras.Model(inputs=[image_input, input_ids, token_type_ids, attention_mask], outputs=[output])

  return model

def federated_model():
  keras_model = image_text_model()
  return tff.learning.models.from_keras_model(
      keras_model,
      input_spec=[tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),
          tf.TensorSpec(shape=(96,), dtype=tf.int32),
          tf.TensorSpec(shape=(96,), dtype=tf.int32),
          tf.TensorSpec(shape=(96,), dtype=tf.int32)
          ],

      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]

  )

# Create a tff learning process
iterative_process =  tff.learning.algorithms.build_weighted_fed_avg(
    model_fn=federated_model,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),
    # metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]
    )

# Initialize the Federated Averaging algorithm to get the initial model state.
state = iterative_process.initialize()

# Run one round of Federated Averaging.
state, metrics = iterative_process.next(state, next(train_generator))
print('round  1, metrics={}'.format(metrics))

# You can continue training with additional rounds as needed.
# state, metrics = iterative_process.next(state, clients_data)
# print('round  2, metrics={}'.format(metrics))
</code></pre>
<p>this is my <code>bert_model</code> code <code>bert_model = TFBertForSequenceClassification.from_pretrained(&quot;bert-base-uncased&quot;, num_labels=5)</code>.
When I want to train the model I got this error. <a href=""https://i.sstatic.net/wCQEr.png"" rel=""nofollow noreferrer"">enter image description here</a>
I load my data by using the generator.
and this is my value error</p>
<pre><code>ValueError: Your Layer or Model is in an invalid state. This can happen for the following cases:
 1. You might be interleaving estimator/non-estimator models or interleaving models/layers made in tf.compat.v1.Graph.as_default() with models/layers created outside of it. Converting a model to an estimator (via model_to_estimator) invalidates all models/layers made before the conversion (even if they were not the model converted to an estimator). Similarly, making a layer or a model inside a a tf.compat.v1.Graph invalidates all layers/models you previously made outside of the graph.
2. You might be using a custom keras layer implementation with custom __init__ which didn't call super().__init__.  Please check the implementation of &lt;class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'&gt; and its bases.


</code></pre>
",23060018,,23060018,,45292.59572,45292.59572,training federated model by bert and resnet pre-train model,<tensorflow><deep-learning><huggingface-transformers><tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
77798059,1,,,45302.27131,,0,53,"<p>I am working on a federated learning project. I write a code to stimulate the process of federated learning. However, after global aggregation in every iteration, the test accuracy of the global model will decrease a lot and remain unchanged in the following iteration. The algorithm of aggregation I used is FedAvg. And I have tried to split my code into different units to find out the problem.
For the local training, the selected clients train for 3 epochs. In this experiment, all five clients will be selected for training and aggregation, the model I used for the local is the vgg16 forked from <code>torchvision</code>, the dataset is the MNIST and split in i.i.d manner for each client:</p>
<pre><code>for id, net_id in enumerate(selected):
    logging.info(&quot;Training Selected Device %s.&quot; % (str(net_id)))
    result = Userlists[net_id].train(hparams['n_local_epochs'])
    logging.info('&gt;&gt; Local model %d: local accuracy: %f in round %d\n' % (id, result['local_test_acc'], step+1)) 
</code></pre>
<p>Before the aggregation of the local model, I test the accuracy of the local model using the test data of the global server,</p>
<pre><code>tesc, conf = misc.compute_accuracy(Userlists[2].model, test_dl_global, get_confusion_matrix=True, device=hparams['device'])
print(tesc)
&gt; 0.2478966346153846
tesc, conf = misc.compute_accuracy(Userlists[3].model, test_dl_global, get_confusion_matrix=True, device=hparams['device'])
print(tesc)
&gt; 0.14413060897435898
tesc, conf = misc.compute_accuracy(Userlists[4].model, test_dl_global, get_confusion_matrix=True, device=hparams['device'])
print(tesc)
&gt; 0.17387820512820512
</code></pre>
<p>And I used the aggregation code below to aggregate the weights of selected clients:</p>
<pre><code>total_sum = 0.0
for client_idx in selected:
    total_sum += Userlists[client_idx].data_len    
    
    
global_para = global_model.state_dict()
client_weights = [torch.tensor(  Userlists[client_idx].data_len/total_sum, device=hparams['device']) for client_idx in selected]

with torch.no_grad():
    for order, idx in enumerate(selected):
        logging.info(f&quot;For Client {idx}&quot;)
        net_para = Userlists[idx].model.state_dict()
        
        if order == 0:
            for key in net_para.keys():
                global_para[key] = net_para[key] * client_weights[order]
        else:
            for key in net_para.keys():
                global_para[key] += net_para[key] * client_weights[order]


global_model.load_state_dict(global_para)
tesc, conf = misc.compute_accuracy(global_model, train_dl_global, get_confusion_matrix=True, device=hparams['device'])
</code></pre>
<p>And the global test accuracy decreases and remains the same as</p>
<pre><code>&gt; 0.11236666666666667
</code></pre>
<p>Although I have try to increase the epochs of local training as the local accuracy increase to <code>40%</code>, the global accuracy still fall into the same value as before. Is there any wrong place in my code for aggregation?</p>
<p>The test accuracy should remain at the same level as the local accuracy.</p>
",16566894,,6933807,,45303.74588,45303.74588,The accuracy decreased after global aggregation in federated learning,<python><machine-learning><pytorch><federated-learning>,0,0,,,,CC BY-SA 4.0
77876217,1,,,45315.8792,,0,42,"<p>Iâ€™m apply federated learning on several datasets,having similar output feature but different input features, how cany I do that. By feature I mean columns in the dataset. I want to know is this even possible to do? Please provide a comprehensive answer?</p>
",20251201,,,,,45315.8792,How can I perform Federated Learning on different dataset files having same output feature but different input feature?,<tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
77918043,1,,,45323.2619,,0,27,"<p>I am looking for a way to create a federated learning scenario with three masters and client network, and this functions similar to centralized federated learning,</p>
<p>does pytorch support this , are there any libraries,policies, algorithms in pytorch that would let me achieve this?</p>
",22216565,,1091386,,45379.27976,45379.27976,multiple masters in centralized federated learning,<python-3.x><pytorch><federated-learning>,0,0,,,,CC BY-SA 4.0
78138686,1,,,45362.25796,,0,18,"<p>I am doing a project in federated learning . I got this error.</p>
<pre><code>  AttributeError Traceback (most recent call last)
    &lt;ipython-input-62-c7a27f8e5bd7&gt; in &lt;cell line: 2&gt;()
          1 sample_clients=emnist_train.client_ids[0:NUM_CLIENTS]
    ----&gt; 2 federated_train_data= make_federated_data(emnist_train,sample_clients)
          3 print('Number of client datasets:{1}'.format(l=len(federated_train_data)))
         4 print('First dataset:{d}'.format(d=federated_train_data[0]))

    1 frames
    &lt;ipython-input-60-5de6a0b9b2fa&gt; in &lt;listcomp&gt;(.0)
          1 def make_federated_data(client_data,client_ids):
          2   return[
     ----&gt; 3       preprocess(client_data.create_tf_dataset_for_clients(x))
          4       for x in client_ids
         5   ]
</code></pre>
<p>Can anyone help me to resolve it ?</p>
<p>I have tried to load different mnist dataset. But I couldn't find data with attributes <code>create_tf_dataset_for_clients</code></p>
",16056184,,6144704,,45363.47374,45363.47374,AttributeError: 'PreprocessClientData' object has no attribute 'create_tf_dataset_for_clients',<federated-learning>,0,0,,,,CC BY-SA 4.0
78176551,1,,,45368.79517,,1,30,"<p>I'm trying to implement federated learning to forecast solar photovoltaic generation using the LADPU dataset.
After preprocessing the dataset, I partitioned it into segments to simulate a federated environment, aligning each segment with unique <code>METER_FID</code> values for 10 different clients.
The next step involved creating sequences from these partitions as LSTM model inputs.
I used a <code>create_sequence</code> function for this, targeting sequences with <code>START_READ</code> and <code>END_READ</code> features to predict <code>INTERVAL_READ</code>.
However, when I split these into training and validation sets and set up PyTorch <code>DataLoader</code> objects (including a separate <code>test_loader</code> for evaluation), there is an issue. My Colab session consistently crashes due to exhausting all available RAM.
I tried to reduce the batch size and limit to 6 CSV files,but the issue persists.</p>
<p>I am very new to it,I am referring to the tutorials and documentation given in <a href=""https://flower.ai"" rel=""nofollow noreferrer"">https://flower.ai</a> for my usecase.I can't figure out the problem or possibly I am missing out on something. Can anyone please help.</p>
<pre><code>#for partitioning I did this

 NUM_CLIENTS = 10

def partition_data(df, num_clients):
    np.random.seed(42) 
    unique_ids = df['METER_FID'].unique()
    np.random.shuffle(unique_ids) 
    partitions = np.array_split(unique_ids, num_clients)  
    partitioned_dfs = [df[df['METER_FID'].isin(ids)] for ids in partitions]
    return partitioned_dfs

partitioned_dfs = partition_data(df, NUM_CLIENTS)

#then created sequences from each partition to serve as input for an LSTM model
def create_sequences_efficiently(df, sequence_length=5):
    sequences, targets = [], []

    df = df.sort_values('INTERVAL_TIME')
    for i in range(sequence_length, len(df)):
        sequence = df[['START_READ', 'END_READ']].values[i-sequence_length:i]  
        target = df['INTERVAL_READ'].values[i]  
        sequences.append(sequence)
        targets.append(target)
    return np.array(sequences), np.array(targets)

#then split
from torch.utils.data import DataLoader, TensorDataset
import torch
from sklearn.model_selection import train_test_split


def create_loaders(partition, sequence_length=5, batch_size=32):
    sequences, targets = create_sequences_efficiently(partition, sequence_length)
    # Convert sequences and targets into PyTorch tensors
    sequence_tensor = torch.tensor(sequences, dtype=torch.float32)
    target_tensor = torch.tensor(targets, dtype=torch.float32)
    # Create a TensorDataset and DataLoader
    dataset = TensorDataset(sequence_tensor, target_tensor)
    return DataLoader(dataset, batch_size=batch_size, shuffle=True)

# create the loaders for each partition
train_loaders, val_loaders = [], []
for partition_df in partitioned_dfs:
    # Split the data of each client into training and validation sets
    train_df, val_df = train_test_split(partition_df, test_size=0.2, random_state=42)
    # Create loaders for the training and validation sets
    train_loader = create_loaders(train_df, sequence_length=5, batch_size=16)
    val_loader = create_loaders(val_df, sequence_length=5, batch_size=16)
    train_loaders.append(train_loader)
    val_loaders.append(val_loader)
</code></pre>
",15836384,,14692,,45368.97157,45368.97157,DataLoader Causing RAM Crashes in PyTorch Federated Learning: Solutions?,<pytorch-dataloader><federated-learning>,0,0,,,,CC BY-SA 4.0
78185619,1,,,45370.41289,,0,47,"<p>This is a loss function of a personalized federated learning framework. When lambda equals 0, all clients train locally. Otherwise they adjust their parameters based on the similarity to the global model.</p>
<p>Version 1, server returns the global_model to every client:</p>
<pre><code>    def mtl_loss_fn(self, logits, labels, shared_model):
        sample_loss_fn = torch.nn.CrossEntropyLoss()
        mean_batch_term = sample_loss_fn(logits, labels)

        shared_model = shared_model.to(device='cuda')

        w_diff = torch.tensor(0., device=self.device)
        for w, w_t in zip(self.model.parameters(), shared_model.parameters()):
            w_diff += torch.pow(torch.norm(w - w_t), 2)

        prox_term = 0.5 * self.lam * w_diff
        # print(f&quot;mean batch term: {mean_batch_term}, prox_term: {prox_term}&quot;)
        return mean_batch_term + prox_term
</code></pre>
<p>Version 2, server returns the parameters of the global_model to every client:</p>
<pre><code>    def mtl_loss_fn(self, logits, labels, shared_model_parameters):
        sample_loss_fn = torch.nn.CrossEntropyLoss()
        mean_batch_term = sample_loss_fn(logits, labels)

        for x in shared_model_parameters:
            x.to(device='cuda')

        w_diff = torch.tensor(0., device=self.device)
        for w, w_t in zip(self.model.parameters(), shared_model_parameters):
            w_diff += torch.pow(torch.norm(w - w_t), 2)

        prox_term = 0.5 * self.lam * w_diff
        # print(f&quot;mean batch term: {mean_batch_term}, prox_term: {prox_term}&quot;)
        return mean_batch_term + prox_term
</code></pre>
<p>Version 1 works well, but version 2 turns into completely local training no matter what lambda is.</p>
<p>I don't know why, they look the same to me..</p>
",21679534,,21679534,,45370.41553,45370.41995,Why these two loss function are not the same?,<pytorch><loss-function><federated-learning>,1,0,,,,CC BY-SA 4.0
78192538,1,,,45371.43569,,0,24,"<p>I am building a CatBoost model to simulate the federated learning system at first I am training the local models on the same Catboost model using a for loop code:</p>
<pre><code>for j in range(len(Train_Datasets)): 
    
    df_train= Train_Datasets[j]
    df_test= Test_Datasets[j]
    x_train = df_train.drop(['index', 'binary_attack'], axis=1)
    x_test = df_test.drop(['index', 'binary_attack'], axis=1)
    y_train = df_train['binary_attack']
    y_test = df_test[&quot;binary_attack&quot;] 
    
    local_model = CatBoostClassifier(**params)
    local_model.fit(x_train, y_train)
</code></pre>
<p>Later I am appending all the local models and sum them using Sum_model function from the Catboost package:</p>
<pre><code>models.append(local_model)
global_model = sum_models(models, weights=0.7)
global_model= to_classifier(global_model)
</code></pre>
<p>I am getting this error whenever I add the weights=0.7 parameter:</p>
<blockquote>
<p>TypeError: object of type 'float' has no len()</p>
</blockquote>
<p>However, I tried once the same code with adding the weights parameter, and it worked. Do you have any suggestions on what might be the problem?</p>
",13201830,,,,,45371.43569,"Error ""TypeError: object of type 'float' has no len()"" when adding parameter ""weights"" to sum_model in catboost classifier",<python-3.x><catboost><federated-learning>,0,0,,,,CC BY-SA 4.0
78221905,1,,,45376.90185,,0,120,"<p>I want to send extra parameters with model updates to server and then utilize those extra parameters in server for other purposes. I am using Flower and Tensorflow for this project. Before sending extra parameters, my model was working perfectly. Currently I have these code<a href=""https://i.sstatic.net/j9nLx.png"" rel=""nofollow noreferrer"">client model</a> <a href=""https://i.sstatic.net/K82hf.png"" rel=""nofollow noreferrer"">server.py</a>.</p>
<p>How do I successfully send extra parameters or values in server and receive it?</p>
<p>Thank you for your help.</p>
<p>I tried to send additional parameters in get_parameter method, and receive it with FedAvg strategy. But I got this error again and again. <a href=""https://i.sstatic.net/zeRVX.png"" rel=""nofollow noreferrer"">error</a></p>
",10359644,,10359644,,45377.67775,45408.43943,How to send extra parameters to server in Federated learning with Flower and Tensorflow?,<python><tensorflow><machine-learning><federated-learning>,0,2,,,,CC BY-SA 4.0
78271162,1,,,45386.04493,,1,21,"<p>I am implementing federated averaging on the <a href=""https://www.stratosphereips.org/datasets-iot23"" rel=""nofollow noreferrer"">IoT-23 dataset(lighter version)</a></p>
<p>Omitting the preprocessing I am saving the data into a test set and 9 train sets as below:</p>
<pre><code>X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state=10, test_size=0.2)
test_set = pd.concat([X_test, Y_test], axis=1)
test_set.to_csv('./dataset/test_set.csv')

num_sets = 9

set_size = len(X_train) // num_sets
train_sets = np.array_split(train_set, num_sets)
for i in range(num_sets):
    train_sets[i].to_csv(f'./dataset/train{i}.csv')#type:ignore
</code></pre>
<p>My model looks like this:</p>
<pre><code>model = models.Sequential([
        layers.Input(shape=(24,)),
        layers.Dense(150,activation='relu'),
        layers.Dense(80,activation='relu'),
        layers.Dropout(0.2),
        layers.Dense(7, activation='softmax')
    ])
    loss_fn = losses.CategoricalFocalCrossentropy(alpha=0.2)
    model.compile(loss=loss_fn, optimizer='rmsprop', metrics=['accuracy'])
</code></pre>
<p>Now with these I am training and saving weights for each of the train sets:</p>
<pre><code>for client_number in range(9):
    model = models.load_model('./model/model.keras')
    train_data=pd.read_csv(f&quot;./dataset/train{client_number}.csv&quot;,dtype='float')
    X_train = train_data.iloc[:, 1:-7]
    y_train = train_data.iloc[:, -7:]
    
    base_model.fit(X_train, y_train, epochs=5)

    model.save_weights(f'./weights/weight{client_number}.weights.h5')#type:ignore
</code></pre>
<p><a href=""https://i.sstatic.net/uogr0.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/uogr0.png"" alt=""enter image description here"" /></a><br />
As you can see from the screenshot each of them does give different accuracies while training</p>
<p>Now for federated averaging I am <a href=""https://towardsdatascience.com/federated-learning-a-step-by-step-implementation-in-tensorflow-aac568283399"" rel=""nofollow noreferrer"">using this <code>sum_scaled_weights()</code> method</a> but without adding weights since I've divided the dataset into equal sizes.</p>
<pre><code>def sum_weights(weight_list):
    averaged_weights = list()
    #get the average grad accross all client gradients
    for grad_list_tuple in zip(*weight_list):
        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)
        averaged_weights.append(layer_mean)
        
    return averaged_weights
</code></pre>
<p>I am aggregating the weights with something like:</p>
<pre><code>model=models.load_model('./model/model.keras')
for i in range(3):
    model.load_weights(f'./weights/weight{i}.weights.h5')#type:ignore
    org_weights.append(model.get_weights())#type:ignore

average_weights = sum_weights(org_weights)
model.set_weights(average_weights)
    
loss, accuracy = model.evaluate(X, y)#type:ignore
print(f'Org Aggregate no.{j} accuracy: {accuracy}')
</code></pre>
<p>Now the issue I'm running into is that regardless of how many weights I aggregate, the accuracy when checking for test ends up the exact same.
eg. with 3 of them seperately (i.e weights 0-2,3-5,6-8):<br />
<a href=""https://i.sstatic.net/r3StG.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/r3StG.png"" alt=""enter image description here"" /></a></p>
<p>with all 9:<br />
<a href=""https://i.sstatic.net/Y8Po0.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Y8Po0.png"" alt=""enter image description here"" /></a></p>
<p>I have tried the test set with the initial weights instead and they do give me different accuracies:<br />
<a href=""https://i.sstatic.net/tUv35.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/tUv35.png"" alt=""enter image description here"" /></a></p>
<p>I'm honestly stumped and curious about how and why this is happening. Any explanation or corrections for any error in the logic would be appreciated.</p>
",21321616,,,,,45386.04493,Federated Averaging somehow always gives identical accuracy on test set,<python><tensorflow><machine-learning><keras><federated-learning>,0,0,,,,CC BY-SA 4.0
78294778,1,,,45390.81962,,0,19,"<p>I have installed tff 0.75.0, TF is 2.14.1, Python is 3.10.12 and working on Google Colab.</p>
<p>Error in my program:</p>
<blockquote>
<p>thisAttributeError: module 'tensorflow_federated.python.learning' has no attribute 'Model'</p>
</blockquote>
<p>I have tried lots of versions by downgrading and upgrading when I do downgrading than I have conflict issues when doing upgrading than these attribute errors.</p>
<p>Which version is best to resolve these kinds of errors?</p>
",22670286,,472495,,45390.87782,45390.87782,module 'tensorflow_federated.python.learning' has no attribute 'Model',<python><tensorflow><google-colaboratory><attributeerror><federated-learning>,0,0,,,,CC BY-SA 4.0
78389817,1,,,45408.43624,,0,30,"<p>I want to use Flower for developing a distributed federated learning application, where instead of a single aggregator, there will be multiple servers for the aggregation.<br />
I am wondering if it is possible to run multiple servers using Flower to decentralize the aggregation and how to do it?</p>
",24702966,,6266506,,45408.55781,45408.55781,Flower API running with multiple aggregation servers,<flower><federated-learning>,0,0,,,,CC BY-SA 4.0
78398118,1,,,45410.50804,,0,20,"<p>I'm implementing the Per-FedAvg algorithm with HF-MAML, in which the Hessian Matrix product is approximated by disturbing model parameters $W$ with a small delta $\delta$ (e.g. 0.001), and is calculated as bellow:</p>
<p>$H = \frac{\nabla (w+\delta*\nabla w)-\nabla (w-\delta*\nabla w)}{2*\delta}$</p>
<p>Then we use the following formula to update model:
$w' = w - \beta \times ( \nabla w * (I- \alpha * H))$</p>
<p>Where \alpha and \beta are predefined learning-rate-like parameters. I is the identity matrix so the upper equation can be written in python code:</p>
<pre class=""lang-py prettyprint-override""><code>for param, grad1, grad2 in zip(model.parameters(), grad_1, grad_2):
    param.data.sub_(beta * grad1 - beta * alpha * grad2)
</code></pre>
<p>After updating the local models, they are sent to server for averaging.
However, when I use AlexNet on CIFAR-10 dataset, the training loss will suddenly explode to Nan at some point. I tried a lot of methods, and the only way to deal with it is to comment the nn.Dropout() functions in model.</p>
<pre class=""lang-py prettyprint-override""><code>        self.classifier = nn.Sequential(
            # nn.Dropout(),
            nn.Linear(256 * 2 * 2, 1024),
            nn.ReLU(inplace=True),
            # nn.Dropout(),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Linear(512, class_num),
        )
</code></pre>
<p>I just don't understand why. The full model code and the training code are as follows.</p>
<pre class=""lang-py prettyprint-override""><code>class AlexNet(nn.Module):
    def __init__(self,class_num=10):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            # 3 32 32
            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),
            # 64 32+2-2=32 32/2=16
            nn.ReLU(inplace=True),
            # 64 16 16
            nn.MaxPool2d(kernel_size=2),
            # 64 8 8
            nn.Conv2d(64, 192, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            # 192 8 8
            nn.MaxPool2d(kernel_size=2),
            # 192 4 4
            nn.Conv2d(192, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            # 384 4 4
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            # 256 4 4
            nn.Conv2d(256, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=2),
            # 256 2 2
        )
        self.classifier = nn.Sequential(
            # nn.Dropout(),
            nn.Linear(256 * 2 * 2, 1024),
            nn.ReLU(inplace=True),
            # nn.Dropout(),
            nn.Linear(1024, 512),
            nn.ReLU(inplace=True),
            nn.Linear(512, class_num),
        )

    def forward(self, x):
        x = self.features(x)
        x = x.view(-1, 256 * 2 * 2)
        x = self.classifier(x)
        # return F.log_softmax(x, dim=1)
        return x
</code></pre>
<pre class=""lang-py prettyprint-override""><code>def train(model, train_loader, alpha, beta, local_iters=None, local_epochs=1, device=torch.device(&quot;cpu&quot;), model_type=None):
    t_start = time.time()
    model.train()
    
    # First Order MAML train for local_ites
    if local_iters is None:
        # 2 batches 1 update
        local_iters = math.ceil(len(train_loader.loader.dataset) / train_loader.loader.batch_size / 2)
    
    losses = [0.0, 0.0, 0.0]
    sample_num = [0, 0, 0]

    for epoch_idx in range(local_epochs):
        for epoch in range(local_iters):
            temp_model = copy.deepcopy(model)
            # step 1: one step train
            batch_1 = next(train_loader)
            temp_model, one_step_loss = one_step(device, batch_1, temp_model, model_type, lr=alpha)

            # step 2: get grad
            batch_2 = next(train_loader)
            grad_1, grad_loss = compute_grad(temp_model, batch_2, device)

            # step 3: approximate 2nd grad
            batch_3 = next(train_loader)
            grad_2, grad2_loss = compute_grad(model, batch_3, device, v=grad_1, second_order_grads=True)

            # step 3: update model
            for param, grad1, grad2 in zip(model.parameters(), grad_1, grad_2):
                param.data.sub_(beta * grad1 - beta * alpha * grad2)
        
            losses = [losses[0]+one_step_loss, losses[1]+grad_loss, losses[2]+grad2_loss]
            sample_num = [sample_num[0]+len(batch_1[0]), sample_num[1]+len(batch_2[0]), sample_num[2]+len(batch_3[0])]

    return {'train_loss': losses[0]/sample_num[0] if sample_num[0] != 0 else losses[0], 
            'grad_loss': losses[1]/sample_num[1] if sample_num[1] != 0 else losses[1], 
            'grad2_loss': losses[2]/sample_num[2] if sample_num[2] != 0 else losses[2],
            'train_time': time.time()-t_start,
            'samples_num': sum(sample_num),
            'params': torch.nn.utils.parameters_to_vector(model.parameters()).detach()}


def one_step(device, data, model, model_type, lr):
    &quot;&quot;&quot;
    Performs one step of training for a given device, data, model, and learning rate.

    Args:
        device (torch.device): The device (CPU or GPU) on which to perform the calculations.
        data (tuple): A tuple containing the input sequence (seq) and corresponding label (label).
        model (torch.nn.Module): The model to train.
        lr (float): The learning rate for the optimizer.

    Returns:
        tuple: A tuple containing the updated model and the loss value as a float.
    &quot;&quot;&quot;
    seq, label = data

    if model_type == 'LR':
        seq = data.squeeze(1).view(-1, 28 * 28)

    seq = seq.to(device)
    label = label.to(device)
    y_pred = model(seq)
    optimizer = torch.optim.SGD(model.parameters(), lr=lr)
    loss_function = nn.CrossEntropyLoss().to(device)
    loss = loss_function(y_pred, label)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    return model, loss.item()


def compute_grad(model, data_batch, device, v=None, second_order_grads=False):
    &quot;&quot;&quot;
    Compute the gradients of the model parameters with respect to the loss function.

    Parameters:
    - model: The model for which to compute the gradients.
    - data_batch: The input data batch consisting of features and labels.
    - device: The device on which to perform the computations.
    - v: Optional. The second-order gradients used for computation.
    - second_order_grads: Optional. Whether to compute second-order gradients.

    Returns:
    - grads: The gradients of the model parameters.
    - loss: The computed loss value.
    &quot;&quot;&quot;
    x, y = data_batch
    x, y = x.to(device), y.to(device)
    loss_func = nn.CrossEntropyLoss().to(device)

    if second_order_grads:
        frz_model_params = copy.deepcopy(model.state_dict())
        delta = 1e-3
        dummy_model_params_1 = OrderedDict()
        dummy_model_params_2 = OrderedDict()
        with torch.no_grad():
            for (layer_name, param), grad in zip(model.named_parameters(), v):
                dummy_model_params_1.update({layer_name: param + delta * grad})
                dummy_model_params_2.update({layer_name: param - delta * grad})

        model.load_state_dict(dummy_model_params_1, strict=False)
        logit_1 = model(x)
        # loss_func = nn.CrossEntropyLoss().to(device)
        loss_1 = loss_func(logit_1, y)

        grads_1 = torch.autograd.grad(loss_1, model.parameters())

        model.load_state_dict(dummy_model_params_2, strict=False)
        logit_2 = model(x)
        # loss_func_2 = nn.CrossEntropyLoss()
        loss_2 = loss_func(logit_2, y)
        grads_2 = torch.autograd.grad(loss_2, model.parameters())

        model.load_state_dict(frz_model_params)

        grads = []
        with torch.no_grad():
            for g1, g2 in zip(grads_1, grads_2):
                grads.append((g1 - g2) / (2 * delta))
        return grads, (loss_1.item()+loss_2.item())/2

    else:
        logit = model(x)
        loss = loss_func(logit, y)
        grads = torch.autograd.grad(loss, model.parameters())
        return grads, loss.item()
</code></pre>
<p>I tried the following:</p>
<ol>
<li><p>lower the learning rate, i.e. Alpha and beta. Didn't help. Some clients' model will suddenly jump to a infinite training loss, then updating these models to server will cause all models to degrade to a mess.</p>
</li>
<li><p>lower the disturbing parameter \delta. It becomes even worse, as in the first round all models get a Nan test loss. I believe this could be the place where the issue hides.</p>
</li>
<li><p>Disable the two Dropout() layer in AlexNet. It worked, and runs smoothly towards the end.</p>
</li>
</ol>
<p>I believe the Dropout somehow break my training process, but disabling it may overfit the model. If I can figure out the real issue then I can use Dropout without concerns.</p>
",24747036,,,,,45410.50804,Nan value when using nn.Dropout() in AlexNet on CIFAR-10 implementing Per-FedAvg algorithm,<pytorch><nan><dropout><federated-learning><meta-learning>,0,0,,,,CC BY-SA 4.0
78398361,1,,,45410.57182,,0,75,"<pre><code>import pandas as pd
import sklearn
from sklearn.datasets import load_iris
Loading data from a CSV file
data = pd.read_csv('D:/Projects/FLGRU_Model/FLDataset/01-12/DrDoS_LDAP.csv')
df = pd.read_csv(data)
Performing data analysis
df.head()  # Display the first few rows
df.describe()  # Statistical summary of the data
</code></pre>
<p>What could be the problem with the following code,? its not reading the data</p>
<p>I was reading the data and te code is giving the following errors</p>
<pre><code> DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.
  data = pd.read_csv('D:/Projects/FLGRU_Model/FLDataset/01-12/DrDoS_LDAP.csv')
Traceback (most recent call last):
</code></pre>
",24748686,,15456681,,45410.58223,45410.67402,Reading Data in Python using pandas,<python><pandas><numpy><federated-learning>,2,3,,,,CC BY-SA 4.0
78410724,1,,,45412.81821,,0,48,"<p>I'm developing a sort of federated learning environment and it contains a Server class and 10 instances of the Client classes. I train the various clients one after the other and I'd like to specify an upper limit regarding the GPU usage for each client.
For example:</p>
<pre><code>class Client:
    def __init__(self, id:int, neighbors:list, trainloader, valloader, testloader, gpu_fraction, device):
        self.id=id
        self.neighbors = neighbors
        self.model=None
        self.trainloader = trainloader
        self.valloader = valloader
        self.testloader = testloader
        self.gpu_fraction = gpu_fraction
        self.GPU_usage_table=None
        self.device = device   
</code></pre>
<p>this is my Client class and I'd like to instantiate every client with a different value of gpu_fraction and then, when a Client executes the training function, I'd like not to use the entire GPU of my PC but just the percentage specified by the gpu_fraction.</p>
<p>I tried with this code</p>
<pre><code>        import tensorflow as tf
        gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=self.gpu_fraction)
        config = tf.compat.v1.ConfigProto(gpu_options=gpu_options)
        session = tf.compat.v1.Session(config=config)
</code></pre>
<p>before executing the training function for every client, but it doesn't seem to work.
To test if this approach works I used the following code:</p>
<pre><code>            nvidia_smi.nvmlInit()
            deviceCount = nvidia_smi.nvmlDeviceGetCount()
            for i in range(deviceCount):
                handle = nvidia_smi.nvmlDeviceGetHandleByIndex(i)
                res = nvidia_smi.nvmlDeviceGetUtilizationRates(handle)
                mem = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)
                table.add_row([i, f&quot;{mem.free/1024**2:5.2f}MB/{mem.total/1024**2:5.2f}MB&quot;, f&quot;{res.gpu:3.1%}&quot;, f&quot;{res.memory:3.1%}&quot;])
</code></pre>
",24171543,,24171543,,45413.69278,45413.69278,GPU percentage allocation for a Python class,<python><pytorch><resources><gpu><federated-learning>,0,3,,,,CC BY-SA 4.0
78557504,1,,,45442.94747,,0,43,"<p>In the federated Learning code below, I'm using Pysyft. the goal is to distribute the FashionMNIST dataset to  different clients</p>
<pre><code>federated_train_loader = syft.FederatedDataLoader(
    datasets.FashionMNIST('../data', train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor(),
                       transforms.Normalize((0.1307,), (0.3081,))
                   ]))
    .federate(client_list),
    batch_size=args['batch_size'], shuffle=True)
</code></pre>
<p>and the error is</p>
<p><code>AttributeError: module 'syft' has no attribute 'FederatedDataLoader'</code></p>
<p>I tried many solutions but nothing worked. please help !</p>
",16611595,,,,,45442.94747,Federated dataloader deprecated?,<python><attributeerror><dataloader><federated-learning><pysyft>,0,3,,,,CC BY-SA 4.0
78567104,1,,,45445.70159,,0,36,"<p>I want to create a web application using React.js, Flask, and the Flower framework with Tensorflow  for image classification. I am stuck and would appreciate any tips or resources. Can anyone help me?</p>
<p>I asked GPT and Gemini, but all the answers didn't work for me.</p>
",25376120,,,,,45445.70159,How to integrate Federated Learning using Flower framworke in react js /flask web app,<reactjs><flask><deep-learning><web-applications><federated-learning>,0,1,,,,CC BY-SA 4.0
78742773,1,,,45486.14396,,0,22,"<p>I'm trying to running the FL project on <a href=""https://github.com/MenguChen/Federated_object_detection"" rel=""nofollow noreferrer"">github</a> , the thing is, when I run the client side with run.sh. It reported the warning/error:</p>
<pre><code>400 &quot;The client is using an unsupported version of the Socket.IO or Engine.IO protocols&quot;
</code></pre>
<p>I checked the code and found that <code>fl_client.py</code> utilizes the <code>socketIO_client</code> to support connection. Since the requirements doesn't contain versions of these packages. I installed them with the <code>pip install -r requirements.txt</code>. So, the versions of these packages are as follows:</p>
<pre><code>socketIO_client==0.7.2
Flask-SocketIO==5.3.6
Flask==3.0.3
</code></pre>
<p>I also asked ChatGPT, it suggests to use <code>python-socketio</code> instead. But when I changed into it, there was a new problem:</p>
<pre><code>Exception in thread Thread-4 (_handle_eio_message):
Traceback (most recent call last):
  File &quot;/home/xxx/miniconda3/envs/flenv/lib/python3.12/threading.py&quot;, line 1073, in _bootstrap_inner
    self.run()
  File &quot;/home/xxx/miniconda3/envs/flenv/lib/python3.12/threading.py&quot;, line 1010, in run
    self._target(*self._args, **self._kwargs)
  File &quot;/home/xxx/miniconda3/envs/flenv/lib/python3.12/site-packages/socketio/client.py&quot;, line 512, in _handle_eio_message
    self._handle_event(pkt.namespace, pkt.id, pkt.data)
  File &quot;/home/xxx/miniconda3/envs/flenv/lib/python3.12/site-packages/socketio/client.py&quot;, line 386, in _handle_event
    r = self._trigger_event(data[0], namespace, *data[1:])
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;/home/xxx/miniconda3/envs/flenv/lib/python3.12/site-packages/socketio/client.py&quot;, line 434, in _trigger_event
    return handler(*args)
           ^^^^^^^^^^^^^^
TypeError: FederatedClient.register_handles.&lt;locals&gt;.handle_init() missing 1 required positional argument: 'data'
</code></pre>
<p>Does anyone has idea how to solve this problem? If so, I'd be very appreciative.</p>
<p>Any idea of how to solve this problem would be appreciated, not limited to the answer.</p>
",23298651,,,,,45486.14396,Socket Mismatch Problem in Federated Learning Project,<flask-socketio><federated-learning>,0,0,,,,CC BY-SA 4.0
78835380,1,78983927,,45509.67139,,1,66,"<p>I am experimenting with TensorFlow Federated, simulating a training process with the FedAvg algorithm.</p>
<pre class=""lang-py prettyprint-override""><code>def model_fn():
  # Wrap a Keras model for use with TensorFlow Federated
  keras_model = get_uncompiled_model()

  # For the federated procedure, the model must be uncompiled
  return tff.learning.models.functional_model_from_keras(
        keras_model,
        loss_fn=tf.keras.losses.BinaryCrossentropy(),
        input_spec=(
              tf.TensorSpec(shape=[None, X_train.shape[1]], dtype=tf.float32),
              tf.TensorSpec(shape=[None], dtype=tf.int32)
        ),
        metrics_constructor=collections.OrderedDict(
              accuracy=tf.keras.metrics.BinaryAccuracy,
              precision=tf.keras.metrics.Precision,
              recall=tf.keras.metrics.Recall,
              false_positives=tf.keras.metrics.FalsePositives,
              false_negatives=tf.keras.metrics.FalseNegatives,
              true_positives=tf.keras.metrics.TruePositives,
              true_negatives=tf.keras.metrics.TrueNegatives
            )
  )

trainer = tff.learning.algorithms.build_weighted_fed_avg(
                      model_fn= model_fn(),
                      client_optimizer_fn=client_optimizer,
                      server_optimizer_fn=server_optimizer
                    )
</code></pre>
<p>I want to use custom weights to aggregate the clients' updates instead of using their number of samples. I know that <code>tff.learning.algorithms.build_weighted_fed_avg()</code> has a parameter called <code>client_weighting,</code> but the only value accepted is from the class <code>tff.learning.ClientWeighting</code>, which is an enum.</p>
<p>So, the only way to do that seems to be to write a custom WeightedAggregator. I've tried following <a href=""https://github.com/google-parfait/tensorflow-federated/blob/main/docs/tutorials/custom_aggregators.ipynb"" rel=""nofollow noreferrer"">this tutorial</a> that explains how to write an unweighted aggregator, but I cannot make it work transforming it into a weighted one.</p>
<p>This is what I've tried to do:</p>
<pre class=""lang-py prettyprint-override""><code>@tff.tensorflow.computation
def custom_weighted_aggregate(values, weights):
    # Normalize client weights
    total_weight = tf.reduce_sum(weights)
    normalized_weights = weights / total_weight

    # Compute weighted sum of client updates
    weighted_sum = tf.nest.map_structure(
        lambda v: tf.reduce_sum(normalized_weights * v, axis=0),
        values
    )

    return weighted_sum

class CustomWeightedAggregator(tff.aggregators.WeightedAggregationFactory):
    def __init__(self):
        pass

    def create(self, value_type, weight_type):
        @tff.federated_computation
        def initialize():
            return tff.federated_value(0.0, tff.SERVER)

        @tff.federated_computation(
            initialize.type_signature.result,
            tff.FederatedType(value_type, tff.CLIENTS),
            tff.FederatedType(weight_type, tff.CLIENTS)
        )
        def next(state, value, weight):
            aggregate_value = tff.federated_map(custom_weighted_aggregate, (value, weight))
            return tff.templates.MeasuredProcessOutput(
                state, aggregate_value, tff.federated_value((), tff.SERVER)
            )

        return tff.templates.AggregationProcess(initialize, next)

    @property
    def is_weighted(self):
        return True
</code></pre>
<p>But I get the following error:</p>
<p><em><strong>AggregationPlacementError</strong>: The &quot;result&quot; attribute of return type of <code>next_fn</code> must be placed at SERVER, but found {&lt;float32[7],float32,float32[1],float32&gt;}@CLIENTS.</em></p>
",15769874,,15769874,,45548.2825,45548.94656,Custom model aggregator TensorFlow Federated,<python><tensorflow><machine-learning><tensorflow-federated><federated-learning>,1,1,,,,CC BY-SA 4.0
78848605,1,,,45512.54763,,0,22,"<p>I'm trying to take two retrained clients in a federated learning pipeline and average their weights. It worked for the first training, but now the second time I'm getting this error can I have tried to fix, but I can't figure out what the issue is.</p>
<p>Here is the error which originates from the line <code>main(model_FTM_path, model_Stanford_path, save_path)</code>.</p>
<pre><code>ValueError: The name &quot;model&quot; is used 2 times in the model. All layer names 
should be unique.
</code></pre>
<pre class=""lang-py prettyprint-override""><code># Takes the two trained clients and weights them into one file 

import tensorflow as tf
from Client_Trainer import CustomLoss

# Deactivate GPU
tf.config.set_visible_devices([], 'GPU')

# Custom loss function
loss_function = CustomLoss.MaskedMSE

def load_model(model_path, prefix):
    model = tf.keras.models.load_model(model_path, custom_objects = {'MaskedMSE': loss_function})

    return model

def ensemble(model_FTM, model_Stanford):
    # Create input layer
    input_shape = model_FTM.input.shape[1:]
    ensemble_input = tf.keras.layers.Input(shape = input_shape, name = 'ensemble_input')

    # Get the outputs of both models
    output_FTM = model_FTM(ensemble_input)
    output_Stanford = model_Stanford(ensemble_input)

    # Average the outputs
    averaged_output = tf.keras.layers.Average(name = &quot;ensemble_average&quot;)([output_FTM, output_Stanford])

    # Create the ensemble model
    ensemble_model = tf.keras.models.Model(inputs = ensemble_input, outputs = averaged_output, name = &quot;ensemble_model&quot;)

    return ensemble_model

def main(model_FTM_path, model_Stanford_path, save_path):
    # Load the models
    model_FTM = load_model(model_FTM_path, &quot;FTM&quot;)
    model_Stanford = load_model(model_Stanford_path, &quot;Stanford&quot;)

    # Build the ensemble model
    ensemble_model = ensemble(model_FTM, model_Stanford)

    # Compile the ensemble model
    ensemble_model.compile(optimizer = 'adam', loss = loss_function, metrics = ['mse'])

    # print(&quot;\nEnsemble Model Summary:&quot;)
    # ensemble_model.summary()
    
    # Save the ensemble model
    ensemble_model.save(save_path)

if __name__ == &quot;__main__&quot;:
     model_FTM_path = 'FTMRetrained_round2.h5'
     model_Stanford_path = 'StanfordRetrained_round2.h5'
     save_path = 'weighted_2clients_round2.h5'

     main(model_FTM_path, model_Stanford_path, save_path)
</code></pre>
",26376632,,4685471,,45512.92715,45512.92715,"ValueError: The name ""model"" is used 2 times in the model. All layer names should be unique",<tensorflow><machine-learning><keras><valueerror><federated-learning>,0,0,,,,CC BY-SA 4.0
78852053,1,,,45513.39666,,0,35,"<p>I am running different datasets with different numbers of clients on federated learning code. However, when working with some datasets, I can set the value of NUM_CLIENTS to a maximum of 20. When the client value exceeds 20, I encounter the error below. Where am I making a mistake?</p>
<pre><code>ValueError                                Traceback (most recent call last)
&lt;ipython-input-19-3e647171f427&gt; in &lt;cell line: 18&gt;()
     35 
     36 
---&gt; 37         client_model.fit(datagen(client[0],client[1], batch_size=batch_size, epochs=epochs),
     38                          epochs=5, steps_per_epoch=steps_per_epoch)
     39 

1 frames
/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py in __init__(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)
   1273 
   1274         if steps_per_epoch == 0:
-&gt; 1275             raise ValueError(
   1276                 &quot;Unexpected value for `steps_per_epoch`. Received value is 0. &quot;
   1277                 &quot;Please check the docstring for `model.fit()` for supported &quot;

ValueError: Unexpected value for `steps_per_epoch`. Received value is 0. Please check the docstring for `model.fit()` for supported values.
</code></pre>
<pre><code>import tensorflow as tf
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Define the number of clients and the number of training rounds
NUM_CLIENTS = 10
NUM_ROUNDS = 3


# Define the clients and their data
clients = []
for i in range(NUM_CLIENTS):
    client_data = train_paths[i * (len(train_paths) // NUM_CLIENTS):(i + 1) * (len(train_paths) // NUM_CLIENTS)]
    client_labels = train_labels[i * (len(train_labels) // NUM_CLIENTS):(i + 1) * (len(train_labels) // NUM_CLIENTS)]
    clients.append((client_data, client_labels))

# Federated learning loop
for round_num in range(NUM_ROUNDS):

    # Select clients
    selected_client_indices = np.random.choice(len(clients), size=int(NUM_CLIENTS * 0.5), replace=False)
    selected_clients = [clients[i] for i in selected_client_indices]

    # Transmit the global model to the selected clients
    for client in selected_clients:
        client_model = tf.keras.models.clone_model(model)
        client_model.set_weights(model.get_weights())

        # Compile the client model
        client_model.compile(optimizer=Adam(learning_rate=0.0001),
        loss='sparse_categorical_crossentropy',
        metrics=['sparse_categorical_accuracy'])

        steps_per_epoch = int(len(client[0]) / 20)


        client_model.fit(datagen(client[0],client[1], batch_size=batch_size, epochs=epochs),
                         epochs=5, steps_per_epoch=steps_per_epoch)

        # Train locally
        steps_per_epoch = int(len(client[0]) / 20)

        # Aggregate the model
        new_weights = []
        for layer_index in range(len(model.get_weights())):
            new_layer_weights = np.mean([client_model.get_weights()[layer_index], model.get_weights()[layer_index]], axis=0)
            new_weights.append(new_layer_weights)
        model.set_weights(new_weights)


batch_size = 32
steps = int(len(test_paths)/batch_size)
y_pred = []
y_true = []
for x,y in tqdm(datagen(test_paths, test_labels, batch_size=batch_size, epochs=1), total=steps):
    pred = model.predict(x)
    pred = np.argmax(pred, axis=-1)
    for i in decode_label(pred):
        y_pred.append(i)
    for i in decode_label(y):
        y_true.append(i)

#     # Evaluate the global model
#     test_loss, test_acc = model.evaluate(test_paths, test_labels,)
#     print('Round {}: Test accuracy = {}'.format(round_num, test_acc))

# # Fine-tune the model
# model.fit(test_paths, test_labels, epochs=1, batch_size=32)

# Deploy the model
model.save('my_model.h5')
</code></pre>
<p>I want to increase the number of clients to 50</p>
",26685898,,,,,45513.39666,The problem of increasing the number of clients in federated learning,<tensorflow><tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
78854316,1,,,45513.80115,,0,25,"<p>I am trying to simulate the Online Federated Learning framework presented in the paper &quot;Communication-Efficient Online Federated Learning Framework for Nonlinear Regression&quot; by Gogineni et al., 2022. The simulation involves using Random Fourier Features (RFF) with a kernel least-mean-square (KLMS) algorithm to perform a nonlinear regression task across multiple clients in a federated setting.</p>
<p><strong>Summary of the Implementation:</strong></p>
<ul>
<li>Number of Clients: 100</li>
<li>Global Iterations: 1000</li>
<li>RFF Dimension: 200</li>
<li>Learning Rate: 0.75</li>
<li>Number of Participating Clients per Iteration: 20</li>
<li>Number of Independent Monte Carlo Trials: 500</li>
</ul>
<p>In each global iteration, a subset of clients is selected, and each client updates its local model using streaming data. The clients then share their model updates with the global server, which aggregates these updates to form a new global model.</p>
<p><strong>Problem:</strong>
The Mean Squared Error (MSE) computed during the simulation is not converging or decreasing as expected. Instead, the MSE fluctuates significantly or does not exhibit the steady decline that should be characteristic of a learning process. I have verified the implementation against the methodology described in the paper, but the results do not align with those presented in the paper's simulations.</p>
<p><strong>Key Aspects of the Simulation:</strong></p>
<ul>
<li>The input signal at each client is generated using a first-order autoregressive (AR) model, with parameters sampled from uniform distributions as described in the paper.</li>
<li>The clients apply a kernel LMS algorithm using random Fourier features to perform the local nonlinear regression.</li>
<li>The global model is updated iteratively by averaging the weights of the selected clients in each global iteration.</li>
</ul>
<p><strong>Code Snippet:</strong></p>
<pre><code>import numpy as np
import matplotlib.pyplot as plt

# Hyperparameters
num_clients = 100  # Number of clients in the simulation
independent_experiment = 10  # Number of independent Monte Carlo trials
feature_dim = 5  # Dimensionality of the input features
rff_dim = 200  # Dimensionality of the random Fourier features
num_participating_clients = 20  # Number of clients participating in each iteration
learning_rate = 0.75  # Learning rate for the local updates
num_iterations = 1000  # Number of iterations for training

# Initialize an array to store the MSE values across all trials
mse_values_all_trials = np.zeros(num_iterations)

# Main loop for averaging over multiple Monte Carlo trials
for _ in range(independent_experiment):
    global_weights = np.zeros(rff_dim)  # Initialize global weights
    x = np.zeros((num_clients, num_iterations, feature_dim))  # Input features for each client
    y = np.zeros((num_clients, num_iterations, 1))  # Target values for each client
    z = np.zeros((num_clients, num_iterations, rff_dim))  # Random Fourier features for each client
    W = np.random.randn(num_clients, feature_dim, rff_dim)  # Random weights for RFF
    b = np.random.uniform(0, 2 * np.pi, (num_clients, 1, rff_dim))  # Random bias for RFF

    # Generate data for each client
    for k in range(num_clients):
        theta_k = np.random.uniform(0.2, 0.9)  # Autoregressive coefficient
        mu_k = np.random.uniform(-0.2, 0.2)  # Mean of the process noise
        sigma2_uk = np.random.uniform(0.2, 1.2)  # Variance of the process noise
        sigma2_nuk = np.random.uniform(0.005, 0.03)  # Variance of the observation noise
        uk = np.random.normal(mu_k, np.sqrt(sigma2_uk), (num_iterations, feature_dim))  # Process noise
        nuk = np.random.normal(0, np.sqrt(sigma2_nuk), (num_iterations, 1))  # Observation noise
        
        # Generate the time series data
        x[k, 0] = uk[0]
        for n in range(1, num_iterations):
            x[k, n, :] = theta_k * x[k, n-1, :] + np.sqrt(1 - theta_k**2) * uk[n]
            y[k, n, :] = (np.sqrt(x[k, n, 0]**2 + np.sin(np.pi * x[k, n, 3])**2) +
                          (0.8 - 0.5*np.exp(-x[k, n, 1]**2)*x[k, n, 2])) + nuk[n]

        # Compute the random Fourier features
        z[k, :, :] = np.sqrt(2 / rff_dim) * np.cos(np.dot(x[k, :, :], W[k, :, :]) + b[k, :, :])
    
    local_weights = [np.zeros(rff_dim) for _ in range(num_clients)]  # Initialize local weights for each client
    mse_values_per_iteration = np.zeros(num_iterations)  # Store MSE for each iteration
    mse_values_per_iteration_per_client = np.zeros((num_clients, num_iterations))  # Store MSE for each client per iteration
    
    # Iterative training process
    for n in range(num_iterations):
        selected_indices = np.random.choice(num_clients, num_participating_clients, replace=False)  # Select random clients
        
        for k in selected_indices:
            local_weights[k] = global_weights  # Start with global weights
            epsilon = y[k, n, :] - np.dot(local_weights[k], z[k, n, :])  # Compute error
            local_weights[k] += learning_rate * z[k, n, :] * epsilon  # Update local weights
            mse_values_per_iteration_per_client[k, n] = epsilon**2  # Compute MSE for the current iteration
            mse_values_per_iteration[n] += mse_values_per_iteration_per_client[k, n]  # Aggregate MSE for selected clients

        mse_values_per_iteration[n] /= num_participating_clients  # Average MSE over participating clients     

        global_weights = np.zeros(rff_dim)  # Reset global weights

        for k in selected_indices:
            global_weights += local_weights[k]  # Aggregate updated local weights

        global_weights /= num_participating_clients  # Average global weights

    mse_values_all_trials += mse_values_per_iteration  # Accumulate MSE across all trials

# Average MSE across all trials and normalize
mse_values_all_trials /= independent_experiment
mse_values_all_trials /= max(mse_values_all_trials)

# Convert MSE to decibels
mse_value_all_trials = 10 * np.log10(mse_values_all_trials)

# Plot the MSE values over iterations
plt.plot(mse_value_all_trials)
plt.xlabel(&quot;Iterations&quot;)
plt.ylabel(&quot;MSE (dB)&quot;)
plt.title(&quot;Mean Squared Error Over Iterations&quot;)
plt.show()
</code></pre>
<p><strong>What I Tried:</strong></p>
<ol>
<li><p><strong>Implemented the Simulation:</strong> I followed the methodology described in the paper by Gogineni et al., implementing the federated learning framework with random Fourier features (RFF) for kernel least-mean-square (KLMS) regression. This involved generating synthetic data for multiple clients, performing local model updates, and aggregating these updates on a global server.</p>
</li>
<li><p><strong>Verified Data Generation:</strong> I ensured that the input signal for each client was generated using a first-order autoregressive (AR) model with the parameters and noise characteristics specified in the paper. I also checked the implementation of the RFF transformation to map input data into the feature space.</p>
</li>
<li><p><strong>Adjusted Learning Rate:</strong> I experimented with different learning rates to see if it would stabilize the MSE. While the paper suggests a learning rate of 0.75, I tried smaller and larger values to see if this would have an effect.</p>
</li>
<li><p><strong>Checked Model Updates:</strong> I verified that the global model updates were correctly computed by averaging the local model weights from the selected clients in each iteration.</p>
</li>
<li><p><strong>Multiple Trials:</strong> The simulation was run over multiple independent Monte Carlo trials to average out randomness, as suggested by the paper.</p>
</li>
</ol>
<p><strong>What I Expected:</strong></p>
<ol>
<li><p><strong>MSE Convergence:</strong> Based on the paper's results, I expected the MSE to show a consistent decrease over the iterations, reflecting the improvement of the global model as more data and updates are accumulated.</p>
</li>
<li><p><strong>Smoother MSE Curve:</strong> While some fluctuations are expected due to the random nature of client selection and data, I anticipated that the overall MSE curve would smooth out and converge to a lower value as the model learns over iterations.</p>
</li>
<li><p><strong>Results Consistent with the Paper:</strong> I expected my simulation results to align closely with the figures presented in the paper, particularly regarding the convergence rate and the final steady-state MSE values.</p>
</li>
</ol>
",18728357,,,,,45513.80115,Unexpected MSE Behavior in Online Federated Learning Simulation Using Random Fourier Features (RFF) Based Kernel LMS,<python><machine-learning><regression><feature-extraction><federated-learning>,0,3,,,,CC BY-SA 4.0
78860719,1,,,45516.36362,,0,28,"<pre><code>Traceback (most recent call last):
  File &quot;/Users/Federated_2Clients/Retrain_2Clients.py&quot;, line 178, in &lt;module&gt;
    Train_Model = RetrainModel(x0, y0, x1, y1)
  File &quot;/Users/Federated_2Clients/Retrain_2Clients.py&quot;, line 158, in RetrainModel
    model.save(model_savepath, overwrite = True)
  File &quot;/opt/anaconda3/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py&quot;, line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File &quot;/opt/anaconda3/lib/python3.10/site-packages/h5py/_hl/group.py&quot;, line 183, in create_dataset
    dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)
  File &quot;/opt/anaconda3/lib/python3.10/site-packages/h5py/_hl/dataset.py&quot;, line 163, in make_new_dset
    dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl, dapl=dapl)
  File &quot;h5py/_objects.pyx&quot;, line 54, in h5py._objects.with_phil.wrapper
  File &quot;h5py/_objects.pyx&quot;, line 55, in h5py._objects.with_phil.wrapper
  File &quot;h5py/h5d.pyx&quot;, line 137, in h5py.h5d.create
ValueError: Unable to create dataset (name already exists)
</code></pre>
<p>Here is the function that is the problem:</p>
<pre><code># Define model
def RetrainModel(InputModel, OutputModel, ValInputModel, ValOutputModel):
    kb.clear_session()

    # Load the model
    model = tf.keras.models.load_model('./Federated_2Clients/2Client_Data/weighted_2clients_round2.h5', compile = False)

    # # Rename layers
    # for i, layer in enumerate(model.layers):
    #     layer._name = f&quot;{layer.name}_{i}&quot;
    # # Rename weights
    # for i, weight in enumerate(model.weights):
    #     weight._name = f&quot;{weight.name}_{i}&quot;

    model.compile(optimizer = 'adam', loss = [CustomLoss.MaskedMSE], metrics = [CustomLoss.MaskedMSE])

    # Train model with 1 Input feature
    model.fit(InputModel, OutputModel, batch_size = cIntBatchSize, epochs = 3, verbose = 2, validation_data = (ValInputModel, ValOutputModel), shuffle = True)

    # Save model
    if dataset == 1:
        model_savepath = (&quot;./Federated_2Clients/2Client_Data/FTMRetrained_round3.h5&quot;)
    elif dataset == 2:
        model_savepath = (&quot;./Federated_2Clients/2Client_Data/StanfordRetrained_round3.h5&quot;)
    else:
        raise ValueError(&quot;Incorrect dataset selected.&quot;)

    # Delete the file if it already exists
    if os.path.exists(model_savepath):
       os.remove(model_savepath)

    # Save the model
    model.save(model_savepath, overwrite = True)
</code></pre>
<p>I've been working on a federated learning pipeline and I'm encountering this error when retraining my model. I've tried renaming the file, changing the path, renaming the layers, and a bunch of other things but this error won't go away. Please help!</p>
",26376632,,26376632,,45516.36559,45516.36559,ValueError: Unable to create dataset (name already exists) for federated learning,<python><tensorflow><valueerror><federated-learning>,0,0,,,,CC BY-SA 4.0
78886217,1,,,45523.15632,,0,47,"<p>I am trying to run the code in the following link <a href=""https://github.com/shaoxiongji/federated-learning"" rel=""nofollow noreferrer"">shaoxiongji/federated-learning</a> using the following steps:</p>
<p><strong>1- Clone the Repository:</strong></p>
<pre><code>git clone https://github.com/shaoxiongji/federated-learning.git
</code></pre>
<p><strong>2- Navigate to the Repository Directory:</strong></p>
<pre><code>cd federated-learning
</code></pre>
<p><strong>3- Install Dependencies:</strong></p>
<pre><code>pip install -r requirements.txt
</code></pre>
<p><strong>4- Run the Code:</strong></p>
<pre><code>python main_fed.py
</code></pre>
<p>but I am facing a problem:</p>
<pre><code>Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz
Traceback (most recent call last):
  File &quot;C:\Users\raineen\federated-learning\main_fed.py&quot;, line 29, in &lt;module&gt;
    dataset_train = datasets.MNIST('../data/mnist/', train=True, download=True, transform=trans_mnist)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\datasets\mnist.py&quot;, line 46, in __init__
    self.download()
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\site-packages\torchvision\datasets\mnist.py&quot;, line 114, in download
    data = urllib.request.urlopen(url)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py&quot;, line 216, in urlopen
    return opener.open(url, data, timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py&quot;, line 525, in open
    response = meth(req, response)
               ^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py&quot;, line 634, in http_response
    response = self.parent.error(
               ^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py&quot;, line 557, in error
    result = self._call_chain(*args)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py&quot;, line 496, in _call_chain
    result = func(*args)
             ^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py&quot;, line 749, in http_error_302
    return self.parent.open(new, timeout=req.timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py&quot;, line 525, in open
    response = meth(req, response)
               ^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py&quot;, line 634, in http_response
    response = self.parent.error(
               ^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py&quot;, line 563, in error
    return self._call_chain(*args)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py&quot;, line 496, in _call_chain
    result = func(*args)
             ^^^^^^^^^^^
  File &quot;C:\Users\raineen\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py&quot;, line 643, in http_error_default
    raise HTTPError(req.full_url, code, msg, hdrs, fp)
urllib.error.HTTPError: HTTP Error 403: Forbidden
</code></pre>
<p>Any assistance, please? I would like to get two figures results like training loss.</p>
",11716727,,,,,45523.15632,Facing a problem with running a Federated Learning code,<python><federated-learning>,0,4,,,,CC BY-SA 4.0
78913655,1,,,45530.38601,,0,25,"<p>I am trying to build a Federating Learning on ColabPro using Flower and pytorch-lightning, but I need to specify an IP &amp; Port number for the server so the clients can communicate with it, also I have to run the server and each client seperately through the multiple terminals, my problem now is I don't know which IP &amp; Port numbers can I use, and how to open multiple terminals at same times on ColabPro.</p>
<p>I tried same model locally and it works.</p>
",27020851,,,,,45530.38601,Federated Learning in ColabPro,<terminal><ip><google-colaboratory><pytorch-lightning><federated-learning>,0,1,,,,CC BY-SA 4.0
78975525,1,,,45546.83197,,0,36,"<p>I'm working on a federated learning project using PyTorch, focusing on medical imaging (MRI) data. Despite using an SSD, the dataset loading phase is unusually slow, and the GPU utilization remains very low across global epochs. Each client handles a significant volume of data, and the frequent client switching seems to exacerbate the issue. I'm looking for ways to optimize data loading and enhance GPU utilization.</p>
<p><strong>Data Details:</strong></p>
<p>Each .npy file corresponds to a pre-processed three-dimensional MRI, approximately 20MB in size.</p>
<p>Each client manages between 500 and 1000 such files, contributing to a total dataset size of around 100GB distributed across clients.</p>
<p><strong>Here's a breakdown of my current setup:</strong></p>
<p>I have a custom dataset class, <code>TrainCNN_Data</code>, which reads <code>.npy</code> files. Each client in the federated learning framework initializes this dataset and loads it using a <code>DataLoader</code> during training. On the server side, training involves iterating through selected clients and training them one by one.</p>
<p><strong>Server-Side Code for Client Training:</strong></p>
<pre class=""lang-py prettyprint-override""><code>class Server:
    def __init__(self, clients, global_rounds):
        self.clients = clients
        self.global_rounds = global_rounds

    def train_clients(self):
        for i in range(self.global_rounds + 1):
            self.selected_clients = self.select_clients()
            for client in self.selected_clients:
                client.train(i)
</code></pre>
<p><strong>Client-Side Data Loading and Training Code:</strong></p>
<pre class=""lang-py prettyprint-override""><code>class Client:
    def prepare_dataset(self, seed):
        self.train_data = TrainCNN_Data(0, self._dataset_dir, _csv_dir_train, seed=seed, classification=classification)

    def load_train_data(self, batch_size=None):
        if batch_size is None:
            batch_size = self.batch_size
        train_dataloader = DataLoader(self.train_data,
                                      batch_size=batch_size,
                                      num_workers=self.num_workers,
                                      pin_memory=self.pin_memory,
                                      drop_last=True)
        return train_dataloader

    def train(self, epoch):
        all_trainloader = self.load_train_data()
        for i, data in enumerate(all_trainloader):
            x, y = data
            x = x.to(self.device)
            # training code...
</code></pre>
<p><strong>Code for the TrainCNN_Data class:</strong></p>
<pre class=""lang-py prettyprint-override""><code>class TrainCNN_Data(Dataset):
    def __init__(self, split_method, data_source, csv_train_dir, seed=666, classification=None):
        if classification is None:
            classification = ['NL', 'AD']
        random.seed(seed)
        self.split_method = split_method
        self.data_source = data_source
        self.csv_train_dir = csv_train_dir

        if self.split_method == 0:
            self.Data_list, self.Label_list = read_labels_from_csv(csv_train_dir, classification=classification)
        else:
            self.Data_list, self.Label_list, self.origin_datasets = read_labels_and_origin_from_csv(csv_train_dir, classification=classification)

    def __len__(self):
        return len(self.Data_list)

    def __getitem__(self, idx):
        if isinstance(idx, slice):
            return [self.get_single_item(i) for i in range(*idx.indices(len(self.Data_list)))]
        else:
            return self.get_single_item(idx)

    def get_single_item(self, idx):
        label = self.Label_list[idx]
        if self.split_method == 0:
            data = np.load(os.path.join(self.data_source, self.Data_list[idx] + '.npy')).astype(np.float32)
        else:
            data = np.load(os.path.join(self.data_source[self.origin_datasets[idx]], self.Data_list[idx] + '.npy')).astype(np.float32)
        data = np.expand_dims(data, axis=0)
        return data, label
</code></pre>
<p>To analyze performance bottlenecks,
I set up <strong>2 clients</strong>, each allocated <strong>100 .npy files</strong>.
I used the <code>torch.profile</code> tool to observe the time taken for <strong>one iteration</strong> of training on <strong>one of the  2 nodes</strong>.</p>
<p>I noticed that <strong>78%</strong> of the time was spent loading the dataset.</p>
<pre><code>-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  
                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls                                                                      Input Shapes  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  
enumerate(DataLoader)#_MultiProcessingDataLoaderIter...        78.45%       40.452s        78.45%       40.453s     919.382ms            44                                                                                []  
                                        cudaMemcpyAsync        20.50%       10.569s        20.50%       10.569s      33.028ms           320                                                                                []  
                                               aten::to         0.00%       1.961ms        14.79%        7.625s     190.635ms            40                               [[8, 1, 181, 217, 181], [], [], [], [], [], [], []]  
                                         aten::_to_copy         0.00%       1.387ms        14.78%        7.623s     190.586ms            40                                   [[8, 1, 181, 217, 181], [], [], [], [], [], []]  
                                            aten::copy_         0.00%       1.802ms        14.78%        7.621s     190.527ms            40                                [[8, 1, 181, 217, 181], [8, 1, 181, 217, 181], []]  
                                               aten::to         0.00%     473.806us         5.73%        2.957s      24.641ms           120                                                  [[], [], [], [], [], [], [], []]  
                                         aten::_to_copy         0.00%       1.651ms         5.73%        2.957s      32.493ms            91                                                      [[], [], [], [], [], [], []]  
                                            aten::copy_         0.00%       1.983ms         5.73%        2.954s      32.467ms            91                                                                      [[], [], []]  
                                       cudaLaunchKernel         0.24%     122.497ms         0.24%     122.497ms       8.800us         13920                                                                                []  
                    Optimizer.step#CosineOptimizer.step         0.06%      32.896ms         0.18%      90.326ms       2.258ms            40                                                                                []  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  --------------------------------------------------------------------------------  
Self CPU time total: 51.566s
</code></pre>
<p><strong>Questions:</strong></p>
<ol>
<li>Are there any common pitfalls or inefficiencies in the way I'm handling data loading across multiple clients that could be causing these issues?</li>
<li>How can I optimize the data loading process in this federated learning context to improve both training speed and GPU usage?</li>
</ol>
<p>Any insights or suggestions on how to tackle these challenges would be greatly appreciated!</p>
",19221659,,,,,45546.83197,Slow Data Loading and Low GPU Utilization in PyTorch Federated Learning with Frequent Client Switching,<pytorch><dataset><pytorch-dataloader><dataloader><federated-learning>,0,1,,,,CC BY-SA 4.0
79070306,1,79070523,,45574.53611,,0,47,"<p>I am trying to deploy a Federated Learning server using Flower (flwr) on a Kubernetes cluster with a custom Docker image (fl-server:latest). The server needs to run on a specific port and host. My goal is to ensure that the server finds an available port before starting to avoid conflicts with other services.</p>
<p>I have implemented a Python class to create both the deployment and the corresponding service using the Kubernetes API. Below is the code for creating the deployment and service:</p>
<pre class=""lang-py prettyprint-override""><code>from kubernetes import client, config
from uuid import uuid4

class DeploymentFL:
    
    def __init__(self):
        pass

    def create_deployment_object(self, model_name: str, port_k8s: str, port_flower: str, model_uuid: str, host: str = &quot;192.168.49.2&quot;) -&gt; client.V1Deployment:
        &quot;&quot;&quot;
        Create a Kubernetes deployment object for a Federated Learning server.
        
        Args:
            model_name (str): The name of the model to be used.
            port_k8s (str): The port number for the Kubernetes service.
            port_flower (str): The port number for the Flower server.
            model_uuid (str): The uuid of the model to identify it.
            host (str): The host address of the server.

        Return:
            client.V1Deployment: The deployment object for the Kubernetes API.
        &quot;&quot;&quot;
        try:
            sanitized_model_name = f&quot;{model_name.lower().replace('_', '-')}&quot;
            name_container = f&quot;fl-server-{sanitized_model_name}-{model_uuid}&quot;
            
            # Define the container with environment variables and health checks
            container = client.V1Container(
                name=name_container,
                image=&quot;fl-server:latest&quot;,
                image_pull_policy=&quot;Never&quot;,
                ports=[
                    client.V1ContainerPort(container_port=int(port_k8s)),
                ],
                env=[
                    client.V1EnvVar(name=&quot;FL_HOST&quot;, value=host),
                    client.V1EnvVar(name=&quot;FL_PORT&quot;, value=str(port_k8s)),
                ],
                volume_mounts=[client.V1VolumeMount(
                    name='model-storage',
                    mount_path='/mnt/data'
                )],
                liveness_probe=client.V1Probe(
                    _exec=client.V1ExecAction(command=[&quot;/bin/sh&quot;, &quot;-c&quot;, f&quot;nc -zv {host} {port_k8s}&quot;]),
                    initial_delay_seconds=60,
                    period_seconds=10,
                    timeout_seconds=5,
                    failure_threshold=3,
                ),
                readiness_probe=client.V1Probe(
                    _exec=client.V1ExecAction(command=[&quot;/bin/sh&quot;, &quot;-c&quot;, f&quot;nc -zv {host} {port_k8s}&quot;]),
                    initial_delay_seconds=30,
                    period_seconds=10,
                    timeout_seconds=5,
                    failure_threshold=3,
                )
            )
            
            # Define the Pod template
            template = client.V1PodTemplateSpec(
                metadata=client.V1ObjectMeta(labels={&quot;app&quot;: name_container}),
                spec=client.V1PodSpec(containers=[container], volumes=[client.V1Volume(
                    name='model-storage',
                    persistent_volume_claim=client.V1PersistentVolumeClaimVolumeSource(claim_name='model-pvc')
                )])
            )
            
            # Define the Deployment specification
            spec = client.V1DeploymentSpec(
                replicas=1,
                template=template,
                selector={'matchLabels': {'app': name_container}}
            )
            
            name_deployment = f&quot;{name_container}-deployment&quot;
            deployment = client.V1Deployment(
                metadata=client.V1ObjectMeta(name=name_deployment),
                spec=spec
            )
            
            return deployment
        except Exception as e:
            print(f&quot;Error at create deployment object: {e}&quot;)

    def create_service_object(self, model_name: str, port: int, model_uuid: str) -&gt; client.V1Service:
        &quot;&quot;&quot;
        Create a Kubernetes service object for a Federated Learning server.

        Args:
            model_name (str): The name of the model to be used.
            port (int): The port number for the server.
            model_uuid (str): The uuid of the model to identify it.

        Return:
            client.V1Service: The service object for the Kubernetes API.
        &quot;&quot;&quot;
        try:
            sanitized_model_name = model_name.lower().replace(&quot;_&quot;, &quot;-&quot;)
            service_name = f&quot;fl-server-{sanitized_model_name}-{model_uuid}-service&quot;
            service = client.V1Service(
                metadata=client.V1ObjectMeta(name=service_name),
                spec=client.V1ServiceSpec(
                    selector={&quot;app&quot;: f&quot;fl-server-{sanitized_model_name}-{model_uuid}&quot;},
                    ports=[client.V1ServicePort(port=port, target_port=port)],
                    type=&quot;NodePort&quot;
                )
            )
            return service, service_name
        except Exception as e:
            print(f&quot;Error at create service object: {e}&quot;)
</code></pre>
<p>below is the python script that generates the fl-server image:</p>
<pre class=""lang-py prettyprint-override""><code>import flwr as fl
import tensorflow as tf
import os
import socket

def is_port_in_use(host, port):
    &quot;&quot;&quot;Check if a port is in use.&quot;&quot;&quot;
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        return s.connect_ex((host, port)) == 0

def run_server(host: str, port: int):
    &quot;&quot;&quot;
    Start a Federated Learning server with the given model.

    Args:
        host (str): The host address for the server.
        port (int): The port number for the server.

    Return:
        None
    &quot;&quot;&quot;
    try:
        # Define the Federated Learning strategy
        strategy = fl.server.strategy.FedAvg(
            fraction_fit=0.1,
            fraction_evaluate=0.1,
            min_fit_clients=2,
            min_evaluate_clients=2,
            min_available_clients=2,
        )

        # Start the Flower server
        fl.server.start_server(
            server_address=f&quot;{host}:{port}&quot;,
            config=fl.server.ServerConfig(num_rounds=3),
            strategy=strategy,
        )
    except Exception as e:
        print(f&quot;Error starting fl server: {e}&quot;)

if __name__ == &quot;__main__&quot;:
    # Read environment variables
    host = os.getenv(&quot;FL_HOST&quot;, &quot;192.168.49.2&quot;)
    port = int(os.getenv(&quot;FL_PORT&quot;, &quot;30878&quot;))

    # Find an available port
    original_port = port
    while is_port_in_use(host, port):
        print(f&quot;Port {port} is already in use. Trying another port...&quot;)
        port += 1

    print(f&quot;Starting Flower server on {host}:{port} (initially tried {original_port})&quot;)
    run_server(host, port)
</code></pre>
<p>I expected the server to start on the first available port. If the specified port is in use, the script should find the next available port and use it to start the server.</p>
<p>Even though the script is designed to check for port availability, I keep getting the following error in the logs when deploying in Kubernetes:</p>
<pre class=""lang-none prettyprint-override""><code>INFO :      Starting Flower server, config: num_rounds=3, no round_timeout
Starting Flower server on 192.168.49.2:30099 (initially tried 30099)
Port in server address 192.168.49.2:30099 is already in use.
</code></pre>
<p>To try to solve the problem, I verified that the port checking logic works correctly by running the script locally.
I ensured that the Kubernetes deployment uses the latest version of the Docker image (fl-server:latest).
I checked that the service selector matches the labels of the pod.
I verified that no other services are using the port using ss and netstat within the container.</p>
<p>Here is my Dockerfile used to build the image:</p>
<pre class=""lang-bash prettyprint-override""><code>FROM python:3.10

# Install dependencies
COPY requirements.txt .
RUN pip install -r requirements.txt

# Copy the application code
COPY fl_server.py /app/fl_server.py
WORKDIR /app

# Run the server
CMD [&quot;python&quot;, &quot;fl_server.py&quot;]
</code></pre>
",13051300,,10008173,,45574.60736,45576.41578,"Kubernetes deployment for Flower server in Python fails with ""Port in server address is already in use""",<python><kubernetes><federated-learning>,1,0,,,,CC BY-SA 4.0
69101385,1,,,44447.43611,,1,384,"<p>With TFF 0.18, I found this problem :</p>
<pre class=""lang-py prettyprint-override""><code>images, labels = next(img_gen.flow_from_directory(path0,target_size=(180, 180), batch_size = 2,class_mode=None))
sample_batch = (images,labels)  # assumes images and labels are np.ndarray
input_spec = tf.nest.map_structure(tensor_spec_from_ndarray, sample_batch)
</code></pre>
<p>here is the output of input_spec</p>
<pre class=""lang-py prettyprint-override""><code>(TensorSpec(shape=(180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(180, 180, 3), dtype=tf.float32, name=None))
</code></pre>
<p>And here is my model:</p>
<pre class=""lang-py prettyprint-override""><code>model = tf.keras.applications.ResNet50(include_top=False, weights=None, input_tensor=tf.keras.Input(shape=(180, 180, 3)), pooling=None)
</code></pre>
",14253961,,14692,,44559.96736,44559.96736,"ValueError: Input 0 is incompatible with layer resnet50: expected shape=(None, 180, 180, 3), found shape=(180, 180, 3)",<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69204874,1,,,44455.35069,,0,98,"<p>So I've got some data from 700-some smart meters. Data from each meter includes electricity usage taken in intervals of 15 mins, outside temperature, humidity, if it's a national holiday...<br>
The goal is to predict combined electricity usage of the users on the grid.<br>
When I combine the data by summing all the electricity and train my model (normalization, some batching, 3 lstm layers with 512 nodes, some dropout, relu activation, adam optimizer, absolute loss, default lr) I get good results which I am happy with.<br>
But when I do it in federated, with each user training on his private data, using the same model I did (server lr = 1.0, because its less confusing i think) i get really bad results. <br>
Unsystematically I messed around with batch size, switching adam for SGD, changing learning rates, upping the epochs, changing the number of users calculating gradients in each round. Nothing seemed to work.
<br>Should i just up the epochs in some order of magnitude? Do i have any theoretical assurance that there exists a set of parameters under which the same model that converged on the sum of data should should converge in federated?<br>
It's more of a soft question, but i may post the code or the results if needed.</p>
",14441027,,,,,44457.64861,centralized vs. federated convergence,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69281046,1,69303729,,44461.37014,,1,93,"<p>I'm using Tensorflow Federated (TFF) to train with differential privacy. Currently I am creating a Tensorflow Privacy NormalizedQuery and then passing it into a TFF DifferentiallyPrivateFactory to create an AggregationProcess:</p>
<pre><code>_weights_type = tff.learning.framework.weights_type_from_model(placeholder_model)
query = tensorflow_privacy.GaussianSumQuery(l2_norm_clip=10.0, stddev=0.1)
query = tensorflow_privacy.NormalizedQuery(query, 20)
agg_proc = tff.aggregators.DifferentiallyPrivateFactory(query)
agg_proc = agg_proc.create(_weights_type.trainable)
</code></pre>
<p>After broadcasting the server state to clients I run a client update function and then use the AggregationProcess like this:</p>
<pre><code>agg_output = agg_proc.next(
    server_state.delta_aggregate_state,
    client_outputs.weights_delta)
</code></pre>
<p>This works great, however I want to experiment with changing the l2_norm_clip and stddev several times during training (making clipping bigger and smaller at various training rounds) but it seems I can only set these parameters when I create the AggregationProcess.</p>
<p>Is is possible to change these parameters during training somehow?</p>
",2623004,,,,,44462.68542,How to change clipping and noise parameters during differentially private training with Tensorflow Federated,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69325272,1,69328134,,44464.43681,,0,2155,"<p>I have a TFF model to run But I got an error.
I provided the x and y and moved forward to implement it like the tutorial.</p>
<p>TF version = 2.5.1
TFF version = 0.19.0</p>
<p>My snippet code is</p>
<pre><code>split = len(usr_data_set)
client_train_dataset = collections.OrderedDict()

for i in range(0, split):
    client_name = &quot;client_&quot; + str(i)
    xx, y = usr_data_set[i] # shape for client one [2441, 13055], for client two 
                            # [2420, 13055], for client three [2451, 13055]

    data = collections.OrderedDict((('x', xx), ('y', y)))


    client_train_dataset[client_name] = data

train_dataset = tff.simulation.datasets.TestClientData(client_train_dataset)

sample_dataset = train_dataset.create_tf_dataset_for_client(train_dataset.client_ids[0])
sample_element = next(iter(sample_dataset))

def preprocess(dataset):
    NUM_EPOCHS = 5
    BATCH_SIZE = 32
    PREFETCH_BUFFER = 10

    def batch_format_fn(element):
        return collections.OrderedDict(
            x=reshape(element['x'], [-1, 13055]),
            y=reshape(element['y'], [-1, 2]))


    return dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE).map(
        batch_format_fn).prefetch(PREFETCH_BUFFER)

preprocessed_sample_dataset = preprocess(sample_dataset)
# sample_batch = nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_sample_dataset)))

def make_federated_data(client_data, client_ids):
    return [preprocess(client_data.create_tf_dataset_for_client(x)) for x in client_ids]


# return make_federated_data(train_dataset, train_dataset.client_ids), preprocessed_sample_dataset
federated_train_data = make_federated_data(train_dataset, train_dataset.client_ids)

# federated_train_data, preprocessed_sample_dataset = tff_dataset(usr_data_set)

losses = tf.keras.losses.CategoricalCrossentropy()
metric = [tf.keras.metrics.CategoricalAccuracy()]

def CNN():

    model = Sequential()
    model.add(Reshape((13055, 1), input_shape=(13055,)))
    model.add(Conv1D(8, kernel_size=7, padding='same', strides=3, activation='relu'))
    model.add(MaxPooling1D(4, strides=2, padding='same'))
    model.add(Conv1D(128, kernel_size=7, padding='same', strides=3, activation='relu'))
    model.add(MaxPooling1D(4, strides=2, padding='same'))
    model.add(Conv1D(64, kernel_size=3, padding='same', strides=1, activation='relu'))
    model.add(MaxPooling1D(4, strides=2, padding='same'))
    model.add(Conv1D(64, kernel_size=3, padding='same', strides=1, activation='relu'))
    model.add(MaxPooling1D(4, strides=2, padding='same'))
    model.add(Flatten())
    model.add(Dense(units=64, activation='relu'))
    model.add(Dense(units=64, activation='relu'))
    model.add(Dense(units=2, activation='softmax'))

    return model



def model_fn():
    keras_model = CNN()
    return tff.learning.from_keras_model(
        keras_model,
        input_spec=preprocessed_sample_dataset.element_spec,
        loss=losses,
        metrics=metric)

iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

print(str(iterative_process.initialize.type_signature))
</code></pre>
<p>I read another post about this error but my all function are in the scope of model_fn and I could not see any other problems.</p>
<p>The full script error is like this,</p>
<pre><code>  File &quot;/Users/amir/Documents/CODE/Python/FedGS/tff_dataset.py&quot;, line 175, in &lt;module&gt;
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/federated_averaging.py&quot;, line 270, in build_federated_averaging_process
    model_update_aggregation_factory=model_update_aggregation_factory)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py&quot;, line 631, in build_model_delta_optimizer_process
    model_weights_type = model_utils.weights_type_from_model(model_fn)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/model_utils.py&quot;, line 100, in weights_type_from_model
    model = model()
  File &quot;/Users/amir/Documents/CODE/Python/FedGS/tff_dataset.py&quot;, line 170, in model_fn
    metrics=metric)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py&quot;, line 175, in from_keras_model
    metrics=metrics))
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py&quot;, line 304, in __init__
    tf.TensorSpec.from_tensor, self.report_local_outputs())
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 889, in __call__
    result = self._call(*args, **kwds)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 957, in _call
    filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 1974, in _call_flat
    flat_outputs = forward_function.call(ctx, args_with_tangents)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 625, in call
    executor_type=executor_type)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/functional_ops.py&quot;, line 1189, in partitioned_call
    args = [ops.convert_to_tensor(x) for x in args]
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/ops/functional_ops.py&quot;, line 1189, in &lt;listcomp&gt;
    args = [ops.convert_to_tensor(x) for x in args]
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py&quot;, line 163, in wrapped
    return func(*args, **kwargs)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py&quot;, line 1525, in convert_to_tensor
    raise RuntimeError(&quot;Attempting to capture an EagerTensor without &quot;
RuntimeError: Attempting to capture an EagerTensor without building a function.
</code></pre>
<p>Can anyone help me fix this? I did anything to solve it but have not succeeded.</p>
",,user10985800,,user10985800,44464.75972,44464.75972,TFF RuntimeError: Attempting to capture an EagerTensor without building a function,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69335892,1,,,44465.60417,,0,338,"<p>I have a multi outputs FedAvg model that I implemented just like the  Tutorial and a bit extends to reach the multi outputs version.</p>
<p>My model function is like below,</p>
<pre><code>  def model_fn(self):
    fed_model = CNN()
    return tff.learning.from_keras_model(
      fed_model,
      input_spec=self.preprocessed_sample_dataset.element_spec,
      loss=[tf.keras.losses.BinaryCrossentropy(),
            tf.keras.losses.BinaryCrossentropy()],
      metrics=[tf.keras.metrics.BinaryAccuracy()])
</code></pre>
<p>the Keras model's last lines are like the below snippet code.</p>
<pre><code>def CNN():
    inp = Input(shape=(13055,))

    x = Dense(units=64, activation='relu')(x)
    a = Dense(units=unit, activation=activ, name='a')(x)
    v = Dense(units=unit, activation=activ, name='v')(x)

    model = Model(inputs=inp, outputs={'a': a, 'v': v})

    return model
</code></pre>
<p>and my TFF dataset is built like the below.</p>
<pre><code>        data = collections.OrderedDict((('x', x),
                                        ('y', collections.OrderedDict((('a', a),
                                                                       ('v', v))))))


        client_train_dataset[client_name] = data

    train_dataset = tff.simulation.datasets.TestClientData(client_train_dataset)

    sample_dataset = train_dataset.create_tf_dataset_for_client(train_dataset.client_ids[0])
    sample_element = next(iter(sample_dataset))

    def preprocess(dataset):
        NUM_EPOCHS = 5
        BATCH_SIZE = 32
        PREFETCH_BUFFER = 10

        def batch_format_fn(element):

            &quot;&quot;&quot;Flatten a batch `pixels` and return the features as an `OrderedDict`.&quot;&quot;&quot;
            return collections.OrderedDict(
                x=reshape(element['x'], [-1, 13055]),
                y=collections.OrderedDict((('a', reshape(element['y']['a'], [-1, 1])),
                                           ('v', reshape(element['y']['v'], [-1, 1])))))


        return dataset.repeat(NUM_EPOCHS).batch(BATCH_SIZE).map(
            batch_format_fn).prefetch(PREFETCH_BUFFER)

    preprocessed_sample_dataset = preprocess(sample_dataset)

    def make_federated_data(client_data, client_ids):
        return [preprocess(client_data.create_tf_dataset_for_client(x)) for x in client_ids]

    federated_train_data = make_federated_data(train_dataset, train_dataset.client_ids)
</code></pre>
<p>when I use the learning API like the one below</p>
<pre><code>      self.iterative_process = tff.learning.build_federated_averaging_process(
          self.model_fn,
          client_optimizer_fn=lambda: SGD(learning_rate=0.02),
          server_optimizer_fn=lambda: SGD(learning_rate=1.0))

      print(str(self.iterative_process.initialize.type_signature))
</code></pre>
<p>I got an error of KeyError: 0 that makes me confused, I do name the outputs same as the <code>y</code> collection.OrderedDict</p>
<pre><code>Traceback (most recent call last):
  File &quot;/Users/amir/Documents/CODE/Python/FedGS/main.py&quot;, line 401, in &lt;module&gt;
    obj = EmoRec(attr)
  File &quot;/Users/amir/Documents/CODE/Python/FedGS/main.py&quot;, line 139, in __init__
    server_optimizer_fn=lambda: SGD(learning_rate=1.0))
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/federated_averaging.py&quot;, line 270, in build_federated_averaging_process
    model_update_aggregation_factory=model_update_aggregation_factory)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py&quot;, line 696, in build_model_delta_optimizer_process
    aggregation_process=aggregation_process)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py&quot;, line 381, in _build_one_round_computation
    @tf.function
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py&quot;, line 479, in __call__
    fn_to_wrap, fn_name, parameter_type, unpack=None)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py&quot;, line 216, in __call__
    result = fn_to_wrap(*args, **kwargs)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 889, in __call__
    result = self._call(*args, **kwds)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 933, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 764, in _initialize
    *args, **kwds))
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 3050, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 3444, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 3289, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 999, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 672, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 986, in wrapper
    raise e.ag_error_metadata.to_exception(e)
tensorflow.python.autograph.impl.api.StagingError: in user code:

    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py:395 _compute_local_training_and_client_delta  *
        client_output = client_delta_fn(dataset, initial_model_weights)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/federated_averaging.py:93 reduce_fn  *
        output = model.forward_pass(batch, training=True)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/dataset_reduce.py:28 _dataset_reduce_fn  *
        return dataset.reduce(initial_state=initial_state_fn(), reduce_func=reduce_fn)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py:389 forward_pass  *
        return self._forward_pass(batch_input, training=training)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py:373 _forward_pass  *
        batch_loss += loss_wt * loss_fn(

    KeyError: 0
</code></pre>
<p>and when I pass a loss function class in model_fn instead of two in a list, I got the error below,</p>
<pre><code>Traceback (most recent call last):
  File &quot;/Users/amir/Documents/CODE/Python/FedGS/main.py&quot;, line 400, in &lt;module&gt;
    obj = EmoRec(attr)
  File &quot;/Users/amir/Documents/CODE/Python/FedGS/main.py&quot;, line 139, in __init__
    server_optimizer_fn=lambda: SGD(learning_rate=1.0))
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/federated_averaging.py&quot;, line 270, in build_federated_averaging_process
    model_update_aggregation_factory=model_update_aggregation_factory)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py&quot;, line 696, in build_model_delta_optimizer_process
    aggregation_process=aggregation_process)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py&quot;, line 381, in _build_one_round_computation
    @tf.function
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py&quot;, line 479, in __call__
    fn_to_wrap, fn_name, parameter_type, unpack=None)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py&quot;, line 216, in __call__
    result = fn_to_wrap(*args, **kwargs)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 889, in __call__
    result = self._call(*args, **kwds)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 933, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 764, in _initialize
    *args, **kwds))
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 3050, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 3444, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 3289, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 999, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 672, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File &quot;/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 986, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in user code:

    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py:395 _compute_local_training_and_client_delta  *
        client_output = client_delta_fn(dataset, initial_model_weights)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/federated_averaging.py:93 reduce_fn  *
        output = model.forward_pass(batch, training=True)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/dataset_reduce.py:28 _dataset_reduce_fn  *
        return dataset.reduce(initial_state=initial_state_fn(), reduce_func=reduce_fn)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py:389 forward_pass  *
        return self._forward_pass(batch_input, training=training)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py:360 _forward_pass  *
        batch_loss = tf.add_n([loss_fn(y_true=y_true, y_pred=predictions)] +
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:155 __call__  **
        losses = call_fn(y_true, y_pred)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:259 call  **
        return ag_fn(y_true, y_pred, **self._fn_kwargs)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper
        return target(*args, **kwargs)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:1743 binary_crossentropy
        y_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:206 wrapper
        return target(*args, **kwargs)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1431 convert_to_tensor_v2_with_dispatch
        value, dtype=dtype, dtype_hint=dtype_hint, name=name)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1441 convert_to_tensor_v2
        as_ref=False)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py:163 wrapped
        return func(*args, **kwargs)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1566 convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function
        return constant(v, dtype=dtype, name=name)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:265 constant
        allow_broadcast=True)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:283 _constant_impl
        allow_broadcast=allow_broadcast))
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:457 make_tensor_proto
        _AssertCompatible(values, dtype)
    /Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:334 _AssertCompatible
        raise TypeError(&quot;Expected any non-tensor type, got a tensor instead.&quot;)

    TypeError: Expected any non-tensor type, got a tensor instead.
</code></pre>
<p>can anyone help me fix this?</p>
",,user10985800,,user10985800,44465.76944,44465.86875,"KeyError: 0, TFF strange error in multi-outputs model",<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69385064,1,,,44469.06597,,0,203,"<p>I went through the source for the CIFAR-100 inbuilt dataset and decided to create a compatible version for the FairFace dataset in order to be able to leverage the other built-in functions without many modifications everywhere once I convert FairFace into a structure very similar to CIFAR-100.</p>
<p>I did search around but was unable to find how the CIFAR-100 SQLite database was created - specifically how the images were converted into BLOB for storage. After a bit of trial and error, I tried doing it this way:</p>
<pre class=""lang-py prettyprint-override""><code>sample = getDatabyIndex(train_labels, index)
example = tf.train.Example(features=tf.train.Features(feature={
  'image' : bytes_feature(sample[0].tobytes()),
  'label' : int64_feature(sample[1])
}))
example = example.SerializeToString()
cur.execute(&quot;insert into examples('split_name','client_id','serialized_example_proto') values(?,?,?)&quot;, ('train', i, sqlite3.Binary(example)))
</code></pre>
<p>Executing this for each sample in the train data and similarly for test data. I am able to load it using this decoding method:</p>
<pre class=""lang-py prettyprint-override""><code>def parse_proto(tensor_proto):
  parse_spec = {
    'image': tf.io.FixedLenFeature(shape=(), dtype=tf.string),
    'label': tf.io.FixedLenFeature(shape=(), dtype=tf.int64),
  }
  decoded_example = tf.io.parse_example(tensor_proto, parse_spec)
  return collections.OrderedDict(
            image=tf.reshape(tf.io.decode_raw(decoded_example['image'], tf.uint8), (224,224,3)),
            label=decoded_example['label'])
</code></pre>
<p>What I noticed, however, is that the final sqlite.lzma compressed archive is 6.4 GB in size whereas the source archive for the dataset was 555 MB. I am guessing that due to the way I am storing the images, compression is not working as well as it could if they were stored in a more compatible manner. I see from the CIFAR-100 code that the images are loaded directly as FixedLenFeatures of shape (32,32,3) which means that they were stored as such but I have been unable to find a way to store my images as such. The only method that worked for me was the bytes_feature route.</p>
<p>What would be the best/recommended way to go about this?</p>
",8357000,,14692,,44559.95069,44559.96319,What is the best way to create a custom federated image dataset for TFF in SQLite format?,<tensorflow><image-classification><tensorflow-federated><federated-learning>,1,1,,,,CC BY-SA 4.0
69464111,1,,,44475.44028,,0,700,"<p>-i have column names [&quot;Date&quot;,&quot;Open&quot;,&quot;High&quot;,&quot;Close&quot;,&quot;Volume&quot;,&quot;Group&quot;]</p>
<p>-i created a additional column name &quot;Group&quot; to represent ClientID</p>
<pre><code>df[&quot;Group&quot;] = &quot;&quot;
client_id_colname = 'Group' # the column that represents client ID
print(df)
count= 0
group = &quot;&quot;
for i, row in df.iterrows():
  
  if count&lt;=3000 and count &gt;= 0:
    group = 'A'
    df.loc[count,'Group']= group
  elif count&lt;=6000 and count &gt;= 3001:
    group = 'B'
    df.loc[count,'Group']= group
  elif count&lt;=9000 and count &gt;= 6001:
    group = 'C'
    df.loc[count,'Group']= group
  else: 
    group = 'D'
    df.loc[count,'Group']= group
  count=count + 1

print(df)
</code></pre>
<p>-i also split the data into train_data and test_data:</p>
<pre><code>train_data = tff.simulation.datasets.ClientData.from_clients_and_fn(
        client_ids=train_client_ids,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
test_data = tff.simulation.datasets.ClientData.from_clients_and_fn(
        client_ids=test_client_ids,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
</code></pre>
<p>-from here how can i create a lstm model to do federated learning and forecast the prediction for &quot;Close&quot; value?</p>
",17088460,,,,,44515.59583,how to create a federated model lstm for stock prediction in python,<python><machine-learning><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
59430106,1,,,43819.78681,,1,145,"<p>I have read all the documents on the tensorflow federated available at tensorflow.org, but I am not sure how to implement my own federated algorithm. For example, I have a compiled keras model, I know how to convert this to tff.computation. It seems that in order to build a federated algorithm one should build an iterative_process. Can anyone help me in this regard? </p>

<p>Thank you so much, </p>
",12572107,,730754,,44163.45764,44163.45764,How to implement my own federated algorithm Usinsg tensorflow federated,<tensorflow><tensorflow-federated><federated-learning>,2,0,,,,CC BY-SA 4.0
59448706,1,,,43821.9625,,0,582,"<p>I am looking for a way to get client models as checkpoints that I can investigate as standard keras model. I looked into <a href=""https://stackoverflow.com/questions/58247978/tensorflow-federated-learning-checkpoint"">this question</a> but it only provides the weights, is there a way to get or save models from clients directly during federated training? </p>
",12575714,,,,,43822.60694,How to get client models (based on Keras) in tensorflow federated?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
59622300,1,,,43837.19931,,1,629,"<p>I tried to customize the model in ""Image classification"" tutorial in Tensorflow Federated. (It originally used a sequential model)
I use Keras ResNet50 but when it began to train, there is always an error ""Incompatible shapes""</p>

<p>Here are my codes:</p>

<pre><code>NUM_CLIENTS = 4
NUM_EPOCHS = 10
BATCH_SIZE = 2
SHUFFLE_BUFFER = 5

def create_compiled_keras_model():
  model = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', 
                                                input_tensor=tf.keras.layers.Input(shape=(100, 
                                                300, 3)), pooling=None)

  model.compile(
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      optimizer=tf.keras.optimizers.SGD(learning_rate=0.02),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
  return model


def model_fn():
  keras_model = create_compiled_keras_model()
  return tff.learning.from_compiled_keras_model(keras_model, sample_batch)

iterative_process = tff.learning.build_federated_averaging_process(model_fn)
</code></pre>

<p>Error information:
<a href=""https://i.sstatic.net/n7Ctu.png"" rel=""nofollow noreferrer"">enter image description here</a></p>

<p>I feel that the shape is incompatible because the epoch and clients information were somehow missing. Would be very thankful if someone could give me a hint.</p>

<p><strong>Updates:</strong></p>

<p>The Assertion error happened during <code>tff.learning.build_federated_averaging_process</code></p>

<pre><code>---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
&lt;ipython-input-164-dac26193d9d8&gt; in &lt;module&gt;()
----&gt; 1 iterative_process = tff.learning.build_federated_averaging_process(model_fn)
      2 
      3 # iterative_process = build_federated_averaging_process(model_fn)

13 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/federated_averaging.py in build_federated_averaging_process(model_fn, server_optimizer_fn, client_weight_fn, stateful_delta_aggregate_fn, stateful_model_broadcast_fn)
    165   return optimizer_utils.build_model_delta_optimizer_process(
    166       model_fn, client_fed_avg, server_optimizer_fn,
--&gt; 167       stateful_delta_aggregate_fn, stateful_model_broadcast_fn)

/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py in build_model_delta_optimizer_process(model_fn, model_to_client_delta_fn, server_optimizer_fn, stateful_delta_aggregate_fn, stateful_model_broadcast_fn)
    349   # still need this.
    350   with tf.Graph().as_default():
--&gt; 351     dummy_model_for_metadata = model_utils.enhance(model_fn())
    352 
    353   # ===========================================================================

&lt;ipython-input-159-b2763ace8e5b&gt; in model_fn()
      1 def model_fn():
      2   keras_model = model
----&gt; 3   return tff.learning.from_compiled_keras_model(keras_model, sample_batch)

/usr/local/lib/python3.6/dist-packages/tensorflow_federated/python/learning/keras_utils.py in from_compiled_keras_model(keras_model, dummy_batch)
    211   # Model.test_on_batch() once before asking for metrics.
    212   if isinstance(dummy_tensors, collections.Mapping):
--&gt; 213     keras_model.test_on_batch(**dummy_tensors)
    214   else:
    215     keras_model.test_on_batch(*dummy_tensors)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in test_on_batch(self, x, y, sample_weight, reset_metrics)
   1007         sample_weight=sample_weight,
   1008         reset_metrics=reset_metrics,
-&gt; 1009         standalone=True)
   1010     outputs = (
   1011         outputs['total_loss'] + outputs['output_losses'] + outputs['metrics'])

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in test_on_batch(model, x, y, sample_weight, reset_metrics, standalone)
    503       y,
    504       sample_weights=sample_weights,
--&gt; 505       output_loss_metrics=model._output_loss_metrics)
    506 
    507   if reset_metrics:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    568         xla_context.Exit()
    569     else:
--&gt; 570       result = self._call(*args, **kwds)
    571 
    572     if tracing_count == self._get_tracing_count():

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    606       # In this case we have not created variables on the first call. So we can
    607       # run the first trace but we should fail if variables are created.
--&gt; 608       results = self._stateful_fn(*args, **kwds)
    609       if self._created_variables:
    610         raise ValueError(""Creating variables on a non-first call to a function""

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   2407     """"""Calls a graph function specialized to the inputs.""""""
   2408     with self._lock:
-&gt; 2409       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   2410     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2411 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2765 
   2766       self._function_cache.missed.add(call_context_key)
-&gt; 2767       graph_function = self._create_graph_function(args, kwargs)
   2768       self._function_cache.primary[cache_key] = graph_function
   2769       return graph_function, args, kwargs

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2655             arg_names=arg_names,
   2656             override_flat_arg_shapes=override_flat_arg_shapes,
-&gt; 2657             capture_by_value=self._capture_by_value),
   2658         self._function_attributes,
   2659         # Tell the ConcreteFunction to clean up its graph once it goes out of

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--&gt; 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--&gt; 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--&gt; 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

AssertionError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_eager.py:345 test_on_batch  *
        with backend.eager_learning_phase_scope(0):
    /usr/lib/python3.6/contextlib.py:81 __enter__
        return next(self.gen)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py:425 eager_learning_phase_scope
        assert ops.executing_eagerly_outside_functions()

    AssertionError: 

</code></pre>
",12665683,,730754,,44163.45694,44163.45694,ResNet model in Tensorflow Federated,<tensorflow><resnet><tensorflow-federated><federated-learning>,2,4,,,,CC BY-SA 4.0
59741397,1,,,43844.85625,,2,1538,"<p>here is the code of my federated learning test</p>

<pre><code>from __future__ import absolute_import, division, print_function
import os
import collections
import warnings
from six.moves import range
import numpy as np
import six
import tensorflow as tf
import tensorflow_federated as tff
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
import PIL


#pretrain

train_datagen1 = tf.keras.preprocessing.image.ImageDataGenerator(vertical_flip=True)
training_set1= train_datagen1.flow_from_directory('folder1/train',target_size=(200, 200), batch_size=32)



)




</code></pre>

<p>Now when I want to create sample_batch like the tutorial in the tensorflow federtaed for image classification</p>

<p>I write this line and it find this error</p>

<pre><code>example_dataset = training_set1.create_tf_dataset_for_client(training_set1.client_ids[0])
</code></pre>

<p>the error</p>

<hr>

<p>TypeError                                 Traceback (most recent call last)
 in 
      1 training_set1.element_type_structure
----> 2 example_dataset = training_set1.create_tf_dataset_for_client(training_set1.client_ids[0])</p>

<p>TypeError: 'abstractproperty' object does not support indexing</p>

<hr>

<p>Can you tell me how I must do to create dummy_batch in order to convert keras model into tff.learning.from_compiled_keras_model(model, dummy_batch)</p>
",12682667,,730754,,44163.68681,44163.68681,Federated learning : convert my own image dataset into tff simulation Clientdata,<python><tensorflow><keras><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
59835749,1,,,43851.29444,,4,584,"<p>(I have posted the question on <a href=""https://github.com/tensorflow/federated/issues/793"" rel=""nofollow noreferrer"">https://github.com/tensorflow/federated/issues/793</a> and maybe also here!)</p>

<p>I have customized my own data and model to federated interfaces and the training converged. But I am confused about an issue that in an images classification task, the whole dataset is extreme large and it can't be stored in a single <code>federated_train_data</code> nor be imported to memory for one time. So I need to load the dataset from the hard disk in batches to memory real-timely and use <code>Keras model.fit_generator</code> instead of <code>model.fit</code> during training, the approach people use to deal with large data.</p>

<p>I suppose in <code>iterative_process</code> shown in image classification tutorial, the model is fitted on a fixed set of data. Is there any way to adjust the code to let it fit to a data generator?I have looked into the source codes but still quite confused. Would be incredibly grateful for any hints.</p>
",12752740,,730754,,44163.45625,44163.45625,Implement data generator in federated training,<tensorflow><keras><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
69499432,1,69530100,,44477.71042,,3,575,"<p>I am a newbie in federated learning and just getting to know TensorFlow Federated TFF framework. I have some questions in my mind I would be really appreciated it if anybody can clarify them:</p>
<ol>
<li>Does Federated Averaging algorithm the only aggregation algorithm supported in TFF? and how it differs from Federated Stochastic Gradient Descent?</li>
<li>Dose Federated Averaging require each client to be trained with the Neural Networks? or it is possible for local data to be trained with any machine learning algorithm?</li>
<li>I have big data, and I am planning to partition my data into smaller datasets and simulated each part as one client? does this work in TFF? and does it consider horizontal or vertical federated learning?</li>
</ol>
<p>Thanks in advance</p>
",3088939,,,,,44480.71736,Federated Averaging and TensorFlow,<tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
69525476,1,,,44480.47778,,1,738,"<p>I was trying to implement <a href=""https://github.com/tensorflow/federated/tree/main/tensorflow_federated/python/examples/simple_fedavg"" rel=""nofollow noreferrer"">tensorflow-federated simple fedavg</a> with <a href=""https://github.com/ozgurcelik/stackoverflowQuestion"" rel=""nofollow noreferrer"">cifar10 dataset and resnet18</a>. Also this is the <a href=""https://colab.research.google.com/drive/1GpZpRfKWzBk4IzIt77kXf-Ut-HzYE1b2?usp=sharing"" rel=""nofollow noreferrer"">pytorch implementation</a>. Just like trainable ones, I have aggregated non-trainable parameters of batch-normalization to server and averaged them. I have used 5 clients and dataset was divided to 5 randomly, 50k/5=10k training samples for each client, so there is no gross skewed distribution. I have tested each client, after training, with the full test dataset,10k samples, that I also use to test server. The problem is after first training round despite each client had 20-25% accuracy, the server has 10% accuracy and basically makes nearly the same predictions for each input. This is the only the case  for first round since after that round server has almost always better accuracy than any client had in that round. For example</p>
<pre><code>Round 0 training loss: 3.0080783367156982
Round 0 client_id: 0 eval_score: 0.2287999987602234
Round 0 client_id: 1 eval_score: 0.2614000141620636
Round 0 client_id: 2 eval_score: 0.22040000557899475
Round 0 client_id: 3 eval_score: 0.24799999594688416
Round 0 client_id: 4 eval_score: 0.2565999925136566
Round 0 validation accuracy: 10.0
Round 1 training loss: 1.920640230178833
Round 1 client_id: 0 eval_score: 0.25220000743865967
Round 1 client_id: 1 eval_score: 0.32199999690055847
Round 1 client_id: 2 eval_score: 0.32580000162124634
Round 1 client_id: 3 eval_score: 0.3513000011444092
Round 1 client_id: 4 eval_score: 0.34689998626708984
Round 1 validation accuracy: 34.470001220703125
Round 2 training loss: 1.65810227394104
Round 2 client_id: 0 eval_score: 0.34369999170303345
Round 2 client_id: 1 eval_score: 0.3138999938964844
Round 2 client_id: 2 eval_score: 0.35580000281333923
Round 2 client_id: 3 eval_score: 0.39649999141693115
Round 2 client_id: 4 eval_score: 0.3917999863624573
Round 2 validation accuracy: 45.0
Round 3 training loss: 1.4956902265548706
Round 3 client_id: 0 eval_score: 0.46380001306533813
Round 3 client_id: 1 eval_score: 0.388700008392334
Round 3 client_id: 2 eval_score: 0.39239999651908875
Round 3 client_id: 3 eval_score: 0.43700000643730164
Round 3 client_id: 4 eval_score: 0.430400013923645
Round 3 validation accuracy: 50.62000274658203
Round 4 training loss: 1.3692104816436768
Round 4 client_id: 0 eval_score: 0.510200023651123
Round 4 client_id: 1 eval_score: 0.42739999294281006
Round 4 client_id: 2 eval_score: 0.4223000109195709
Round 4 client_id: 3 eval_score: 0.45080000162124634
Round 4 client_id: 4 eval_score: 0.45559999346733093
Round 4 validation accuracy: 54.83000183105469
</code></pre>
<p>To solve the issue with first round I tried to repeat the dataset but it didnt help. After that I tried to use all the cifar10 training samples for each client meaning instead of creating 5 different datasets of 10k samples for each client I used all 50k samples as the dataset.</p>
<pre><code>Round 0 training loss: 1.9335068464279175
Round 0 client_id: 0 eval_score: 0.4571000039577484
Round 0 client_id: 1 eval_score: 0.4514000117778778
Round 0 client_id: 2 eval_score: 0.4738999903202057
Round 0 client_id: 3 eval_score: 0.4560000002384186
Round 0 client_id: 4 eval_score: 0.4697999954223633
Round 0 validation accuracy: 10.0
Round 1 training loss: 1.4404207468032837
Round 1 client_id: 0 eval_score: 0.5945000052452087
Round 1 client_id: 1 eval_score: 0.5909000039100647
Round 1 client_id: 2 eval_score: 0.5864999890327454
Round 1 client_id: 3 eval_score: 0.5871999859809875
Round 1 client_id: 4 eval_score: 0.5684000253677368
Round 1 validation accuracy: 59.57999801635742
Round 2 training loss: 1.0174440145492554
Round 2 client_id: 0 eval_score: 0.7002999782562256
Round 2 client_id: 1 eval_score: 0.6953999996185303
Round 2 client_id: 2 eval_score: 0.6830999851226807
Round 2 client_id: 3 eval_score: 0.6682999730110168
Round 2 client_id: 4 eval_score: 0.6754000186920166
Round 2 validation accuracy: 72.41999816894531
Round 3 training loss: 0.7608759999275208
Round 3 client_id: 0 eval_score: 0.7621999979019165
Round 3 client_id: 1 eval_score: 0.7608000040054321
Round 3 client_id: 2 eval_score: 0.7390000224113464
Round 3 client_id: 3 eval_score: 0.7301999926567078
Round 3 client_id: 4 eval_score: 0.7303000092506409
Round 3 validation accuracy: 78.33000183105469
Round 4 training loss: 0.5893330574035645
Round 4 client_id: 0 eval_score: 0.7814000248908997
Round 4 client_id: 1 eval_score: 0.7861999869346619
Round 4 client_id: 2 eval_score: 0.7804999947547913
Round 4 client_id: 3 eval_score: 0.7694000005722046
Round 4 client_id: 4 eval_score: 0.758400022983551
Round 4 validation accuracy: 81.30000305175781
</code></pre>
<p>Clients obviously had the same initialization but i guess due to gpu use there were some minor accuracy differences yet each had 45+% accuracy. But as you can see even this didnt help with the first round. When using a simple cnn, such as the one available in the &quot;.main&quot;, with suitable parameters this problem doesnt exist. And using</p>
<pre><code>learning_rate=0.01 or momentum=0
</code></pre>
<p>instead of</p>
<pre><code>learning_rate=0.1 and momentum=0.9
</code></pre>
<p>reduces this for problem the first round but it has overall worse performance and i am trying to reproduce a paper that used the latter parameters.</p>
<p>I have also tried the same with pytorch and got the very similar results. <a href=""https://colab.research.google.com/drive/1GpZpRfKWzBk4IzIt77kXf-Ut-HzYE1b2?usp=sharing"" rel=""nofollow noreferrer"">Colab for pytorch code</a> The results for both are available in github.</p>
<p>I am very confused with that. Especially when I used entire training dataset and when each client had 45% accuracy. Also why get good results for following rounds? What changed between first round and the others? Every time clients had the same initialization with each other, same loss function, and same optimizer with the same parameters. The only thing that changed is the actual initialization between rounds.</p>
<p>So is there a special initialization that solves this first round problem or am I missing something?</p>
<p><em><strong>Edit:</strong></em></p>
<p>When the entire cifar10 training set is used for each client and dataset.repeat is used to repeat data.</p>
<pre><code>Pre-training validation accuracy: 9.029999732971191
Round 0 training loss: 1.6472676992416382
Round 0 client_id: 0 eval_score: 0.5931000113487244
Round 0 client_id: 1 eval_score: 0.5042999982833862
Round 0 client_id: 2 eval_score: 0.5083000063896179
Round 0 client_id: 3 eval_score: 0.5600000023841858
Round 0 client_id: 4 eval_score: 0.6104999780654907
Round 0 validation accuracy: 10.0
</code></pre>
<p>What catches my attention here is the client accuracy here is actually very similar to second round (round 1) accuracy of clients when dataset wasnt repeated(previous results). so eventhough server had 10% accuracy it didnt affect much the results of the next round.</p>
<p>This is how it works with a simple cnn (defined in the main.py in github)</p>
<pre><code>With the training set divided to 5
Pre-training validation accuracy: 9.489999771118164
Round 0 training loss: 2.1234841346740723
Round 0 client_id: 0 eval_score: 0.30250000953674316
Round 0 client_id: 1 eval_score: 0.2879999876022339
Round 0 client_id: 2 eval_score: 0.2533999979496002
Round 0 client_id: 3 eval_score: 0.25999999046325684
Round 0 client_id: 4 eval_score: 0.2897999882698059
Round 0 validation accuracy: 31.18000030517578

Entire training set for all the clients
Pre-training validation accuracy: 9.489999771118164
Round 0 training loss: 1.636365532875061
Round 0 client_id: 0 eval_score: 0.47850000858306885
Round 0 client_id: 1 eval_score: 0.49470001459121704
Round 0 client_id: 2 eval_score: 0.4918000102043152
Round 0 client_id: 3 eval_score: 0.492900013923645
Round 0 client_id: 4 eval_score: 0.4043000042438507
Round 0 validation accuracy: 50.62000274658203
</code></pre>
<p>As we can see when a simple cnn is used server accuracy is better than the best client accuracy, and definitely better than the average, beginning from the very first round. I am trying to understand why the resnet fails to do that and makes the same predictions regardless of input. After the first round the predictions look like</p>
<pre><code>[[0.02677999 0.02175025 0.10807421 0.25275248 0.08478505 0.20601839
  0.16497472 0.09307405 0.01779539 0.02399557]
 [0.04087764 0.03603332 0.09987792 0.23636964 0.07425722 0.19982725
  0.13649824 0.09779423 0.03454168 0.04392283]
 [0.02448712 0.01900426 0.11061406 0.25295085 0.08886322 0.20792796
  0.17296027 0.08762561 0.01570844 0.01985822]
 [0.01790532 0.01536059 0.11237497 0.2519772  0.09357632 0.20954111
  0.18946911 0.08571784 0.01004946 0.01402805]
 [0.02116687 0.02263201 0.10294028 0.25523028 0.08544692 0.21299754
  0.17604835 0.088608   0.01438032 0.02054946]
 [0.01598492 0.01457187 0.10899033 0.25493488 0.09417254 0.20747423
  0.19798534 0.08387674 0.0089481  0.01306108]
 [0.01432306 0.01214803 0.11237216 0.25138852 0.09796435 0.2036258
  0.20656979 0.08344456 0.00726837 0.01089529]
 [0.01605278 0.0135905  0.11161591 0.25388476 0.09531546 0.20592561
  0.19932476 0.08305667 0.00873495 0.01249863]
 [0.02512863 0.0238647  0.10465285 0.24918261 0.08625458 0.21051233
  0.16839236 0.09075507 0.01765386 0.02360307]
 [0.05418856 0.05830322 0.09909651 0.20211859 0.07324574 0.18549475
  0.11666768 0.0990423  0.05081367 0.06102907]]
</code></pre>
<p>They all return 3rd label.</p>
",16428078,,16428078,,44480.99861,44833.38194,"Federated Averaging (fedavg) with resnet 18 that has batch_normalization makes the same prediction after first round, but in no other rounds",<tensorflow><pytorch><tensorflow-federated><federated-learning>,1,1,,,,CC BY-SA 4.0
69538510,1,,,44481.41458,,0,138,"<p>I would like to deploy TFF in a way, where I have one central (aggregation) server on a VM in a cloud and two different VMs with nodes, that train the model. Is this possible with TFF? Does it have the protocols necessary to communicate over the internet etc. or is it more of a Tensorflow with FL algorithms that can be used with different frameworks that provide the architecture?</p>
<p>Thank you</p>
",9334092,,,,,44481.76944,Does TFF support deployment across different devices and clouds?,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
69542184,1,,,44481.59514,,2,284,"<p>Currently I am working on a federated-learning project using TensorFlow Federated.
I was making a request from a server to check if my code was working when I got this error:</p>
<pre><code>    RuntimeError: No default context installed.
    
    You should not expect to get this error using the TFF API.
</code></pre>
<p>However, I only encounter it under some specific conditions.</p>
<p>Scenario goes like this (all the code is bellow):</p>
<p>A http request is made from the website. The function <em>upload_and_train</em> in <em>routes/developers.py</em> handles the request. Inside this, the <em>start_processing</em> function is called which starts the training preprocess (gathering train data, initializing hyperparameters etc). Finally the <em>federated_computation_new</em> function is called (which is where it also crashes) which starts the federated learning.
It crashes when it reaches the call: <em>iterative_process.initialize()</em>.</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(model_fn,client_optimizer_fn=lambda: tf.keras.optimizers.SGD(lr=0.5))
state = iterative_process.initialize()
</code></pre>
<p>The confusing part is the following. If I run the code locally, everything goes well, the training process is working; no errors. If I run it on the server It also works for the first request made. Afterwards it crashes and returns the same error (stated in more details bellow) on all the following requests until I restart the server. Then it again works perfectly for the first call, and proceeds to crash on subsequent calls.</p>
<p>This issue is driving me nuts, I can't figure it out. My only remaining idea is that something is happening after the first call (a process is not closed or something like that) and on subsequent calls it doesn't get a &quot;fresh&quot; start? Although it shouldn't happen in the first place.</p>
<p>Full error message bellow:</p>
<pre><code>    143.205.173.225 - - [12/Oct/2021 13:18:05] &quot;[35m[1mPOST /api/Developers/use_cases/text_processing/developer_id/3/upload_and_train HTTP/1.1[0m&quot; 500 -
INFO:werkzeug:143.205.173.225 - - [12/Oct/2021 13:18:05] &quot;[35m[1mPOST /api/Developers/use_cases/text_processing/developer_id/3/upload_and_train HTTP/1.1[0m&quot; 500 -
 doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU
ERROR:main:Exception on /api/Developers/use_cases/text_processing/developer_id/4/upload_and_train [POST]
Traceback (most recent call last):
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/flask/app.py&quot;, line 2447, in wsgi_app
    response = self.full_dispatch_request()
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/flask/app.py&quot;, line 1952, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/flask/app.py&quot;, line 1821, in handle_user_exception
    reraise(exc_type, exc_value, tb)
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/flask/_compat.py&quot;, line 39, in reraise
    raise value
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/flask/app.py&quot;, line 1950, in full_dispatch_request
    rv = self.dispatch_request()
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/flask/app.py&quot;, line 1936, in dispatch_request
    return self.view_functions[rule.endpoint](**req.view_args)
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/connexion/decorators/decorator.py&quot;, line 48, in wrapper
    response = function(request)
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/connexion/decorators/uri_parsing.py&quot;, line 144, in wrapper
    response = function(request)
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/connexion/decorators/validation.py&quot;, line 384, in wrapper
    return function(request)
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/connexion/decorators/parameter.py&quot;, line 121, in wrapper
    return function(**kwargs)
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/routes/developers.py&quot;, line 46, in upload_and_train
    last_train_metrics = main_proc.start_processing(use_case,developer_id)
  File &quot;processing/text_processing/main_proc.py&quot;, line 17, in start_processing
    state,metrics = federated_computation_new(train_dataset,test_dataset)
  File &quot;processing/text_processing/federated_algorithm.py&quot;, line 29, in federated_computation_new
    state = iterative_process.initialize()
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py&quot;, line 521, in __call__
    return context.invoke(self, arg)
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/context_stack/runtime_error_context.py&quot;, line 41, in invoke
    self._raise_runtime_error()
  File &quot;/home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/context_stack/runtime_error_context.py&quot;, line 23, in _raise_runtime_error
    raise RuntimeError(
RuntimeError: No default context installed.

You should not expect to get this error using the TFF API.

If you are getting this error when testing a module inside of `tensorflow_federated/python/core/...`, you may need to explicitly invoke `execution_contexts.set_local_execution_context()` in the `main` function of your test.

</code></pre>
<p>First Function which handles the incoming requests.
The request contains 4 parameters: 2 identifiers the &quot;use_case&quot; and the &quot;developer_&quot;id&quot; and 2 formData files which contain the training data, which is stored locally.</p>
<pre><code>def upload_and_train(use_case: str, developer_id: int):


    use_case_path = 'processing/'+use_case+'/'
    sys.path.append(use_case_path)
    import main_proc

    app_path = dirname(dirname(abspath(__file__)))
    file_dict = request.files
    db_File_True = file_dict[&quot;dataset_file1&quot;]
    db_File_Fake = file_dict[&quot;dataset_file2&quot;]
    true_csv_path = os.path.join(app_path+&quot;/&quot;+use_case_path+&quot;db/&quot;, &quot;True.csv&quot;)
    fake_csv_path = os.path.join(app_path+&quot;/&quot;+use_case_path+&quot;db/&quot;, &quot;Fake.csv&quot;)
    db_File_True.save(true_csv_path)
    db_File_Fake.save(fake_csv_path)
    time.sleep(5) #wait for the files to be copied before proceeding
    #THEN start processing
    last_train_metrics = main_proc.start_processing(use_case,developer_id) # &lt;============== GOES INTO HERE &amp; CRASHES
    metricsJson = trainMetricsToJSON(last_train_metrics)    

    return Response(status=200, response=metricsJson)
</code></pre>
<p>The function which starts the preprocessing:</p>
<pre><code>def start_processing(use_case, developer_id:int = 0):
    globals.initialize(use_case,developer_id)
    globals.TRAINER_ID = developer_id
    
    
    train_dataset, test_dataset= get_preprocessed_train_test_data()

    state,metrics = federated_computation_new(train_dataset,test_dataset) # &lt;============== GOES INTO HERE &amp; CRASHES  
    trained_metrics= metrics['train']
    
    timestamp = int(time.time())
    globals.DATASET_ID = timestamp
    
    written_row = save_to_file_CSV(use_case,globals.TRAINER_ID,timestamp,globals.DATASET_ID,trained_metrics['sparse_categorical_accuracy'],trained_metrics['loss'])
    return written_row

</code></pre>
<p>The function where the federated training is being done:</p>
<pre><code>def federated_computation_new(train_dataset,test_dataset):

    # Training and evaluating the model
    iterative_process = tff.learning.build_federated_averaging_process(model_fn,client_optimizer_fn=lambda: tf.keras.optimizers.SGD(lr=0.5))
    state = iterative_process.initialize() # &lt;============== CRASHES HERE

    print(type(state))

    for n in range(globals.EPOCHS):
        state, metrics = iterative_process.next(state, train_dataset)
        print('round  {}, training metrics={}'.format(n+1, metrics))

    evaluation = tff.learning.build_federated_evaluation(model_fn)
    eval_metrics = evaluation(state.model, train_dataset)
    print('Training evaluation metrics={}'.format(eval_metrics))

    test_metrics = evaluation(state.model, test_dataset)
    print('Test evaluation metrics={}'.format(test_metrics))
    #############################################################################################
    #Save Last Trained Model
    import pickle
    with open(&quot;processing/&quot;+globals.USE_CASE+&quot;/last_model&quot;,'wb') as f:
        pickle.dump(state, f)
    return state,metrics
</code></pre>
<pre><code>def model_fn():
  keras_model = get_simple_LSTM_model()

  return tff.learning.from_keras_model(
      keras_model,
      input_spec=globals.INPUT_SPEC,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>The function: /home/itec/bogdan/Articonf/smart/tools/federated-training/app/venv/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py&quot;, line 521,</p>
<pre><code>def __call__(self, *args, **kwargs):
    context = self._context_stack.current
    arg = pack_args(self._type_signature.parameter, args, kwargs, context)
    return context.invoke(self, arg) # &lt;============== This returns the runtime Error
</code></pre>
<p>Thank you very much in advance for your time and patience.</p>
",10151621,,114900,,44481.59653,44481.97014,"""RuntimeError: No default context installed. "" when using Tensorflow Federated",<python><tensorflow><runtime-error><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69591102,1,,,44484.92222,,1,159,"<p>Currently trying to use federated analytics (and eventually federated learning) at work. We are exploring PyTorch Federated and TensorFlow Federated. When I watched the TensorFlow Federated Tutorials on Google TechTalk, all tutorials were being connected to simulated data sets available locally and they confirmed that TensorFlow Federated is only ready for simulations and not for production. Do we know when TensorFlow Federated will be ready for production?</p>
",17164021,,,,,44484.98194,When will TensorFlow Federated be ready for production?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69596586,1,69627599,,44485.61042,,1,114,"<p>I'm trying to understand how Tensorflow Federated Works, using the simple_fedavg as example.</p>
<p>I still don't understand how to change what the client send to the server, for example.</p>
<p>I don't want to send all the weights of the update, i want to send a list formed like this:</p>
<pre><code>  test[index] = test_stc.stc_compression(test[index], sparsification_rate)
</code></pre>
<p>Where <code>test_stc.stc_compression(test[index], sparsification_rate)</code> return 5 values: <code>negatives, positives, average, original_shape, new_shape</code>, then i would like to access those information on the server side before running the  <code>round_model_delta = tff.federated_mean(client_outputs.weights_delta, weight=weight_denom)</code> for creating the weights that i will use for the <code>tff.federated_mean</code>.</p>
<p>So, basically, i would like to change <code>client_update</code> to send a list that i have created instead of all the weights and then, on the server create a custom list of weights using the information that the client sent. Only after the creation of the new custom list of weight i would like the server to update the model.</p>
<p>I actually tried to change the <code>return ClientOutput(test, client_weight, loss_sum / client_weight)</code> of the <code>client_update</code>, but then i don't know how to access the <code>test</code> variable on the server and in which procedure/function i would need to do it.</p>
<p>I hope that i made myself clear enough since my main language is not english.</p>
",12749028,,,,,44488.35972,How to change the update that the client send to the server Tensorflow Federated,<python><tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
69607949,1,69627733,,44486.81667,,2,106,"<p>I have created a custom encoder/decoder like so:</p>
<pre><code>import tensorflow as tf

from tensorflow_model_optimization.python.core.internal import tensor_encoding as te


# noinspection PyUnresolvedReferences
class SparseTernaryCompressionEncodingStage(te.core.EncodingStageInterface):
    AVERAGE = 'average'
    NEGATIVES = 'negatives'
    POSITIVES = 'positives'
    TESTING = 'testing'
    NEW_SHAPE = 'new_shape'
    ORIGINAL_SHAPE = 'original_shape'

    def name(self):
        pass

    def compressible_tensors_keys(self):
        pass

    def commutes_with_sum(self):
        pass

    def decode_needs_input_shape(self):
        pass

    def get_params(self):
        pass

    def encode(self, original_tensor, encode_params):
        original_shape = tf.shape(original_tensor)
        tensor = tf.reshape(original_tensor, [-1])
        sparsification_rate = int(len(tensor) / 100 * 1)
        new_shape = tensor.get_shape().as_list()
        if sparsification_rate == 0:
            sparsification_rate = 1
        mask = tf.cast(tf.abs(tensor) &gt;= tf.math.top_k(tf.abs(tensor), sparsification_rate)[0][-1], tf.float32)
        inv_mask = tf.cast(tf.abs(tensor) &lt; tf.math.top_k(tf.abs(tensor), sparsification_rate)[0][-1], tf.float32)
        tensor_masked = tf.multiply(tensor, mask)
        average = tf.reduce_sum(tf.abs(tensor_masked)) / sparsification_rate
        compressed_tensor = tf.add(tf.multiply(average, mask) * tf.sign(tensor), tf.multiply(tensor_masked, inv_mask))
        negatives = tf.where(compressed_tensor &lt; 0)
        positives = tf.where(compressed_tensor &gt; 0)

        encoded_x = {self.AVERAGE: average, self.NEGATIVES: negatives, self.POSITIVES: positives,
                     self.NEW_SHAPE: new_shape, self.ORIGINAL_SHAPE: original_shape}

        return encoded_x

    def decode(self, encoded_tensors, decode_params, num_summands=None, shape=None):
        decompressed_tensor = tf.zeros(self.NEW_SHAPE, tf.float32)
        average_values_negative = tf.fill([len(self.NEGATIVES), ], -self.AVERAGE)
        average_values_positive = tf.fill([len(self.POSITIVES), ], self.AVERAGE)
        decompressed_tensor = tf.tensor_scatter_nd_update(decompressed_tensor, self.NEGATIVES, average_values_negative)
        decompressed_tensor = tf.tensor_scatter_nd_update(decompressed_tensor, self.POSITIVES, average_values_positive)
        decompressed_tensor = tf.reshape(decompressed_tensor, self.ORIGINAL_SHAPE)
        return decompressed_tensor
</code></pre>
<p>Now, i would like to use the encode function to encode all the weights that the client send to the server and, on the server, use the decode function to be able to obtain all the weights back. Basically, instead of sending all the weights from the client to the server, i want to send only some necessaries information that will let me able to create the weights back from only 5 informations.</p>
<p>The problem is that i don't understand how to tell the client to use this encoder to send the information and to the server to use the decoder before trying to do:
<code>round_model_delta = tff.federated_mean(client_outputs.weights_delta, weight=weight_denom)</code></p>
<p>I'm using <a href=""https://github.com/tensorflow/federated/tree/v0.19.0/tensorflow_federated/python/examples/simple_fedavg"" rel=""nofollow noreferrer"">Tensorflow Federated simple_fedavg</a> as basic project.</p>
",12749028,,12749028,,44487.00625,44489.49306,How to implement custom encode Tensorflow Federated,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69614134,1,69627894,,44487.41597,,1,614,"<p>I have this run_one_round function like this:</p>
<pre><code>def run_one_round(server_state, federated_dataset):
    &quot;&quot;&quot;Orchestration logic for one round of computation.
    Args:
      server_state: A `ServerState`.
      federated_dataset: A federated `tf.data.Dataset` with placement
        `tff.CLIENTS`.
    Returns:
      A tuple of updated `ServerState` and `tf.Tensor` of average loss.
    &quot;&quot;&quot;
    tf.print(&quot;run_one_round&quot;)
    server_message = tff.federated_map(server_message_fn, server_state)
    server_message_at_client = tff.federated_broadcast(server_message)

    client_outputs = tff.federated_map(
        client_update_fn, (federated_dataset, server_message_at_client))

    weight_denom = client_outputs.client_weight

    from tensorflow_federated.python.core.impl.federated_context import value_impl
    value = value_impl.to_value(client_outputs.test, None)
    from tensorflow_federated.python.core.impl.types import placements
    from tensorflow_federated.python.core.impl.federated_context import value_utils
    value = value_utils.ensure_federated_value(value, placements.CLIENTS,
                                               'value to be averaged')

    value_comp = value.comp
    testing = []
    import sparse_ternary_compression
    for index in range(len(value_comp[0])):
        testing.append(
            sparse_ternary_compression.stc_decompression(value_comp[0][index][0], value_comp[0][index][1],
                                                         value_comp[0][index][2], value_comp[0][index][3],
                                                         value_comp[0][index][4]))

    # round_model_delta indica i pesi che vengono usati su server_update. Quindi Ã¨ quello che va cambiato
    round_model_delta = tff.federated_mean(
        client_outputs.weights_delta, weight=weight_denom)

    server_state = tff.federated_map(server_update_fn, (server_state, round_model_delta))
    round_loss_metric = tff.federated_mean(client_outputs.model_output, weight=weight_denom)

    return server_state, round_loss_metric, value.comp
</code></pre>
<p>But when i try to do:</p>
<pre><code>value_comp = value.comp
testing = []
import sparse_ternary_compression
for index in range(len(value_comp[0])):
    testing.append(
        sparse_ternary_compression.stc_decompression(value_comp[0][index][0], value_comp[0][index][1],
                                                     value_comp[0][index][2], value_comp[0][index][3],
                                                     value_comp[0][index][4]))
</code></pre>
<p>I get this error:&quot;</p>
<pre><code>File &quot;/mnt/d/Davide/Uni/TesiMagistrale/ProgettoTesi/simple_fedavg_tff.py&quot;, line 137, in run_one_round
    for index in range(len(value_comp[0])):
TypeError: 'Call' object is not subscriptable
</code></pre>
<p>While if i return the value <code>value.comp</code> and then i do the same operations inside the main it works fine.</p>
<pre><code>    for round_num in range(FLAGS.total_rounds):
        print(&quot;--------------------------------------------------------&quot;)
        sampled_clients = np.random.choice(train_data.client_ids, size=FLAGS.train_clients_per_round, replace=False)
        sampled_train_data = [train_data.create_tf_dataset_for_client(client) for client in sampled_clients]
</code></pre>
<p>The code is the same, so why i can't use the <code>for</code> loop inside <code>run_one_round</code> function?</p>
<pre><code>        server_state, train_metrics, value_comp = iterative_process.next(server_state, sampled_train_data)

        testing = []
        import sparse_ternary_compression
        for index in range(len(value_comp[0])):
            testing.append(sparse_ternary_compression.stc_decompression(value_comp[0][index][0], value_comp[0][index][1],
                                                                   value_comp[0][index][2], value_comp[0][index][3],
                                                                   value_comp[0][index][4]))
        print(testing)
        print(f'Round {round_num}')
        print(f'\tTraining loss: {train_metrics:.4f}')
        if round_num % FLAGS.rounds_per_eval == 0:
            server_state.model_weights.assign_weights_to(keras_model)
            accuracy = evaluate(keras_model, test_data)
            print(f'\tValidation accuracy: {accuracy * 100.0:.2f}%')
            tf.print(tf.compat.v2.summary.scalar(&quot;Accuracy&quot;, accuracy * 100.0, step=round_num))
</code></pre>
<p>Basically i just want to access to the <code>test</code> variable that the client send using <code>client_update</code> and do some operation on that list before <code>tff.federated_mean</code> function.</p>
<p>The problem maybe is that <code>run_one_round</code> is a <code>tff.federated_computation</code>?</p>
",12749028,,12749028,,44487.62569,44488.37361,Tensorflow Federated object is not subscriptable,<python><tensorflow><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
69619028,1,69627986,,44487.66042,,1,582,"<p>I'm using Tensorflow Federated, but i'm actually have some problem while trying to executes some operation on the server after reading the client update.</p>
<p>This is the function</p>
<pre><code>@tff.federated_computation(federated_server_state_type,
                           federated_dataset_type)
def run_one_round(server_state, federated_dataset):
    &quot;&quot;&quot;Orchestration logic for one round of computation.
    Args:
      server_state: A `ServerState`.
      federated_dataset: A federated `tf.data.Dataset` with placement
        `tff.CLIENTS`.
    Returns:
      A tuple of updated `ServerState` and `tf.Tensor` of average loss.
    &quot;&quot;&quot;
    tf.print(&quot;run_one_round&quot;)
    server_message = tff.federated_map(server_message_fn, server_state)
    server_message_at_client = tff.federated_broadcast(server_message)

    client_outputs = tff.federated_map(
        client_update_fn, (federated_dataset, server_message_at_client))

    weight_denom = client_outputs.client_weight


    tf.print(client_outputs.weights_delta)
    round_model_delta = tff.federated_mean(
        client_outputs.weights_delta, weight=weight_denom)

    server_state = tff.federated_map(server_update_fn, (server_state, round_model_delta))
    round_loss_metric = tff.federated_mean(client_outputs.model_output, weight=weight_denom)

    return server_state, round_loss_metric, client_outputs.weights_delta.comp
</code></pre>
<p>I want to print the <code>client_outputs.weights_delta</code> and doing some operation on the weights that the client sent to the server before using the <code>tff.federated_mean</code> but i don't get how to do so.</p>
<p>When i try to print i get this</p>
<p><code>Call(Intrinsic('federated_map', FunctionType(StructType([FunctionType(StructType([('weights_delta', StructType([TensorType(tf.float32, [5, 5, 1, 32]), TensorType(tf.float32, [32]), ....]) as ClientOutput, PlacementLiteral('clients'), False)))])) </code></p>
<p>Any way to modify those elements?</p>
<p>I tried with using <code>return client_outputs.weights_delta.comp</code> doing the modification in the main (i can do that) and then i tried to invocate a new method for doing the rest of the operations for the server update, but the error is:</p>
<p><code>AttributeError: 'IterativeProcess' object has no attribute 'calculate_federated_mean'</code>
where calculate_federated_mean was the name of the new function i created.</p>
<p>This is the main:</p>
<pre><code> for round_num in range(FLAGS.total_rounds):
        print(&quot;--------------------------------------------------------&quot;)
        sampled_clients = np.random.choice(train_data.client_ids, size=FLAGS.train_clients_per_round, replace=False)
        sampled_train_data = [train_data.create_tf_dataset_for_client(client) for client in sampled_clients]

        server_state, train_metrics, value_comp = iterative_process.next(server_state, sampled_train_data)

        print(f'Round {round_num}')
        print(f'\tTraining loss: {train_metrics:.4f}')
        if round_num % FLAGS.rounds_per_eval == 0:
            server_state.model_weights.assign_weights_to(keras_model)
            accuracy = evaluate(keras_model, test_data)
            print(f'\tValidation accuracy: {accuracy * 100.0:.2f}%')
            tf.print(tf.compat.v2.summary.scalar(&quot;Accuracy&quot;, accuracy * 100.0, step=round_num))
</code></pre>
<p>Based on the simple_fedavg project from github [Tensorflow Federated simple_fedavg][1] as basic project.</p>
<p>EDIT 1:</p>
<p>So, thanks to @Jakub Konecny i made some progress, but i have found a new problem that i don't actually understand.</p>
<p>So, if i use this <code>client_update</code></p>
<pre><code>@tf.function
def client_update(model, dataset, server_message, client_optimizer):
    &quot;&quot;&quot;Performans client local training of `model` on `dataset`.
    Args:
      model: A `tff.learning.Model`.
      dataset: A 'tf.data.Dataset'.
      server_message: A `BroadcastMessage` from server.
      client_optimizer: A `tf.keras.optimizers.Optimizer`.
    Returns:
      A 'ClientOutput`.
    &quot;&quot;&quot;
    model_weights = model.weights
    initial_weights = server_message.model_weights
    tf.nest.map_structure(lambda v, t: v.assign(t), model_weights,
                          initial_weights)

    num_examples = tf.constant(0, dtype=tf.int32)
    loss_sum = tf.constant(0, dtype=tf.float32)
    # Explicit use `iter` for dataset is a trick that makes TFF more robust in
    # GPU simulation and slightly more performant in the unconventional usage
    # of large number of small datasets.
    for batch in iter(dataset):
        with tf.GradientTape() as tape:
            outputs = model.forward_pass(batch)
        grads = tape.gradient(outputs.loss, model_weights.trainable)
        client_optimizer.apply_gradients(zip(grads, model_weights.trainable))
        batch_size = tf.shape(batch['x'])[0]
        num_examples += batch_size
        loss_sum += outputs.loss * tf.cast(batch_size, tf.float32)

    weights_delta = tf.nest.map_structure(lambda a, b: a - b,
                                          model_weights.trainable,
                                          initial_weights.trainable)


    client_weight = tf.cast(num_examples, tf.float32)

    import sparse_ternary_compression
    sparsification_rate = 1
    testing_new = []
    #TODO Da non applicare alle bias
    for tensor in weights_delta:
        testing_new.append(sparse_ternary_compression.stc_compression(tensor, sparsification_rate))

    return ClientOutput(weights_delta, client_weight, loss_sum / client_weight, testing_new)
</code></pre>
<p>with those functions:</p>
<pre><code>@tff.tf_computation
def stc_compression(original_tensor, sparsification_percentage):
    original_shape = tf.shape(original_tensor)
    tensor = tf.reshape(original_tensor, [-1])
    sparsification_percentage = tf.cast(sparsification_percentage, tf.float64)
    sparsification_rate = tf.size(tensor) / 100 * sparsification_percentage
    sparsification_rate = tf.cast(sparsification_rate, tf.int32)
    new_shape = tensor.get_shape().as_list()
    if sparsification_rate == 0:
        sparsification_rate = 1
    mask = tf.cast(tf.abs(tensor) &gt;= tf.math.top_k(tf.abs(tensor), sparsification_rate)[0][-1], tf.float32)
    inv_mask = tf.cast(tf.abs(tensor) &lt; tf.math.top_k(tf.abs(tensor), sparsification_rate)[0][-1], tf.float32)
    tensor_masked = tf.multiply(tensor, mask)
    sparsification_rate = tf.cast(sparsification_rate, tf.float32)
    average = tf.reduce_sum(tf.abs(tensor_masked)) / sparsification_rate
    compressed_tensor = tf.add(tf.multiply(average, mask) * tf.sign(tensor), tf.multiply(tensor_masked, inv_mask))
    negatives = tf.where(compressed_tensor &lt; 0)
    positives = tf.where(compressed_tensor &gt; 0)
    return negatives, positives, average, original_shape, new_shape

@tff.tf_computation
def stc_decompression(negatives, positives, average, original_shape, new_shape):
    decompressed_tensor = tf.zeros(new_shape, tf.float32)
    average_values_negative = tf.fill([tf.shape(negatives)[0], ], -average)
    average_values_positive = tf.fill([tf.shape(positives)[0], ], average)
    decompressed_tensor = tf.tensor_scatter_nd_update(decompressed_tensor, negatives, average_values_negative)
    decompressed_tensor = tf.tensor_scatter_nd_update(decompressed_tensor, positives, average_values_positive)
    decompressed_tensor = tf.reshape(decompressed_tensor, original_shape)
    return decompressed_tensor


@tff.tf_computation
def testing_new_list(list):
    testing = []
    for index in list:
        testing.append(
            stc_decompression(index[0], index[1],
                              index[2], index[3],
                              index[4]))

    return testing
</code></pre>
<p>called like so inside the <code>run_one_round</code> function</p>
<pre><code>@tff.federated_computation(federated_server_state_type,
                               federated_dataset_type)
    def run_one_round(server_state, federated_dataset):
        &quot;&quot;&quot;Orchestration logic for one round of computation.
        Args:
          server_state: A `ServerState`.
          federated_dataset: A federated `tf.data.Dataset` with placement
            `tff.CLIENTS`.
        Returns:
          A tuple of updated `ServerState` and `tf.Tensor` of average loss.
        &quot;&quot;&quot;
        server_message = tff.federated_map(server_message_fn, server_state)
        server_message_at_client = tff.federated_broadcast(server_message)

        client_outputs = tff.federated_map(
            client_update_fn, (federated_dataset, server_message_at_client))

        weight_denom = client_outputs.client_weight

        import sparse_ternary_compression
        testing = tff.federated_map(sparse_ternary_compression.testing_new_list, client_outputs.test)

        # round_model_delta indica i pesi che vengono usati su server_update. Quindi Ã¨ quello che va cambiato
        round_model_delta = tff.federated_mean(
            client_outputs.weights_delta, weight=weight_denom)

        server_state = tff.federated_map(server_update_fn, (server_state, round_model_delta))
        round_loss_metric = tff.federated_mean(client_outputs.model_output, weight=weight_denom)

        return server_state, round_loss_metric, testing
</code></pre>
<p>but i get this exception</p>
<pre><code>Traceback (most recent call last):
  File &quot;/mnt/d/Davide/Uni/TesiMagistrale/ProgettoTesi/main.py&quot;, line 214, in &lt;module&gt;
    app.run(main)
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/absl/app.py&quot;, line 312, in run
    _run_main(main, args)
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/absl/app.py&quot;, line 258, in _run_main
    sys.exit(main(argv))
  File &quot;/mnt/d/Davide/Uni/TesiMagistrale/ProgettoTesi/main.py&quot;, line 171, in main
    iterative_process = simple_fedavg_tff.build_federated_averaging_process(
  File &quot;/mnt/d/Davide/Uni/TesiMagistrale/ProgettoTesi/simple_fedavg_tff.py&quot;, line 95, in build_federated_averaging_process
    def client_update_fn(tf_dataset, server_message):
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py&quot;, line 478, in __call__
    wrapped_func = self._strategy(
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py&quot;, line 216, in __call__
    result = fn_to_wrap(*args, **kwargs)
  File &quot;/mnt/d/Davide/Uni/TesiMagistrale/ProgettoTesi/simple_fedavg_tff.py&quot;, line 98, in client_update_fn
    return client_update(model, tf_dataset, server_message, client_optimizer)
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&quot;, line 889, in __call__
    result = self._call(*args, **kwds)
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&quot;, line 933, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&quot;, line 763, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/eager/function.py&quot;, line 3050, in _get_concrete_function_internal_garbage_collected
    graph_function, _ = self._maybe_define_function(args, kwargs)
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/eager/function.py&quot;, line 3444, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/eager/function.py&quot;, line 3279, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 999, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py&quot;, line 672, in wrapped_fn
    out = weak_wrapped_fn().__wrapped__(*args, **kwds)
  File &quot;/home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 986, in wrapper
    raise e.ag_error_metadata.to_exception(e)
tensorflow.python.autograph.pyct.error_utils.KeyError: in user code:

        /mnt/d/Davide/Uni/TesiMagistrale/ProgettoTesi/simple_fedavg_tf.py:222 client_update  *
            testing_new.append(sparse_ternary_compression.stc_compression(tensor, sparsification_rate))
        /home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/computation/function_utils.py:608 __call__  *
            return concrete_fn(packed_arg)
        /home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/computation/function_utils.py:525 __call__  *
            return context.invoke(self, arg)
        /home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/tensorflow_context/tensorflow_computation_context.py:54 invoke  *
            init_op, result = (
        /home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow_federated/python/core/impl/utils/tensorflow_utils.py:1097 deserialize_and_call_tf_computation  *
            input_map = {
        /home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3931 get_tensor_by_name  **
            return self.as_graph_element(name, allow_tensor=True, allow_operation=False)
        /home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3755 as_graph_element
            return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
        /home/davide/Tesi/virtual-environment/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3795 _as_graph_element_locked
            raise KeyError(&quot;The name %s refers to a Tensor which does not &quot;
    
        KeyError: &quot;The name 'sub:0' refers to a Tensor which does not exist. The operation, 'sub', does not exist in the graph.&quot;
    
    
    Process finished with exit code 1
</code></pre>
<p>EDIT 2:</p>
<p>Fixed the problem above by changing the decorator of the functions <code>stc_compression</code> and <code>stc_decompression</code> from <code>tff.tf_computation</code> to <code>tf.function</code>. Now seems to work fine because, if i print the variable <code>testing</code> that i got from the <code>return server_state, round_loss_metric, testing</code> inside <code>run_one_round</code> i get the weights that i wanted from the start.</p>
",12749028,,12749028,,44508.40903,44508.40903,Access and modify weights sent from client on the server tensorflow federated,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69739007,1,,,44496.53333,,1,208,"<p>everyone:</p>
<p>I try to load the <code>'/root/.tff/emnist_all.sqlite'</code> in the federated processes. Into the example I can find, only see the local simulation.</p>
<pre class=""lang-py prettyprint-override""><code>    print('### CLIENT_DATA')  
    database_path = '/root/.tff/emnist_all.sqlite'
    client_data = sql_client_data.SqlClientData(database_path, 'digits_only_train').preprocess(_add_proto_parsing).datasets
</code></pre>
<p>but this is only loading server data (simulation client data).</p>
<p>I think that is necessary to use <code>federated_map</code> to load each dataset by the client. I'm a little lost.</p>
<p>Could everyone help me, please?</p>
<p>The rest of the code (summary) is:</p>
<pre class=""lang-py prettyprint-override""><code>    print('### GET CHANNELS')
    # set up the remote executors
    channels = get_channels(list_host)
    tff.backends.native.set_remote_execution_context(channels)
    
    print('### TRAINER')
    trainer = tff.learning.build_federated_averaging_process(model_fn, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01))
    
    print('### EVALUATE')
    evaluate(trainer, preprocessed_data_for_clients)
</code></pre>
",16231206,,14692,,44500.78333,44500.80903,Load data in each client,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69767043,1,,,44498.41806,,3,306,"<p>I'm trying to modify TensorFlow Federated example. I want to create a submodel from the original model and use the newly created one for the training phase and then send the weights to the server so that he will update the original model.</p>
<p>I know this shouldn't have been done inside <code>client_update</code> but the server should send the correct submodel directly to the client, but for now i prefer doing so.</p>
<p>For now i have 2 problem:</p>
<ol>
<li>Seems like i can't create a new model inside the <code>client_update</code> function like so:</li>
</ol>
<pre class=""lang-py prettyprint-override""><code>    @tf.function
    def client_update(model, dataset, server_message, client_optimizer):
        &quot;&quot;&quot;Performans client local training of `model` on `dataset`.
        Args:
          model: A `tff.learning.Model`.
          dataset: A 'tf.data.Dataset'.
          server_message: A `BroadcastMessage` from server.
          client_optimizer: A `tf.keras.optimizers.Optimizer`.
        Returns:
          A 'ClientOutput`.
        &quot;&quot;&quot;
    
        model_weights = model.weights
    
        import dropout_model
        dropout_model = dropout_model.get_dropoutmodel(model)
    
    
        initial_weights = server_message.model_weights
        tf.nest.map_structure(lambda v, t: v.assign(t), model_weights,
                              initial_weights)
        .....
</code></pre>
<p>The error is this one:</p>
<pre><code>ValueError: tf.function-decorated function tried to create variables on non-first call.
</code></pre>
<p>The model created is like this:</p>
<pre class=""lang-py prettyprint-override""><code>    def from_original_to_submodel(only_digits=True):
        &quot;&quot;&quot;The CNN model used in https://arxiv.org/abs/1602.05629.
        Args:
          only_digits: If True, uses a final layer with 10 outputs, for use with the
            digits only EMNIST dataset. If False, uses 62 outputs for the larger
            dataset.
        Returns:
          An uncompiled `tf.keras.Model`.
        &quot;&quot;&quot;
        data_format = 'channels_last'
        input_shape = [28, 28, 1]
        max_pool = functools.partial(
            tf.keras.layers.MaxPooling2D,
            pool_size=(2, 2),
            padding='same',
            data_format=data_format)
        conv2d = functools.partial(
            tf.keras.layers.Conv2D,
            kernel_size=5,
            padding='same',
            data_format=data_format,
            activation=tf.nn.relu)
        model = tf.keras.models.Sequential([
            conv2d(filters=32, input_shape=input_shape),
            max_pool(),
            conv2d(filters=64),
            max_pool(),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(410, activation=tf.nn.relu), #20% dropout
            tf.keras.layers.Dense(10 if only_digits else 62),
        ])
        return model
    
    def get_dropoutmodel(model):
        keras_model = from_original_to_submodel(only_digits=False)
        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
        return tff.learning.from_keras_model(keras_model, loss=loss, input_spec=model.input_spec)
</code></pre>
<ol start=""2"">
<li>Is more like a theorical question. I would like to train a sub model like i said, so i would take the original model weights sent from the server <code>initial_weights</code> and for each layer i would assign a sublist of random weights to the submodel weights. For example, <code>initial_weights</code> for the layer 6 contains 100 elements, my new submodel for the same layer has only 40 elements, i would choose from a random with a seed the 40 elements, doing the training and then send the seed to the server, so that he would choose the same indeces and then update only them. Is that correct? My second version was to create still 100 elements(40 random and 60 equal to 0) but i think this will mess the model performance when aggregating on the server side.</li>
</ol>
<p>EDIT:</p>
<p>I have modified the <code>client_update_fn</code> function like so:</p>
<pre><code>@tff.tf_computation(tf_dataset_type, server_message_type)
def client_update_fn(tf_dataset, server_message):
    model = model_fn()
    submodel = submodel_fn()
    client_optimizer = client_optimizer_fn()
    return client_update(model, submodel, tf_dataset, server_message, client_optimizer)
</code></pre>
<p>Adding a new parameter to the function <code>build_federated_averaging_process</code> like so:</p>
<pre><code>def build_federated_averaging_process(
        model_fn, submodel_fn,
        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),
        client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.1)):
</code></pre>
<p>And in the <code>main.py</code> i did this:</p>
<pre><code>def tff_submodel_fn():
    keras_model = create_submodel_dropout(only_digits=False)
    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
    return tff.learning.from_keras_model(keras_model, loss=loss, input_spec=train_data.element_type_structure)

iterative_process = simple_fedavg_tff.build_federated_averaging_process(
    tff_model_fn, tff_submodel_fn, server_optimizer_fn, client_optimizer_fn)
</code></pre>
<p>Now inside the <code>client_update</code> i can use the submodel:</p>
<pre><code>@tf.function
def client_update(model, submodel, dataset, server_message, client_optimizer):
    &quot;&quot;&quot;Performans client local training of `model` on `dataset`.
    Args:
      model: A `tff.learning.Model`.
      dataset: A 'tf.data.Dataset'.
      server_message: A `BroadcastMessage` from server.
      client_optimizer: A `tf.keras.optimizers.Optimizer`.
    Returns:
      A 'ClientOutput`.
    &quot;&quot;&quot;



    model_weights = model.weights
    initial_weights = server_message.model_weights      
    submodel_weights = submodel.weights
    tf.nest.map_structure(lambda v, t: v.assign(t), submodel_weights,
                          initial_weights)
    num_examples = tf.constant(0, dtype=tf.int32)
    loss_sum = tf.constant(0, dtype=tf.float32)

    # Explicit use `iter` for dataset is a trick that makes TFF more robust in
    # GPU simulation and slightly more performant in the unconventional usage
    # of large number of small datasets.
    weights_delta = []
    testing = False
    if not testing:
        for batch in iter(dataset):
            with tf.GradientTape() as tape:
                outputs = model.forward_pass(batch)
            grads = tape.gradient(outputs.loss, submodel_weights.trainable)
            client_optimizer.apply_gradients(zip(grads, submodel_weights.trainable))
            batch_size = tf.shape(batch['x'])[0]
            num_examples += batch_size
            loss_sum += outputs.loss * tf.cast(batch_size, tf.float32)

        weights_delta = tf.nest.map_structure(lambda a, b: a - b,
                                              submodel_weights.trainable,
                                              initial_weights.trainable)
    client_weight = tf.cast(num_examples, tf.float32)
    return ClientOutput(weights_delta, client_weight, loss_sum / client_weight)
</code></pre>
<p>I recieve this error:</p>
<pre><code>    ValueError: No gradients provided for any variable: ['conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'dense_2/kernel:0', 'dense_2/bias:0', 'dense_3/kernel:0', 'dense_3/bias:0'].

Fatal Python error: Segmentation fault

Current thread 0x00007f27af18b740 (most recent call first):
  File &quot;virtual-environment/lib/python3.8/site-packages/tensorflow/python/framework/ops.py&quot;, line 1853 in _create_c_op
  File &quot;virtual-environment/lib/python3.8/site-packages/tensorflow/python/framework/ops.py&quot;, line 2041 in __init__
  File &quot;virtual-environment/lib/python3.8/site-packages/tensorflow/python/framework/ops.py&quot;, line 3557 in _create_op_internal
  File &quot;virtual-environment/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 599 in _create_op_internal
  File &quot;virtual-environment/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py&quot;, line 748 in _apply_op_helper
  File &quot;virtual-environment/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py&quot;, line 1276 in delete_iterator
  File &quot;virtual-environment/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py&quot;, line 549 in __del__

Process finished with exit code 11
</code></pre>
<p>For now the model is the same as the original one, i copied the function <code>create_original_fedavg_cnn_model</code> inside <code>create_submodel_dropout</code> so i don't understand what's wrong</p>
",17278977,,14692,,44756.5375,44756.5375,Training submodel instead of full model Tensorflow Federated,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69783251,1,,,44500.05069,,2,133,"<p>I want to create a custom aggregator where the state is the unique client state of each client. To initialize I can define client states as usual, and then use <code>federated_collect</code> to place <code>@SERVER</code> placement since thats what <code>initialize_fn()</code> wants. I can also do the same for creating <code>new_state</code> in the <code>next_fn()</code>. The problem is once I don't know how I can &quot;broadcast&quot; these states back into clients. Normally <code>federated_broadcast</code> takes say <code>A@SERVER</code> and then makes copies of it equal to number of clients. so for two clients it would be <code>{A}@CLIENTS</code> lets say <code>(A A)</code>. What I want is to have <code>AB@SERVER</code> turning into <code>(A B)</code>.</p>
<p>I am currently defining client states outside the aggregation process, and then passing these in <code>run_one_round</code> of iterative process. use <code>federated_collect</code> to collect these states from measurements of aggregator, and then unstack it outside. So from the outside of the federated computations it looks like</p>
<pre class=""lang-py prettyprint-override""><code>    server_state, train_metrics , client_states, aggregation_state = iterative_process.next(
                    server_state, sampled_train_data, client_states, aggregation_state)
    client_states = [x for x in client_states]
</code></pre>
<p>In TFF</p>
<pre class=""lang-py prettyprint-override""><code>    output = aggregation_process.next(aggregation_state, client_outputs.weights_delta, client_states)
    new_aggregation_state = output.state
    round_model_delta = output.result
    new_client_states = output.measurements
</code></pre>
<p>in aggregator</p>
<pre class=""lang-py prettyprint-override""><code>        measurements = tff.federated_collect(new_client_states)
        return tff.templates.MeasuredProcessOutput(
            state=new_state, result= round_model_delta, measurements=measurements)
</code></pre>
<p>But I am trying to define and handle these client states completely inside the aggregator so that I can plug this aggregator into <code>tff.learning.build_federated_averaging_process</code> like</p>
<pre class=""lang-py prettyprint-override""><code>    iterative_process = tff.learning.build_federated_averaging_process(
        model_fn,
        client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),
        model_update_aggregation_factory=my_aggregation_factory)
</code></pre>
<p>Is that possible? if so how?</p>
",16428078,,14692,,44500.76597,44500.77361,custom aggregators with client_states as states,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60070016,1,,,43866.26528,,0,41,"<p>I am implementing the skip-gram model in a federated learning setup. I get the inputs and label in the following way:</p>

<pre><code>train_inputs_embed = tf.nn.embedding_lookup(variables.weights, batch['target_id'])  
train_labels = tf.reshape(batch['context_id'], [-1, 1])
</code></pre>

<p>When I define the loss as follows</p>

<pre><code>loss = tf.reduce_mean(tf.nn.sampled_softmax_loss(weights=variables.nce_weights,
                                                 biases=variables.bias,
                                                 inputs=train_inputs_embed,
                                                 labels=train_labels,
                                                 num_sampled=5,
                                                 num_true=1,
                                                 num_classes=vocab_size))
</code></pre>

<p>I get the following error</p>

<pre><code> ValueError: Shape must be rank 2 but is rank 3 for 'sampled_softmax_loss/concat_4' (op: 'ConcatV2') with input shapes: [?,1], [?,?,5], [].
</code></pre>

<p>But, the following code (taken from eval section of sampled_softmax_loss function) works for the <strong>same inputs and labels</strong> !!</p>

<pre><code>logits = tf.matmul(train_inputs_embed, tf.transpose(variables.nce_weights))
logits = tf.nn.bias_add(logits, variables.bias)
labels_one_hot = tf.one_hot(train_labels, vocab_size)
loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=labels_one_hot, logits=logits))
</code></pre>

<p>How to fix resolve this issue?</p>
",914250,,,,,43866.84236,Sampled softmax loss eval code works but function call results in ValueError,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60077515,1,,,43866.58472,,0,145,"<p>In the Federated learning context, I try to simulate a code with TFF so the type of my dataset is 'DatasetV1Adapter' (tf.data.Dataset) instead the dataset of emnist in the tutorial <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">ImageClassification</a>   was of type  'TensorSliceDataset'</p>
<p>So that can cause a problem ?  must I change the type of my dataset ?</p>
",12682667,,-1,,44002.38333,43875.42222,TFF: TensorSliceDataset,<dataset><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60153603,1,,,43871.64861,,1,553,"<p>I write a code with TFF from my own dataset, all the code run correctly except 
this line</p>

<p>In train_data, I make 4 dataset, loaded with tf.data.Dataset, they have the type ""DatasetV1Adapter""</p>

<pre><code>def client_data(n):
  ds = source.create_tf_dataset_for_client(source.client_ids[n])
  return ds.repeat(10).map(map_fn).shuffle(500).batch(20)

federated_train_data = [client_data(n) for n in range(4)]

batch = tf.nest.map_structure(lambda x: x.numpy(), iter(train_data[0]).next())

def model_fn():
  model = tf.keras.models.Sequential([
    .........
  return tff.learning.from_compiled_keras_model(model, batch)   
</code></pre>

<p>all this run correctly and I get trainer and state:</p>

<pre><code>trainer = tff.learning.build_federated_averaging_process(model_fn)

</code></pre>

<p>Except, When I would to begin training and round with this code:</p>

<pre><code>state, metrics = iterative_process.next(state, federated_train_data) 
print('round  1, metrics={}'.format(metrics))
</code></pre>

<p>I can't. error comes! So, from where can be the error? from type of dataset? or the way that I make my data federated?</p>
",12682667,,12682667,,43892.53333,43895.62431,Tensorflow Federated : Why my iterative Process unable to train rounds,<tensorflow2.0><tensorflow-federated>,2,4,,,,CC BY-SA 4.0
60181180,1,60220244,,43873.1875,,1,810,"<p>I am following the tutorial 'Federated Learning for Image Classification', but using my own dataset and resnet50. I got this error, when running <code>iterative_process.next</code>.</p>

<p>I believe it was caused by <code>tf.data.Dataset.from_generator</code>
here is my code:</p>

<pre><code>
par1_train_data_dir = './par1/train'
par2_train_data_dir = './par2/train'
input_shape = (img_height, img_width, 3)

img_gen = ImageDataGenerator(preprocessing_function=preprocess_input)

ds_par1 = tf.data.Dataset.from_generator(
    img_gen.flow_from_directory,  args=[par1_train_data_dir,(img_height,img_width)],
    output_types=(tf.float32, tf.float32), 
    output_shapes=([batch_size,img_height,img_width,3], [batch_size,num_classes])
)
ds_par2 = tf.data.Dataset.from_generator(
    img_gen.flow_from_directory,  args=[par2_train_data_dir,(img_height,img_width)],
    output_types=(tf.float32, tf.float32), 
    output_shapes=([batch_size,img_height,img_width,3], [batch_size,num_classes])
)

dataset_dict={}
dataset_dict['1'] = ds_par1
dataset_dict['2'] = ds_par2

def create_tf_dataset_for_client_fn(client_id):
    return dataset_dict[client_id]

train_data = tff.simulation.ClientData.from_clients_and_fn(['1','2'],create_tf_dataset_for_client_fn)

def make_federated_data(client_data, client_ids):
    return [client_data.create_tf_dataset_for_client(x)
          for x in client_ids]

federated_train_data = make_federated_data(train_data, train_data.client_ids)

images, labels = next(img_gen.flow_from_directory(par1_train_data_dir,batch_size=batch_size,target_size=(img_height,img_width)))
sample_batch = (images,labels)

def create_compiled_keras_model():
    pretrain_model = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', 
                                                input_tensor=tf.keras.layers.Input(shape=(img_height, 
                                                img_width, 3)), pooling=None)

    Inp = Input((img_height, img_width, 3))
    x = pretrain_model(Inp)

    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    predictions = Dense(10, activation='softmax')(x)
    model = Model(inputs=Inp, outputs=predictions,name='resnet50_transfer')    

    model.compile(
      loss=tf.keras.losses.categorical_crossentropy,
      optimizer=tf.keras.optimizers.SGD(learning_rate=0.02))
    return model

def model_fn():
    keras_model = create_compiled_keras_model()
    return tff.learning.from_compiled_keras_model(keras_model, sample_batch)

iterative_process = tff.learning.build_federated_averaging_process(model_fn)
state = iterative_process.initialize()

NUM_ROUNDS = 11
for round_num in range(2, NUM_ROUNDS):
    state, metrics = iterative_process.next(state, federated_train_data)
    print('round {:2d}, metrics={}'.format(round_num, metrics))
</code></pre>

<p>I got the error
<code>InvalidArgumentError: TypeError: endswith first arg must be bytes or a tuple of bytes, not str
</code>
here is more information</p>

<pre><code>InvalidArgumentError                      Traceback (most recent call last)
&lt;ipython-input-48-b01b66dc0dcd&gt; in &lt;module&gt;
      1 NUM_ROUNDS = 11
      2 for round_num in range(2, NUM_ROUNDS):
----&gt; 3     state, metrics = iterative_process.next(state, federated_train_data)
      4     print('round {:2d}, metrics={}'.format(round_num, metrics))

~/miniconda3/lib/python3.6/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py in __call__(self, *args, **kwargs)

~/miniconda3/lib/python3.6/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py in pack_args(parameter_type, args, kwargs, context)

~/miniconda3/lib/python3.6/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py in pack_args_into_anonymous_tuple(args, kwargs, type_spec, context)

~/miniconda3/lib/python3.6/site-packages/tensorflow_federated/python/core/impl/reference_executor.py in ingest(self, arg, type_spec)
    627         intrinsic_defs.FEDERATED_MEAN.uri:
    628             self._federated_mean,
--&gt; 629         intrinsic_defs.FEDERATED_BROADCAST.uri:
    630             self._federated_broadcast,
    631         intrinsic_defs.FEDERATED_COLLECT.uri:

~/miniconda3/lib/python3.6/site-packages/tensorflow_federated/python/core/impl/reference_executor.py in to_representation_for_type(value, type_spec, callable_handler)
    239     else:
    240       return [
--&gt; 241           to_representation_for_type(v, type_spec.member, callable_handler)
    242           for v in value
    243       ]

~/miniconda3/lib/python3.6/site-packages/tensorflow_federated/python/core/impl/reference_executor.py in &lt;listcomp&gt;(.0)
    239     else:
    240       return [
--&gt; 241           to_representation_for_type(v, type_spec.member, callable_handler)
    242           for v in value
    243       ]

~/miniconda3/lib/python3.6/site-packages/tensorflow_federated/python/core/impl/reference_executor.py in to_representation_for_type(value, type_spec, callable_handler)
    198       if tf.executing_eagerly():
    199         return [
--&gt; 200             to_representation_for_type(v, type_spec.element, callable_handler)
    201             for v in value
    202         ]

~/miniconda3/lib/python3.6/site-packages/tensorflow_federated/python/core/impl/reference_executor.py in &lt;listcomp&gt;(.0)
    197     if isinstance(value, tf.data.Dataset):
    198       if tf.executing_eagerly():
--&gt; 199         return [
    200             to_representation_for_type(v, type_spec.element, callable_handler)
    201             for v in value

~/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in __next__(self)
    620 
    621   def __next__(self):  # For Python 3 compatibility
--&gt; 622     return self.next()
    623 
    624   def _next_internal(self):

~/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in next(self)
    664     """"""Returns a nested structure of `Tensor`s containing the next element.""""""
    665     try:
--&gt; 666       return self._next_internal()
    667     except errors.OutOfRangeError:
    668       raise StopIteration

~/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in _next_internal(self)
    649             self._iterator_resource,
    650             output_types=self._flat_output_types,
--&gt; 651             output_shapes=self._flat_output_shapes)
    652 
    653       try:

~/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py in iterator_get_next_sync(iterator, output_types, output_shapes, name)
   2671   _ctx = _context._context or _context.context()
   2672   if _ctx is not None and _ctx._thread_local_data.is_eager:
-&gt; 2673     try:
   2674       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(
   2675         _ctx._context_handle, _ctx._thread_local_data.device_name,

~/miniconda3/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: TypeError: endswith first arg must be bytes or a tuple of bytes, not str
Traceback (most recent call last):

  File ""/root/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 464, in get_iterator
    self._next_id += 1

KeyError: 2


During handling of the above exception, another exception occurred:


Traceback (most recent call last):

  File ""/root/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/script_ops.py"", line 221, in __call__
    """"""

  File ""/root/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 585, in generator_py_func

  File ""/root/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 466, in get_iterator
    # NOTE(mrry): Explicitly create an array of `np.int64` because implicit

  File ""/root/miniconda3/lib/python3.6/site-packages/keras_preprocessing/image/image_data_generator.py"", line 540, in flow_from_directory
    interpolation=interpolation

  File ""/root/miniconda3/lib/python3.6/site-packages/keras_preprocessing/image/directory_iterator.py"", line 126, in __init__
    classes, filenames = res.get()

  File ""/root/miniconda3/lib/python3.6/multiprocessing/pool.py"", line 644, in get
    raise self._value

  File ""/root/miniconda3/lib/python3.6/multiprocessing/pool.py"", line 119, in worker
    result = (True, func(*args, **kwds))

  File ""/root/miniconda3/lib/python3.6/site-packages/keras_preprocessing/image/utils.py"", line 216, in _list_valid_filenames_in_directory
    for root, fname in valid_files:

  File ""/root/miniconda3/lib/python3.6/site-packages/keras_preprocessing/image/utils.py"", line 172, in _iter_valid_files
    if fname.lower().endswith('.tiff'):

TypeError: endswith first arg must be bytes or a tuple of bytes, not str


     [[{{node PyFunc}}]] [Op:IteratorGetNextSync]
</code></pre>

<p>my environment</p>

<pre><code>tensorboard==1.15.0
tensorcache==0.4.2
tensorflow==1.15.2
tensorflow-addons==0.6.0
tensorflow-estimator==1.15.1
tensorflow-federated==0.4.0
</code></pre>

<p><strong>UPDATE</strong></p>

<p>I've upgraded tf==2.1.0 and tff==0.12.0, the error disappeared, but I got another error.</p>

<p>It seems that the generator reaches the last batch and does not match the input shape. </p>

<p>But ImageDataGenerator does not need to set <code>drop_remainder</code>.Is there anything wrong with my code?</p>

<pre><code>InvalidArgumentError:  ValueError: `generator` yielded an element of shape (50, 224, 224, 3) where an element of shape (64, 224, 224, 3) was expected.
Traceback (most recent call last):

  File ""/root/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/script_ops.py"", line 236, in __call__
    ret = func(*args)

  File ""/root/miniconda3/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 825, in generator_py_func
    ""of shape %s was expected."" % (ret_array.shape, expected_shape))

ValueError: `generator` yielded an element of shape (50, 224, 224, 3) where an element of shape (64, 224, 224, 3) was expected.


     [[{{node PyFunc}}]]
     [[import/StatefulPartitionedCall_1/ReduceDataset]] [Op:__inference_wrapped_function_277930]

Function call stack:
wrapped_function
</code></pre>
",2207938,,2207938,,43880.64097,44716.62222,tensorflow federated : TypeError when using customized dataset and model,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60183787,1,,,43873.34097,,1,428,"<p>I am trying to study  federated machine learning on time series data. The data is collected from multiple clients. How to convert this data into federated data ?</p>
",12883985,,,,,43875.20139,How to create Federated data for Time series data?,<time-series><hdf5><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
60194646,1,60683758,,43873.75903,,2,244,"<p>Is it possible to TRAIN a neural network model with Tensoflow Lite/Or any other frameworks on smartphones?</p>

<p>Specifically in the context for federative learning?</p>
",4234324,,,,,43904.6,Is it possible to TRAIN a neural network model with Tensoflow Lite/Or any other frameworks on smartphones?,<deep-learning><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
60198252,1,,,43873.96736,,0,823,"<p>I implemented Resnet34 model in federated images classification tutorial. After 10 rounds the training accuracy can be higher than 90%, however, the evaluation accuracy using the last round's <code>state.model</code> is always around 50%.</p>

<pre><code>    evaluation = tff.learning.build_federated_evaluation(model_fn)
    federated_test_data = make_federated_data(emnist_test, sample_clients)
    test_metrics = evaluation(state.model, federated_test_data)
    str(test_metrics)
</code></pre>

<p>I am very confused what's possibly wrong with the evaluation part? Also, I printed the untrainable variables (mean and variance in BatchNorm) of the server's model, which are 0 and 1 with no updates/averaging after those rounds. Should they be like that or that could be the problem?
Thanks very much! </p>

<p><strong>Updates:</strong> </p>

<p>The codes to prepare training data and printed results:</p>

<pre><code>len(emnist_train.client_ids)
4

emnist_train.element_type_structure
OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int64, name=None)),('pixels',TensorSpec(shape=(256, 256, 3), dtype=tf.float32, name=None))])


NUM_CLIENTS = 4
NUM_EPOCHS = 1
BATCH_SIZE = 30
SHUFFLE_BUFFER = 500

def preprocess(dataset):
  def element_fn(element):
    return collections.OrderedDict([
        ('x', element['pixels']),
        ('y', tf.reshape(element['label'], [1])),
    ])
  return dataset.repeat(NUM_EPOCHS).map(element_fn).shuffle(
      SHUFFLE_BUFFER).batch(BATCH_SIZE)



sample_clients = emnist_train.client_ids[0:NUM_CLIENTS]

federated_train_data = make_federated_data(emnist_train, sample_clients)

preprocessed_example_dataset = preprocess(example_dataset)

sample_batch = tf.nest.map_structure(
    lambda x: x.numpy(), iter(preprocessed_example_dataset).next())

def make_federated_data(client_data, client_ids):
      return [preprocess(client_data.create_tf_dataset_for_client(x))
          for x in client_ids]



len(federated_train_data), federated_train_data[0]
(4,&lt;BatchDataset shapes: OrderedDict([(x, (None, 256, 256, 3)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int64)])&gt;)
</code></pre>

<p>The training and evaluation codes:</p>

<pre><code> def create_compiled_keras_model():
  base_model = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', input_shape=(256,256,3,))
  global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
  prediction_layer = tf.keras.layers.Dense(2, activation='softmax')

  model = tf.keras.Sequential([
                               base_model,
                               global_average_layer,
                               prediction_layer
                               ])
  model.compile(optimizer = tf.keras.optimizers.SGD(lr = 0.001, momentum=0.9), loss = tf.keras.losses.SparseCategoricalCrossentropy(), metrics = [tf.keras.metrics.SparseCategoricalAccuracy()])
  return model

def model_fn():
  keras_model = create_compiled_keras_model()
  return tff.learning.from_compiled_keras_model(keras_model, sample_batch)
iterative_process = tff.learning.build_federated_averaging_process(model_fn)
state = iterative_process.initialize()
for round_num in range(2, 12):
  state, metrics = iterative_process.next(state, federated_train_data)
  print('round {:2d}, metrics={}'.format(round_num, metrics, state))


evaluation = tff.learning.build_federated_evaluation(model_fn)
federated_test_data = make_federated_data(emnist_test, sample_clients)

len(federated_test_data), federated_test_data[0]
(4,
 &lt;BatchDataset shapes: OrderedDict([(x, (None, 256, 256, 3)), (y, (None, 1))]), types: OrderedDict([(x, tf.float32), (y, tf.int64)])&gt;)

test_metrics = evaluation(state.model, federated_test_data)
str(test_metrics)
</code></pre>

<p>The training and evaluations results after each round:</p>

<pre><code>round  1, metrics=&lt;sparse_categorical_accuracy=0.5089045763015747,loss=0.7813001871109009,keras_training_time_client_sum_sec=0.008826255798339844&gt;

&lt;sparse_categorical_accuracy=0.49949443340301514,loss=8.0671968460083,keras_training_time_client_sum_sec=0.0&gt;


round  2, metrics=&lt;sparse_categorical_accuracy=0.519825279712677,loss=0.7640910148620605,keras_training_time_client_sum_sec=0.011750459671020508&gt;

&lt;sparse_categorical_accuracy=0.49949443340301514,loss=8.0671968460083,keras_training_time_client_sum_sec=0.0&gt;


round  3, metrics=&lt;sparse_categorical_accuracy=0.5099126100540161,loss=0.7513422966003418,keras_training_time_client_sum_sec=0.0039823055267333984&gt;

&lt;sparse_categorical_accuracy=0.49949443340301514,loss=8.0671968460083,keras_training_time_client_sum_sec=0.0&gt;


round  4, metrics=&lt;sparse_categorical_accuracy=0.5278897881507874,loss=0.7905193567276001,keras_training_time_client_sum_sec=0.0010638236999511719&gt;

&lt;sparse_categorical_accuracy=0.49949443340301514,loss=8.0671968460083,keras_training_time_client_sum_sec=0.0&gt;


round  5, metrics=&lt;sparse_categorical_accuracy=0.5199933052062988,loss=0.7782396674156189,keras_training_time_client_sum_sec=0.012729644775390625&gt;

&lt;sparse_categorical_accuracy=0.49949443340301514,loss=8.0671968460083,keras_training_time_client_sum_sec=0.0&gt;
</code></pre>
",12752740,,730754,,44163.45625,44168.26667,Low evaluation accuracy of Resnet in TensorFlow Federated,<tensorflow><tf.keras><resnet><tensorflow-federated><federated-learning>,2,0,,,,CC BY-SA 4.0
60265798,1,,,43878.65069,,1,1702,"<p>In the federated learning context, One such classmethod that should work would be tff.simulation.ClientData.from_clients_and_fn. Here, if I pass a list of client_ids and a function which returns the appropriate dataset when given a client id, you will have your hands on a fully functional ClientData.</p>

<p>I think here, an approach for defining the function I may use is to construct a Python dict which maps client IDs to tf.data.Dataset objects--you could then define a function which takes a client id, looks up the dataset in the dict, and returns the dataset.
So I define function as below but I think it is wrong, what do you think?</p>

<pre><code>list = [""0"",""1"",""2""]
tab = {""0"":ds, ""1"":ds, ""2"":ds}
def create_tf_dataset_for_client_fn(id):
    return ds

source = tff.simulation.ClientData.from_clients_and_fn(list, create_tf_dataset_for_client_fn) 
</code></pre>

<p>I suppose here that the 4 clients have the same dataset :'ds'</p>
",12682667,,,,,43879.85278,TFF: How define tff.simulation.ClientData.from_clients_and_fn Function?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60279026,1,,,43879.44653,,0,242,"<p>I am trying to understand tensorflow federated. I was referring to <a href=""https://www.tensorflow.org/federated/tutorials/custom_federated_algorithms_2#gradient_descent_on_a_sequence_of_local_data"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/custom_federated_algorithms_2#gradient_descent_on_a_sequence_of_local_data</a> site. Here I am not understanding how to print the values of passed by each client in this function? </p>

<pre><code>SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER, all_equal=True)

@tff.federated_computation(
    SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)
def federated_train(model, learning_rate, data):
  return tff.federated_mean(
      tff.federated_map(
          local_train,
          [tff.federated_broadcast(model),
           tff.federated_broadcast(learning_rate),
           data]))
</code></pre>

<p>and also can anybody tell me what is the use of tff.sequence_reduce.</p>

<p>Please help.</p>
",12902339,,,,,43882.21319,How to print values passed by client in tensorflow federated?,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60285187,1,60341984,,43879.67708,,1,147,"<p>I am analyzing a method that I have implemented in Tensorflow Federated with FedAvg. I need to have a histogram for every clients' delta weights that are communicated to the server. Each client separately called in <code>simulation/federated_avaraging.py</code>, but the thing is I can not call the following API in there. <code>tf.summary.histogram()</code>. any help would be appreciated.</p>
",,user10985800,,user10985800,43879.71111,43882.65278,How to plot Histogram summary for delta weight in Federated Tensorflow?,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60285568,1,,,43879.69167,,0,54,"<p>Does tensorflow-federated support assigning different hyper-parameters(like batch-size or learning rate) for different simulated devices?</p>
",4616724,,,,,43882.22292,Learning parameters of each simulated device,<tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60457040,1,60461904,,43889.75,,1,119,"<p>This is my model, and I have implemented it once in TensorFlow. </p>

<pre><code>def create_compiled_keras_model():

    inputs = Input(shape=(7, 20, 1))
    l0_c = Conv2D(32, kernel_size=(7, 7), padding='valid', activation='relu')(inputs)
    l1_c = Conv2D(32, kernel_size=(1, 5), padding='same', activation='relu')(l0_c)
    l1_p = AveragePooling2D(pool_size=(1, 2), strides=2, padding='same')(l1_c)
    l2_c = Conv2D(64, kernel_size=(1, 4), padding='same', activation='relu')(l1_p)
    l2_p = AveragePooling2D(pool_size=(1, 2), strides=2, padding='same')
    l3_c = Conv2D(2, kernel_size=(1, 1), padding='valid', activation='sigmoid')(l2_p)
    predictions = Flatten()(l3_c)
    predictions = tf.cast(predictions, dtype='float32')
    model = Model(inputs=inputs, outputs=predictions)
    opt = Adam(lr=0.0005)
    print(model.summary())
    def loss_fn(y_true, y_pred):
        return tf.reduce_mean(tf.keras.losses.binary_crossentropy(y_pred, y_true))
    model.compile(optimizer=opt,
                  loss=loss_fn,
                  metrics=['accuracy'])
    return model
</code></pre>

<p>I get this error in TensorFlow Federated. </p>

<pre><code>Traceback (most recent call last):
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py"", line 270, in report
    keras_metric = metric_type.from_config(metric_config)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 594, in from_config
    return cls(**config)
TypeError: __init__() missing 1 required positional argument: 'fn'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/amir/Documents/CODE/Python/FL/fl_dataset_khudemon/fl.py"", line 203, in &lt;module&gt;
    quantization_part = FedAvgQ.build_federated_averaging_process(model_fn)
  File ""/Users/amir/Documents/CODE/Python/FL/fl_dataset_khudemon/new_fedavg_keras.py"", line 195, in build_federated_averaging_process
    stateful_delta_aggregate_fn, stateful_model_broadcast_fn)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py"", line 351, in build_model_delta_optimizer_process
    dummy_model_for_metadata = model_utils.enhance(model_fn())
  File ""/Users/amir/Documents/CODE/Python/FL/fl_dataset_khudemon/fl.py"", line 196, in model_fn
    return tff.learning.from_compiled_keras_model(keras_model, sample_batch)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py"", line 216, in from_compiled_keras_model
    return model_utils.enhance(_TrainableKerasModel(keras_model, dummy_tensors))
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py"", line 491, in __init__
    inner_model.loss_weights, inner_model.metrics)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py"", line 381, in __init__
    federated_output, federated_local_outputs_type)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/api/computations.py"", line 223, in federated_computation
    return computation_wrapper_instances.federated_computation_wrapper(*args)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py"", line 410, in __call__
    self._wrapper_fn)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py"", line 103, in _wrap
    concrete_fn = wrapper_fn(fn, parameter_type, unpack=None)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper_instances.py"", line 78, in _federated_computation_wrapper_fn
    suggested_name=name))
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/federated_computation_utils.py"", line 76, in zero_or_one_arg_fn_to_building_block
    context_stack))
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py"", line 652, in &lt;lambda&gt;
    return lambda arg: _call(fn, parameter_type, arg)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py"", line 645, in _call
    return fn(arg)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py"", line 377, in federated_output
    type(metric), metric.get_config(), variables)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py"", line 260, in federated_aggregate_keras_metric
    @tff.tf_computation(member_type)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py"", line 415, in &lt;lambda&gt;
    return lambda fn: _wrap(fn, arg_type, self._wrapper_fn)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py"", line 103, in _wrap
    concrete_fn = wrapper_fn(fn, parameter_type, unpack=None)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper_instances.py"", line 44, in _tf_wrapper_fn
    target_fn, parameter_type, ctx_stack)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/tensorflow_serialization.py"", line 278, in serialize_py_fn_as_tf_computation
    result = target(*args)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py"", line 652, in &lt;lambda&gt;
    return lambda arg: _call(fn, parameter_type, arg)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py"", line 645, in _call
    return fn(arg)
  File ""/Users/amir/tensorflow/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py"", line 278, in report
    t=metric_type, c=metric_config, e=e))
TypeError: Caught exception trying to call `&lt;class 'tensorflow.python.keras.metrics.MeanMetricWrapper'&gt;.from_config()` with config {'name': 'accuracy', 'dtype': 'float32'}. Confirm that &lt;class 'tensorflow.python.keras.metrics.MeanMetricWrapper'&gt;.__init__() has an argument for each member of the config.
Exception: __init__() missing 1 required positional argument: 'fn'

</code></pre>

<p>My dataset's label is a kind of two labels <code>[0. 1.]</code> and I used <code>binary_crossentropy</code> for loss function. But the accuracy gets back the error. I am sure it is related to multiple labels. The loss calculated without any problem when I remove the accuracy. Any help would be greatly appreciated.</p>
",,user10985800,,user10985800,43900.45,43900.45,get 'TypeError: Caught exception' for using 'accuracy' in Tensorflow Federated,<python><keras><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
69891610,1,69891789,,44509.03681,,2,310,"<p>I am implementing federated learning through tensorflow-federated. The tutorial and all other material available compared the accuracy of the federated (global) model after each communication round. Is there a way I can compute the accuracy of each local model to compare against federated (global) model.</p>
<p>Summary:
Total number of clients: 15
For each communication round: Local vs Federated Model performance</p>
<p>References:</p>
<ol>
<li>(<a href=""https://colab.research.google.com/github/tensorflow/federated/blob/main/docs/tutorials/federated_learning_for_image_classification.ipynb#scrollTo=blQGiTQFS9_r"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/tensorflow/federated/blob/main/docs/tutorials/federated_learning_for_image_classification.ipynb#scrollTo=blQGiTQFS9_r</a>)</li>
</ol>
",8354239,,,,,44644.13611,Local Model performance in Tensorflow Federated,<tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
69949143,1,,,44512.88611,,2,1000,"<p>Can TensorFlow Federated be installed on Windows?
Documentation only describes Ubuntu and MacOS   <a href=""https://www.tensorflow.org/federated/install"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/install</a></p>
",9263920,,,,,44515.58056,TensorFLow Federated on Windows,<windows><installation><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
70160910,1,,,44529.85069,,1,486,"<p>I'm using the <a href=""https://github.com/tensorflow/federated/tree/v0.19.0/tensorflow_federated/python/examples/simple_fedavg"" rel=""nofollow noreferrer"">Simple fedavg example</a> from the github of tensorflow federated, i was trying to change the dataset and the model, but i can't get any positive feedback, the accuracy is always at 1%.</p>
<p>This is the code, i just changed the model part and the dataset from the simple_fedavg example. Any idea? I tried with different optimizers, but still no luck.</p>
<pre><code># Copyright 2020, The TensorFlow Federated Authors.
#
# Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
&quot;&quot;&quot;Simple FedAvg to train EMNIST.

This is intended to be a minimal stand-alone experiment script built on top of
core TFF.
&quot;&quot;&quot;

import collections
import functools
from absl import app
from absl import flags
import numpy as np
import tensorflow as tf
import tensorflow_federated as tff
import random

import simple_fedavg_tf
import simple_fedavg_tff
import os

np.set_printoptions(precision=None, suppress=None)

# Training hyperparameters
flags.DEFINE_integer('total_rounds', 50, 'Number of total training rounds.')
flags.DEFINE_integer('rounds_per_eval', 1, 'How often to evaluate')
flags.DEFINE_integer('train_clients_per_round', 4,
                     'How many clients to sample per round.')
flags.DEFINE_integer('client_epochs_per_round', 5,
                     'Number of epochs in the client to take per round.')
flags.DEFINE_integer('batch_size', 16, 'Batch size used on the client.')
flags.DEFINE_integer('test_batch_size', 128, 'Minibatch size of test data.')

# Optimizer configuration (this defines one or more flags per optimizer).
flags.DEFINE_float('server_learning_rate', 1, 'Server learning rate.')
flags.DEFINE_float('client_learning_rate', 0.0005, 'Client learning rate.')

FLAGS = flags.FLAGS


def create_vgg19_model():
    model = tf.keras.applications.VGG19(include_top=True,
                                        weights=None,
                                        input_shape=(32, 32, 3),
                                        classes=100)
    return model


def get_cifar100_dataset():
    cifar100_train, cifar100_test = tff.simulation.datasets.cifar100.load_data()

    def element_fn(element):
        return collections.OrderedDict(
            x=tf.expand_dims(element['image'], -1), y=element['label'])

    def preprocess_train_dataset(dataset):
        # Use buffer_size same as the maximum client dataset size,
        # 418 for Federated EMNIST
        return dataset.map(element_fn).shuffle(buffer_size=418).repeat(
            count=FLAGS.client_epochs_per_round)  # .batch(
        # FLAGS.batch_size, drop_remainder=False)

    def preprocess_test_dataset(dataset):
        return dataset.map(element_fn).batch(
            FLAGS.test_batch_size, drop_remainder=False)

    cifar100_train = cifar100_train.preprocess(preprocess_train_dataset)
    cifar100_test = preprocess_test_dataset(
        cifar100_test.create_tf_dataset_from_all_clients())
    return cifar100_train, cifar100_test

def server_optimizer_fn():
    return tf.keras.optimizers.SGD(learning_rate=FLAGS.server_learning_rate)

def client_optimizer_fn():
    return tf.keras.optimizers.Adam(learning_rate=FLAGS.client_learning_rate)


def main(argv):
    if len(argv) &gt; 1:
        raise app.UsageError('Too many command-line arguments.')
    client_devices = tf.config.list_logical_devices('GPU')
    print(client_devices)
    server_device = tf.config.list_logical_devices('CPU')[0]
    tff.backends.native.set_local_execution_context(
        server_tf_device=server_device, client_tf_devices=client_devices)

    train_data, test_data = get_cifar100_dataset()

    def tff_model_fn():
        &quot;&quot;&quot;Constructs a fully initialized model for use in federated averaging.&quot;&quot;&quot;
        # keras_model = create_original_fedavg_cnn_model(only_digits=False)
        keras_model = create_vgg19_model()
        # keras_model.summary()
        loss = tf.keras.losses.SparseCategoricalCrossentropy()
        return simple_fedavg_tf.KerasModelWrapper(keras_model,
                                                  test_data.element_spec, loss)

    iterative_process = simple_fedavg_tff.build_federated_averaging_process(
        tff_model_fn, tff_model_fn, tff_model_fn, tff_model_fn, server_optimizer_fn, client_optimizer_fn)
    server_state = iterative_process.initialize()

    metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')
    model = tff_model_fn()

    for round_num in range(FLAGS.total_rounds):
        sampled_clients = np.random.choice( train_data.client_ids,  size=FLAGS.train_clients_per_round,   replace=False)
        sampled_train_data = [ train_data.create_tf_dataset_for_client(client).batch( FLAGS.batch_size, drop_remainder=False)
            for client in sampled_clients
        ]

        server_state, train_metrics = iterative_process.next(
            server_state, sampled_train_data)

        print(f'Round {round_num} training loss: {train_metrics}')
        if round_num % FLAGS.rounds_per_eval == 0:
            model.from_weights(server_state.model_weights)
            accuracy = simple_fedavg_tf.keras_evaluate(model.keras_model, test_data,
                                                       metric)
            print(f'Round {round_num} validation accuracy: {accuracy * 100.0}')
if __name__ == '__main__':
    app.run(main)

</code></pre>
",12749028,,,,,44529.85069,Using CIFAR-100 datased with VGG19 model in simple_fedavg example,<python><tensorflow><tensorflow-federated>,0,3,,,,CC BY-SA 4.0
70196914,1,,,44532.39167,,2,108,"<p>I would like to Fine-tune the pre-trained model  with Federated Learning, So I do this:</p>
<pre class=""lang-py prettyprint-override""><code>def create_keras_model():
    baseModel = tf.keras.models.load_model(path\to\model)
    headModel = baseModel.output
    model_output = tf.keras.layers.Dense(3)(headModel)
    model = tf.keras.Model(inputs=baseModel.input, outputs=model_output)
    for layer in baseModel.layers:
        layer.trainable = False
    return model

state = iterative_process.initialize()
keras_model = create_keras_model()
state = tff.learning.state_with_new_model_weights(
    state,
    trainable_weights=[v.numpy() for v in keras_model.trainable_weights],
    non_trainable_weights=[
        v.numpy() for v in keras_model.non_trainable_weights
    ])

evaluation = tff.learning.build_federated_evaluation(model_fn)
</code></pre>
<p>And here is the training loop :</p>
<pre class=""lang-py prettyprint-override""><code>for round_num in range(1, NUM_ROUNDS):
    state, _ = iterative_process.next(state, train_data)
    test_metrics = evaluation(state.model, test_data)
    print(test_metrics))
</code></pre>
<p>The problem is that test accuracy still constant and does not increase after all round  :</p>
<pre class=""lang-py prettyprint-override""><code>round  1, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.8680933)])
round  2, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.836558)])
round  3, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.82953715)])
round  4, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.82713753)])
round  5, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.82613766)])
round  6, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.8256878)])
round  7, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.82548285)])
round  8, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.825384)])
round  9, metrics=OrderedDict([('categorical_accuracy', 0.67105263), ('loss', 0.825332)])
</code></pre>
<p>I would like to understand the reason, If there is another way to do this? Knowing that my dataset is an image dataset with 3 class.</p>
",14253961,,14253961,,44564.3375,44564.3375,TFF: finetune with pretrained network : Test accuracy still constant after all rounds,<tensorflow><tensorflow-federated><federated-learning>,0,2,,,,CC BY-SA 4.0
70333328,1,,,44543.44444,,1,32,"<p>To improve this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#training_the_model_on_federated_data"" rel=""nofollow noreferrer"">tutorial</a> and test other things, I was pretrained the network with a centralized way in EMNIST database. Then I would like to Fine tune the pretrained network with a federated code above.
So, I only added:</p>
<pre><code>def create_keras_model():
  return tf.keras.models.Sequential([
      tf.keras.models.load_model(path/to/model, compile=False)
      tf.keras.layers.Dense(10, kernel_initializer='zeros'),
      tf.keras.layers.Softmax(),
  ])
</code></pre>
<p>The problem is that I find same test accuracy values compared to test accuracy values without fine tuning a pretrained network.
Can you please give me solution.</p>
",14253961,,,,,44543.44444,TFF : change the code have no effect in changing test accuracy values,<tensorflow-federated><federated-learning>,0,1,,,,CC BY-SA 4.0
70338012,1,70544437,,44543.69583,,1,98,"<p>I have a problem with training using <code>tff.simulation.FilePerUserClientData</code> - I am quickly running out of RAM after 5-6 rounds with 10 clients per round.
The RAM usage is steadily increasing with each round.
I tried to narrow it down and realized that the issue is not the actual iterative process but the creation of the client datasets.
Simply calling <code>create_tf_dataset_for_client(client)</code> in a loop causes the problem.</p>
<p>So this is a minimal version of my code:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import tensorflow_federated as tff
import numpy as np
import pickle

BATCH_SIZE = 16
EPOCHS = 2
MAX_SEQUENCE_LEN = 20
NUM_ROUNDS = 100
CLIENTS_PER_ROUND = 10

def decode_fn(record_bytes):
    return tf.io.parse_single_example(
        record_bytes,
        {&quot;x&quot;: tf.io.FixedLenFeature([MAX_SEQUENCE_LEN], dtype=tf.string),
         &quot;y&quot;: tf.io.FixedLenFeature([MAX_SEQUENCE_LEN], dtype=tf.string)}
    )

def dataset_fn(path):
    return tf.data.TFRecordDataset([path]).map(decode_fn).padded_batch(BATCH_SIZE).repeat(EPOCHS)

def sample_client_data(data, client_ids, sampling_prob):
    clients_total = len(client_ids)
    x = np.random.uniform(size=clients_total)
    sampled_ids = [client_ids[i] for i in range(clients_total) if x[i] &lt; sampling_prob]
    data = [train_data.create_tf_dataset_for_client(client) for client in sampled_ids]
    return data
    
with open('users.pkl', 'rb') as f:
    users = pickle.load(f)
    
train_client_ids = users[&quot;train&quot;]
client_id_to_train_file = {i: &quot;reddit_leaf_tf/&quot; + i for i in train_client_ids}

train_data = tff.simulation.datasets.FilePerUserClientData(
    client_ids_to_files=client_id_to_train_file,
    dataset_fn=dataset_fn
)

sampling_prob = CLIENTS_PER_ROUND / len(train_client_ids)

for round_num in range(0, NUM_ROUNDS):
    print('Round {r}'.format(r=round_num))
    participants_data = sample_client_data(train_data, train_client_ids, sampling_prob)
    print(&quot;Round Completed&quot;)
</code></pre>
<p>I am using tensorflow-federated 19.0.</p>
<p>Is there something wrong with the way I create the client datasets or is it somehow expected that the RAM from the previous round is not freed?</p>
",17667231,,14692,,44559.92222,44561.72917,Running Out of RAM using FilePerUserClientData,<tensorflow-datasets><tensorflow-federated><federated-learning>,1,2,,,,CC BY-SA 4.0
70376178,1,,,44546.36736,,1,296,"<p>I'm beginner in federated learning.
I try to add gaussian noise to gradient in client_updata.
If anyone attempt to do , please teach me how to do.
Thank you in advance.</p>
<pre><code>def client_update(model, dataset, server_weights, client_optimizer):
  &quot;&quot;&quot;Performs training (using the server model weights) on the client's dataset.&quot;&quot;&quot;
  # Initialize the client model with the current server weights.
  client_weights = model.trainable_variables
  # Assign the server weights to the client model.
  tf.nest.map_structure(lambda x, y: x.assign(y),
                        client_weights, server_weights)
  
  # Use the client_optimizer to update the local model.
  for batch in dataset:
    with tf.GradientTape() as tape:
      # Compute a forward pass on the batch of data
      outputs = model.forward_pass(batch)
    # Compute the corresponding gradient
    grads = tape.gradient(outputs.loss, client_weights)
    grads_and_vars = zip(grads, client_weights)
    # Apply the gradient using a client optimizer.
    # Update weights
    client_optimizer.apply_gradients(grads_and_vars)
  
  return client_weights
</code></pre>
",17550182,,,,,44670.5125,How implement differential privacy in federated learning,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60463530,1,,,43890.37639,,1,158,"<p>I want to know if it is possible to use different weights and bias for each of the clients in tensorflow_federated.</p>

<p>Please help.</p>
",12902339,,,,,43890.68611,Can I use different weights and bias for each of the clients in tensorflow federated?,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60489703,1,,,43892.55417,,0,283,"<p>When I run my code without TFF (training my model with model.fit()), I notice that use of CPU is 5 % and my code run GPU . But if I introduce TFF : aside GPU,  training takes a lot of CPU (order of 90 %) and a lot of memory, Knowing that I use:
Tensorflow Federated v 0.12.0
Tensorflow v 2.1.0</p>
",12682667,,,,,43892.7375,TFF uses a lot of CPU,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60501245,1,,,43893.26875,,2,177,"<p>I want to know if we can broadcast different models for each of the clients from the server in tensorflow_federated?</p>

<p>Can anyone please help?</p>
",12902339,,,,,43909.63403,Can I broadcast different models for each of the clients in federated_tensorflow?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60508005,1,,,43893.54653,,1,419,"<p>I have build my code TFF with VGG16 model. However, at training time, my accuracy does not change and stays around 0.5 even after 11 rounds.
I have tried changing the learning rate but has no significant effect.!!!
So, What are the metrics and things that I can change in the code to increase the accuracy, because when I run my code, the accuracy is stable and don't increase!!</p>

<p>Here is the code of my VGG16</p>

<pre><code>def create_compiled_keras_model():

    IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)
    VGG16_MODEL = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')

#VGG16_MODEL.trainable=False
    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
    prediction_layer = tf.keras.layers.Dense(......)


    model = tf.keras.Sequential([ VGG16_MODEL, global_average_layer, prediction_layer ])


    model.compile  .............
    return model

...
iterative_process = tff.learning.build_federated_averaging_process(model_fn)
state = iterative_process.initialize()
for round_num in range(2, 12):
  state, metrics = iterative_process.next(state, federated_train_data)
  print('round {:2d}, metrics={}'.format(round_num, metrics, state))
</code></pre>
",12682667,,12682667,,43916.63056,43916.63056,Why my accuracy does not increase in TFF with VGG16 model?,<tensorflow-federated>,1,1,,,,CC BY-SA 4.0
60564780,1,,,43896.54931,,1,67,"<p>In TFF, It is necessary to determinate number of rounds. So, to obtain optimal performance of our model, How we can know the optimal number of rounds?</p>
",12429601,,,,,43899.19236,How determinate number of rounds in TFF context,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60757397,1,,,43909.52361,,1,149,"<p>We all know that the evaluation step is quite important  to evaluate our model on a test basis. I wanted to know if it is necessary to go through the round step(training) before doing the evaluation? that mean my code can be like this? it is correct like below??</p>

<pre><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()
...
def create_keras_model():
  return tf.keras.models.Sequential([
      tf.keras.layers.Input(shape=(784,)),
      tf.keras.layers.Dense(10, kernel_initializer='zeros'),
      tf.keras.layers.Softmax(),
  ])
def model_fn():
  # We _must_ create a new model here, and _not_ capture it from an external
  # scope. TFF will call this within different graph contexts.
  keras_model = create_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      dummy_batch=sample_batch,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))
state = iterative_process.initialize()
evaluation = tff.learning.build_federated_evaluation(model_fn)
train_metrics = evaluation(state.model, federated_train_data)
federated_test_data = make_federated_data(emnist_test, sample_clients)
test_metrics = evaluation(state.model, federated_test_data)
</code></pre>

<p>without going through this step</p>

<pre><code>for round_num in range(2, 11):
  state, metrics = iterative_process.next(state, federated_train_data)
  print('round {:2d}, metrics={}'.format(round_num, metrics))
</code></pre>

<p>Is that possible and give me correct result?
Thanks for you all</p>
",12682667,,,,,44672.52153,in TFF context : Is the evaluation step depends on training process?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60771007,1,,,43910.36736,,0,96,"<p>in TFF, the variable  <code>state</code> is used for evaluation like below :</p>

<p><code>test_metrics = evaluation(state.model, federated_test_data)</code></p>

<p>So How we can keep this varibale or save it when I find the best one of highest-performing</p>
",12682667,,,,,43913.62569,"in TFF : How keeping (or saving) the ""state"" of highest-performing",<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60815004,1,,,43913.58264,,1,1290,"<p>The following error occurred while running ""<a href=""https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/gans/experiments/emnist/run_experiments.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/gans/experiments/emnist/run_experiments.py</a>"" (I am attempting to regenerate the results of the paper):</p>

<pre><code>ModuleNotFoundError: No module named 'tensorflow_federated.python.research'
</code></pre>

<ol>
<li>Here is the full list of my anaconda environment information:<a href=""https://i.sstatic.net/vZad1.png"" rel=""nofollow noreferrer"">conda environment information</a></li>
<li>and I am using Pycharm in Ubuntu 16.04:<a href=""https://i.sstatic.net/CDOf8.png"" rel=""nofollow noreferrer"">IDE</a></li>
<li>Last but not least, I have tried to execute the code in the terminal but the error continued to exist, so I'm afraid that the problem is not concerned with the Pycharm IDE.<a href=""https://i.sstatic.net/qCUCZ.png"" rel=""nofollow noreferrer"">the problem is not concerned with IDE</a></li>
</ol>

<p>It will be appreciated if you could give me some suggestions.</p>
",6875073,,6875073,,43913.58958,43913.62222,ModuleNotFoundError: No module named 'tensorflow_federated.python.research',<python><ubuntu><deep-learning><tensorflow2.0><tensorflow-federated>,1,2,,,,CC BY-SA 4.0
60839809,1,,,43914.90556,,0,173,"<p>I'm relatively new to tensorflow, I've read a book about machine learning and I've took Udacity's course. I've been tasked with recreating the Image Captioning Model found on this tutorial <a href=""https://www.tensorflow.org/tutorials/text/image_captioning"" rel=""nofollow noreferrer"">https://www.tensorflow.org/tutorials/text/image_captioning</a> using the Federated Learning library that tensorflow offers, so far everything is easy and I've managed to understand what I'm supposed to do until I reached the part of designing the model. In the federated learning tutorial (<a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification</a>), In designing the variables part, how am i supposed to know the shape of the weights and bias?</p>

<p>Sorry if this is an obvious question but i've been struggling with shapes for quite sometime now, Thank you in advance! :)</p>

<p>EDIT: Sorry, I forgot to add this part to the question: How am I supposed to know the variables of my model? I know that the weights and bias are the base of the model along with the loss and the accuracy is for me to know how good the model performs, but is there anything else I need to know?</p>
",7820400,,7820400,,43914.90972,43915.55556,Federated Learning for Image Captioning,<tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60841235,1,60849666,,43915.00972,,1,555,"<p>I want to train a federated model with the FedAvg Algorithm on TFF (Tensorflow Federated) using a 3-channel (X, Y, Z) accelerometer dataset with a time frame length of 128.</p>

<p>My goal is to train a federated model using </p>

<pre><code>tff.learning.from_keras_model
</code></pre>

<p>The guides on the TensorFlow Federated website mostly deal with datasets which already comes in the desired format for the model</p>

<pre><code>tensorflow_federated.python.simulation.hdf5_client_data.HDF5ClientData
</code></pre>

<p>I'm quite lost on how to convert my raw dataset to the desired format for TFF.</p>

<p>The dataset I am using has the following shape: </p>

<pre><code>X: (-1, 128, 3) and Y: (-1)
</code></pre>

<p>X: are floats
Y: are the integer labels of my dataset ranging from 0-6</p>

<p>Can anybody give me some pointers/examples on how I can tackle this?</p>
",12992742,,12992742,,43915.04236,43915.55347,How to prepare my dataset(Not Images) to implement FedAVG on Tensorflow Federated?,<python><deep-learning><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60876340,1,,,43916.89097,,0,407,"<p>I want to save a TensorFlow federated model which was trained with the FedAvg Algorithm as a Keras/.h5 model. I couldn't find the documents on this and would like to know how it may be done.
Also if possible, I'd like to have access to both the aggregated server model and the models of the clients.</p>

<p>The code I use to train the federated model is below:</p>

<pre><code>def model_fn():
    model = tf.keras.models.Sequential([
      tf.keras.layers.Input(shape=(segment_size,num_input_channels)),
      tf.keras.layers.Flatten(), 
      tf.keras.layers.Dense(units=400, activation='relu'),
      tf.keras.layers.Dropout(dropout_rate),
      tf.keras.layers.Dense(units=100, activation='relu'),
      tf.keras.layers.Dropout(dropout_rate),
      tf.keras.layers.Dense(activityCount, activation='softmax'),
    ])
    return tff.learning.from_keras_model(
      model,
      dummy_batch=batch,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
trainer = tff.learning.build_federated_averaging_process(
    model_fn, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learningRate))

def evaluate(num_rounds=communicationRound):
  state = trainer.initialize()
  roundMetrics = []
  evaluation = tff.learning.build_federated_evaluation(model_fn)

  for round_num in range(num_rounds):
    t1 = time.time()
    state, metrics = trainer.next(state, train_data)
    t2 = time.time()
    test_metrics = evaluation(state.model, train_data)

    roundMetrics.append('round {:2d}, metrics={}, loss={}'.format(round_num, metrics.sparse_categorical_accuracy , metrics.loss))
    roundMetrics.append(""The test accuracy is "" + str(test_metrics.sparse_categorical_accuracy))
    roundMetrics.append('round time={}'.format(t2 - t1))
    print('round {:2d}, accuracy={}, loss={}'.format(round_num, metrics.sparse_categorical_accuracy , metrics.loss))
    print(""The test accuracy is "" + str(test_metrics.sparse_categorical_accuracy))
    print('round time={}'.format(t2 - t1))
  outF = open(filepath+'stats'+architectureType+'.txt', ""w"")
  for line in roundMetrics:
    outF.write(line)
    outF.write(""\n"")
  outF.close()
</code></pre>
",12992742,,12992742,,43916.94514,43918.40069,How can I save a trained TensorFlow Federated model as a .h5 model?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60903579,1,60915694,,43918.68889,,1,248,"<p>I am getting the following error when I try to load the Tensorflow Federated library on a server. I am using tensorflow_federated version 0.13.1 </p>

<p>The Cuda version I have on the server is 10.2 . The Cudnn library is above 7.6.</p>

<p>What is the <code>""libnvinfer.so.6""</code> that is being asked?</p>

<pre><code>2020-03-28 17:26:18.357394: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-03-28 17:26:18.410547: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-03-28 17:26:18.464258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Traceback (most recent call last):
  File ""FedAvgREALWORLDWork.py"", line 52, in &lt;module&gt;
    import tensorflow_federated as tff
  File ""/user/env/lib/python3.5/site-packages/tensorflow_federated/__init__.py"", line 61, in &lt;module&gt;
    from tensorflow_federated.python import learning
  File ""/user/env/lib/python3.5/site-packages/tensorflow_federated/python/learning/__init__.py"", line 17, in &lt;module&gt;
    from tensorflow_federated.python.learning import framework
  File ""/user/env/lib/python3.5/site-packages/tensorflow_federated/python/learning/framework/__init__.py"", line 20, in &lt;module&gt;
    from tensorflow_federated.python.learning.framework.optimizer_utils import build_model_delta_optimizer_process
  File ""/user/env/lib/python3.5/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py"", line 176
    f'({old_value.dtype}, {old_value.shape}) != '
    ^
SyntaxError: invalid syntax
</code></pre>
",12992742,,12992742,,43921.35278,43921.35278,Error when running TensorFlow Federated on server,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
70398702,1,70419956,,44547.86389,,1,223,"<p>I want to implement local DP model using TFF, that is, each client trains it's own differentially private model and sends noisy gradients to the server, and the server just aggregates and distributes in a standard FL fashion. I tried changing the client optimizer to keras DP optimizer, but that didnt work. Any suggestions are appreciated.</p>
",2245992,,,,,44550.40625,Client level differential privacy in Tensorflow Federated (Local DP),<tensorflow><keras><privacy><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
70426568,1,70464656,,44550.77847,,1,134,"<p>So my goal is basically implementing <a href=""https://arxiv.org/pdf/1704.05021.pdf"" rel=""nofollow noreferrer"">global top-k subsampling</a>. Gradient sparsification is quite simple and I have already done this building on <a href=""https://github.com/tensorflow/federated/tree/main/tensorflow_federated/python/examples/stateful_clients"" rel=""nofollow noreferrer"">stateful clients example</a>, but now I would like to use encoders as you have recommended <a href=""http://jakubkonecny.com/files/tensor_encoding.pdf"" rel=""nofollow noreferrer"">here at page 28</a>. Additionally I would like to average only the non-zero gradients, so say we have 10 clients but only 4 have nonzero gradients at a given position for a communication round then I would like to divide the sum of these gradients to 4, not 10. I am hoping to achieve this by summing gradients at numerator and masks, 1s and 0s, at denominator. Also moving forward I will add randomness to gradient selection so it is imperative that I create those masks concurrently with gradient selection. The code I have right now is</p>
<pre><code>import tensorflow as tf

from tensorflow_model_optimization.python.core.internal import tensor_encoding as te


@te.core.tf_style_adaptive_encoding_stage
class GrandienrSparsificationEncodingStage(te.core.AdaptiveEncodingStageInterface):
  &quot;&quot;&quot;An example custom implementation of an `EncodingStageInterface`.
  Note: This is likely not what one would want to use in practice. Rather, this
  serves as an illustration of how a custom compression algorithm can be
  provided to `tff`.
  This encoding stage is expected to be run in an iterative manner, and
  alternatively zeroes out values corresponding to odd and even indices. Given
  the determinism of the non-zero indices selection, the encoded structure does
  not need to be represented as a sparse vector, but only the non-zero values
  are necessary. In the decode mehtod, the state (i.e., params derived from the
  state) is used to reconstruct the corresponding indices.
  Thus, this example encoding stage can realize representation saving of 2x.
  &quot;&quot;&quot;

  ENCODED_VALUES_KEY = 'stateful_topk_values'
  INDICES_KEY = 'indices'
  SHAPES_KEY = 'shapes'
  ERROR_COMPENSATION_KEY = 'error_compensation'

  def encode(self, x, encode_params):
    shapes_list = [tf.shape(y) for y in x]
    flattened = tf.nest.map_structure(lambda y: tf.reshape(y, [-1]), x)
    gradients = tf.concat(flattened, axis=0)
    error_compensation = encode_params[self.ERROR_COMPENSATION_KEY]
    
    gradients_and_error_compensation = tf.math.add(gradients, error_compensation)

    percentage = tf.constant(0.1, dtype=tf.float32)
    k_float = tf.multiply(percentage, tf.cast(tf.size(gradients_and_error_compensation), tf.float32))
    k_int = tf.cast(tf.math.round(k_float), dtype=tf.int32)

    values, indices = tf.math.top_k(tf.math.abs(gradients_and_error_compensation), k = k_int, sorted = False)
    indices = tf.expand_dims(indices, 1)
    sparse_gradients_and_error_compensation = tf.scatter_nd(indices, values, tf.shape(gradients_and_error_compensation))

    new_error_compensation = tf.math.subtract(gradients_and_error_compensation, sparse_gradients_and_error_compensation)
    state_update_tensors = {self.ERROR_COMPENSATION_KEY: new_error_compensation}
    
    encoded_x = {self.ENCODED_VALUES_KEY: values,
                 self.INDICES_KEY: indices,
                 self.SHAPES_KEY: shapes_list}

    return encoded_x, state_update_tensors

  def decode(self,
             encoded_tensors,
             decode_params,
             num_summands=None,
             shape=None):
    del num_summands, decode_params, shape  # Unused.
    flat_shape = tf.math.reduce_sum([tf.math.reduce_prod(shape) for shape in encoded_tensors[self.SHAPES_KEY]])
    sizes_list = [tf.math.reduce_prod(shape) for shape in encoded_tensors[self.SHAPES_KEY]]
    scatter_tensor = tf.scatter_nd(
        indices=encoded_tensors[self.INDICES_KEY],
        updates=encoded_tensors[self.ENCODED_VALUES_KEY],
        shape=[flat_shape])
    nonzero_locations = tf.nest.map_structure(lambda x: tf.cast(tf.where(tf.math.greater(x, 0), 1, 0), tf.float32) , scatter_tensor)
    reshaped_tensor = [tf.reshape(flat_tensor, shape=shape) for flat_tensor, shape in
            zip(tf.split(scatter_tensor, sizes_list), encoded_tensors[self.SHAPES_KEY])]
    reshaped_nonzero = [tf.reshape(flat_tensor, shape=shape) for flat_tensor, shape in
            zip(tf.split(nonzero_locations, sizes_list), encoded_tensors[self.SHAPES_KEY])]
    return  reshaped_tensor, reshaped_nonzero


  def initial_state(self):
    return {self.ERROR_COMPENSATION_KEY: tf.constant(0, dtype=tf.float32)}

  def update_state(self, state, state_update_tensors):
    return {self.ERROR_COMPENSATION_KEY: state_update_tensors[self.ERROR_COMPENSATION_KEY]}

  def get_params(self, state):
    encode_params = {self.ERROR_COMPENSATION_KEY: state[self.ERROR_COMPENSATION_KEY]}
    decode_params = {}
    return encode_params, decode_params

  @property
  def name(self):
    return 'gradient_sparsification_encoding_stage'

  @property
  def compressible_tensors_keys(self):
    return False

  @property
  def commutes_with_sum(self):
    return False

  @property
  def decode_needs_input_shape(self):
    return False

  @property
  def state_update_aggregation_modes(self):
    return {}
</code></pre>
<p>I have run some simple tests manually following the steps you outlined <a href=""http://jakubkonecny.com/files/tensor_encoding.pdf"" rel=""nofollow noreferrer"">here at page 45</a>. It works but I have some questions/problems.</p>
<ol>
<li>When I use list of tensors of same shape (ex:2 2x25 tensors) as input,x, of encode it works without any issues but when I try to use list of tensors of different shapes (2x20 and 6x10) it gives and error saying</li>
</ol>
<blockquote>
<p>InvalidArgumentError: Shapes of all inputs must match: values[0].shape = [2,20] != values<a href=""https://arxiv.org/pdf/1704.05021.pdf"" rel=""nofollow noreferrer"">1</a>.shape = [6,10] [Op:Pack] name: packed</p>
</blockquote>
<p>How can I resolve this issue? As i said I want to use global top-k so it is essential I encode entire trainable model weights at once. Take the <a href=""https://arxiv.org/abs/1602.05629"" rel=""nofollow noreferrer"">cnn model used here</a>, all the tensors have different shapes.</p>
<ol start=""2"">
<li>How can I do the averaging I described at the beginning? For example <a href=""https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression#build_a_custom_broadcast_and_aggregate_function"" rel=""nofollow noreferrer"">here</a> you have done</li>
</ol>
<blockquote>
<p>mean_factory = tff.aggregators.MeanFactory(
tff.aggregators.EncodedSumFactory(mean_encoder_fn), # numerator
tff.aggregators.EncodedSumFactory(mean_encoder_fn), # denominator )</p>
</blockquote>
<p>Is there a way to repeat this with one output of decode going to numerator and other going to denominator? How can I handle dividing 0 by 0? tensorflow has divide_no_nan function, can I use it somehow or do I need to add eps to each?</p>
<ol start=""3"">
<li><p>How is partition handled when I use encoders? Does each client get a unique encoder holding a unique state for it? As you have discussed <a href=""https://arxiv.org/pdf/1912.04977.pdf"" rel=""nofollow noreferrer"">here at page 6</a> client states are used in cross-silo settings yet what happens if client ordering changes?</p>
</li>
<li><p><a href=""https://stackoverflow.com/questions/65830370/tensorflow-federated-compression-how-to-implement-a-stateful-encoder-to-be-used/65841812#65841812"">Here</a> you have recommended using <a href=""https://github.com/tensorflow/federated/tree/main/tensorflow_federated/python/examples/stateful_clients"" rel=""nofollow noreferrer"">stateful clients example</a>. Can you explain this a bit further? I mean in the run_one_round where exactly encoders go and how are they used/combined with client update and aggregation?</p>
</li>
<li><p>I have some additional information such as sparsity I want to pass to encode. What is the suggested method for doing that?</p>
</li>
</ol>
",16428078,,16428078,,44552.96875,44553.67222,how to apply custom encoders to multiple clients at once? how to use custom encoders in run_one_round?,<tensorflow-federated>,1,2,,,,CC BY-SA 4.0
70434265,1,,,44551.45208,,0,190,"<p>I'm using TFF 0.18
When using :</p>
<pre><code>state = tff.structure.update_struct(state, model=tff.learning.ModelWeights.from_model(keras_model))
</code></pre>
<p>I find this error, So how can I solve this problem without changing TFF version.</p>
",14253961,,,,,44551.50694,AttributeError: module 'tensorflow_federated.python.common_libs.structure' has no attribute 'update_struct',<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
70563080,1,,,44564.34028,,1,114,"<p>I would like to load a pretrained network in the inside of <code>create_keras_model()</code>
So I write this :</p>
<pre class=""lang-py prettyprint-override""><code>def create_keras_model():
  
    baseModel = tf.keras.models.load_model(model_path, compile=False)
 
    headModel = baseModel.output
    model_output = tf.keras.layers.Dense(3, activation=&quot;softmax&quot;, name=&quot;output&quot;)(headModel)

    model = tf.keras.Model(inputs=baseModel.input, outputs=model_output)
    
    return model

def model_fn():
    keras_model = create_keras_model()  
    return tff.learning.from_keras_model(keras_model, input_spec = input_spec, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])


@tff.tf_computation
def get_weights_from_disk():
   keras_model = create_keras_model()

   return keras_model

@tff.federated_computation
def server_init():
  # There may be state other than weights that needs to get returned from here,
  # as in the implementation of build_federated_averaging_process.
  return tff.federated_eval(get_weights_from_disk(), tff.SERVER)


old_iterproc = tff.learning.build_federated_averaging_process(model_fn=model_fn, server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0), client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.001))
new_iterproc = tff.templates.IterativeProcess(intialize_fn=server_init,
  next_fn=old_iterproc.next)
state = new_iterproc.initialize()
</code></pre>
",14253961,,14692,,44564.53333,44564.54306,TypeError: Cannot capture a result of an unsupported type tensorflow.python.keras.engine.functional.Functional,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
70590588,1,,,44566.39792,,0,1217,"<p>I use TFF v:0.18
I would like to load a pretrained network in the inside of <code>create_keras_model()</code> So I write this :</p>
<pre class=""lang-py prettyprint-override""><code>def create_keras_model():
    baseModel = tf.keras.models.load_model(model_path, compile=False)
    headModel = baseModel.output
    model_output = tf.keras.layers.Dense(3, activation=&quot;softmax&quot;, name=&quot;output&quot;)(headModel)
    model = tf.keras.Model(inputs=baseModel.input, outputs=model_output)
    return model
new_iterproc = tff.templates.IterativeProcess(intialize_fn=server_init_tff, next_fn=old_iterproc.next)
state = new_iterproc.initialize()
</code></pre>
<p>But I find this error:</p>
<pre class=""lang-py prettyprint-override""><code>    new_iterproc = tff.templates.IterativeProcess(intialize_fn=server_init_tff, next_fn=old_iterproc.next)
TypeError: __init__() got an unexpected keyword argument 'intialize_fn'
</code></pre>
<p>I don't believe that the syntax is error,</p>
",14253961,,14253961,,44566.81944,44566.81944,TypeError: __init__() got an unexpected keyword argument 'intialize_fn',<tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
60920524,1,,,43919.86667,,1,576,"<p>I am trying to experiment with remote executor runtime with the example provided on this link.
<a href=""https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/examples/remote_executor_example.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/examples/remote_executor_example.py</a></p>

<p>If I using CPU based tensorflow, then everything works fine. However, for GPU based tensorflow
the follow error occurs and aborts execution:</p>

<pre class=""lang-none prettyprint-override""><code>2020-03-29 16:27:22.904103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-29 16:27:22.904807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 978 MB memory) -&gt; physical GPU (device: 0, name: GRID V100DX-32C, pci bus id: 0000:02:00.0, compute capability: 7.0)
2020-03-29 16:27:22.995000: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: No unary variant device copy function found for direction: 1 and Variant type_index: tensorflow::data::(anonymous namespace)::DatasetVariantWrapper
[[{{node partitionedcall_args_0/_2}}]]
</code></pre>

<p>How do I solve this ? Have anyone faced similar issues ?</p>
",13149118,,11301900,,43920.0125,43963.98194,Error while using GPU based remote execution with Tensorflow federated,<python><tensorflow-federated>,1,4,,,,CC BY-SA 4.0
60935065,1,,,43920.68681,,0,246,"<p>I am working on optimizing the communication costs in Federated Learning. Therefore, I need to simulate realistic network delays and measure communication overhead (the communication between the clients and the server). Is it possible to do that with TFF? Is there a realistic networking model for communications in Federated Learning setting?</p>
",11472601,,,,,43922.21042,Is there a way to simulate the communications costs in tensorflow-federated?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60966874,1,,,43922.36458,,2,266,"<p>I tried the code mentioned on homepage of tensorflow federated site....</p>

<p><a href=""https://www.tensorflow.org/federated"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated</a></p>

<p>Got the error:</p>

<pre><code>RuntimeError: Cannot run the event loop while another loop is running
</code></pre>

<p>Complete code:</p>

<p><a href=""https://github.com/shantanuo/stack_question/blob/master/tensorflow_federated.ipynb"" rel=""nofollow noreferrer"">https://github.com/shantanuo/stack_question/blob/master/tensorflow_federated.ipynb</a></p>

<p>How do I run the sample code?</p>
",139150,,,,,43955.22917,running the event loop in tf federated,<tensorflow-federated>,2,0,,,,CC BY-SA 4.0
60982530,1,,,43923.02569,,1,1028,"<p>I am a newer in Deep Learning and TFF. I need to use a CNN to classify images from EMNIST. And I see the tutorials on GitHub named Federated Learning for Image Classification. I create a Network named CNN, and then I use forward_pass function to instance a cnn model to calculate the predictions. But TFF need to pass the model variables as trainable variables to the tff.learning.Model. I print the CNN model.variables. I don't know how to named them so I use cnn_conv2d_kernel to represents cnn/conv2d/kernel. Here is my code:</p>

<p>the model.variables printed:</p>

<pre><code>variables: [&lt;tf.Variable 'cnn/conv2d/kernel:0' shape=(5, 5, 1, 32) dtype=float32&gt;, &lt;tf.Variable 'cnn/conv2d/bias:0' shape=(32,) dtype=float32&gt;, &lt;tf.Variable 'cnn/conv2d_1/kernel:0' shape=(5, 5, 32, 64) dtype=float32&gt;, &lt;tf.Variable 'cnn/conv2d_1/bias:0' shape=(64,) dtype=float32&gt;, &lt;tf.Variable 'cnn/dense/kernel:0' shape=(3136, 1024) dtype=float32&gt;, &lt;tf.Variable 'cnn/dense/bias:0' shape=(1024,) dtype=float32&gt;, &lt;tf.Variable 'cnn/dense_1/kernel:0' shape=(1024, 10) dtype=float32&gt;, &lt;tf.Variable 'cnn/dense_1/bias:0' shape=(10,) dtype=float32&gt;]
</code></pre>

<p>My variables created to pass trainable and non_trainable variables to tff.learning.Model:</p>

<pre><code>MnistVariables = collections.namedtuple(
'MnistVariables','cnn_conv2d_kernel cnn_conv2d_bias cnn_conv2d_1_kernel cnn_conv2d_1_bias cnn_dense_kernel cnn_dense_bias cnn_dense_1_kernel cnn_dense_1_bias num_examples loss_sum accuracy_sum'
</code></pre>

<p>)</p>

<pre><code>def create_mnist_variables():
  return MnistVariables(
      # weights=tf.Variable(
      #     # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),
      #     lambda: tf.zeros(dtype=tf.float32, shape=(28,28,10)),
      #     name='weights',
      #     trainable=True),
      # bias=tf.Variable(
      #     lambda: tf.zeros(dtype=tf.float32, shape=(10)),
      #     name='bias',
      #     trainable=True),

      cnn_conv2d_kernel=tf.Variable(
          # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),
          lambda: tf.zeros(dtype=tf.float32, shape=(5,5,1,32)),
          name='cnn_conv2d_kernel',
          trainable=True),
      cnn_conv2d_bias=tf.Variable(
          # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),
          lambda: tf.zeros(dtype=tf.float32, shape=(32,)),
          name='cnn_conv2d_bias',
          trainable=True),
      cnn_conv2d_1_kernel=tf.Variable(
          # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),
          lambda: tf.zeros(dtype=tf.float32, shape=(5,5,32,64)),
          name='cnn_conv2d_1_kernel',
          trainable=True),
      cnn_conv2d_1_bias=tf.Variable(
          # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),
          lambda: tf.zeros(dtype=tf.float32, shape=(64,)),
          name='cnn_conv2d_1_bias',
          trainable=True),
      cnn_dense_kernel=tf.Variable(
          # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),
          lambda: tf.zeros(dtype=tf.float32, shape=(3136,1024)),
          name='cnn_dense_kernel',
          trainable=True),
      cnn_dense_bias=tf.Variable(
          # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),
          lambda: tf.zeros(dtype=tf.float32, shape=(1024,)),
          name='cnn_dense_bias',
          trainable=True),
      cnn_dense_1_kernel=tf.Variable(
          # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),
          lambda: tf.zeros(dtype=tf.float32, shape=(1024,10)),
          name='cnn_dense_1_kernel',
          trainable=True),
      cnn_dense_1_bias=tf.Variable(
          # lambda: tf.zeros(dtype=tf.float32, shape=(784,10)),
          lambda: tf.zeros(dtype=tf.float32, shape=(10,)),
          name='cnn_dense_1_bias',
          trainable=True),
      num_examples=tf.Variable(0.0, name='num_examples', trainable=False),
      loss_sum=tf.Variable(0.0, name='loss_sum', trainable=False),
      accuracy_sum=tf.Variable(0.0, name='accuracy_sum', trainable=False)
  )
</code></pre>

<p>my partial tff.learning.Model code:</p>

<pre><code>class MnistModel(tff.learning.Model):

  def __init__(self):
    self._variables = create_mnist_variables()

  #æ‰€æœ‰çš„â€œtf.Variablesâ€éƒ½åº”è¯¥åœ¨â€œ__init__â€ä¸­å¼•å…¥
  @property
  def trainable_variables(self):
    #return [self._variables.weights, self._variables.bias]
    return [self._variables.cnn_conv2d_kernel,
        self._variables.cnn_conv2d_bias,
        self._variables.cnn_conv2d_1_kernel,
        self._variables.cnn_conv2d_1_bias,
        self._variables.cnn_dense_kernel,
        self._variables.cnn_dense_bias,
        self._variables.cnn_dense_1_kernel,
        self._variables.cnn_dense_1_bias
        ]
</code></pre>

<p>please forgive my poor English and help me please.(Please)</p>

<p>Now ,I have a new problem:</p>

<pre><code>ValueError: No gradients provided for any variable: ['cnn_conv2d_kernel:0', 'cnn_conv2d_bias:0', 'cnn_conv2d_1_kernel:0', 'cnn_conv2d_1_bias:0', 'cnn_dense_kernel:0', 'cnn_dense_bias:0', 'cnn_dense_1_kernel:0', 'cnn_dense_1_bias:0'].
</code></pre>
",13086990,,13086990,,43923.03819,43925.84306,"ValueError: Tensor(""cnn/conv2d/kernel:0"", shape=(), dtype=resource) must be from the same graph as Tensor(""Placeholder:0"", shape=(), dtype=variant)",<tensorflow><keras><deep-learning><conv-neural-network><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
60998080,1,,,43923.75069,,2,376,"<p>I would like to simulate this code of federated learning for image classification with random samples of users in each round,
This tutorial uses all clients on training, insteed, I would to modify this code in such a way, in each round a random samples of clients are chosen.
 So what we can change in this code to force it to choice client randomly</p>

<pre><code>import collections
import time

import tensorflow as tf
tf.compat.v1.enable_v2_behavior()

import tensorflow_federated as tff

source, _ = tff.simulation.datasets.emnist.load_data()


def map_fn(example):
  return collections.OrderedDict(
      x=tf.reshape(example['pixels'], [-1, 784]), y=example['label'])


def client_data(n):
  ds = source.create_tf_dataset_for_client(source.client_ids[n])
  return ds.repeat(10).shuffle(500).batch(20).map(map_fn)


train_data = [client_data(n) for n in range(10)]
element_spec = train_data[0].element_spec

def model_fn():
  model = tf.keras.models.Sequential([
      tf.keras.layers.Input(shape=(784,)),
      tf.keras.layers.Dense(units=10, kernel_initializer='zeros'),
      tf.keras.layers.Softmax(),
  ])
  return tff.learning.from_keras_model(
      model,
      input_spec=element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])


trainer = tff.learning.build_federated_averaging_process(
    model_fn, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.02))

....
NUM_ROUNDS = 11
for round_num in range(2, NUM_ROUNDS):
  state, metrics = trainer.next(state, federated_train_data)
  print('round {:2d}, metrics={}'.format(round_num, metrics))
</code></pre>
",12682667,,12682667,,43925.82778,44358.46806,TFF: How simulate training on random samples of users in each round,<tensorflow-federated>,2,0,,,,CC BY-SA 4.0
61008774,1,,,43924.39236,,1,127,"<p>I am attempting to utilise TensorFlow Federated for an image classification task with 7 classes and 3-5 clients. Each client has a different class distribution of labels. I have successfully implemented <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">this tutorial</a> for my use-case and am now looking for improvements. I have a few questions:</p>

<ol>
<li>Can individual clients have different class weights in their loss function based on the class distribution that is unique to that client? </li>
<li>If so, how would one implement this? </li>
<li>If not, is it because federated averaging process requires that the clients and the global model share the same loss function?</li>
</ol>
",13208966,,,,,43924.46389,How would one implement class weighting for individual federated learning clients?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61025323,1,61033780,,43925.3375,,0,2518,"<p>This is code snippet from <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification</a></p>

<p>The example is of image classification problem using federated learning. Below function is pre-processing function of emnist data (which is of size 28*28). Can anyone help to understand why the data was reshaped to -1 to 784? as far as I understand, we convert it from two dimensional to one dimensional array because it is easier to process. But I am not sure why -1 was included. Isn't it 0 o 784 would have been enough?</p>

<pre><code>NUM_CLIENTS = 10
NUM_EPOCHS = 5
BATCH_SIZE = 20
SHUFFLE_BUFFER = 100
PREFETCH_BUFFER=10

def preprocess(dataset):

  def batch_format_fn(element):
    """"""Flatten a batch `pixels` and return the features as an `OrderedDict`.""""""
    return collections.OrderedDict(
        x=tf.reshape(element['pixels'], **[-1, 784]**),
        y=tf.reshape(element['label'], **[-1, 1]**))

  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(
      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)
</code></pre>
",1113945,,,,,44013.38194,"Why the eminst data is converted from (28*28) to [-1, 784] instead of [0,784] in image classification problem?",<python><machine-learning><mnist><tensorflow-federated>,2,1,,,,CC BY-SA 4.0
61034455,1,61174252,,43925.85903,,2,1413,"<p>I'm trying to make an image captioning model using the federated learning library provided by tensorflow, but I'm stuck at this error </p>

<p><code>Input 0 of layer dense is incompatible with the layer: : expected min_ndim=2, found ndim=1.</code></p>

<p>this is my input_spec: </p>

<pre><code>input_spec=collections.OrderedDict(x=(tf.TensorSpec(shape=(2048,), dtype=tf.float32), tf.TensorSpec(shape=(34,), dtype=tf.int32)), y=tf.TensorSpec(shape=(None), dtype=tf.int32))
</code></pre>

<p>The model takes image features as the first input and a list of vocabulary as a second input, but I can't express this in the input_spec variable. I tried expressing it as a list of lists but it still didn't work. What can I try next?</p>
",7820400,,472495,,43929.52361,43933.66458,TensorFlow Federated: How can I write an Input Spec for a model with more than one input,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61054659,1,,,43927.29931,,0,2308,"<p>I got this error when I want to create a HDF5ClientData instance just like the emnsit. Here is my code:</p>

<pre><code>TestNIST = tff.simulation.hdf5_client_data.HDF5ClientData(""mynist.hdf5"")
</code></pre>

<p>And I have added some data into mynist.hdf5 before. I don't know why it happen.</p>

<p><a href=""https://i.sstatic.net/o5gxa.png"" rel=""nofollow noreferrer"">the instance of emnist</a></p>

<p>here is my error like:</p>

<pre><code>KeyError                                  Traceback (most recent call last)
&lt;ipython-input-169-00a78fdc8682&gt; in &lt;module&gt;()
----&gt; 1 TestNIST = tff.simulation.hdf5_client_data.HDF5ClientData(""mynist.hdf5"")

1 frames
h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

/usr/local/lib/python3.6/dist-packages/h5py/_hl/group.py in __getitem__(self, name)
    262 
    263         Named HDF5 object (Dataset, Group, Datatype)
--&gt; 264             A hard link is created at ""name"" which points to the
    265             given object.
    266 

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/h5o.pyx in h5py.h5o.open()

KeyError: ""Unable to open object (object 'examples' doesn't exist)""
</code></pre>
",13086990,,,,,43927.31181,"KeyError: ""Unable to open object (object 'examples' doesn't exist)""",<tensorflow><hdf5><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61056770,1,,,43927.39861,,1,108,"<p>I create a <code>DataSet</code> following EMNIST. But When I train my model it seems to be trapped in a infinite loop and RAM gets filled in a short time. Here is the code. I print my dataset and EMNIST dataset to draw a comparison (<code>BAL1</code> is my DataSet):</p>
<pre class=""lang-py prettyprint-override""><code>print(tf.data.Dataset.from_tensor_slices(
  collections.OrderedDict(
    (name, ds.value) for name, ds 
    in sorted(f[&quot;examples&quot;][BAL1.client_ids[0]].items())
  )))
example_dataset = emnist_train.create_tf_dataset_for_client(
  emnist_train.client_ids[0])
print(example_dataset)
</code></pre>
<p>Here is the result:</p>
<pre><code>    &lt;TensorSliceDataset shapes: OrderedDict([(label, ()), (pixels, (28, 28))]), types: OrderedDict([(label, tf.int32), (pixels, tf.float32)])&gt;
    &lt;TensorSliceDataset shapes: OrderedDict([(label, ()), (pixels, (28, 28))]), types: OrderedDict([(label, tf.int32), (pixels, tf.float32)])&gt;
</code></pre>
<p>and this is the part I use <code>BAL1</code> to replace EMNIST:</p>
<pre class=""lang-py prettyprint-override""><code>sample_clients = BAL1.client_ids[0:NUM_CLIENTS]
 
federated_train_data = make_federated_data(BAL1, sample_clients)
    
state, metrics = iterative_process.next(state, federated_train_data)
print('round 1, metrics={}'.format(metrics))
</code></pre>
<p>My model can work well with EMNIST. But if I change EMNIST to my dataset, the &quot;Python3 Google compute Engine&quot; becomes busy. Even after waiting a long time nothing is calculated, so I have to interrupt it.</p>
",13086990,,12480730,,44004.66597,44004.66597,Application hangs if training tff Model using a created Client DataSet,<python><tensorflow2.0><tensorflow-datasets><tensorflow-federated>,0,2,,,,CC BY-SA 4.0
61102268,1,,,43929.575,,1,536,"<p>I am trying to run my python code which uses <code>tensorflow-federated</code> on a GPU. To set up my environment, I use <code>venv</code>. First, I install <code>tensorflow-gpu</code>, and my python code then can recognize the GPU, I use <code>tf.test.gpu_device_name()</code>. However, as soon as I install <code>tensorflow-fedenerated</code>, my python stops seeing any GPU and starts using CPUs!! 
I am using Ubuntu 16.04.6 LTS. I tried a plenty of combinations of different versions of the packages:</p>

<pre><code>python = 3.6, 3.7
cuda = 10.0, 10.1
tensorflow-gpu = 1.13.1, 1.15, 2.1.0, 2.0.0-alpha0
tensorflow-fedenerated = 0.2.0, 0.12.0, 0.13.0
</code></pre>
",8461136,,8461136,,43934.51319,43934.51319,Can't run Tensorflow-federated on GPU,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61108381,1,,,43929.80556,,1,226,"<p>I would like to try this <a href=""https://www.tensorflow.org/federated/api_docs/python/tff/learning/assign_weights_to_keras_model"" rel=""nofollow noreferrer"">method</a> of TFF  with this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">tutorial</a> but I find error witch I can't understand. I use assign_weight and after that I evaluate my model
Here is my code :</p>

<pre><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()
...
def create_compiled_keras_model():
    model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(
          10, activation=tf.nn.softmax, kernel_initializer='zeros', input_shape=(784,))])

    model.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
     optimizer=tf.keras.optimizers.SGD(learning_rate=0.02),
     metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
    return model

def model_fn():
    keras_model = create_compiled_keras_model()
    return tff.learning.from_compiled_keras_model(keras_model, sample_batch)

iterative_process = tff.learning.build_federated_averaging_process(model_fn)
state = iterative_process.initialize()
state, metrics = iterative_process.next(state, train_data)

NUM_ROUNDS = 11
for round_num in range(1, NUM_ROUNDS):
    state, metrics = iterative_process.next(state, train_data)
    print('round {:2d}, metrics={}'.format(round_num, metrics))

evaluation = tff.learning.build_federated_evaluation(model_fn)
train_metrics = evaluation(state.model, train_data)


keras_model = create_compiled_keras_model()
keras_model.compile(
    loss=tf.keras.losses.SparseCategoricalCrossentropy(),
     optimizer=tf.keras.optimizers.SGD(learning_rate=0.02),
     metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
tff.learning.assign_weights_to_keras_model(keras_model, state.model)
centralized_data= emnist_test.create_tf_dataset_from_all_clients()
loss, accuracy = keras_model.evaluate(centralized_data, verbose =1)
print('loss={}, accuracy={}'.format(loss, accuracy))

</code></pre>

<p>Error message :</p>

<pre><code>loss, accuracy = keras_model.evaluate(centralized_data, verbose =1)
ValueError: No data provided for ""dense_input"". Need data for each key in: ['dense_input']

</code></pre>
",12682667,,,,,43929.80556,"Error while trying ""tff.learning.assign_weights_to_keras_model"" method",<tensorflow-federated>,0,1,,,,CC BY-SA 4.0
61136411,1,,,43931.34306,,0,29,"<p>I met a strange problem when I used my created data set in TFF. I created a data set for federated training, where I allocate 5 clients examples as follows: 600 600 300 700 300. But when I trained them in model, I found the number of examples is 600 600 600 600 700. I was so confused. And then, I printed the process information of my created data set and checked the HDF5 file of the dataset, and both of them were 600 600 300 700 300. 
I use this code to see how many examples in the client in the HDF5 file, the result is 700:</p>

<pre><code>len(f3[""examples""][client_ids[3]][""label""].value)
</code></pre>

<p>I use this code to instance the data set and see how many examples in the client:</p>

<pre><code>BAL3 = tff.simulation.hdf5_client_data.HDF5ClientData(""BAL3.hdf5"")

    num_clients_BAL3 = len(BAL3.client_ids)

    example_dataset = BAL3.create_tf_dataset_for_client(
        BAL3.client_ids[3]
    )
    example_element = next(iter(example_dataset))
    n = 0
    iter_ = iter(example_dataset)
    while(iter_):
      next(iter_)
      n = n+1
      print(n) #n stop at 600
</code></pre>

<p>I use this code to instance the data set of third client and debug:</p>

<pre><code>BAL3 = tff.simulation.hdf5_client_data.HDF5ClientData(""BAL3.hdf5"")

example_dataset = BAL3.create_tf_dataset_for_client(
    BAL3.client_ids[3]
)
example_element = next(iter(example_dataset))
n = 0
iter_ = iter(example_dataset)
while(n &lt; 601): #n&lt;600 can work well
  example_element = next(iter_)
  n = n+1
  #print(n)

print(example_element['label'].numpy() )
plt.imshow(example_element['pixels'].numpy(), cmap='gray', aspect='equal')
plt.grid(False)
_=plt.show()
</code></pre>

<p>I allocated the third client 700 examples when I created the data set. But when I iterated data of this client I found it showed 600 examples. The tff HDF5 file showed 700 too.</p>
",13086990,,,,,43962.80486,Why I allocate 600 examples to a client but there are 700 when I train the model in TFF?,<tensorflow-datasets><tensorflow-federated>,1,2,,,,CC BY-SA 4.0
61152605,1,,,43932.2375,,3,184,"<p>How to perform asynchronous model training using TFF framework?</p>

<p>I review the iterative training process loop, however I am not sure how to know which clients models are received.</p>
",13149118,,,,,43961.55833,Async - FL Model,<tensorflow-federated>,1,2,,,,CC BY-SA 4.0
61199743,1,,,43935.09722,,0,28,"<p>I am training a FL model. I select 5 clients every cycle. I want to get the examples gap between a client and the maximum quantity client. Can Server broadcast the max number of examples among the 5 clients to others during this cycle? Is it legal? </p>
",13086990,,,,,43961.52847,Can Server broadcast the max number of examples to every client in a train cycle in FL? Is this action an invasion of privacy?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61219479,1,,,43936.02431,,1,592,"<p>I create a Non-IID data set where I divide 60000 examples(10 classes and every class has 6000 examples) to 200 fragments, and every fragment  has 300 examples. There are 100 clients and I allocate 2 fragments randomly to every client. This is the situation of some clients. 
<a href=""https://i.sstatic.net/P8Uhu.png"" rel=""nofollow noreferrer"">the situation of some clients</a></p>

<p>I use this data set to train my TFF model. The accuracy of train set is about 0.99 but the accuracy of test set is only about 0.5. I try many times but no change. 
And I think maybe the model is over-fit so I add two dropout to test, but I get the same result. Then I change relu() funcion to leakyrelu(), and change the optimizer function from SGD to Adam, but accuracy also is about 0.5. I don't why. I know Non-IID will cause descend of accuracy and FedAvg can relieve it. TFF use FedAvg to aggregate client model that means I have use FedAvg to be my underlying structure, is it right? But why I get a so low accaracy?  </p>
",13086990,,,,,43960.72778,Why I create a Non-IID data set like the FedAvg in paper of McMahan but test accuracy of this data set is just only 0.5?,<python><tensorflow><imbalanced-data><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
70715524,1,,,44575.80278,,1,97,"<p>I am using TensorFlow Federated to simulate a scenario in which clients hosted on a remote server can work with our very sparse dataset in a federated setting.</p>
<p>Presently, the code is capable of running with a small subset of the very sparse dataset being loaded on the server-side and passing it to the remote workers hosted on another device. The data is in SVM Light format and can be loaded through sklearn's <em>load_svmlight_file</em> function, but needs to be converted into Tensors to work within tff. The current solution to do so involves converting the very sparse data into a dense array, then setting it up through the <em>tf.data.Dataset.from_tensor_slices</em> function for use with a keras model (following existing examples for tff).</p>
<p>This works, but takes up significant memory resources and is not suitable for the dataset as it cannot be run remotely for more than six samples due to the sparse data's serialized size, nor locally with more than a few hundred samples due to the size in memory.</p>
<p>To mitigate this, I converted the data into SparseTensors, but this approach fails due to the <em>tff.learning.from_keras_model</em> function expecting a pair of TensorSpec input_spec values, not a SparseTensorSpec input_spec with the labels being TensorSpec.</p>
<p>So, are there any concrete examples or known methods to work with SparseTensors within keras models in tff? Or must they be as Tensors for now? The data loads fine when not converted to regular Tensors so I will need to find a solution for working with the sparse data.</p>
<p>If there is presently no way to do so, are there examples of strategies within tff to work with very small subsets of data at a time, either being loaded directly with the remote client or being passed from the server?</p>
<p>Thanks!</p>
",17934973,,,,,44578.44722,TensorFlow Federated - How to work with SparseTensors,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
70745268,1,,,44578.72569,,0,174,"<p>Part of the simulation program that I am working on allows clients to load local data from their device without the server being able to access that data.</p>
<p>Following the idea from <a href=""https://stackoverflow.com/questions/60265798/tff-how-define-tff-simulation-clientdata-from-clients-and-fn-function"">this post</a>, I have the following code configured to assign the client a path to load the data from. Although the data is in svmlight format, loading it line-by-line can still allow it to be preprocessed afterwards.</p>
<pre><code>client_paths = {
    'client_0': '&lt;path_here&gt;',
    'client_1': '&lt;path_here&gt;',
}

def create_tf_dataset_for_client_fn(id):
    path = client_paths.get(id)
    data = tf.data.TextLineDataset(path) 

path_source = tff.simulation.datasets.ClientData.from_clients_and_fn(client_paths.keys(), create_tf_dataset_for_client_fn)
</code></pre>
<p>The code above allows a path to be loaded during runtime from the remote client's-side by the following line of code.</p>
<pre><code>data = path_source.create_tf_dataset_for_client('client_0')
</code></pre>
<p>Here, the data variable can be iterated through and can be used to display the contents on the client on the remote device when calling tf.print(). But, I need to preprocess this data into an appropriate format before continuing. I am presently attempting to convert this from a string Tensor in svmlight format into a SparseTensor of the appropriate format.</p>
<p>The issue is that, although the defined preprocessing method works in a standalone scenario (i.e. when defined as a function and tested on a manually defined Tensor of the same format), it fails when the code is executed during the client update @tf.function in the tff algorithm. Below is the specified error when executing the notebook cell which contains a @tff.tf_computation function which calls an @tf.function which does the preprocessing and retrieves the data.</p>
<p><em>ValueError: Shape must be rank 1 but is rank 0 for '{{node Reshape_2}} = Reshape[T=DT_INT64, Tshape=DT_INT32](StringToNumber_1, Reshape_2/shape)' with input shapes: [?,?], [].</em></p>
<p>Since the issue occurs when executing the client's @tff.tf_computation update function which calls the @tf.function with the preprocessing code, I am wondering how I can allow the function to perform the preprocessing on the data without errors. I assume that if I can just get the functions to properly be run when defined that when called remotely it will work.</p>
<p>Any ideas on how to address this issue? Thank you for your help!</p>
<p>For reference, the preprocessing function uses tf computations to manipulate the data. Although not optimal yet, below is the code presently being used. This is inspired from <a href=""https://www.programcreek.com/python/example/90313/tensorflow.string_split"" rel=""nofollow noreferrer"">this link</a> on string_split examples. I have extracted the code to put directly into the client's @tf.function after loading the TextLineDataset as well, but this also fails.</p>
<pre><code>def decode_libsvm(line):
        # Split the line into columns, delimiting by a blank space
        cols = tf.strings.split([line], ' ')
        # Retrieve the labels from the first column as an integer
        labels = tf.strings.to_number(cols.values[0], out_type=tf.int32)
        # Split all column pairs
        splits = tf.strings.split(cols.values[1:], ':')
        # Convert splits into a sparse matrix to retrieve all needed properties
        splits = splits.to_sparse()
        # Reshape the tensor for further processing
        id_vals = tf.reshape(splits.values, splits.dense_shape)
        # Retrieve the indices and values within two separate tensors
        feat_ids, feat_vals = tf.split(id_vals, num_or_size_splits=2, axis=1)
        # Convert the indices into int64 numbers
        feat_ids = tf.strings.to_number(feat_ids, out_type=tf.int64)
        # To reload within a SparseTensor, add a dimension to feat_ids with a default value of 0
        feat_ids = tf.reshape(feat_ids, -1)
        feat_ids = tf.expand_dims(feat_ids, 1)
        feat_ids = tf.pad(feat_ids, [[0,0], [0,1]], constant_values=0)
        # Extract and flatten the values
        feat_vals = tf.strings.to_number(feat_vals, out_type=tf.float32)
        feat_vals = tf.reshape(feat_vals, -1)
        # Configure a SparseTensor to contain the indices and values
        sparse_output = tf.SparseTensor(indices=feat_ids, values=feat_vals, dense_shape=[1, &lt;shape&gt;])
        return {&quot;x&quot;: sparse_output, &quot;y&quot;: labels}
</code></pre>
<h2>Update (Fix)</h2>
<p>Following the advice from Jakub's comment, the issue was fixed by enclosing the reshape and expand_dim calls in [], when needed. Now there is no issue running the code within tff.</p>
<pre><code>def decode_libsvm(line):
        # Split the line into columns, delimiting by a blank space
        cols = tf.strings.split([line], ' ')
        # Retrieve the labels from the first column as an integer
        labels = tf.strings.to_number(cols.values[0], out_type=tf.int32)
        # Split all column pairs
        splits = tf.strings.split(cols.values[1:], ':')
        # Convert splits into a sparse matrix to retrieve all needed properties
        splits = splits.to_sparse()
        # Reshape the tensor for further processing
        id_vals = tf.reshape(splits.values, splits.dense_shape)
        # Retrieve the indices and values within two separate tensors
        feat_ids, feat_vals = tf.split(id_vals, num_or_size_splits=2, axis=1)
        # Convert the indices into int64 numbers
        feat_ids = tf.strings.to_number(feat_ids, out_type=tf.int64)
        # To reload within a SparseTensor, add a dimension to feat_ids with a default value of 0
        feat_ids = tf.reshape(feat_ids, [-1])
        feat_ids = tf.expand_dims(feat_ids, [1])
        feat_ids = tf.pad(feat_ids, [[0,0], [0,1]], constant_values=0)
        # Extract and flatten the values
        feat_vals = tf.strings.to_number(feat_vals, out_type=tf.float32)
        feat_vals = tf.reshape(feat_vals, [-1])
        # Configure a SparseTensor to contain the indices and values
        sparse_output = tf.SparseTensor(indices=feat_ids, values=feat_vals, dense_shape=[1, &lt;shape&gt;])
        return {&quot;x&quot;: sparse_output, &quot;y&quot;: labels}
</code></pre>
",17934973,,17934973,,44579.62639,44579.62639,TensorFlow Federated - Loading and preprocessing data on a remote client,<tensorflow><tensorflow-federated>,0,2,,,,CC BY-SA 4.0
70825390,1,71004238,,44584.77778,,1,463,"<p>I just started studying federated learning and want to apply it to a certain dataset, and there are some questions that have risen up.</p>
<p>My data is containing records of 3 categories, each of which is having 3 departments. I am planning to have 3 different federated learning models for each category and treat the three department of this category as the distributed clients.</p>
<p>Is this possible? or building federated learning models requires having thousands of clients?</p>
<p>Thanks</p>
",17534198,,,,,44598.19236,Limited number of clients used in federated learning,<tensorflow-federated><federated><federated-learning>,1,1,,,,CC BY-SA 4.0
71037598,1,71039629,,44600.69722,,2,250,"<p>I am trying to implement a custom aggregation using TFF by changing the code from this <a href=""https://www.tensorflow.org/federated/tutorials/building_your_own_federated_learning_algorithm"" rel=""nofollow noreferrer"">tutorial</a> . I would like to rewrite <code>next_fn</code> so that all the client weights are placed at the server for further computations. As <code>federated_collect</code> was removed from tff-nightly, I am trying to do that using <code>federated_aggregate</code>.</p>
<p>This is what I have so far:</p>
<pre><code>def accumulate(x, y):
    x.append(y)
    return x


def merge(x, y):
    x.extend(y)
    return y


@tff.federated_computation(federated_server_type, federated_dataset_type)
def next_fn(server_state, federated_dataset):
    server_weights_at_client = tff.federated_broadcast(
        server_state.trainable_weights)
    client_deltas = tff.federated_map(
        client_update_fn, (federated_dataset, server_weights_at_client))

    z = []
    agg_result = tff.federated_aggregate(client_deltas, z,
                                         accumulate=tff.tf_computation(accumulate),
                                         merge=tff.tf_computation(merge),
                                         report=tff.tf_computation(lambda x: x))

    new_weights = do_smth_with_result(agg_result)
    server_state = tff.federated_map(
        server_update_fn, (server_state, new_weights))
    return server_state
</code></pre>
<p>However this results in the following Exception:</p>
<pre><code>  File &quot;/home/yana/Documents/Uni/Thesis/grufedatt_try.py&quot;, line 351, in &lt;module&gt;
    def next_fn(server_state, federated_dataset):
  File &quot;/home/yana/anaconda3/envs/fedenv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py&quot;, line 494, in __call__
    wrapped_func = self._strategy(
  File &quot;/home/yana/anaconda3/envs/fedenv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py&quot;, line 222, in __call__
    result = fn_to_wrap(*args, **kwargs)
  File &quot;/home/yana/Documents/Uni/Thesis/grufedatt_try.py&quot;, line 358, in next_fn
    agg_result = tff.federated_aggregate(client_deltas, z,
  File &quot;/home/yana/anaconda3/envs/fedenv/lib/python3.9/site-packages/tensorflow_federated/python/core/impl/federated_context/intrinsics.py&quot;, line 140, in federated_aggregate
    raise TypeError(
TypeError: Expected parameter `accumulate` to be of type (&lt;&lt;&lt;float32[9999,96],float32[96,1024],float32[256,1024],float32[1024],float32[256,96],float32[96]&gt;&gt;,&lt;float32[9999,96],float32[96,1024],float32[256,1024],float32[1024],float32[256,96],float32[96]&gt;&gt; -&gt; &lt;&lt;float32[9999,96],float32[96,1024],float32[256,1024],float32[1024],float32[256,96],float32[96]&gt;&gt;), but received (&lt;&lt;&gt;,&lt;float32[9999,96],float32[96,1024],float32[256,1024],float32[1024],float32[256,96],float32[96]&gt;&gt; -&gt; &lt;&lt;float32[9999,96],float32[96,1024],float32[256,1024],float32[1024],float32[256,96],float32[96]&gt;&gt;) instead.
</code></pre>
",17667231,,,,,44600.80208,How to gather all client weights at server in TFF?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71160311,1,,,44609.61667,,1,376,"<p>I wrote following codes on a new google collabs notebook:</p>
<pre><code>!pip install --quiet --upgrade tensorflow-federated-nightly

import tensorflow as tf
import tensorflow_federated as tff
</code></pre>
<p>And I got these error messages while importing <code>tensorflow_federeated</code>:</p>
<pre><code>/usr/local/lib/python3.7/dist-packages/keras/api/_v1/keras/experimental/__init__.py in &lt;module&gt;()
      8 from keras.feature_column.sequence_feature_column import SequenceFeatures
      9 from keras.layers.rnn.lstm_v1 import PeepholeLSTMCell
---&gt; 10 from keras.optimizers.learning_rate_schedule import CosineDecay
     11 from keras.optimizers.learning_rate_schedule import CosineDecayRestarts
     12 from keras.premade_models.linear import LinearModel

ModuleNotFoundError: No module named 'keras.optimizers.learning_rate_schedule'; 'keras.optimizers' is not a package
</code></pre>
<p>These errors seem to be spawning from the modules installed on the colabs itself, instead of my code.
<br/>Any idea on what can be done to fix this?</p>
",14574920,,14574920,,44609.62639,45071.42778,Tensorflow federated can't be imported on google collabs notebook,<keras><google-colaboratory><tf.keras><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
71167600,1,71178429,,44610.08681,,3,410,"<p>I am working to build a federated learning model using TFF and I have some questions:</p>
<ol>
<li><p>I am preparing the dataset, I have separate files of data, with same features and different samples. I would consider each of these files as a single client. How can I maintain this in TFF?</p>
</li>
<li><p>The data is not balanced, meaning, the size of data varies in each file. Is this affecting the modeling process?</p>
</li>
<li><p>The size of the data is a bit small, one file (client) is having 300 records and another is 1500 records, is it suitable to build a federated learning model?</p>
</li>
</ol>
<p>Thanks in advance</p>
",17534198,,17534198,,44610.09375,44611.03403,How to build federated learning model of unbalanced and small dataset,<machine-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
71179882,1,,,44610.88194,,1,348,"<p>As <a href=""https://www.tensorflow.org/federated/tutorials/simulations"" rel=""nofollow noreferrer"">in the tutorial</a>, trying to execute <code>tff.learning.build_federated_averaging_process(model_fn, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.02))</code> but on orchestrator (server) with data saved on edge node (client) using <code>tf.data.experimental.load()</code> method:</p>
<pre><code>@tff.tf_computation
def make_data():
    element_spec = collections.OrderedDict([('x', tf.TensorSpec(shape=(None, 784), dtype=tf.float32, name=None)),
             ('y', tf.TensorSpec(shape=(None,), dtype=tf.int32, name=None))])
    data = tf.data.experimental.load('./train_data', element_spec = element_spec)
    return data
</code></pre>
<p>However, I'm getting the following error:</p>
<pre><code>W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at dataset_ops.cc:175 : Not found: Could not find metadata file.
         [[{{node LoadDataset/_1}}]]
</code></pre>
<p>TF data was saved using <code>tf.data.experimental.save(train_data[0], './train_data')</code> method. The implementation works when executed locally: <code>tff.backends.native.set_local_execution_context()</code></p>
<p>python - 3.7</p>
<p>libraries versions:</p>
<p>tensorflow - 2.5.2</p>
<p>tensorflow-estimator - 2.5.0</p>
<p>tensorflow-federated - 0.19.0</p>
<p>Any help would be most appreciated.</p>
",18247529,,18247529,,44610.90972,44616.39167,Runtime Error: tensorflow.python.framework.errors_impl.NotFoundError: Could not find metadata file. [[{{node LoadDataset/_1}}]] [Op:DatasetFromGraph],<tensorflow><tensorflow-federated>,1,3,,,,CC BY-SA 4.0
71231671,1,71262841,,44615.21806,,0,69,"<p>I'm following the tutorial of TensorFlow_Federated: custom_federated_algorithms_2. Everything works when I just copy and run the tutorial's code. So I wanna change the code by myself for being more familar with tff. Then bug appeared.</p>
<p>My runtime environment:</p>
<p>python: <code>3.8.12</code></p>
<p>tensorflow: <code>2.5.0</code></p>
<p>tensorflow_federated: <code>0.19.0</code></p>
<p>Code below is the orginal code of testing model in tutorial:</p>
<pre class=""lang-py prettyprint-override""><code>MODEL_SPEC = collections.OrderedDict(
    weights=tf.TensorSpec(shape=[784, 10], dtype=tf.float32),
    bias=tf.TensorSpec(shape=[10], dtype=tf.float32))
MODEL_TYPE = tff.to_type(MODEL_SPEC)
print(MODEL_TYPE) # &lt;weights=float32[784,10],bias=float32[10]&gt;


BATCH_SPEC = collections.OrderedDict(
    x=tf.TensorSpec(shape=[None, 784], dtype=tf.float32),
    y=tf.TensorSpec(shape=[None], dtype=tf.int32)
)
BATCH_TYPE = tff.to_type(BATCH_SPEC)
print(BATCH_TYPE) # &lt;x=float32[?,784],y=int32[?]&gt;
</code></pre>
<p>And I changed the <code>MODEL_TYPE</code> into:</p>
<pre class=""lang-py prettyprint-override""><code>MODEL_SPEC = collections.OrderedDict(
    fc1=tf.TensorSpec(shape=[784, 256], dtype=tf.float32),
    b1=tf.TensorSpec(shape=[256], dtype=tf.float32),
    fc2=tf.TensorSpec(shape=[256, 128], dtype=tf.float32),
    b2=tf.TensorSpec(shape=[128], dtype=tf.float32),
    fc3=tf.TensorSpec(shape=[128, 10], dtype=tf.float32),
    b3=tf.TensorSpec(shape=[10], dtype=tf.float32)
)
MODEL_TYPE = tff.to_type(MODEL_SPEC)

</code></pre>
<p>Thanks to the structure of model changed, the process of forward pass needs to be changed too:</p>
<pre class=""lang-py prettyprint-override""><code># original
@tf.function
def forward_pass(model, batch):
  predicted_y = tf.nn.softmax(
      tf.matmul(batch['x'], model['weights']) + model['bias'])
  return -tf.reduce_mean(
      tf.reduce_sum(
          tf.one_hot(batch['y'], 10) * tf.math.log(predicted_y), axis=[1]))

@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)
def batch_loss(model, batch):
  return forward_pass(model, batch)

# new 
@tf.function
def forward(model, batch):
    logits = batch[&quot;x&quot;] @ model[&quot;fc1&quot;] + model[&quot;b1&quot;]

    logits = logits @ model[&quot;fc2&quot;] + model[&quot;b2&quot;]

    logits = logits @ model[&quot;fc3&quot;] + model[&quot;b3&quot;]

    logits = tf.nn.softmax(logits, axis=-1,)
    
    one_hot_y = tf.one_hot(batch[&quot;y&quot;], depth=10)
    return -tf.reduce_mean(tf.reduce_sum(tf.math.log(logits) * one_hot_y, axis=[1]))


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)
def batch_loss(model, batch):
    return forward(model, batch)
</code></pre>
<p>I didn't change the <code>batch_train()</code> code.</p>
<pre class=""lang-py prettyprint-override""><code>@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)
def batch_train(initial_model, batch, learning_rate):
  # Define a group of model variables and set them to `initial_model`. Must
  # be defined outside the @tf.function.
  model_vars = collections.OrderedDict([
      (name, tf.Variable(name=name, initial_value=value))
      for name, value in initial_model.items()
  ])
  optimizer = tf.keras.optimizers.SGD(learning_rate)

  @tf.function
  def _train_on_batch(model_vars, batch):
    # Perform one step of gradient descent using loss from `batch_loss`.
    with tf.GradientTape() as tape:
      loss = forward_pass(model_vars, batch)
    grads = tape.gradient(loss, model_vars)
    optimizer.apply_gradients(
        zip(tf.nest.flatten(grads), tf.nest.flatten(model_vars)))
    return model_vars

  return _train_on_batch(model_vars, batch)
   
</code></pre>
<p>And it works fine so far. But when implementing the <code>local_train()</code> section, errors appeared even I just using the original code.</p>
<pre class=""lang-py prettyprint-override""><code>initial_model = collections.OrderedDict(
    fc1=tf.zeros([784, 256]),
    b1=tf.zeros([256]),
    fc2=tf.zeros([256,128]),
    b2=tf.zeros([128]),
    fc3=tf.zeros([128, 10]),
    b3=tf.zeros([10])
)
LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)

@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)
def local_train(initial_model, learning_rate, all_batches):

  @tff.tf_computation(LOCAL_DATA_TYPE, tf.float32)
  def _insert_learning_rate_to_sequence(dataset, learning_rate):
    return dataset.map(lambda x: (x, learning_rate))

  batches_with_learning_rate = _insert_learning_rate_to_sequence(all_batches, learning_rate)

  # Mapping function to apply to each batch.
  @tff.federated_computation(MODEL_TYPE, batches_with_learning_rate.type_signature.element)
  def batch_fn(model, batch_with_lr):
    batch, lr = batch_with_lr
    return batch_train(model, batch, lr)

  return tff.sequence_reduce(batches_with_learning_rate, initial_model, batch_fn)

locally_trained_model = local_train(initial_model, 1e-1, mnist_train_dataset[5])
# ValueError: Unable to unpack value [] as a tf.compat.v1.GraphDef
</code></pre>
",16330728,,16330728,,44615.22153,44617.33889,"How to solve ""ValueError: Unable to unpack value [] as a tf.compat.v1.GraphDef""",<python><tensorflow><tensorflow-federated>,2,1,,,,CC BY-SA 4.0
61243073,1,,,43937.21458,,1,471,"<p>Does tensorflow-federated support assigning different batch-size for different simulated devices, and changing batch-size for different epoch?</p>
",4616724,,730754,,44163.45556,44163.45556,Does tensorflow-federated support dynamic batch size?,<tensorflow><tensorflow2.0><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
61268081,1,,,43938.38889,,1,3032,"<p>I want to have access to features from TensorFlow federated (tff.python.research) which aren't present with the pip3 install method.</p>

<p>I'm working on a remote server that does not have bazel, thus I cannot build from source. Are there other ways to get and install the latest working version of TFF from its GitHub REPO?</p>

<p>(<a href=""https://github.com/tensorflow/federated"" rel=""nofollow noreferrer"">https://github.com/tensorflow/federated</a>)</p>
",12992742,,,,,44509.62431,How to install Tensorflow federated directly from GitHub or local download?,<tensorflow><github><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61393106,1,,,43944.71806,,0,472,"<p>It's very awesome to see that tensorflow-federated could support distributed training now. I referred to the example <a href=""https://github.com/tensorflow/federated/blob/master/docs/tutorials/high_performance_simulation_with_kubernetes.ipynb"" rel=""nofollow noreferrer"">here</a>. 
However, it seems the training data are sent from server to client at each epoch, and the client(remote_executor_service) doesn't hold any dataset. It is different from typical federated learning scenario. So I was wondering could I place training data separately on each client?</p>
",4616724,,,,,43961.52014,Does tensorflow-federated support placing training data on client side?,<tensorflow-federated><remote-execution>,1,0,,,,CC BY-SA 4.0
61393382,1,,,43944.72847,,2,67,"<p>I want to perform some research regarding quantization/sparsification, I would like to use run_experiment.py script as a template, to do so in a clean matter as research is not part of the pip package I was wondering if it is possible to build it myself and then reuse it as a dependency (as in run_experiment.py some functions from research are used). I am not sure however how to do it. I am not familiar with bazel. I was able to install it and run the script, that's all. Any guidance would be highly appreciated! Or if it's not possible it would be good to know as well! Thank you for any advice in this matter.</p>

<p>EDIT:
I built something using bazel and I have it in bazel-bin I don't know now however how to reuse it in my script, as if I just wanted to do it in a python manner <br>
<code>from research.compression import compression_process_adapter</code> <br>
or somehthing similar in my script</p>
",9794882,,9794882,,43944.74028,43960.70764,build research and use it as an external package for research project,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61419057,1,,,43945.98403,,1,1537,"<p>I have 2 classes and every class has 140 examples, and I have 4 clients, I would like to create a non-iid dataset like the paper of McMahan, how divide examples into fragments ? </p>
",12682667,,,,,45581.73194,TFF: How create a Non-IID dataset,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61450093,1,,,43948.03403,,0,155,"<p>By simulating a tff code with random choice of clients in each round, I find that the accuracy increases to 0.9 then relapses to 0.5 and then from 0.8 to 0.6 and so on, it is not increasing.
have you any idea? 
Thank you!</p>
",12682667,,,,,43960.71458,TFF: accuracy is not increasing while simulating random samples of users,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61458419,1,61459058,,43948.5,,5,1461,"<p>I am trying to federate a keras model which has multiple inputs.
These some of these inputs are categorical and some of them are numerical, so I have some DenseFeature layers to embed the values.</p>
<p>The problem is that using  <code>tff.learning.from_keras_model()</code> to expect as input_spec a dictionary with just 2 elements (x,y) but I have multiple inputs which then I have to distinguish in the model to perform the Embedding correctly with the feature_columns functions and the DenseFeature layers.</p>
<p>How can I handle the single feature columns if the model accepts just an 'x' as input without proper columns names?</p>
<p>Here is the code and the error:</p>
<pre><code>def create_keras_model():
  l = tf.keras.layers

  # handling numerical columns 
  for header in numerical_column_names:
    feature_columns.append(feature_column.numeric_column(header))

  # handling the categorical feature  
  pickup = feature_column.categorical_column_with_vocabulary_list(
      'pickup_location_id', [i for i in range(number_of_locations)])
  #pickup_one_hot = feature_column.indicator_column(pickup)
  #feature_columns.append(pickup_one_hot)

  pickup_embedding = feature_column.embedding_column(pickup, dimension=64)
  #feature_columns.append(pickup_embedding)


  feature_inputs = {
    'pickup_week_day_sin': tf.keras.Input((1,), name='pickup_week_day_sin'),
    'pickup_week_day_cos': tf.keras.Input((1,), name='pickup_week_day_cos'),
    'pickup_hour_sin': tf.keras.Input((1,), name='pickup_hour_sin'),
    'pickup_hour_cos': tf.keras.Input((1,), name='pickup_hour_cos'),
    'pickup_month_sin': tf.keras.Input((1,), name='pickup_month_sin'),
    'pickup_month_cos': tf.keras.Input((1,), name='pickup_month_cos'),
  }
  numerical_features = l.DenseFeatures(feature_columns)(feature_inputs)#{'x': a}

  location_input = {
      'pickup_location_id': tf.keras.Input((1,), dtype=tf.dtypes.int32, name='pickup_location_id'),
  }
  categorical_features = l.DenseFeatures(pickup_embedding)(location_input)#{'x': a}
  #i = l.Input(shape=(64+6,))

  #embedded_lookup_feature = tf.feature_column.numeric_column('x', shape=(784))
  conca = l.Concatenate()([categorical_features, numerical_features])

  dense = l.Dense(128, activation='relu')(conca)
  dense_1 = l.Dense(128, activation='relu')(dense)
  dense_2 = layers.Dense(number_of_locations, kernel_initializer='zeros')(dense_1)
  output = l.Softmax()(dense_2)

  inputs = list(feature_inputs.values()) + list(location_input.values())
  return tf.keras.Model(inputs=inputs, outputs=output)
</code></pre>
<hr />
<pre><code>input_spec = preprocessed_example_dataset.element_spec
def model_fn():
  # We _must_ create a new model here, and _not_ capture it from an external
  # scope. TFF will call this within different graph contexts.
  keras_model = create_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=input_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]
      )
</code></pre>
<hr />
<p>error when called:</p>
<pre><code>ValueError: The top-level structure in `dummy_batch` or `input_spec` must contain exactly two elements, as it must contain type information for both inputs to and predictions from the model.
</code></pre>
<hr />
<p>preprocessed_example_dataset.element_spec:</p>
<pre><code>OrderedDict([('pickup_location_id',
              TensorSpec(shape=(None,), dtype=tf.int32, name=None)),
             ('pickup_hour_sin',
              TensorSpec(shape=(None,), dtype=tf.float32, name=None)),
             ('pickup_hour_cos',
              TensorSpec(shape=(None,), dtype=tf.float32, name=None)),
             ('pickup_week_day_sin',
              TensorSpec(shape=(None,), dtype=tf.float32, name=None)),
             ('pickup_week_day_cos',
              TensorSpec(shape=(None,), dtype=tf.float32, name=None)),
             ('pickup_month_sin',
              TensorSpec(shape=(None,), dtype=tf.float32, name=None)),
             ('pickup_month_cos',
              TensorSpec(shape=(None,), dtype=tf.float32, name=None)),
             ('y', TensorSpec(shape=(None,), dtype=tf.int32, name=None))])
</code></pre>
",8527872,,5446749,,44654.38819,44944.04097,Tensorflow Federated | tff.learning.from_keras_model() with a model with DenseFeature layer and multiple inputs,<python><tensorflow><keras><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61603476,1,,,43955.98889,,2,2609,"<p>after simulating this code of federated learning for image classification, I would like to save my model so I add this two lines</p>

<pre><code>ckpt_manager = FileCheckpointManager(""model.h5"")
ckpt_manager.save_checkpoint(ServerState.from_anon_tuple(state), round_num=2) 
</code></pre>

<p>So here is all my code:</p>

<pre><code>import collections
import time

import tensorflow as tf
tf.compat.v1.enable_v2_behavior()

import tensorflow_federated as tff

source, _ = tff.simulation.datasets.emnist.load_data()


def map_fn(example):
  return collections.OrderedDict(
      x=tf.reshape(example['pixels'], [-1, 784]), y=example['label'])
def client_data(n):
  ds = source.create_tf_dataset_for_client(source.client_ids[n])
  return ds.repeat(10).shuffle(500).batch(20).map(map_fn)


train_data = [client_data(n) for n in range(10)]
element_spec = train_data[0].element_spec

def model_fn():
  model = tf.keras.models.Sequential([
      tf.keras.layers.Input(shape=(784,)),
      tf.keras.layers.Dense(units=10, kernel_initializer='zeros'),
      tf.keras.layers.Softmax(),
  ])
  return tff.learning.from_keras_model(
      model,
      input_spec=element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])


trainer = tff.learning.build_federated_averaging_process(
    model_fn, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.02))

....
NUM_ROUNDS = 11
for round_num in range(2, NUM_ROUNDS):
  state, metrics = trainer.next(state, federated_train_data)
  print('round {:2d}, metrics={}'.format(round_num, metrics))


ckpt_manager = FileCheckpointManager(""model.h5"")
ckpt_manager.save_checkpoint(ServerState.from_anon_tuple(state), round_num=9)
</code></pre>

<p>But this error does appear: </p>

<pre><code>NameError: name 'FileCheckpointManager' is not defined
</code></pre>

<p>I will appreciate it if you told me how I solve this problem</p>
",12682667,,,,,43956.10486,NameError: name 'FileCheckpointManager' is not defined while saving model,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71251685,1,,,44616.50347,,3,2436,"<p>I tried to install tensorflow_federated in google colab. I used</p>
<pre><code>pip install --quiet tensorflow-federated-nightly
import tensorflow-federated as tff
</code></pre>
<p>and it worked. but now when I try to import it get this error:</p>
<pre><code>AttributeError: module 'keras.api._v2.keras.experimental' has no attribute 'PeepholeLSTMCell'
</code></pre>
<p>I don't know why I get this error, because I didn't have any problem before.</p>
<p>I also used the following code to install tensorflow-federated:</p>
<pre><code>pip install --upgrade tensorflow-federated-nightly 
</code></pre>
<p>but I get the same error.</p>
<p>How do I fix it?</p>
<p>My versions are:</p>
<p><code>tensorflow 2.8.0</code>,
<code>keras 2.8.0</code>,
<code>tensorflow-federated-nightly  0.19.0.dev20220218</code></p>
",17945316,,9848043,,44628.51806,45262.9875,module 'keras.api._v2.keras.experimental' has no attribute 'PeepholeLSTMCell',<python><tensorflow><google-colaboratory><tensorflow-federated>,2,1,,,,CC BY-SA 4.0
71273332,1,71277862,,44618.05556,,2,767,"<p>I am building a federated learning model using my own dataset.
I aim to build a multi classification model.
The data are presented in separate 8 CSV files.</p>
<p>I followed the instructions in this <a href=""https://stackoverflow.com/questions/60265798/tff-how-define-tff-simulation-clientdata-from-clients-and-fn-function"">post</a> As shown in the code below.</p>
<pre><code>dataset_paths = {
  'client_0': '/content/ds1.csv',
  'client_1': '/content/ds2.csv',
  'client_2': '/content/ds3.csv',
  'client_3': '/content/ds4.csv',
  'client_4': '/content/ds5.csv',
}

def create_tf_dataset_for_client_fn(id):
   path = dataset_paths.get(id)
   if path is None:
     raise ValueError(f'No dataset for client {id}')
   return tf.data.Dataset.TextLineDataset(path)

source = tff.simulation.datasets.ClientData.from_clients_and_fn(
  dataset_paths.keys(), create_tf_dataset_for_client_fn)
</code></pre>
<p>but it gave me this error</p>
<pre><code>AttributeError: type object 'ClientData' has no attribute 'from_clients_and_fn'
</code></pre>
<p>I was reading this <a href=""https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/ClientData#datasets"" rel=""nofollow noreferrer"">documentation</a> and found that <code>.datasets</code> methods would work, so I replaced with <code>.from_clients_and_fn</code> and the error disappeared but I dont know if it is right and what is next?</p>
<p>My questions are:</p>
<ol>
<li>it this is a right method to upload the data to the clients?</li>
<li>if it is not possible to upload the CSV files separately, can I combine all of the data into one CSV file and then consider them as a non-IID data and train them accordingly?
I need some guidance here</li>
</ol>
<p>and thanks in advance</p>
",17534198,,17534198,,44618.60278,44618.64097,tff.simulation.datasets.ClientData to build federated learning model from CSV files,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71285825,1,71287281,,44619.62431,,2,477,"<p>I am preparing a dataset for federation settings, in the code below, I have multiple CSV files and used each is considered a single client.</p>
<pre><code>dataset_paths = {
  'client_0': '/content/drive/ds1.csv',
  'client_1': '/content/drive/ds2.csv',
  'client_2': '/content/drive/ds3.csv',
  'client_3': '/content/drive/ds4.csv',
  'client_4': '/content/drive/ds5.csv',
}
## Defining the Dtyps for each columns in the datasets 
record_defaults = [int(), int(), int(), int(), float(),float(),float(),float(),float(),float(), int(), int()]

@tf.function
def create_tf_dataset_for_client_fn(dataset_path):
   return tf.data.experimental.CsvDataset(
     dataset_path, record_defaults=record_defaults, header=True )

source = tff.simulation.datasets.FilePerUserClientData(
  dataset_paths, create_tf_dataset_for_client_fn) 
</code></pre>
<p>I wanted to access the data so I can determine the <code>features</code> and <code>label</code> column. so I typed:</p>
<pre><code>for x in source.create_tf_dataset_for_client('client_1'):
  print(x)  
&gt;&gt;&gt; (&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2145209674&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=14&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=64.17&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=18.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=70.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=80.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=30.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=270.14&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=7&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2143677297&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=9&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=60.83&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=14.89&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=75.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=42.5&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=184.72&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=8&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2138537298&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=11&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.83&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=18.82&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=70.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=85.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=30.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=295.14&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=7&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2103817421&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=9&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=77.5&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=8.8&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=75.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=90.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=64.58&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=6&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2081702335&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=10&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=75.83&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=9.7&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=77.5&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=90.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=78.47&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=6&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2067936920&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=1&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=11&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=80.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=10.95&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=77.5&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=95.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=100.0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=6&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=2&gt;)
(&lt;tf.Tensor: shape=(), dtype=int32, numpy=-2065922700&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=0&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=11&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.83&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=3.76&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=65.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=70.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=60.0&gt;, &lt;tf.Tensor: shape=(), dtype=float32, numpy=11.81&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=6&gt;, &lt;tf.Tensor: shape=(), dtype=int32, numpy=3&gt;)
</code></pre>
<p><em>there are more rows since I have a big size of data</em>
So I can access these data as they are tensor objects,
<strong>Question1</strong> how can I state that <code>DataFrame.iloc[1:-1] #Features</code>
and <code>DataFrame.iloc[:-1] #Label</code>
<strong>Question2</strong> How can I split each file to training and testing sets to start the training process?</p>
",17534198,,17534198,,44622.95764,44622.95764,Using create_tf_dataset_for_client() to define the training examples in the dataset,<python><tensorflow><tensorflow-datasets><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
71289273,1,71296104,,44619.97847,,2,304,"<p>I am building a federated learning model.
I have written the code below, but I keep getting the error, which is also not true
please let me know how to use the function <code>train_test_client_split</code> properly?</p>
<pre><code>
@tf.function
def create_tf_dataset_for_client_fn(dataset_path):
   return tf.data.experimental.CsvDataset(
     dataset_path, record_defaults=record_defaults, header=True )

source = tff.simulation.datasets.FilePerUserClientData(
  dataset_paths, create_tf_dataset_for_client_fn)
print(source.client_ids)
&gt;&gt; ['client_0', 'client_1', 'client_2']

@classmethod
def from_clients_and_fn():
    client_ids: Iterable[str]
    create_tf_dataset_for_client_fn: Callable[[str], tf.data.Dataset]

Splitting=source.from_clients_and_tf_fn(['client_0', 'client_1', 'client_2'],create_tf_dataset_for_client_fn)

source.train_test_client_split(client_data=Splitting,
                               num_test_clients=1)
</code></pre>
<p><code>NotFoundError: client_1; No such file or directory [Op:IteratorGetNext]</code></p>
<p>The file is there and the path is correct, but I don't know what it the problem here?</p>
",17534198,,9657861,,44620.58125,44620.58125,TFF: train_test_client_split to partition each client data,<python><tensorflow><machine-learning><tensorflow-datasets><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71322383,1,71322429,,44622.50208,,2,260,"<p>I am trying to mimic the federated learning implementation provided <a href=""https://www.tensorflow.org/federated/tutorials/working_with_client_data"" rel=""nofollow noreferrer"">here: Working with tff's clientData</a> in order to understand the code clearly.
I reached to this point where I need clarification in.</p>
<pre><code>def preprocess_dataset(dataset):
  &quot;&quot;&quot;Create batches of 5 examples, and limit to 3 batches.&quot;&quot;&quot;

  def map_fn(input):
    return collections.OrderedDict(
        x=tf.reshape(input['pixels'], shape=(-1, 784)),
        y=tf.cast(tf.reshape(input['label'], shape=(-1, 1)), tf.int64),
    )

  return dataset.batch(5).map(
      map_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE).take(5)
</code></pre>
<ol>
<li>what does <code>dataset.batch(5)</code> refer to? are these batches are taking from the data to training and the 3 are for testing?</li>
<li>what does <code>.take(5)</code> mean?</li>
</ol>
",17534198,,17534198,,44622.675,44622.675,Tff: define the usage of Tensorflow.take() function,<python><tensorflow><machine-learning><tensorflow-datasets><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71330639,1,71348195,,44623.00278,,2,878,"<p>I am new in federated learning
I am currently experimenting with a model by following the official TFF documentation. But I am stuck with an issue and hope I find some explanation here.</p>
<p>I am using my own dataset, the data are distributed in multiple files, each file is a single client (as I am planning to structure the model). and the dependant and independent variables have been defined.</p>
<p><strong>Now, my question is how can I split the data into training and testing sets in each client(file) in federated learning? like what we -normally- do in the centralized ML models</strong>
The following code is what I have implemented so far:
<em>note</em> my code is inspired by the official documentation and this <a href=""https://stackoverflow.com/questions/71289273/tff-train-test-client-split-to-partition-each-client-data"">post</a> which is almost similar to my application, but it aims to split the clients as training and testing clients itself while my aim is to split the data inside these clients.</p>
<pre><code>dataset_paths = {
  'client_0': '/content/drive/MyDrive/Colab Notebooks/1.csv',
  'client_1': '/content/drive/MyDrive/Colab Notebooks/2.csv',
  'client_2': '/content/drive/MyDrive/Colab Notebooks/3.csv'
}
record_defaults = [int(), int(), int(), int(), float(),float(),float(),
                   float(),float(),float(), int(), int(),float(),float(),int()]

@tf.function
def create_tf_dataset_for_client_fn(dataset_path):
   return tf.data.experimental.CsvDataset(dataset_path,
                                          record_defaults=record_defaults,
                                          header=True)

@tf.function
def add_parsing(dataset):
  def parse_dataset(*x):
    ## x defines the dependant varable &amp; y defines the independant 
    return OrderedDict([('x', x[-1]), ('y', x[1:-1])])
  return dataset.map(parse_dataset, num_parallel_calls=tf.data.AUTOTUNE)

source = tff.simulation.datasets.FilePerUserClientData(
  dataset_paths, create_tf_dataset_for_client_fn) 

source = source.preprocess(add_parsing)
## Creat the the datasets from client data 
dataset_creation=source.create_tf_dataset_for_client(source.client_ids[0-2])
print(dataset_creation)
&gt;&gt;&gt; _VariantDataset element_spec=OrderedDict([('x', TensorSpec(shape=(), dtype=tf.int32, name=None)), ('y', (TensorSpec(shape=(), dtype=tf.int32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int32, name=None)))])&gt;
## Convert the x into array(I think it is necessary for spliting to training and testing sets ) 
test= tf.nest.map_structure(lambda x: x.numpy(),next(iter(dataset_creation)))
print(test)
&gt;&gt;&gt; OrderedDict([('x', 1), ('y', (0, 1, 9, 85.0, 7.75, 85.0, 95.0, 75.0, 50.0, 6))])
</code></pre>
<p>My understanding to supervised ML is to split the data into training and testing sets as in the below code, I am not sure how to do this in Federated learning and whether it will work this way or not?</p>
<pre><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, random_state = 42) 
</code></pre>
<p>So, please I am looking for an explanation for this issue so I can proceed to the training phase.</p>
",18358769,,9657861,,44624.33194,44630.56597,splitting the data into training and testing in federated learning,<python><tensorflow><tensorflow-datasets><tensorflow-federated>,1,3,,,,CC BY-SA 4.0
71396780,1,71428053,,44628.60972,,1,233,"<p>I am working on pre-processed data that were already siloed into separated csv files to represent separated local data for federated learning.</p>
<p>To correct implement the federated learning with these multiple CSVs on TensorFlow Federated, I am just trying to reproduce the same approach with a toy example in the iris dataset. However, when trying to use the method <code>tff.simulation.datasets.TestClientData</code>, I am getting the error:</p>
<pre><code>TypeError: can't pickle _thread.RLock objects
</code></pre>
<p>The current code is as follows, first, load the three iris dataset CSV files (50 samples on each) into a dictionary from the filenames iris1.csv, iris2.csv, and iris3.csv:</p>
<pre><code>    silos = {}
    for silo in silos_files:
        silo_name = silo.replace(&quot;.csv&quot;, &quot;&quot;)
        silos[silo_name] = pd.read_csv(silos_path + silo)
        silos[silo_name][&quot;variety&quot;].replace({&quot;Setosa&quot; : 0, &quot;Versicolor&quot; : 1, &quot;Virginica&quot; : 2}, inplace=True)
</code></pre>
<p>Creating a new dict with tensors:</p>
<pre><code>    silos_tf = collections.OrderedDict()
    for key, silo in silos.items():
        silos_tf[key] = tf.data.Dataset.from_tensor_slices((silo.drop(columns=[&quot;variety&quot;]).values, silo[&quot;variety&quot;].values))
</code></pre>
<p>Finally, trying to converting the Tensorflow Dataset into a Tensorflow Federated Dataset:</p>
<pre><code>tff_dataset = tff.simulation.datasets.TestClientData(
    silos_tf
)
</code></pre>
<p>That raises the error:</p>
<pre><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-58-a4b5686509ce&gt; in &lt;module&gt;()
      1 tff_dataset = tff.simulation.datasets.TestClientData(
----&gt; 2     silos_tf
      3 )

/usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/simulation/datasets/from_tensor_slices_client_data.py in __init__(self, tensor_slices_dict)
     59     &quot;&quot;&quot;
     60     py_typecheck.check_type(tensor_slices_dict, dict)
---&gt; 61     tensor_slices_dict = copy.deepcopy(tensor_slices_dict)
     62     structures = list(tensor_slices_dict.values())
     63     example_structure = structures[0]

...

/usr/lib/python3.7/copy.py in deepcopy(x, memo, _nil)
    167                     reductor = getattr(x, &quot;__reduce_ex__&quot;, None)
    168                     if reductor:
--&gt; 169                         rv = reductor(4)
    170                     else:
    171                         reductor = getattr(x, &quot;__reduce__&quot;, None)

TypeError: can't pickle _thread.RLock objects
</code></pre>
<p>I also tried to use Python dictionary instead of OrderedDict but the error is the same. For this experiment, I am using Google Colab with <a href=""https://colab.research.google.com/github/tensorflow/federated/blob/main/docs/tutorials/working_with_client_data.ipynb"" rel=""nofollow noreferrer"">this notebook</a> as reference running with TensorFlow 2.8.0 and TensorFlow Federated version 0.20.0. I also used these previous questions as references:</p>
<p><a href=""https://stackoverflow.com/questions/58004272/is-there-a-reasonable-way-to-create-tff-clients-datat-sets"">Is there a reasonable way to create tff clients datat sets?</a></p>
<p><a href=""https://stackoverflow.com/questions/67147951/tensorflow-federated-python-simulation-has-no-attribute-fromtensorslicesclien"">&#39;tensorflow_federated.python.simulation&#39; has no attribute &#39;FromTensorSlicesClientData&#39; when using tff-nightly</a></p>
<p>I am not sure if this is a good way that derives for a case beyond the toy example, please, if any suggestion on how to bring already siloed data for TFF tests, I am thankful.</p>
",7946473,,,,,44630.71111,Loading multiple CSV files (silos) to compose Tensorflow Federated dataset,<tensorflow-datasets><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
71426658,1,,,44630.64236,,2,242,"<p>I am trying to implement federated learning with Tensorflow Federated. I am not able to run the tensorflow model on the dataset existing on the client machine. The process followed is as below.</p>
<ol>
<li>I have one server machine which host the dataset to be used for federated learning. I have created the model and TFF learning average process in the server.</li>
<li>The remote executor service is running on a client machine(GCP VM). The server broadcast is working fine and the model training is executing on the client machine.</li>
<li>But the data for the model training is passed as a parameter to client machine with the broadcast process. Is there a way to train the model with the data hosted on the client machine?</li>
</ol>
",18428250,,18428250,,44636.21389,44636.21389,Tensorflow Federated learning on multiple machines,<tensorflow-federated>,0,0,,,,CC BY-SA 4.0
71428904,1,71464579,,44630.75972,,3,1083,"<p>I am following TFF tutorials to build my FL model
My data is contained in different CSV files which are considered as different clients.
Following this <a href=""https://www.tensorflow.org/federated/tutorials/building_your_own_federated_learning_algorithm"" rel=""nofollow noreferrer"">tutorial</a>, and build the Keras model function as following</p>
<pre><code>@tf.function
def create_tf_dataset_for_client_fn(dataset_path):
   return tf.data.experimental.CsvDataset(dataset_path, 
                                          record_defaults=record_defaults,
                                          header=True)
   
@tf.function
def add_parsing(dataset):
  def parse_dataset(*x):
    return OrderedDict([('y', x[-1]), ('x', x[1:-1])])
  return dataset.map(parse_dataset, num_parallel_calls=tf.data.AUTOTUNE)
source = tff.simulation.datasets.FilePerUserClientData(
  dataset_paths, create_tf_dataset_for_client_fn) 

client_ids = sorted(source.client_ids)

# Make sure the client ids are tensor strings when splitting data.
source._client_ids = [tf.cast(c, tf.string) for c in source.client_ids] 
source = source.preprocess(add_parsing)

train, test = source.train_test_client_split(source, 1)

train_client_ids = train.client_ids

train_data = train.create_tf_dataset_for_client(train_client_ids[0])

def create_keras_model():
  initializer = tf.keras.initializers.GlorotNormal(seed=0)
  return tf.keras.models.Sequential([
      tf.keras.layers.Input(shape=(32,)),
      tf.keras.layers.Dense(10, kernel_initializer=initializer),
      tf.keras.layers.Softmax(),
  ])
def model_fn():
  keras_model = create_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=train_data.element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>Then I followed instructions and run other <code>@tff.tf_computation</code> functions as the tutorial, like <code>def server_init()</code>, <code>def initialize_fn()</code>, <code>def client_update()</code> and <code>def server_update()</code>. But when I run the def <code>client_update_fn()</code> I got this error</p>
<pre><code>ValueError: in user code:

   File &quot;&lt;ipython-input-14-cada45ffae0f&gt;&quot;, line 12, in client_update  *
       for batch in dataset:
   File &quot;/usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/learning/keras_utils.py&quot;, line 455, in forward_pass  *
       return self._forward_pass(batch_input, training=training)
   File &quot;/usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/learning/keras_utils.py&quot;, line 408, in _forward_pass  *
       predictions = self.predict_on_batch(inputs, training)
   File &quot;/usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/learning/keras_utils.py&quot;, line 398, in predict_on_batch  *
       return self._keras_model(x, training=training)
   File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_v1.py&quot;, line 740, in __call__  **
       self.name)
   File &quot;/usr/local/lib/python3.7/dist-packages/keras/engine/input_spec.py&quot;, line 200, in assert_input_compatibility
       raise ValueError(f'Layer &quot;{layer_name}&quot; expects {len(input_spec)} input(s),'

ValueError: Layer &quot;sequential&quot; expects 1 input(s), but it received 10 input tensors. Inputs received: [&lt;tf.Tensor 'x:0' shape=() dtype=int32&gt;, &lt;tf.Tensor 'x_1:0' shape=() dtype=int32&gt;, &lt;tf.Tensor 'x_2:0' shape=() dtype=int32&gt;, &lt;tf.Tensor 'x_3:0' shape=() dtype=float32&gt;, &lt;tf.Tensor 'x_4:0' shape=() dtype=float32&gt;, &lt;tf.Tensor 'x_5:0' shape=() dtype=float32&gt;, &lt;tf.Tensor 'x_6:0' shape=() dtype=float32&gt;, &lt;tf.Tensor 'x_7:0' shape=() dtype=float32&gt;, &lt;tf.Tensor 'x_8:0' shape=() dtype=float32&gt;, &lt;tf.Tensor 'x_9:0' shape=() dtype=int32&gt;]
</code></pre>
<p>Notes:</p>
<ul>
<li>each CSV file has 10 column as features (input) and one column as label (output).</li>
<li>I added the <code>shape=(32,)</code> arbitrary, I don't really know what are the shape of the data is in each column?</li>
</ul>
<p>So, the question is, how to feed the data to the keras model and overcome this error</p>
<p>Thanks in advance</p>
",17534198,,9657861,,44634.33819,44635.65833,"ValueError: Layer ""sequential"" expects 1 input(s), but it received 10 input tensors",<python><tensorflow><keras><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71441616,1,,,44631.68472,,2,266,"<p>The accuracy is stuck on 0.111 on every round. But the same model gives an accuracy of 91% in the normal tensorflow environment. The optimizer used in both scenarios is SGD. The model function :
`</p>
<pre><code>def model_fn():
 model=tf.keras.Sequential()
 model.add(tf.keras.applications.MobileNetV2(include_top = False, pooling = 'avg',
 weights = 'imagenet',input_shape=(96,96,3)))
 model.add(tf.keras.layers.Dense(10, activation = 'softmax'))
 model.layers[0].trainable = False
 return tff.learning.from_keras_model(model,input_spec=collections.OrderedDict([('x', 
 tf.TensorSpec(shape(None,96,96,3),dtype=tf.float32, name=None)),
         ('y', tf.TensorSpec(shape=(None,), dtype=tf.int32, name=None))]),
 loss=tf.keras.losses.SparseCategoricalCrossentropy(),
 metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>`</p>
",18432145,,,,,44631.68472,"On Mnist dataset, MobileNet is showing low accuracy in tff learning environment but shows high accuracy in tensorflow env. How to improve accuracy?",<tensorflow><machine-learning><deep-learning><tensorflow-federated><mobilenet>,0,1,,,,CC BY-SA 4.0
71441870,1,71514340,,44631.69653,,-2,930,"<p>While I am studying Federated Learning, I have some questions that popped up in my mind that needed some clarification.</p>
<ol>
<li>We first have defined clients, each client will be split into training and testing sets. The training data are used to train the local models. Now, what testing data are used for? are they used to test the global model? or to test each local model?</li>
<li>when training the global model, we first calculate the resulted weight of each local model, and then send it to the global model. In modeling the local clients, is there any validity check on the model itself before sending to the global model or it is sent anyway and then it will be updated by the global model.</li>
</ol>
<p>Are there any papers explaining these points?</p>
",17534198,,17534198,,44632.53958,45119.21181,Training the global and local model in federated learning,<tensorflow><machine-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
71470160,1,,,44634.63958,,1,39,"<p>I work with TFF, here is a part of my code :</p>
<pre><code>def create_keras_model():
    
    baseModel = tf.keras.applications.ResNet50(include_top=False, weights=None, input_tensor=tf.keras.Input(shape=(224, 224, 3)))

    for layer in baseModel.layers:
        layer.trainable = False
    return model
</code></pre>
<p>With this model I find test-accuracy value = <code>0.8</code>
Now, I would like to change <code>layer.trainable = True</code>, but the test-accuracy value decrease to <code>0.2</code> and loss becomes <code>12 </code>. which is not normal, can anyone tell why.</p>
",14253961,,14253961,,44686.31736,44686.31736,TFF: 'trainable=True ' causes decrinsing of accuracy,<tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
71496155,1,,,44636.47014,,1,91,"<p>The state object returned by iterative_process.initialize() is typically a Python container (tuple, collections.OrderedDict, etc) that contains numpy arrays. I would like that the value of state is not random, instead it begin from loaded model.
As the beginning, I write this :</p>
<pre><code>def create_keras_model():   
  Model = tf.keras.models.load_model(path)
  return Model
def model_fn(): 
    keras_model = create_keras_model()   
    return tff.learning.from_keras_model(keras_model..)
iterative_process = tff.learning.build_federated_averaging_process(model_fn=model_fn..)
state = iterative_process.initialize()
</code></pre>
<p>But test accuracy result does not change at all comparing by the normal case(if I don't load an external model).</p>
<p>That's why, I try this solution:</p>
<pre><code># initialize_fn() function
@tff.tf_computation
def server_init():
    model = model_fn()
    return model.trainable_variables

@tff.federated_computation
def initialize_fn():
    return tff.federated_value(server_init(), tff.SERVER) 

iterative_process = tff.templates.IterativeProcess(initialize_fn, next_fn)
state = iterative_process.initialize()
state['model'] = create_keras_model()
</code></pre>
<p>But I find this error:</p>
<pre><code>NameError: name 'next_fn' is not defined
</code></pre>
<p>So in my case, how can I define next_fn ?
Thanks</p>
",12682667,,12682667,,44636.55347,44636.55347,TFF : Modify the value of state,<tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
61677696,1,,,43959.46181,,3,1453,"<p>I have followed <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">this emnist tutorial</a> to create an image classification experiment (7 classes) with the aim of training a classifier on 3 silos of data with the TFF framework.</p>

<p>Before training begins, I convert the model to a tf keras model using <code>tff.learning.assign_weights_to_keras_model(model,state.model)</code> to evaluate on my validation set. Regardless of the label, the model only predicts one class. This is to be expected as no training of the model has occurred yet. However, I repeat this step after each federated averaging round and the problem persists. All validation images are predicted to one class. I also save the tf keras model weights after each round and make predictions on the test set - no changes.</p>

<p>Some of the steps I have taken to check the source of the issue:</p>

<ol>
<li>Checked if the tf keras model weights are updating when the FL model is converted after each round - they are updating.</li>
<li>Ensured that the buffer size is greater than the training dataset size for each client.</li>
<li>Compared the predictions to the class distribution in the training datasets. There is a class imbalance but the one class that the model predicts is not necessarily the majority class. Also, it is not always the same class. For the most part, it predicts only class 0.</li>
<li>Increased the number of rounds to 5 and epochs per round to 10. This is computationally very intensive as it is quite a large model being trained with approx 1500 images per client.</li>
<li>Investigated the TensorBoard logs from each training attempt. The training loss is decreasing as the round progresses.</li>
<li>Tried a much simpler model - basic CNN with 2 conv layers. This allowed me to greatly increase the number of epochs and rounds. When evaluating this model on the test set, it predicted 4 different classes but the performance remains very bad. This would indicate that I just would need to increase the number of rounds and epochs for my original model to increase the variation in predictions. This is difficult due the large training time that would be a result.</li>
</ol>

<p>Model details:</p>

<p>The model uses the XceptionNet as the base model with the weights unfrozen. This performs well on the classification task when all the training images are pooled into a global dataset. Our aim is to hopefully achieve a comparable performance with FL.</p>

<pre><code>base_model = Xception(include_top=False,
                      weights=weights,
                      pooling='max',
                      input_shape=input_shape)
x = GlobalAveragePooling2D()( x )
predictions = Dense( num_classes, activation='softmax' )( x )
model = Model( base_model.input, outputs=predictions )
</code></pre>

<p>Here is my training code:</p>

<pre><code>def fit(self):
    """"""Train FL model""""""
    # self.load_data()
    summary_writer = tf.summary.create_file_writer(
        self.logs_dir
    )
    federated_averaging = self._construct_iterative_process()
    state = federated_averaging.initialize()
    tfkeras_model = self._convert_to_tfkeras_model( state )
    print( np.argmax( tfkeras_model.predict( self.val_data ), axis=-1 ) )
    val_loss, val_acc = tfkeras_model.evaluate( self.val_data, steps=100 )

    with summary_writer.as_default():
        for round_num in tqdm( range( 1, self.num_rounds ), ascii=True, desc=""FedAvg Rounds"" ):

            print( ""Beginning fed avg round..."" )
            # Round of federated averaging
            state, metrics = federated_averaging.next(
                state,
                self.training_data
            )
            print( ""Fed avg round complete"" )
            # Saving logs
            for name, value in metrics._asdict().items():
                tf.summary.scalar(
                    name,
                    value,
                    step=round_num
                )
            print( ""round {:2d}, metrics={}"".format( round_num, metrics ) )
            tff.learning.assign_weights_to_keras_model(
                tfkeras_model,
                state.model
            )
            # tfkeras_model = self._convert_to_tfkeras_model(
            #     state
            # )
            val_metrics = {}
            val_metrics[""val_loss""], val_metrics[""val_acc""] = tfkeras_model.evaluate(
                self.val_data,
                steps=100
            )
            for name, metric in val_metrics.items():
                tf.summary.scalar(
                    name=name,
                    data=metric,
                    step=round_num
                )
            self._checkpoint_tfkeras_model(
                tfkeras_model,
                round_num,
                self.checkpoint_dir
            )
def _checkpoint_tfkeras_model(self,
                              model,
                              round_number,
                              checkpoint_dir):
    # Obtaining model dir path
    model_dir = os.path.join(
        checkpoint_dir,
        f'round_{round_number}',
    )
    # Creating directory
    pathlib.Path(
        model_dir
    ).mkdir(
        parents=True
    )
    model_path = os.path.join(
        model_dir,
        f'model_file_round{round_number}.h5'
    )
    # Saving model
    model.save(
        model_path
    )

def _convert_to_tfkeras_model(self, state):
    """"""Converts global TFF modle of TF keras model

    Takes the weights of the global model
    and pushes them back into a standard
    Keras model

    Args:
        state: The state of the FL server
            containing the model and
            optimization state

    Returns:
        (model); TF Keras model

    """"""
    model = self._load_tf_keras_model()
    model.compile(
        loss=self.loss,
        metrics=self.metrics
    )
    tff.learning.assign_weights_to_keras_model(
        model,
        state.model
    )
    return model

def _load_tf_keras_model(self):
    """"""Loads tf keras models

    Raises:
        KeyError: A model name was not defined
            correctly

    Returns:
        (model): TF keras model object

    """"""
    model = create_models(
        model_type=self.model_type,
        input_shape=[self.img_h, self.img_w, 3],
        freeze_base_weights=self.freeze_weights,
        num_classes=self.num_classes,
        compile_model=False
    )

    return model

def _define_model(self):
    """"""Model creation function""""""
    model = self._load_tf_keras_model()

    tff_model = tff.learning.from_keras_model(
        model,
        dummy_batch=self.sample_batch,
        loss=self.loss,
        # Using self.metrics throws an error
        metrics=[tf.keras.metrics.CategoricalAccuracy()] )

    return tff_model

def _construct_iterative_process(self):
    """"""Constructing federated averaging process""""""
    iterative_process = tff.learning.build_federated_averaging_process(
        self._define_model,
        client_optimizer_fn=lambda: tf.keras.optimizers.SGD( learning_rate=0.02 ),
        server_optimizer_fn=lambda: tf.keras.optimizers.SGD( learning_rate=1.0 ) )
    return iterative_process
</code></pre>
",13208966,,13208966,,43962.40556,43979.47847,Model performance not improving during federated learning training,<python><tensorflow><keras><deep-learning><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61786305,1,61789226,,43964.95625,,2,734,"<p>My goal is to load a base model from a .hdf5 file (it's a Keras model), and continue to train it with federated learning. Here is how I initialize the base model for FL:</p>

<pre><code>def model_fn():
    model = tf.keras.load_model(path/to/model.hdf5)
    return tff.learning.from_keras_model(model=model, 
                                         dummy_batch=db, 
                                         loss=loss, 
                                         metrics=metrics)

trainer = tff.learning.build_federated_averaging_process(model_fn)
state = trainer.initialize()
</code></pre>

<p>However, it seems like the resulting state.model weights are randomly initialized, and are different from my saved model. When I evaluate the model's performance even before any federated training, it performs as a randomly initialized model: 50% accuracy. Here's how I evaluate the performance:</p>

<pre><code>def evaluate(state):
    keras_model = tf.keras.models.load_model(path/to/model.hdf5, compile=False)
    tff.learning.assign_weights_to_keras_model(keras_model, state.model)
    keras_model.compile(loss=loss, metrics=metrics)
    return keras_model.evaluate(features, values)
</code></pre>

<p>How can I initialize a tff model with the saved model weights?</p>
",12949520,,12949520,,43965.66042,43967.81458,TFF loading a pre-trained Keras model,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
61882422,1,61882833,,43970.11736,,0,514,"<p>I ran the tensorflow federated tutorial code on <a href=""https://colab.research.google.com/github/tensorflow/federated/blob/v0.13.1/docs/tutorials/federated_learning_for_image_classification.ipynb"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/tensorflow/federated/blob/v0.13.1/docs/tutorials/federated_learning_for_image_classification.ipynb</a> . I got this error </p>

<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-17-d5336a451ad0&gt; in &lt;module&gt;()
      2     model_fn,
      3     client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
----&gt; 4     server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

2 frames
&lt;ipython-input-16-7b97120f96c2&gt; in model_fn()
      7       dummy_batch=sample_batch,
      8       loss=tf.keras.losses.SparseCategoricalCrossentropy(),
----&gt; 9       metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

TypeError: from_keras_model() got an unexpected keyword argument 'dummy_batch'
</code></pre>

<p>The provided notebook updates the <code>tensorflow_federated</code> to latest version, so tff version is 0.14.0. So in version 0.14.0, we no longer need to feed the dummy batch? Is usual tff working pipline has changed?</p>

<p>P.S. Downgrading <code>tensorflow_federated</code> to version 0.13.1 works.</p>
",10791187,,,,,43970.15139,`tensorflow_federated.learning.from_keras_model()` no longer contains 'dummy_batch' keyword?,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
62040659,1,,,43978.42639,,2,147,"<p>I'm currently researching with TFF and image classification (Federated Learning for Image Classification) emnist.</p>

<p>I'm looking at hyper parameters for the model learning rate and optimizer. Is grid search a good approach here ? . In a real world scenario would you simply sample clients/devices from the overall domain and if so if I was to do a grid search would I have to fix my client samples 1st. In which case does it make sense to do the grid search. </p>

<p>What would be a typical real world way of selecting parameters, ie is this more a heuristic approach. ?</p>

<p>Colin . . .</p>
",13626403,,730754,,44163.45486,44163.45486,Grid Search Applicable for TFF and FL.?,<grid-search><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
71506975,1,71508537,,44637.17014,,3,4504,"<p>Following the previous code <a href=""https://stackoverflow.com/questions/71428904/valueerror-layer-sequential-expects-1-inputs-but-it-received-10-input-tens"">here</a> I am in process to evaluate the federated learning model and I got couple of issues.
This is the code for evaluation</p>
<pre><code>central_test = test.create_tf_dataset_from_all_clients()
test_data = central_test.map(reshape_data)

# function that accepts a server state, and uses 
#Keras to evaluate on the test dataset.
def evaluate(server_state):
  keras_model = create_keras_model()
  keras_model.compile(
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  
  )
  keras_model.set_weights(server_state)
  keras_model.evaluate(central_test)

server_state = federated_algorithm.initialize()
evaluate(server_state)
</code></pre>
<p>this is the error message</p>
<pre><code>ValueError: Missing data for input &quot;input_2&quot;. You passed a data dictionary with keys ['y', 'x']. Expected the following keys: ['input_2']

</code></pre>
<p>So what would be the problem here?
and is the use of the method <code>create_tf_dataset_from_all_clients</code> in its right place? since -as it is written in the <a href=""https://www.tensorflow.org/federated/tutorials/building_your_own_federated_learning_algorithm"" rel=""nofollow noreferrer"">tutorial</a>- used for <strong>create a centralized evaluation dataset</strong>. why do we need to use centralized dataset?</p>
",17534198,,17534198,,44637.75556,44637.75556,"ValueError: Missing data for input ""input_2"". You passed a data dictionary with keys ['y', 'x']. Expected the following keys: ['input_2']",<python><tensorflow><keras><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71607216,1,,,44644.74236,,2,97,"<pre><code>I tried to print client updates as mentioned.

@tff.federated_computation
def aggregate_mnist_metrics_across_clients(metrics):
return 
{'num_examples': tff.federated_sum(metrics.num_examples),'loss': tff.federated_mean(metrics.loss, metrics.num_examples),'accuracy': tff.federated_mean(metrics.accuracy, metrics.num_examples),'per_client/num_examples': tff.federated_collect(metrics.num_examples),'per_client/loss': tff.federated_collect(metrics.loss),'per_client/accuracy': tff.federated_collect(metrics.accuracy)}
</code></pre>
<p>But it did not work. It displays blank values for a client on executing the first round. Can you please look into it. Thanks</p>
<p>round 1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('value_sum_process', ()), ('weight_sum_process', ())])), ('train', {'accuracy': 0.0990099, 'loss': 2.7817621, 'num_examples': 202.0, 'per_client/accuracy': &lt;ConcatenateDataset shapes: (), types: tf.float32&gt;, 'per_client/loss': &lt;ConcatenateDataset shapes: (), types: tf.float32&gt;, 'per_client/num_examples': &lt;ConcatenateDataset shapes: (), types: tf.float32&gt;})])</p>
",9703017,,,,,44646.83333,"how can print client local updates (loss, accuracy) in tensorflow federated",<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71630891,1,,,44646.78333,,1,92,"<p>I use tensorflow fedprox to implement federated learning.(tff.learning.algorithms.build_unweighted_fed_prox)</p>
<pre class=""lang-py prettyprint-override""><code>def model_fn():
    keras_model = create_keras_model()
    return tff.learning.from_keras_model(
        keras_model,
        input_spec=preprocessed_example_dataset.element_spec,
        loss=tf.keras.losses.SparseCategoricalCrossentropy(),
        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]
    )

iterative_process = tff.learning.algorithms.build_unweighted_fed_prox(
    model_fn, 0.001,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.001),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0)
)

import nest_asyncio
nest_asyncio.apply()

state = iterative_process.initialize()

for round in range(3, 11):
    state = iterative_process.next(state.state, federated_train_data)
    print('round {:2d}, metrics={}'.format(round, state.metrics))
</code></pre>
<p>and the result of training is:</p>
<p>round  3, 'sparse_categorical_accuracy'= 0.6435834</p>
<p>round  4, 'sparse_categorical_accuracy'= 0.6955319</p>
<p>round  5, 'sparse_categorical_accuracy'= 0.74295634</p>
<p>round  6, 'sparse_categorical_accuracy'= 0.78176934</p>
<p>round  7, 'sparse_categorical_accuracy'= 0.80838746</p>
<p>round  8, 'sparse_categorical_accuracy'= 0.8300672</p>
<p>round  9, 'sparse_categorical_accuracy'= 0.8486338</p>
<p>round 10, 'sparse_categorical_accuracy', 0.86639416</p>
<hr />
<p>but when I want to evaluate my model on test data I get error:</p>
<pre><code>evaluation = tff.learning.build_federated_evaluation(model_fn)
test_metrics = evaluation(state.state, federated_test_data)

TypeError: Mismatched number of elements between type spec and value in `to_representation_for_type`. Type spec has 2 elements, value has 5.
</code></pre>
<p>How do I fix it?</p>
",17945316,,1779532,,44648.18958,44648.18958,"Mismatched number of elements between type spec and value in `to_representation_for_type`. Type spec has 2 elements, value has 5",<python><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
71672074,1,71673359,,44650.23889,,0,233,"<p>I am trying to evaluate the Federated Learning model following this <a href=""https://www.tensorflow.org/federated/tutorials/building_your_own_federated_learning_algorithm"" rel=""nofollow noreferrer"">tutorial</a>. As in the code below</p>
<pre><code>test_data = test.create_tf_dataset_from_all_clients().map(reshape_data).batch(2)
test_data = test_data.map(lambda x: (x['x'], x['y']))

def evaluate(server_state):
  keras_model = create_keras_model()
  keras_model.compile(
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]  
  )
  keras_model.set_weights(server_state)
  keras_model.evaluate(test_data)

server_state = federated_algorithm.initialize()
evaluate(server_state)

&gt;&gt;&gt; 271/271 [==============================] - 1s 2ms/step - loss: 23.7232 - sparse_categorical_accuracy: 0.3173
</code></pre>
<p>after that, I train it for multiple rounds and then evaluate</p>
<pre><code>server_state = federated_algorithm.initialize()
for round in range(20):
  server_state = federated_algorithm.next(server_state, train_data)

evaluate(server_state)

&gt;&gt;&gt; 271/271 [==============================] - 1s 2ms/step - loss: 5193926.5000 - sparse_categorical_accuracy: 0.4576

</code></pre>
<p>I see that the accuracy increased, but the loss value is very large. Why is that and how can I fix it?
also, how can I see the train results of every round?</p>
",17534198,,,,,44650.32083,TFF: evaluating the federated learning model and got a large increase of loss value,<python><tensorflow><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
71680438,1,,,44650.66389,,1,118,"<p>I have designed the Federated Learning model with TensorFlow Federated framework. Defined the iterative process as below,</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.9))
</code></pre>
<p>I have 2 remote workers running the tffruntime remote executor service and the context for running computation is defined as <code>tff.backends.native.set_remote_python_execution_context(channels)</code>. When the model is broadcasted to the client with <code>iterative_process.next(state, train_data)</code>, how can we identify that the client metrics is aggregated and applied to the server model. Is the single api <code>build_federated_averaging_process</code> is enough to get the metrics from clients, aggregate and then update the server model? If means how can we identify that the server model is updated? Can anyone please help me to understand this.</p>
",18428250,,17534198,,44658.24028,44663.62708,How the centralized server model is updated with aggregated client metrics in TensorflowFederated,<tensorflow><machine-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
71710530,1,,,44652.71319,,1,285,"<p>I am building a federated learning model using Tensorflow federated, and I am following the tutorials provided in the official documentation.
As I can see, most of the implementations provided are using a neural network as the local ML model. As I just did in the following snippet.</p>
<pre><code>def create_keras_model():
  initializer = tf.keras.initializers.Zeros()
  return tf.keras.models.Sequential([
      tf.keras.layers.Input(shape=(9,)),
      tf.keras.layers.Dense(4, kernel_initializer=initializer),
      tf.keras.layers.Softmax(),
  ])
def model_fn():
  keras_model = create_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=train_data[0].element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>Since I am building a multi-classification model with (9) features and (4) target labels.
Can I use a different ML model for local training, like (logistic regression )? and how can I adjust that?</p>
",18358769,,,,,44652.71319,Train the local model in federated learning using logistic regression,<python><tensorflow><tensorflow-federated>,0,1,,,,CC BY-SA 4.0
71748346,1,,,44656.34375,,1,340,"<p>I am working with TensorFlow Federated framework and designed a keras model for a binary classification problem. I defined the iterative process with <code>tff.learning.build_federated_averaging_process</code> and broadcasted the model with
<code>state, metrics = iterative_process.next(state, train_data)</code></p>
<p>After the above steps are executed I tried to run the prediction,</p>
<pre class=""lang-py prettyprint-override""><code>    model_test=create_keras_model() # function defining the binary classification model
    model_test.compile(optimizer='adam',            
    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
                metrics=['accuracy'])
    pred_out=model_test.predict(a[0].take(20)) # a[0] is the dataset constructed with the function 
                                             create_tf_dataset_for_client()
    classes =( pred_out &gt;0.5 ).astype(&quot;int32&quot;)
    np.unique(classes)

    array([[0],
       [1],
       [0],
       [0],
       [1],
       [1],
       [1],
       [0],
       [0],
       [1],
       [1],
       [0],
       [1],
       [1],
       [0],
       [0],
       [0],
       [1],
       [1],
       [0]], dtype=int32)
</code></pre>
<p>But after applying the tff learning model weights of the state to the model, the prediction is not working as expected. It is showing the same value for all the rows.</p>
<pre class=""lang-py prettyprint-override""><code>    model_test=create_keras_model() # function defining the binary classification model
    state.model.assign_weights_to(model_test)
    pred_out=model_test.predict(a[0].take(20)) # a[0] is the dataset constructed with the function 
                                             create_tf_dataset_for_client()
    print(pred_out)

    array([[-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368],
       [-0.2798368]], dtype=float32)
</code></pre>
<p>Upon consecutive research, I understood that the the above value '-0.2798368' is the value in state Modelweights</p>
<pre class=""lang-py prettyprint-override""><code>    print(state.model.assign_weights_to(keras_model))
    ModelWeights(trainable=[array([[-4.984627  , -5.193449  , -5.790202  , 
    -5.5200233 , -5.5461893 ,
    -4.977145  , -5.4065394 , -5.619186  , -5.3337646 , -5.136057  ],
    [-0.5657665 , -5.8657775 , -5.3425145 , -5.2261133 , -5.330576  ,
    -5.9684296 , -5.4551187 , -5.3567815 , -4.8706098 , -5.7063856 ],
    [-5.6153154 , -5.9375963 , -5.4587545 , -5.689524  , -5.463484  ,
    -4.9066486 , -5.752383  , -0.3759068 , -5.4120364 , -5.8245053 ],
    [-5.2911777 , -5.42058   , -5.932811  , -5.4922986 , -0.41761395,
    -5.432293  , -5.309703  ,  0.31641293, -5.635701  , -5.7644367 ],
    [ 0.07086992, -5.0122833 , -5.2278    , -5.2102866 , -0.03762579,
    -0.43286362, -4.865974  , -0.3707862 , -5.9437294 , -5.1678157 ],
    [-5.6853213 , -5.467271  , -5.7508802 , -5.4324217 , -5.3518825 ,
    -5.033523  , -4.8834076 , -4.8871975 , -5.9014115 , -5.3266053 ],
    [-5.280035  , -5.763103  , -5.828321  , -5.780304  , -5.908666  ,
    -5.6955295 , -5.6714606 , -4.9686913 , -4.898386  , -5.12075   ],
    [-4.8388877 , -5.7745824 , -5.1134114 , -5.779592  , -5.616187  ,
    -4.870717  , -5.131807  , -5.9274936 , -5.345783  , -5.113287  ]],
    dtype=float32), array([-5.4049463, -5.4049444, -5.404945 , -5.404946 , 
    -5.404945 ,
    -5.4049444, -5.404945 , -5.404945 , -5.4049454, -5.4049444],
    dtype=float32), array([[ 4.972922 ],
    [-4.823935 ],
    [ 4.916144 ],
    [ 5.0096955],
    [-4.9212008],
    [-5.1436653],
    [ 4.8211393],
    [-4.8939514],
    [ 5.1752467],
    [-5.01398  ]], dtype=float32), **array([-0.2798368]**, dtype=float32)], 
    non_trainable=[])
</code></pre>
<ol>
<li>Do we need to apply the state model weights to the server model explicitly or the tff.learning.build_federated_averaging_process api will take care of updating the server model by default? It is given in the tff tutorial that &quot;The aggregate model delta is applied at the server by using the tf.keras.optimizers.Optimizer.apply_gradients method of the server optimizer.&quot;</li>
</ol>
<p>Any guidance/suggestions here as where am I going wrong?</p>
",18428250,,14692,,44672.52847,44728.55764,Keras model prediction after tensorflow federated learning,<python><tensorflow><keras><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
71822452,1,71834242,,44662.14722,,0,1734,"<p>I am applying federated averaging on my federated learning model. After running the model for thousands rounds the model still did not converged.
How can I increase the number of epochs in training, and how it differs from the number of rounds?
And how can I reach to convergence, since I tried to increase the number of rounds but it take long time to train (I am using Google Colab, and the execution time can not be more than 24 hours I also tried subscribed to Google Colab Pro to use the GPU but it did not work well)</p>
<p>The code and the training results are provided below</p>
<pre><code>train_data = [train.create_tf_dataset_for_client(c).repeat(2).map(reshape_data)
.batch(batch_size=50,num_parallel_calls=50)
 for c in train_client_ids]

iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.0001),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.9))

NUM_ROUNDS = 50000
state = iterative_process.initialize()

logdir = &quot;/tmp/logs/scalars/training/&quot;
summary_writer = tf.summary.create_file_writer(logdir)

with summary_writer.as_default():
  for round_num in range(0, NUM_ROUNDS):
    state, metrics = iterative_process.next(state, train_data)
    if (round_num% 1000) == 0:
      print('round {:2d}, metrics={}'.format(round_num, metrics))
      for name, value in metrics['train'].items():
        tf.summary.scalar(name, value, step=round_num)
</code></pre>
<p>And the output in shown in
<a href=""https://i.sstatic.net/SMC38.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/SMC38.png"" alt=""this image"" /></a></p>
",17534198,,17534198,,44662.28819,44662.87361,Epochs vs Rounds in federated learning,<python><tensorflow><google-colaboratory><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71839866,1,,,44663.37639,,1,863,"<p>i followed the instructions given by the official tf documentation, but i just cannot resolve the various problems encountered.
Did anyone have the experience installing tff on m1 mac and can show me your overall process?</p>
<pre><code>conda create -n federated python=3.8


conda activate federated

pip install --upgrade tensorflow_federated
</code></pre>
<p>everything seems to be fine according to the terminal output, however,
after</p>
<pre><code>import tensorflow_federated as tff
</code></pre>
<p>i got a RunTimeError:</p>
<pre><code>RuntimeError: This version of jaxlib was built using AVX instructions, which your CPU and/or operating system do not support. You may be able work around this issue by building jaxlib from source.
</code></pre>
<p>how to resolve this?</p>
",18780973,,18780973,,44675.65486,45183.61181,Can anyone give me a comprehensive guide to installing tensorflow-federated on M1 Mac?,<tensorflow><apple-m1><tensorflow-federated>,1,3,,,,CC BY-SA 4.0
71883746,1,,,44666.49861,,0,1819,"<p>I tried to implement federated learning based on the LSTM approach.</p>
<pre><code>def create_keras_model():
    model = Sequential()
    model.add(LSTM(32, input_shape=(3,1)))
    model.add(Dense(1))
    return model

def model_fn():
    keras_model = create_keras_model()
    return tff.learning.from_keras_model(
      keras_model,
      input_spec=(look_back, 1),
      loss=tf.keras.losses.mean_squared_error(),
      metrics=[tf.keras.metrics.mean_squared_error()])
</code></pre>
<p>but I got this error when I want to define iterative_process.</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.001),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

TypeError: Missing required positional argument
</code></pre>
<p>How do I fix it?</p>
",17945316,,,,,45001.86528,Missing required positional argument:,<python><tensorflow><lstm><tensorflow-federated><federated-learning>,1,1,,,,CC BY-SA 4.0
62063550,1,,,43979.47639,,1,339,"<p>I've been trying to characterize the learning process (accuracy and loss) on the Federated Learning for Image Classification notebook tutorial with TF Federated.</p>

<p>I'm seeing major improvements in speed of convergence by modifying the epoch hyperparameter. 
Changing epochs from 5, 10, 20 etc. But I'm also seeing major increase in training accuracy. 
I suspect overfitting is occurring, though then I evaluate on the test set accuracy is still high.</p>

<p>Wondering what is going on. ? </p>

<p>My understanding is that the epoch param controls the # of forward/back prop on each client per round of training. Is this correct ? 
So ie 10 rounds of training on 10 clients with 10 epochs would be 10 Epochs X 10 Clients X 10 rounds.
Realise a lager range of clients is needed etc but I was expecting to see poorer accuracy on the test set. </p>

<p>What can I do to see whats going on. Could I use the evaluation check with something like learning curves to to see if overfitting is occurring ?</p>

<p><code>test_metrics = evaluation(state.model, federated_test_data)</code>
Only appears to give a single data point, how can I get the individual test accuracy for each test example validated?</p>
",13626403,,4685471,,43979.63333,43980.5375,Tensorflow Federated Image Classification Example #Epochs has major effect. Is the model overfitting?,<machine-learning><deep-learning><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
62092301,1,,,43980.75972,,1,206,"<p>Please I need Help!
After writing my code of TFF, I would like to save my model So I add this line in the end of code </p>

<pre><code>ckpt_manager = checkpoint_manager.FileCheckpointManager(""model.h5"")
ckpt_manager.save_checkpoint(state, round_num=1)

</code></pre>

<p>The error was:</p>

<pre><code>TypeError: To be compatible with tf.contrib.eager.defun, Python functions must return zero or more Tensors; in compilation of &lt;function FileCheckpointManager.save_checkpoint.&lt;locals&gt;.&lt;lambda&gt; at 0x7f06b40de730&gt;, found return value of type &lt;class 'tensorflow_federated.python.common_libs.anonymous_tuple.AnonymousTuple'&gt;, which is not a Tensor.
</code></pre>
",12429601,,,,,43982.94722,TFF : TypeError while saving model,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
62273164,1,,,43991.01944,,0,3098,"<p>RuntimeError: Cannot run the event loop while another loop is running</p>

<p>Trying to setup tensorflow_federated in my local. All import versions are right:</p>

<p>CUDA = 10.1, </p>

<p>python = 3.6.9,</p>

<p>tensorflow = 2.2.0,</p>

<p>tf_federated = latest</p>

<p>This error is not happening in google Colab. But, happens in my local machine when I am trying to do any federated computations. I get the runtime error: 
RuntimeError: Cannot run the event loop while another loop is running</p>

<pre><code>RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-5-9c097e9baec9&gt; in &lt;module&gt;
----&gt; 1 tff.federated_computation(lambda: 'hi')()

~\AppData\Local\Continuum\anaconda3\envs\tflocal\lib\asyncio\base_events.py in run_forever(self)
    426         if events._get_running_loop() is not None:
    427             raise RuntimeError(
--&gt; 428                 'Cannot run the event loop while another loop is running')
    429         self._set_coroutine_wrapper(self._debug)
    430         self._thread_id = threading.get_ident()

RuntimeError: Cannot run the event loop while another loop is running
</code></pre>
",9799778,,,,,44346.75278,Cannot run the event loop when another loop is running,<tensorflow><tensorflow2.0><tensorflow-serving><tensorflow-federated>,2,1,,,,CC BY-SA 4.0
62298296,1,,,43992.32361,,1,126,"<p>I try to run a simple federated computation using tensorflow_federated.
tff.federated_computation() -> after running this, the kernel freezes and am not able to run other cells.</p>

<p>TF-Federated needs asyncio to prevent <a href=""https://github.com/tensorflow/federated/issues/842"" rel=""nofollow noreferrer"">this</a> error. </p>

<p>My code is available <a href=""https://github.com/tensorflow/federated/issues/869"" rel=""nofollow noreferrer"">here</a>. </p>
",9799778,,13329963,,43997.38819,43997.38819,Kernel freezes when running federated computation with tensorflow_federated and nest_asyncio,<tensorflow><jupyter-notebook><python-asyncio><tensorflow-federated><nest-asyncio>,1,0,,,,CC BY-SA 4.0
62311087,1,,,43992.7875,,-1,87,"<p>Does federated learning provide privacy securities for the model being trained? </p>
",13723023,,,,,43993.10625,Privacy Secrity for training model when using federated learning,<python><deep-learning><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
62323656,1,,,43993.49028,,4,397,"<p>Validating with typical AI/ML models is predicated on all the data being available locally. 
Splitting the data into e.g. 80/20 % split, 80% data for training, and 20% for test/evaluation. 
This scenario isnâ€™t applicable to the FL paradigm. </p>

<p>Using the evaluation function with TFF, should you validate at the individual <strong>client</strong> level or at a <strong>global</strong> level. i.e. </p>

<p>Next word prediction example scenario:
From the perspective of the solution developer, you may wish to evaluate model accuracy over a <strong>larger</strong> a number of users, but from the perspective of a <strong>single</strong> user, you want your next word prediction model to be performed for your personal needs.</p>

<p>Example, </p>

<pre><code>Eval Loop.
NUM_ROUNDS = 10
for round_num in range(1, NUM_ROUNDS+1):
...
  federated_test_data = random_clients(emnist_test.client_ids,10)
  test_metrics = evaluation(state.model, federated_test_data)
  print('Validation round {:2d}, metrics={}'.format(round_num, test_metrics))
...
</code></pre>

<p>Where you have a previously define function random_clients to randomly sample from the domain of available clients.? </p>

<p>Do you evaluate on a single client or on multiple clients?</p>
",13626403,,8709945,,43994.35347,43994.76875,"TFF Federated Learning, Evaluation Approach",<machine-learning><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
62332459,1,62350428,,43993.82778,,1,448,"<p>1: problem:
I have the need to use a custom data set in a tff simulation. I have built on the tff/python/research/compression example ""run_experiment.py"". 
The error: </p>

<pre><code>  File ""B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""&lt;ipython-input-2-47998fd56829&gt;"", line 1, in &lt;module&gt;
    runfile('B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py', args=['--experiment_name=temp', '--client_batch_size=20', '--client_optimizer=sgd', '--client_learning_rate=0.2', '--server_optimizer=sgd', '--server_learning_rate=1.0', '--total_rounds=200', '--rounds_per_eval=1', '--rounds_per_checkpoint=50', '--rounds_per_profile=0', '--root_output_dir=B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/logs/fed_out/'], wdir='B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection')
  File ""B:\tools and software\PyCharm 2020.1\plugins\python\helpers\pydev\_pydev_bundle\pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""B:\tools and software\PyCharm 2020.1\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py"", line 292, in &lt;module&gt;
    app.run(main)
  File ""B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py"", line 285, in main
    train_main()
  File ""B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py"", line 244, in train_main
    input_spec=input_spec),
  File ""B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py"", line 193, in model_builder
    metrics=[tf.keras.metrics.Accuracy()]
  File ""B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\learning\keras_utils.py"", line 125, in from_keras_model
    if len(input_spec) != 2:
TypeError: object of type 'TensorSpec' has no len()
</code></pre>

<p>highlighting: <strong>TypeError: object of type 'TensorSpec' has no len()</strong></p>

<p>2: have tried:
I have looked at the response to: <a href=""https://stackoverflow.com/questions/61034455/tensorflow-federated-how-can-i-write-an-input-spec-for-a-model-with-more-than-o"">TensorFlow Federated: How can I write an Input Spec for a model with more than one input</a> 
describing what would be needed to produce a custom input spec for. 
I might be miss understanding input spec.</p>

<p>If I don't need to do this, and there is a better way, please tell.</p>

<p>3: source:</p>

<pre><code>    df = get_train_data(sysarg)
    x_train, x_opt, x_test = np.split(df.sample(frac=1,
                                                random_state=17),
                                      [int(1 / 3 * len(df)), int(2 / 3 * len(df))])

    x_train, x_opt, x_test = create_scalar(x_opt, x_test, x_train)
    input_spec = tf.nest.map_structure(tf.TensorSpec.from_tensor, tf.convert_to_tensor(x_train))
</code></pre>
",13716568,,,,,43994.77292,"TFF: Custom input spec with custom data set - TypeError: object of type 'TensorSpec"" has no len()",<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71898178,1,,,44667.975,,1,161,"<p>I want to evaluate my federated learning model using <code>tff.learning.build_federated_evaluation</code>. Initially, got reasonable results. but can I run the evaluation process for multiple rounds (as in the training phase done <a href=""https://stackoverflow.com/questions/71822452/epochs-vs-rounds-in-federated-learning"">here</a>) to get more stable results?</p>
<p>The evaluation code is provided below.</p>
<pre><code>train, test = source.train_test_client_split(source, 2,seed=0)
test_client_ids = test.client_ids

test_data= [test.create_tf_dataset_from_all_clients().map(reshape_data)
.batch(batch_size=10)
 for c in test_client_ids]

eval_process=tff.learning.build_federated_evaluation(model_fn)

eval_process(state.model, test_data)

</code></pre>
<p>The evaluation output.</p>
<pre><code>OrderedDict([('eval',
              OrderedDict([('sparse_categorical_accuracy', 0.53447974),
                           ('loss', 1.0230521),
                           ('num_examples', 11514),
                           ('num_batches', 1152)]))])
</code></pre>
",17534198,,,,,44672.52708,Use tff.learning.build_federated_evaluation for multiple rounds,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71899247,1,,,44668.18194,,1,204,"<pre><code>iterative_process = tff.learning.algorithms.build_unweighted_fed_prox( 
    model_fn,
    proximal_strength= 0.5,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

state, metrics = iterative_process.next(state, federated_train_data)
print('round  1, metrics={}'.format(metrics))
</code></pre>
<p>On executing the round 1, it throws  (TypeError: cannot unpack non-iterable LearningProcessOutput object).</p>
<p>It was working fine when we use Fedavg, but not with fedprox</p>
",18157505,,17534198,,44678.59583,44678.59583,fedprox tensorflow federated (TypeError: cannot unpack non-iterable LearningProcessOutput object),<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
71988768,1,72001769,,44675.55,,1,47,"<p>I have a TFF code that takes a slightly different optimization path while training across different runs, despite having set all the operator-level seeds, numpy seeds for sampling clients in each round, etc. The <a href=""https://www.tensorflow.org/federated/faq#how_can_i_ensure_randomness_in_tff_matches_my_expectations"" rel=""nofollow noreferrer"">FAQ section on TFF website</a> does talk about randomness and expectation in TFF, but I found the answer slightly confusing. Is it the case that some aspects of the randomness can't be directly controlled even after setting all the operator-level seeds that one could; because one can't control the way sub-sessions are started and ended?</p>
<p>To be more specific, these are all the operator-level seeds that my code already sets: <code>dataset.shuffle, create_tf_dataset_from_all_clients, keras.initializers</code> and <code>np.random.seed</code> for per-round client sampling (which uses numpy). I have verified that the initial model state is the same across runs, but as soon as training starts, the model states start diverging across different runs. The divergence is gradual/slow in most cases, but not always.</p>
<p>The code is quite complex, so not adding it here.</p>
",4623996,,,,,44676.63194,"Reproducibility, Controlling Randomness, Operator-level Randomness in TFF",<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
72022654,1,,,44678.10833,,2,1177,"<pre><code>eval_model = None
for round_num in range(1, 51):
    state, tff_metrics = iterative_process.next(state, federated_train_data)
    eval_model = create_keras_model()
    eval_model.compile(optimizer=optimizers.SGD(learning_rate=0.3),loss=losses.SparseCategoricalCrossentropy(),metrics=[metrics.SparseCategoricalAccuracy()])
    tff.learning.assign_weights_to_keras_model(eval_model, state.model)
    ev_result = eval_model.evaluate(x_test, y_test, verbose=0)
    print('round {:2d}, metrics={}'.format(round_num, tff_metrics))
    print(f&quot;Eval loss : {ev_result[0]} and Eval accuracy : {ev_result[1]}&quot;)
    tff_train_acc.append(float(tff_metrics.sparse_categorical_accuracy))
    tff_val_acc.append(ev_result[1])
    tff_train_loss.append(float(tff_metrics.loss))
    tff_val_loss.append(ev_result[0])
</code></pre>
<p>It throws an error that we cannot assign weights. Earlier it was working.</p>
",18157505,,12520740,,44679.18333,45058.24306,AttributeError: module 'tensorflow_federated.python.learning' has no attribute 'assign_weights_to_keras_model',<tensorflow><tensorflow-federated>,2,1,,,,CC BY-SA 4.0
72035825,1,73571436,,44678.92222,,1,2175,"<p>I'm working in colab notebook, and the importing of tff (import tensorflow_federated as tff) was working for months, but suddenly, now when I try to import tff as usual I faced this problem..</p>
<pre><code>!pip install --quiet --upgrade tensorflow-federated
!pip install --quiet --upgrade tensorflow-model-optimization
!pip install --quiet --upgrade nest-asyncio

import nest_asyncio
nest_asyncio.apply()

import numpy as np
import tensorflow as tf
import tensorflow_federated as tff
from tensorflow_model_optimization.python.core.internal import tensor_encoding as te

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-7-c8d605e9ca2e&gt; in &lt;module&gt;()
      2 import numpy as np
      3 import tensorflow as tf
----&gt; 4 import tensorflow_federated as tff
      5 
      6 from tensorflow_model_optimization.python.core.internal import tensor_encoding as te

7 frames
/usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/common_libs/structure.py in &lt;module&gt;()
    263 
    264 def to_odict(struct: Struct,
--&gt; 265              recursive: bool = False) -&gt; collections.OrderedDict[str, Any]:
    266   &quot;&quot;&quot;Returns `struct` as an `OrderedDict`, if possible.
    267 

TypeError: 'type' object is not subscriptable
</code></pre>
<p>Even when I run it in the colab tutorial itself! in this link <a href=""https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_image_classification.ipynb"" rel=""nofollow noreferrer"">https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials/federated_learning_for_image_classification.ipynb</a> I have the same issue!</p>
<p>Appreciate any idea or suggestions!</p>
",18969005,,,,,44805.62014,TypeError: 'type' object is not subscriptable when importing tensorflow_federated as tff,<tensorflow><typeerror><google-colaboratory><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
72052364,1,,,44680.12778,,0,156,"<p>I'm trying train a federated model for the mnist dataset. I am using the code avaible at <a href=""https://www.tensorflow.org/federated/tutorials/simulations"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/simulations</a> for the setup.
The dataset version being used is the the one from keras (not the federated version from leaf that is used in tff). I'm making a partition of it, saving it on a dictionary and implementing my ClientData instance with <code>tff.simulation.datasets.TestClientData</code>.<br />
Applying this change works just fine. However, if I change the model from the simulation, every round gives me a ~0.1 accuracy.</p>
<p>The model in the tutorial is as simple as it can get, an input layer of 28*28=784 neurons stacked over an output layer of dim 10 with Softmax activation:</p>
<pre><code>model = tf.keras.models.Sequential([
  tf.keras.layers.InputLayer(input_shape=(784,)), 
  tf.keras.layers.Dense(units=10, kernel_initializer='zeros'),
  tf.keras.layers.Softmax(),
])
</code></pre>
<p>And the new model is a cnn:</p>
<pre><code> model = tf.keras.Sequential(
        [
            tf.keras.layers.Conv2D(
                16,
                8,
                strides=2,
                padding=&quot;same&quot;,
                activation=&quot;relu&quot;,
                input_shape=(28, 28, 1),
            ),
            tf.keras.layers.MaxPool2D(2, 1),
            tf.keras.layers.Conv2D(
                32, 4, strides=2, padding=&quot;valid&quot;, activation=&quot;relu&quot;
            ),
            tf.keras.layers.MaxPool2D(2, 1),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(32, activation=&quot;relu&quot;),
            tf.keras.layers.Dense(10),
        ]
    )
</code></pre>
<p>Accuracy changed from round to round on the first case, increasing, reaching 0.94 quite fast.
On the second case I ran it for about 240 rounds with 3 fixed clients, 20k elements each, 10 epochs, batch size 32. Still couldn't get out of the ~0.1 accuracy and loss of ~2.3</p>
<p>The model works fine for this dataset. I already tested it on a centrilized version and a federated version using Flower framework reaching 0.99 accuracy. But for some reason I can't make it work on tff.</p>
<p>Environment:
MacOs BigSur
tensorflow==2.8.0
tensorflow-federated==0.22.0</p>
<p>I expect the metrics and loss to change more. Could it be that there is a problem with using other Models?</p>
<p>Full code:</p>
<pre><code>from tensorflow.keras.datasets import cifar10, mnist
import numpy as np

EPOCHS = 10
BATCH_SIZE = 32

# ROUND_CLIENTS &lt;= NUM_CLIENTS
ROUND_CLIENTS = 3
NUM_CLIENTS = 3

NUM_ROUNDS = 400

    
def make_client(num_clients,X, y):
    total_image_count = len(X)
    image_per_set = int(np.floor(total_image_count/num_clients))

    client_train_dataset = collections.OrderedDict()
    for i in range(1, num_clients+1):
        client_name = i-1
        start = image_per_set * (i-1)
        end = image_per_set * i

        print(f&quot;Adding data from {start} to {end} for client : {client_name}&quot;)
        data = collections.OrderedDict((('label', y[start:end]), ('pixels', X[start:end])))
        client_train_dataset[client_name] = data
    
    train_dataset = tff.simulation.datasets.TestClientData(client_train_dataset)
    
    return train_dataset


def preprocess(X: np.ndarray, y: np.ndarray):
    &quot;&quot;&quot;Basic preprocessing for MNIST dataset.&quot;&quot;&quot;
    X = np.array(X, dtype=np.float32) / 255
    X = X.reshape((X.shape[0], 28, 28, 1))

    y = np.array(y, dtype=np.int32)
    y = tf.keras.utils.to_categorical(y, num_classes=10)

    return X, y


(X_train, y_train), (X_test, y_test) = mnist.load_data()
(X_train, y_train) = preprocess(X_train, y_train)
(X_test, y_test) = preprocess(X_test, y_test)

mnistFedTrain = make_client(NUM_CLIENTS,X_train,y_train)

def map_fn(example):
    return collections.OrderedDict(
      x=example['pixels'], 
        y=example['label'])


def client_data(client_id):
    ds = mnistFedTrain.create_tf_dataset_for_client(mnistFedTrain.client_ids[client_id])
    return ds.repeat(EPOCHS).shuffle(500).batch(BATCH_SIZE).map(map_fn)


train_data = [client_data(n) for n in range(ROUND_CLIENTS)]
element_spec = train_data[0].element_spec

def create_cnn_model() -&gt; tf.keras.Model:
    &quot;&quot;&quot;Returns a sequential keras CNN Model.&quot;&quot;&quot;
    return tf.keras.Sequential(
        [
            tf.keras.layers.Conv2D(
                16,
                8,
                strides=2,
                padding=&quot;same&quot;,
                activation=&quot;relu&quot;,
                input_shape=(28, 28, 1),
            ),
            tf.keras.layers.MaxPool2D(2, 1),
            tf.keras.layers.Conv2D(
                32, 4, strides=2, padding=&quot;valid&quot;, activation=&quot;relu&quot;
            ),
            tf.keras.layers.MaxPool2D(2, 1),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(32, activation=&quot;relu&quot;),
            tf.keras.layers.Dense(10),
        ]
    )

def model_fn():
    model = create_cnn_model()
    return tff.learning.from_keras_model(
      model,
      input_spec=element_spec,
      loss=tf.keras.losses.CategoricalCrossentropy(
                from_logits=True, reduction=tf.losses.Reduction.NONE
            ),
      metrics=[tf.keras.metrics.CategoricalAccuracy()]
    )


trainer = tff.learning.build_federated_averaging_process(
    model_fn, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.02))


def evaluate(num_rounds=NUM_ROUNDS):
    state = trainer.initialize()
    for i in range(num_rounds):
        t1 = time.time()
        state, metrics = trainer.next(state, train_data)
        t2 = time.time()
        print('\n Round {r}: metrics {m}, round time {t:.2f} seconds'.format(
            m=metrics['train'], r=i, t=t2 - t1))

t1 = time.time()
evaluate(NUM_ROUNDS)
t2 = time.time()

print('Seconds:',t2 - t1,' = Minutes:', (t2 - t1)/60)
</code></pre>
<p>I've had a similar problem with other models as well, e.g.  MobileNetV2 implemented in tf for cifar10:
`model = tf.keras.applications.MobileNetV2((32, 32, 3), classes=10, weights=None)</p>
",18982150,,18982150,,44680.76806,44680.76806,Models in Tensorflow Federated get stucked at 0.1 accuracy,<python><tensorflow><machine-learning><keras><tensorflow-federated>,0,4,,,,CC BY-SA 4.0
72059732,1,,,44680.61528,,0,390,"<p>I have TensorFlow (2.8.0) installed and running on my Apple Silicon M1 MacBook. But facing dependency error on trying to install tensorflow-federated with the below error on running <code>pip install tensorflow-federated</code> in terminal :</p>
<pre><code>ERROR: Cannot install tensorflow-federated==0.1.0, tensorflow-federated==0.10.0, tensorflow-federated==0.10.1, tensorflow-federated==0.11.0, tensorflow-federated==0.12.0, tensorflow-federated==0.13.0, tensorflow-federated==0.13.1, tensorflow-federated==0.14.0, tensorflow-federated==0.15.0, tensorflow-federated==0.16.0, tensorflow-federated==0.16.1, tensorflow-federated==0.17.0, tensorflow-federated==0.18.0, tensorflow-federated==0.19.0, tensorflow-federated==0.2.0, tensorflow-federated==0.20.0, tensorflow-federated==0.21.0, tensorflow-federated==0.22.0, tensorflow-federated==0.3.0, tensorflow-federated==0.4.0, tensorflow-federated==0.5.0, tensorflow-federated==0.6.0, tensorflow-federated==0.7.0 and tensorflow-federated==0.9.0 because these package versions have conflicting dependencies.

The conflict is caused by:
    tensorflow-federated 0.22.0 depends on tensorflow~=2.8.0
    tensorflow-federated 0.21.0 depends on tensorflow~=2.8.0
    tensorflow-federated 0.20.0 depends on tensorflow~=2.8.0
    tensorflow-federated 0.19.0 depends on tensorflow~=2.5.0
    tensorflow-federated 0.18.0 depends on tensorflow-addons~=0.12.0
    tensorflow-federated 0.17.0 depends on tensorflow~=2.3.0
    tensorflow-federated 0.16.1 depends on tensorflow-addons~=0.10.0
    tensorflow-federated 0.16.0 depends on tensorflow-addons~=0.10.0
    tensorflow-federated 0.15.0 depends on tensorflow-addons~=0.10.0
    tensorflow-federated 0.14.0 depends on tensorflow~=2.2.0
    tensorflow-federated 0.13.1 depends on tensorflow~=2.1.0
    tensorflow-federated 0.13.0 depends on tensorflow~=2.1.0
    tensorflow-federated 0.12.0 depends on tensorflow~=2.1.0
    tensorflow-federated 0.11.0 depends on tensorflow-addons~=0.6.0
    tensorflow-federated 0.10.1 depends on tensorflow-addons~=0.6.0
    tensorflow-federated 0.10.0 depends on tensorflow-addons~=0.6.0
    tensorflow-federated 0.9.0 depends on tf-nightly
    tensorflow-federated 0.7.0 depends on tf-nightly
    tensorflow-federated 0.6.0 depends on tf-nightly
    tensorflow-federated 0.5.0 depends on tf-nightly
    tensorflow-federated 0.4.0 depends on tensorflow~=1.13
    tensorflow-federated 0.3.0 depends on tensorflow~=1.13
    tensorflow-federated 0.2.0 depends on tensorflow~=1.13
    tensorflow-federated 0.1.0 depends on tensorflow&gt;=1.13.0rc2

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip attempt to solve the dependency conflict

ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts
</code></pre>
",17405676,,,,,44699.06875,Unable to install 'Tensorflow Federated' on Apple Silicon M1,<tensorflow><apple-m1><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
72076723,1,72077739,,44682.52083,,1,3298,"<p>I'm testing this tutorial with non-IID distribution for federated learning:
<a href=""https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression</a></p>
<p>In this posted question <a href=""https://stackoverflow.com/questions/64970504/tensorflow-federated-how-to-tune-non-iidness-in-federated-dataset"">TensorFlow Federated: How to tune non-IIDness in federated dataset?</a> it suggested to use tff.simulation.datasets.build_single_label_dataset() as a way to produce a non-IID distribution for the dataset.</p>
<p>I tried to apply that first (see the code) and got an error !</p>
<pre><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(
    only_digits=False)
emnist_train1 = tff.simulation.datasets.build_single_label_dataset(
  emnist_train.create_tf_dataset_from_all_clients(),
  label_key='label', desired_label=1)

print(emnist_train1.element_spec)
</code></pre>
<blockquote>
<blockquote>
<p>OrderedDict([('label', TensorSpec(shape=(), dtype=tf.int32, name=None)), ('pixels', TensorSpec(shape=(28, 28), dtype=tf.float32, name=None))])</p>
</blockquote>
</blockquote>
<pre><code>print(next(iter(emnist_train1))['label'])
</code></pre>
<blockquote>
<blockquote>
<p>tf.Tensor(1, shape=(), dtype=int32)</p>
</blockquote>
</blockquote>
<pre><code>MAX_CLIENT_DATASET_SIZE = 418

CLIENT_EPOCHS_PER_ROUND = 1
CLIENT_BATCH_SIZE = 20
TEST_BATCH_SIZE = 500

def reshape_emnist_element(element):
  return (tf.expand_dims(element['pixels'], axis=-1), element['label'])

def preprocess_train_dataset(dataset):
  return (dataset
          .shuffle(buffer_size=MAX_CLIENT_DATASET_SIZE)
          .repeat(CLIENT_EPOCHS_PER_ROUND)
          .batch(CLIENT_BATCH_SIZE, drop_remainder=False)
          .map(reshape_emnist_element))

emnist_train1 = emnist_train1.preprocess(preprocess_train_dataset)

&gt;&gt; ---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-17-cda96c33a0f6&gt; in &lt;module&gt;()
     15           .map(reshape_emnist_element))
     16 
---&gt; 17 emnist_train1 = emnist_train1.preprocess(preprocess_train_dataset)

AttributeError: 'MapDataset' object has no attribute 'preprocess'
</code></pre>
<p>Since dataset is filtered, it is not able to preprocess!
So, in this case, it is filtered based on what label?</p>
<pre><code>... label_key='label', desired_label=1)
</code></pre>
<p><strong>the desired label = 1 for which label in EMNIST?</strong></p>
<p><strong>My Question is:</strong></p>
<p>How can I apply this function tff.simulation.datasets.build_single_label_dataset()
to get non-IID dataset <em><strong>(different number of samples for each client)</strong></em> in this specific tutorial ! <a href=""https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression</a> in details without error regarding the filtered dataset!</p>
<p>Appreciate any help!</p>
<p>Thanks a lot!</p>
",18969005,,,,,44682.61667,AttributeError: 'MapDataset' object has no attribute 'preprocess' in tensorflow_federated tff,<python><tensorflow><google-colaboratory><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72086887,1,,,44683.52986,,1,126,"<p>I'm testing this tutorial with non-IID distribution for federated learning: <a href=""https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression</a>, and using <code>tff.simulation.datasets.build_single_label_dataset()</code> as a way to produce a non-IID distribution for the dataset.</p>
<p>But I faced an error regarding keras values in the <code>input_spec</code>.</p>
<p>The code:</p>
<pre><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(
    only_digits=False)

emnist_train1 = tff.simulation.datasets.build_single_label_dataset(
  emnist_train.create_tf_dataset_from_all_clients(),
  label_key='label', desired_label=1)

MAX_CLIENT_DATASET_SIZE = 418

CLIENT_EPOCHS_PER_ROUND = 1
CLIENT_BATCH_SIZE = 20
TEST_BATCH_SIZE = 500

def reshape_emnist_element(element):
  return (tf.expand_dims(element['pixels'], axis=-1), element['label'])

def preprocess_train_dataset(dataset):
  return (dataset
          .shuffle(buffer_size=MAX_CLIENT_DATASET_SIZE)
          .repeat(CLIENT_EPOCHS_PER_ROUND)
          .batch(CLIENT_BATCH_SIZE, drop_remainder=False)
          .map(reshape_emnist_element))

emnist_train1 = preprocess_train_dataset(emnist_train1)

import random
NUM_CLIENTS = 100

client_datasets = [
   emnist_train1.take(random.randint(1, CLIENT_BATCH_SIZE))
   for _ in range(NUM_CLIENTS)
]

emnist_train1 = client_datasets

def create_original_fedavg_cnn_model(only_digits=True):
  &quot;&quot;&quot;The CNN model used in https://arxiv.org/abs/1602.05629.&quot;&quot;&quot;
  data_format = 'channels_last'

  max_pool = functools.partial(
      tf.keras.layers.MaxPooling2D,
      pool_size=(2, 2),
      padding='same',
      data_format=data_format)
  conv2d = functools.partial(
      tf.keras.layers.Conv2D,
      kernel_size=5,
      padding='same',
      data_format=data_format,
      activation=tf.nn.relu)

  model = tf.keras.models.Sequential([
      tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),
      conv2d(filters=32),
      max_pool(),
      conv2d(filters=64),
      max_pool(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(512, activation=tf.nn.relu),
      tf.keras.layers.Dense(10 if only_digits else 62),
      tf.keras.layers.Softmax(),
  ])

  return model

input_spec = emnist_train.create_tf_dataset_for_client(
    emnist_train.client_ids[0]).element_spec

def tff_model_fn():
  keras_model = create_original_fedavg_cnn_model()
  return tff.learning.from_keras_model(
      keras_model=keras_model,
      input_spec=input_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

federated_averaging = tff.learning.build_federated_averaging_process(
    model_fn=tff_model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
&lt;ipython-input-11-7661a3b7dc92&gt; in &lt;module&gt;()
      3     model_fn=tff_model_fn,
      4     client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
----&gt; 5     server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

6 frames
/usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/learning/keras_utils.py in from_keras_model(keras_model, loss, input_spec, loss_weights, metrics)
    176           'The `input_spec` is a collections.abc.Mapping (e.g., a dict), so it '
    177           'must contain an entry with key `\'{}\'`, representing the input(s) '
--&gt; 178           'to the Keras model.'.format(model_lib.MODEL_ARG_NAME))
    179     if model_lib.MODEL_LABEL_NAME not in input_spec:
    180       raise ValueError(
</code></pre>
<blockquote>
<p>ValueError: The <code>input_spec</code> is a collections.abc.Mapping (e.g., a dict), so it must contain an entry with key <code>'x'</code>, representing the input(s) to the Keras model.</p>
</blockquote>
<p>What does that mean? How can I solve it?</p>
",18969005,,4621513,,44683.65625,44683.65625,"ValueError: The `input_spec` is a collections.abc.Mapping (e.g., a dict), so it must contain an entry with key `'x'`, representing the input(s)",<python><keras><google-colaboratory><tensorflow-federated><federated-learning>,0,1,,,,CC BY-SA 4.0
72121192,1,,,44686.09167,,0,275,"<p>I tried to implement federated learning. (Using TensorFlow federated core)</p>
<pre><code>def create_keras_model():
    model = Sequential()
    model.add(Conv2D(16, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(226,232,1)))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    
    model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    
    model.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    
    model.add(Flatten())

    model.add(Dense(128, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(10, activation='softmax'))
    return model



def model_fn():
      keras_model = create_keras_model()
      return tff.learning.from_keras_model(
          keras_model,
          input_spec=federated_train_data[0].element_spec,
          loss=tf.keras.losses.SparseCategoricalCrossentropy(),
          metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

def initialize_fn():
  model = model_fn()
  return model.trainable_variables

def next_fn(server_weights, federated_dataset):
  # Broadcast the server weights to the clients.
  server_weights_at_client = broadcast(server_weights)

  # Each client computes their updated weights.
  client_weights = client_update(federated_dataset, server_weights_at_client)

  # The server averages these updates.
  mean_client_weights = mean(client_weights)

  # The server updates its model.
  server_weights = server_update(mean_client_weights)

  return server_weights


@tf.function
def client_update(model, dataset, server_weights, client_optimizer):
  &quot;&quot;&quot;Performs training (using the server model weights) on the client's dataset.&quot;&quot;&quot;
  # Initialize the client model with the current server weights.
  client_weights = model.trainable_variables
  # Assign the server weights to the client model.
  tf.nest.map_structure(lambda x, y: x.assign(y),
                        client_weights, server_weights)

  # Use the client_optimizer to update the local model.
  for batch in dataset:
    with tf.GradientTape() as tape:
      # Compute a forward pass on the batch of data
      outputs = model.forward_pass(batch)

    # Compute the corresponding gradient
    grads = tape.gradient(outputs.loss, client_weights)
    grads_and_vars = zip(grads, client_weights)

    # Apply the gradient using a client optimizer.
    client_optimizer.apply_gradients(grads_and_vars)

  return client_weights

@tf.function
def server_update(model, mean_client_weights):
  &quot;&quot;&quot;Updates the server model weights as the average of the client model weights.&quot;&quot;&quot;
  model_weights = model.trainable_variables
  # Assign the mean client weights to the server model.
  tf.nest.map_structure(lambda x, y: x.assign(y),
                        model_weights, mean_client_weights)
  return model_weights

@tff.federated_computation(tff.FederatedType(tf.float32, tff.CLIENTS))
def get_average_temperature(client_temperatures):
  return tff.federated_mean(client_temperatures)

@tff.tf_computation(tf.float32)
def add_half(x):
  return tf.add(x, 0.5)


@tff.federated_computation(tff.FederatedType(tf.float32, tff.CLIENTS))
def add_half_on_clients(x):
  return tff.federated_map(add_half, x)


@tff.tf_computation
def server_init():
  model = model_fn()
  return model.trainable_variables


@tff.federated_computation
def initialize_fn():
  return tff.federated_value(server_init(), tff.SERVER)


whimsy_model = model_fn()
tf_dataset_type = tff.SequenceType(whimsy_model.input_spec)


model_weights_type = server_init.type_signature.result


@tff.tf_computation(tf_dataset_type, model_weights_type)
def client_update_fn(tf_dataset, server_weights):
  model = model_fn()
  client_optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)
  return client_update(model, tf_dataset, server_weights, client_optimizer)


@tff.tf_computation(model_weights_type)
def server_update_fn(mean_client_weights):
  model = model_fn()
  return server_update(model, mean_client_weights)


federated_server_type = tff.FederatedType(model_weights_type, tff.SERVER)
federated_dataset_type = tff.FederatedType(tf_dataset_type, tff.CLIENTS)

@tff.federated_computation(federated_server_type, federated_dataset_type)
def next_fn(server_weights, federated_dataset):
  # Broadcast the server weights to the clients.
  server_weights_at_client = tff.federated_broadcast(server_weights)

  # Each client computes their updated weights.
  client_weights = tff.federated_map(
      client_update_fn, (federated_dataset, server_weights_at_client))

  # The server averages these updates.
  mean_client_weights = tff.federated_mean(client_weights)

  # The server updates its model.
  server_weights = tff.federated_map(server_update_fn, mean_client_weights)

  return server_weights,client_weights


federated_algorithm = tff.templates.IterativeProcess(
    initialize_fn=initialize_fn,
    next_fn=next_fn
)


server_state = federated_algorithm.initialize()
</code></pre>
<p>and save server_state (weights) after each round:</p>
<pre><code>for round in range(3,15):
  server_state,client_weights = federated_algorithm.next(server_state, federated_train_data)
  FileCheckpointManager(root_dir= '/content/drive/MyDrive',prefix='fed_per_',step= 1,keep_total= 1,keep_first= True).save_checkpoint(state=server_state,round_num=round)
</code></pre>
<p>now I want to use this pre_trained model for a new federated learning case where the weights of the CNN layer are fixed and only the weights of the 3 last layers are changed.</p>
<p>could someone help me with how I can do this?</p>
",17945316,,,,,44686.3125,How can I use transfer learning in federated learning?,<python><tensorflow><transfer-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72132691,1,72217176,,44686.81319,,2,936,"<p>I am using the TensorFlow federated framework for
a multiclassification problem. I am following the <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">tutorials</a> and most of them use the metric (<code>tf.keras.metrics.SparseCategoricalAccuracy</code>) to measure the models' accuracy.
I wanted to explore the other measures like (AUC, recall, F1, and precision) but I am getting the errors.
The code and the error message are provided below.</p>
<pre><code>def create_keras_model():
  initializer = tf.keras.initializers.Zeros()
  return tf.keras.models.Sequential([
      tf.keras.layers.Input(shape=(8,)),
      tf.keras.layers.Dense(64),
      tf.keras.layers.Dense(4, kernel_initializer=initializer),
      tf.keras.layers.Softmax(),
  ])
def model_fn():
  keras_model = create_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=train_data[0].element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy(),
               tf.keras.metrics.Recall()]
      )
</code></pre>
<p>The error</p>
<pre><code>ValueError: Shapes (None, 4) and (None,) are incompatible
</code></pre>
<p>Is it because of the muti classification problem, that we cannot use these measures with it? and if so, is there any other metric I may use to measure my multi-classification model.</p>
",18358769,,,,,44699.33333,Use different metrics in tf.keras.metrics for mutli-classification model,<python><tensorflow><keras><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
72146421,1,,,44687.80486,,2,528,"<p>I'm trying to test a compression technique in federated learning with <strong>non-IID</strong> using this API tff.simulation.datasets.build_single_label_dataset(), following these posts:</p>
<ul>
<li><a href=""https://stackoverflow.com/questions/64970504/tensorflow-federated-how-to-tune-non-iidness-in-federated-dataset"">TensorFlow Federated: How to tune non-IIDness in federated dataset?</a></li>
<li><a href=""https://stackoverflow.com/questions/72076723/attributeerror-mapdataset-object-has-no-attribute-preprocess-in-tensorflow/72077739#72077739"">AttributeError: &#39;MapDataset&#39; object has no attribute &#39;preprocess&#39; in tensorflow_federated tff</a></li>
</ul>
<p>But after defining the model and training it, I got <strong>this error</strong> :</p>
<pre><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-16-b04459984716&gt; in &lt;module&gt;()
     10 
     11 train(federated_averaging_process=federated_averaging, num_rounds=10,
---&gt; 12       num_clients_per_round=NUM_CLIENTS, summary_writer=summary_writer)

&lt;ipython-input-15-7157bce2bb0f&gt; in train(federated_averaging_process, num_rounds, num_clients_per_round, summary_writer)
     11       # sample the clients parcitipated in this round.
     12       sampled_clients = np.random.choice(
---&gt; 13           fed_emnist_train.client_ids,
     14           size=num_clients_per_round,
     15           replace=False)

AttributeError: 'MapDataset' object has no attribute 'client_ids'
</code></pre>
<p><strong>The code:</strong></p>
<pre><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(
    only_digits=False)

# for non-IID we use this API tff.simulation.datasets.build_single_label_dataset()
fed_emnist_train = tff.simulation.datasets.build_single_label_dataset(
  emnist_train.create_tf_dataset_from_all_clients(),
  label_key='label', desired_label=1)

MAX_CLIENT_DATASET_SIZE = 418

CLIENT_EPOCHS_PER_ROUND = 1
CLIENT_BATCH_SIZE = 20
TEST_BATCH_SIZE = 500

def reshape_emnist_element(element):
  return (tf.expand_dims(element['pixels'], axis=-1), element['label'])

def preprocess_train_dataset(dataset):
  return (dataset
          .shuffle(buffer_size=MAX_CLIENT_DATASET_SIZE)
          .repeat(CLIENT_EPOCHS_PER_ROUND)
          .batch(CLIENT_BATCH_SIZE, drop_remainder=False)
          .map(reshape_emnist_element))

fed_emnist_train = preprocess_train_dataset(fed_emnist_train)

# for unbalanced dataset
import random
NUM_CLIENTS = 100

client_datasets = [
   fed_emnist_train.take(random.randint(1, CLIENT_BATCH_SIZE))
   for _ in range(NUM_CLIENTS)
]

# defining a model 
def create_original_fedavg_cnn_model(only_digits=False):
  data_format = 'channels_last'

  max_pool = functools.partial(
      tf.keras.layers.MaxPooling2D,
      pool_size=(2, 2),
      padding='same',
      data_format=data_format)
  conv2d = functools.partial(
      tf.keras.layers.Conv2D,
      kernel_size=5,
      padding='same',
      data_format=data_format,
      activation=tf.nn.relu)

  model = tf.keras.models.Sequential([
      tf.keras.layers.InputLayer(input_shape=(28, 28, 1)),
      conv2d(filters=32),
      max_pool(),
      conv2d(filters=64),
      max_pool(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(512, activation=tf.nn.relu),
      tf.keras.layers.Dense(10 if only_digits else 62),
      tf.keras.layers.Softmax(),
  ])

  return model

input_spec = client_datasets[0].element_spec

def tff_model_fn():
  keras_model = create_original_fedavg_cnn_model()
  return tff.learning.from_keras_model(
      keras_model=keras_model,
      input_spec=input_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

# training the model 
federated_averaging = tff.learning.build_federated_averaging_process(
    model_fn=tff_model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

# utility function
def format_size(size):
  size = float(size)
  for unit in ['bit','Kibit','Mibit','Gibit']:
    if size &lt; 1024.0:
      return &quot;{size:3.2f}{unit}&quot;.format(size=size, unit=unit)
    size /= 1024.0
  return &quot;{size:.2f}{unit}&quot;.format(size=size, unit='TiB')

def set_sizing_environment():
  sizing_factory = tff.framework.sizing_executor_factory()
  context = tff.framework.ExecutionContext(executor_fn=sizing_factory)
  tff.framework.set_default_context(context)

  return sizing_factory

# trains the federated averaging process and output metrics
def train(federated_averaging_process, num_rounds, num_clients_per_round, summary_writer):
  # create a environment to get communication cost
  environment = set_sizing_environment()

  # initialize the FedAvg algorithm to get the initial server state
  state = federated_averaging_process.initialize()

  with summary_writer.as_default():
    for round_num in range(num_rounds):
      # sample the clients parcitipated in this round.
      sampled_clients = np.random.choice(
          fed_emnist_train.client_ids,
          size=num_clients_per_round,
          replace=False)
      # create a list of `tf.Dataset` instances from the data of sampled clients
      sampled_train_data = [
          fed_emnist_train.create_tf_dataset_for_client(client)
          for client in sampled_clients
      ]
      
      state, metrics = federated_averaging_process.next(state, sampled_train_data)

      size_info = environment.get_size_info()
      broadcasted_bits = size_info.broadcast_bits[-1]
      aggregated_bits = size_info.aggregate_bits[-1]

      print('round {:2d}, metrics={}, broadcasted_bits={}, aggregated_bits={}'.format(round_num, metrics, format_size(broadcasted_bits), format_size(aggregated_bits)))

      # add metrics to Tensorboard
      for name, value in metrics['train'].items():
          tf.summary.scalar(name, value, step=round_num)

      tf.summary.scalar('cumulative_broadcasted_bits', broadcasted_bits, step=round_num)
      tf.summary.scalar('cumulative_aggregated_bits', aggregated_bits, step=round_num)
      summary_writer.flush()

# first, clean the log directory to avoid conflicts
try:
  tf.io.gfile.rmtree('/tmp/logs/scalars')
except tf.errors.OpError as e:
  pass 

# set up the log directory and writer for Tensorboard.
logdir = &quot;/tmp/logs/scalars/original/&quot;
summary_writer = tf.summary.create_file_writer(logdir)

train(federated_averaging_process=federated_averaging, num_rounds=10,
      num_clients_per_round=NUM_CLIENTS, summary_writer=summary_writer)

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-16-b04459984716&gt; in &lt;module&gt;()
     10 
     11 train(federated_averaging_process=federated_averaging, num_rounds=10,
---&gt; 12       num_clients_per_round=NUM_CLIENTS, summary_writer=summary_writer)

&lt;ipython-input-15-7157bce2bb0f&gt; in train(federated_averaging_process, num_rounds, num_clients_per_round, summary_writer)
     11       # sample the clients parcitipated in this round.
     12       sampled_clients = np.random.choice(
---&gt; 13           fed_emnist_train.client_ids,
     14           size=num_clients_per_round,
     15           replace=False)

AttributeError: 'MapDataset' object has no attribute 'client_ids'
</code></pre>
<p><strong>What does that mean?
Appreciate any help!</strong></p>
",18969005,,18969005,,44687.91806,44688.52292,AttributeError: 'MapDataset' object has no attribute 'client_ids' in tensorflow_federated TFF,<python><tensorflow><google-colaboratory><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72179718,1,72190334,,44691.05208,,3,561,"<p>I'm trying to test this tutorial <a href=""https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/tff_for_federated_learning_research_compression</a> with <strong>CIFAR100 dataset</strong>, but the <strong>accuracy</strong> is <strong>dropping</strong> each round!</p>
<p><strong>Does my tuning for the hyper parameter is the reason??</strong></p>
<p>Here is my code:</p>
<pre><code>cifar_train, cifar_test = tff.simulation.datasets.cifar100.load_data()

MAX_CLIENT_DATASET_SIZE = 418

CLIENT_EPOCHS_PER_ROUND = 1
CLIENT_BATCH_SIZE = 20
TEST_BATCH_SIZE = 500

def reshape_cifar_element(element):
  return (tf.expand_dims(element['image'], axis=-1), element['label'])

def preprocess_train_dataset(dataset):
  &quot;&quot;&quot;Preprocessing function for the EMNIST training dataset.&quot;&quot;&quot;
  return (dataset
          # Shuffle according to the largest client dataset
          .shuffle(buffer_size=MAX_CLIENT_DATASET_SIZE)
          # Repeat to do multiple local epochs
          .repeat(CLIENT_EPOCHS_PER_ROUND)
          # Batch to a fixed client batch size
          .batch(CLIENT_BATCH_SIZE, drop_remainder=False)
          # Preprocessing step
          .map(reshape_cifar_element))

cifar_train = cifar_train.preprocess(preprocess_train_dataset)

# defining a model 
def create_original_fedavg_cnn_model():
  data_format = 'channels_last'

  max_pool = functools.partial(
      tf.keras.layers.MaxPooling2D,
      pool_size=(2, 2),
      padding='same',
      data_format=data_format)
  conv2d = functools.partial(
      tf.keras.layers.Conv2D,
      kernel_size=5,
      padding='same',
      data_format=data_format,
      activation=tf.nn.relu)

  model = tf.keras.models.Sequential([
      tf.keras.layers.InputLayer(input_shape=(32, 32, 3)),
      conv2d(filters=32),
      max_pool(),
      conv2d(filters=64),
      max_pool(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(512, activation=tf.nn.relu),
      tf.keras.layers.Dense(100, activation=None),
      tf.keras.layers.Softmax(),
  ])
  return model

input_spec = cifar_train.create_tf_dataset_for_client(
    cifar_train.client_ids[0]).element_spec

def tff_model_fn():
  keras_model = create_original_fedavg_cnn_model()
  return tff.learning.from_keras_model(
      keras_model=keras_model,
      input_spec=input_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

# training the model 
federated_averaging = tff.learning.build_federated_averaging_process(
    model_fn=tff_model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.05),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

# utility function
def format_size(size):
  size = float(size)
  for unit in ['bit','Kibit','Mibit','Gibit']:
    if size &lt; 1024.0:
      return &quot;{size:3.2f}{unit}&quot;.format(size=size, unit=unit)
    size /= 1024.0
  return &quot;{size:.2f}{unit}&quot;.format(size=size, unit='TiB')

def set_sizing_environment():
  sizing_factory = tff.framework.sizing_executor_factory()
  context = tff.framework.ExecutionContext(executor_fn=sizing_factory)
  tff.framework.set_default_context(context)

  return sizing_factory

def train(federated_averaging_process, num_rounds, num_clients_per_round, summary_writer):
  environment = set_sizing_environment()

  # Initialize the Federated Averaging algorithm to get the initial server state.
  state = federated_averaging_process.initialize()

  with summary_writer.as_default():
    for round_num in range(num_rounds):
      # Sample the clients parcitipated in this round.
      sampled_clients = np.random.choice(
          cifar_train.client_ids,
          size=num_clients_per_round,
          replace=False)
      # Create a list of `tf.Dataset` instances from the data of sampled clients.
      sampled_train_data = [
          cifar_train.create_tf_dataset_for_client(client)
          for client in sampled_clients
      ]
      state, metrics = federated_averaging_process.next(state, sampled_train_data)

      size_info = environment.get_size_info()
      broadcasted_bits = size_info.broadcast_bits[-1]
      aggregated_bits = size_info.aggregate_bits[-1]

      print('round {:2d}, metrics={}, broadcasted_bits={}, aggregated_bits={}'.format(round_num, metrics, format_size(broadcasted_bits), format_size(aggregated_bits)))

      # Add metrics to Tensorboard.
      for name, value in metrics['train'].items():
          tf.summary.scalar(name, value, step=round_num)

      # Add broadcasted and aggregated data size to Tensorboard.
      tf.summary.scalar('cumulative_broadcasted_bits', broadcasted_bits, step=round_num)
      tf.summary.scalar('cumulative_aggregated_bits', aggregated_bits, step=round_num)
      summary_writer.flush()

# Clean the log directory to avoid conflicts.
try:
  tf.io.gfile.rmtree('/tmp/logs/scalars')
except tf.errors.OpError as e:
  pass  # Path doesn't exist

# Set up the log directory and writer for Tensorboard.
logdir = &quot;/tmp/logs/scalars/original/&quot;
summary_writer = tf.summary.create_file_writer(logdir)

train(federated_averaging_process=federated_averaging, num_rounds=10,
      num_clients_per_round=100, summary_writer=summary_writer)
</code></pre>
<p>And this is the output:</p>
<pre><code>round  0, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0299), ('loss', 15.586388), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=6.56Gibit, aggregated_bits=6.56Gibit
round  1, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0046), ('loss', 16.042076), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=13.13Gibit, aggregated_bits=13.13Gibit
round  2, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0107), ('loss', 15.945647), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=19.69Gibit, aggregated_bits=19.69Gibit
round  3, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0104), ('loss', 15.950482), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=26.26Gibit, aggregated_bits=26.26Gibit
round  4, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0115), ('loss', 15.932754), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=32.82Gibit, aggregated_bits=32.82Gibit
round  5, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0111), ('loss', 15.9391985), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=39.39Gibit, aggregated_bits=39.39Gibit
round  6, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0112), ('loss', 15.937586), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=45.95Gibit, aggregated_bits=45.95Gibit
round  7, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.012), ('loss', 15.924692), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=52.52Gibit, aggregated_bits=52.52Gibit
round  8, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0105), ('loss', 15.948869), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=59.08Gibit, aggregated_bits=59.08Gibit
round  9, metrics=OrderedDict([('broadcast', ()), ('aggregation', OrderedDict([('mean_value', ()), ('mean_weight', ())])), ('train', OrderedDict([('sparse_categorical_accuracy', 0.0096), ('loss', 15.963377), ('num_examples', 10000), ('num_batches', 500)]))]), broadcasted_bits=65.64Gibit, aggregated_bits=65.64Gibit
</code></pre>
<p>Here is the input structure:</p>
<pre><code>OrderedDict([('coarse_label', TensorSpec(shape=(), dtype=tf.int64, name=None)), ('image', TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name=None)), ('label', TensorSpec(shape=(), dtype=tf.int64, name=None))])
</code></pre>
<p>I don't know where is my mistake!</p>
<ul>
<li><p><strong>Are the hyper parameter that are defined in the layers in create_original_fedavg_cnn_model() wrong? or in preprocess_train_dataset()?</strong></p>
</li>
<li><p><strong>How to tune the parameters for the same tutorial for CIFAR100 dataset?</strong></p>
</li>
</ul>
<p>Appreciate any help! Thanks.</p>
",18969005,,,,,44691.70764,How to tune hyper parameters for CIFAR100 in tensorflow_federated TFF without dropping in the accuracy?,<python><tensorflow><google-colaboratory><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72230991,1,,,44694.59236,,1,35,"<p>I would like to print the state that receives each client after training,
Here is my loop:</p>
<pre><code>NUM_ROUNDS = 5
for round_num in range(NUM_ROUNDS):
  print('Round {r}'.format(r=round_num))
  print(state.model)
  state, metrics = fed_avg.next(state, train_datasets)
  train_metrics = metrics['train']
  print('\tTrain: loss={l:.3f}, accuracy={a:.3f}'.format(
      l=train_metrics['loss'], a=train_metrics['accuracy']))
</code></pre>
<p>Here <code>state.model</code> is the state in each round, but I would like to see the state that receives each client from the 4 clients.
Thanks</p>
",14253961,,,,,44694.59236,TFF : Print state that receives each client,<tensorflow-federated>,0,0,,,,CC BY-SA 4.0
72241747,1,,,44695.65347,,2,526,"<p>I want to add noise to the gradient on the client side. I modified <code>tf.keras.optimizers.Adam()</code> to <code>DPKerasAdamOptimizer()</code>, but it doesn't work.</p>
<pre><code>    iterative_process = tff.learning.build_federated_averaging_process(
        model_fn=Create_tff_model,
        client_optimizer_fn=lambda: DPKerasAdamOptimizer(1,1.85))
</code></pre>
<p>The error is</p>
<pre><code>AssertionError: Neither _compute_gradients() or get_gradients() on the differentially private optimizer was called. This means the training is not differentially private. It may be the case that you need to upgrade to TF 2.4 or higher to use this particular optimizer.
</code></pre>
<p>I can add noise on the server side using the <code>tff.learning.model_update_aggregator.dp_aggregator(noise_multiplier, client_per_round)</code>, but how to add noise on the client side?</p>
",18772903,,,user17242583,44695.66111,44704.40347,How to add noise (differential privacy) to clients weights in federal learning?,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
72263736,1,,,44697.75556,,2,2139,"<p>I try to install tensorflow federated.</p>
<pre><code>pip install --quiet --upgrade tensorflow_federated_nightly
</code></pre>
<p>but when I want to import tensorflow federated, I get this warning and after that google colab notebook is restarted.</p>
<pre><code>WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.checkpoint_management has been moved to tensorflow.python.checkpoint.checkpoint_management. The old module will be deleted in version 2.9.
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.resource has been moved to tensorflow.python.trackable.resource. The old module will be deleted in version 2.11.
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base_delegate has been moved to tensorflow.python.trackable.base_delegate. The old module will be deleted in version 2.11.
WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.graph_view has been moved to tensorflow.python.checkpoint.graph_view. The old module will be deleted in version 2.11.
</code></pre>
<p>Also, I try install tensorflow federated as this way:</p>
<pre><code>pip install --quiet --upgrade tensorflow_federated
</code></pre>
<p>but get error when import tensorflow federated</p>
<pre><code>TypeError: 'type' object is not subscriptable
</code></pre>
<p>how do I fix it?</p>
",19129842,,19129842,,44698.80486,44702.02778,Cant to install tensorflow_federated,<python><tensorflow><google-colaboratory><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72327186,1,,,44702.26597,,3,243,"<p>I am building a multi-classification federated learning model using TensorFlow. And I want to generate a confusion matrix for my model, but I don't know how to find the y_true and y_pred in my federated computation code.
The federated computation code:</p>
<pre><code>def train(NUM_ROUNDS, data_frame):
  state = iterative_process.initialize()
  for round_num in range(0, NUM_ROUNDS):
    train_metrics = eval_process(state.model, test_data)['eval']
    state, _= iterative_process.next(state, train_data)
    print(f'Round {round_num:3d}: {train_metrics}')
    data_frame = data_frame.append({'Round': round_num,
                                      **train_metrics}, ignore_index=True)
  

  test_metrics = eval_process(state.model, test_data)
  print(&quot;The final evaluation is: &quot;)
  print(test_metrics)

  return data_frame

data_frame = pd.DataFrame()
NUM_ROUNDS = 2

print(f'Starting training')
data_frame = train(NUM_ROUNDS, data_frame)
print()
</code></pre>
<pre><code>Starting training
Round   0: OrderedDict([('sparse_categorical_accuracy', 0.12227074), ('loss', 1.3862933), ('num_examples', 916), ('num_batches', 184)])
Round   1: OrderedDict([('sparse_categorical_accuracy', 0.57969433), ('loss', 1.7442805), ('num_examples', 916), ('num_batches', 184)])
The final evaluation is: 
OrderedDict([('eval', OrderedDict([('sparse_categorical_accuracy', 0.17467248), ('loss', 1.7451892), ('num_examples', 916), ('num_batches', 184)]))])
</code></pre>
<p>The confusion matrix code is:</p>
<pre><code>classes=[0,1,2,3]
logdir='log'
tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)

con_mat = tf.math.confusion_matrix(labels=y_true, predictions=y_pred).numpy()
con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)

con_mat_df = pd.DataFrame(con_mat_norm,
                     index = classes, 
                     columns = classes)

figure = plt.figure(figsize=(8, 8))
sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)
plt.tight_layout()
plt.ylabel('True label')
plt.xlabel('Predicted label')
plt.show()
</code></pre>
<p>so, is this the right way to generate a confusion matrix for federated learning and how can I find the <code>y_true</code> to pass it to the function?</p>
",17534198,,,,,44803.39097,Pass y_true for Confusion Matrix of federated learning model,<python><tensorflow><keras><tensorflow-federated>,0,2,,,,CC BY-SA 4.0
62398225,1,62399766,,43997.94861,,1,366,"<h1>1 issue at large</h1>

<p>I am producing a iterative process via tff.learning.build_federated_averaging_process(). and receive the error: </p>

<pre><code>
    Traceback (most recent call last):
      File ""B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
        exec(code_obj, self.user_global_ns, self.user_ns)
      File ""&lt;ipython-input-2-47998fd56829&gt;"", line 1, in &lt;module&gt;
        runfile('B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py', args=['--experiment_name=temp', '--client_batch_size=20', '--client_optimizer=sgd', '--client_learning_rate=0.2', '--server_optimizer=sgd', '--server_learning_rate=1.0', '--total_rounds=200', '--rounds_per_eval=1', '--rounds_per_checkpoint=50', '--rounds_per_profile=0', '--root_output_dir=B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/logs/fed_out/'], wdir='B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection')
      File ""B:\tools and software\PyCharm 2020.1\plugins\python\helpers\pydev\_pydev_bundle\pydev_umd.py"", line 197, in runfile
        pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
      File ""B:\tools and software\PyCharm 2020.1\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
        exec(compile(contents+""\n"", file, 'exec'), glob, loc)
      File ""B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py"", line 306, in &lt;module&gt;
        app.run(main)
      File ""B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\absl\app.py"", line 299, in run
        _run_main(main, args)
      File ""B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\absl\app.py"", line 250, in _run_main
        sys.exit(main(argv))
      File ""B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py"", line 299, in main
        train_main()
      File ""B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py"", line 262, in train_main
        server_optimizer_fn=server_optimizer_fn,
      File ""B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\learning\federated_averaging.py"", line 211, in build_federated_averaging_process
        stateful_delta_aggregate_fn, stateful_model_broadcast_fn)
      File ""B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\learning\framework\optimizer_utils.py"", line 498, in build_model_delta_optimizer_process
        py_typecheck.check_callable(model_fn)
      File ""B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\common_libs\py_typecheck.py"", line 106, in check_callable
        type_string(type(target))))
    TypeError: Expected a callable, found non-callable tensorflow_federated.python.learning.model_utils.EnhancedModel.

</code></pre>

<h3>highlighting:</h3>

<pre><code>in build_federated_averaging_process
    stateful_delta_aggregate_fn, stateful_model_broadcast_fn)
</code></pre>

<p><strong>and</strong></p>

<pre><code>TypeError: Expected a callable, found non-callable tensorflow_federated.python.learning.model_utils.EnhancedModel.
</code></pre>

<h1>2 have tried</h1>

<ol>
<li>looked at another similar issue <a href=""https://stackoverflow.com/questions/57381329/expected-a-callable-found-non-callable-tensorflow-federated-python-learning-mod"">here</a>  have tried to make
model_fn a collection.abc Callable, <code>model_fn=Callable[[], model_fn]</code> 
only creates a new error.</li>
</ol>

<h1>3 some code:</h1>

<ul>
<li><p>iterative process:</p>

<pre><code>

 model_fn = model_builder(input_dim=sysarg,
                             input_spec=input_spec)
    iterative_process = tff.learning.build_federated_averaging_process(
        model_fn=model_fn,
        client_optimizer_fn=client_optimizer_fn,
        server_optimizer_fn=server_optimizer_fn,
    )
    iterative_process = compression_process_adapter.CompressionProcessAdapter(iterative_process)```
</code></pre></li>
<li><p>model bulder:</p></li>
</ul>

<pre><code>
    def model_builder(input_dim, input_spec):
           model = create_model(input_dim)
            return tff.learning.from_keras_model(keras_model=model,
                                                 loss=tf.keras.losses.MeanSquaredError(),
                                                 input_spec=input_spec,
                                                 metrics=[tf.keras.metrics.Accuracy()],
                                                 )

</code></pre>

<ul>
<li>create model (for good measure)</li>
</ul>

<pre><code>
    def create_model(input_dim):
           autoencoder = Sequential([
                tf.keras.layers.Dense(int(0.75 * input_dim), activation=""tanh"", input_shape=(input_dim,)),
                tf.keras.layers.Dense(int(0.5 * input_dim), activation=""tanh""),
                tf.keras.layers.Dense(int(0.33 * input_dim), activation=""tanh""),
                tf.keras.layers.Dense(int(0.25 * input_dim), activation=""tanh""),
                tf.keras.layers.Dense(int(0.33 * input_dim), activation=""tanh""),
                tf.keras.layers.Dense(int(0.5 * input_dim), activation=""tanh""),
                tf.keras.layers.Dense(int(0.75 * input_dim), activation=""tanh""),
                tf.keras.layers.Dense(input_dim)
                ])

</code></pre>
",13716568,,,,,43998.07847,When using building a federated averaging process - TypeError: Expected a callable.... found Enhanced Model,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
62398875,1,,,43998,,1,433,"<pre><code>def create_keras_model():
model = Sequential([
    Conv2D(16, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Conv2D(32, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Conv2D(64, 3, padding='same', activation='relu'),
    MaxPooling2D(),
    Flatten(),
    Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),
    Dropout(0.5),
    Dense(1, activation='sigmoid')
])

model.load_weights('/content/drive/My Drive/localmodel/weights')
return model
</code></pre>

<p>Tried something like this in Colab, but I get errno 21, is a directory.</p>

<p>Then I tried another method as shown below,  </p>

<pre><code>tff_model = create_keras_model() #now this function doesnt load weights, just returns a Sequential model   
tff.learning.assign_weights_to_keras_model(tff_model, model_with_weights)
</code></pre>

<p>Just like assign_weights_to_keras_model() transfers weights from tff_model to keras model, I want to transfer weights from keras model to tff_model. How can this be done?</p>
",9799778,,730754,,44163.45417,44163.45417,How to transfer weights from baseline model to federated model?,<tensorflow><tensorflow-federated><federated-learning>,2,4,,,,CC BY-SA 4.0
62416384,1,,,43998.82083,,1,740,"<h2>AttributeError: 'list' object has no attribute '_flatten_tensor_specs'</h2>
<ol>
<li>problem:
Currently, when creating an iterative process with a build federated averaging process, I am able to pass in a functools. partial successful.
however, there must be an error in the above code that produces a structure needed for the model_fn to go through
correctly.</li>
<li>have tried:
looking at the input data. This custom data set is built for a autoencoder and the original TF solution never used labels. As this solution is built to take in the training data, train the model, then work on the test data, and validate on the validation set to produce a threshold.
There might be a issue with the underlying production.</li>
<li>sources:</li>
</ol>
<pre class=""lang-py prettyprint-override""><code>        df, y_train = get_train_data(sysarg)
        x_train, x_opt, x_test = np.split(df.sample(frac=1,
                                           random_state=17),
                                          [int(1 / 3 * len(df)), int(2 / 3 * len(df))])
        x_train, x_opt, x_test = create_scalar(x_opt, x_test, x_train)
        input_spec = tf.nest.map_structure(tf.TensorSpec.from_tensor,
                                           [tf.convert_to_tensor(x_train),
                                            tf.convert_to_tensor(y_train)])
        assign_weights_fn = compression_process_adapter.CompressionServerState.assign_weights_to_keras_model
        iterative_process = tff.learning.build_federated_averaging_process(
            model_fn=functools.partial(model_builder,
                                       input_dim=sysarg,                                     input_spec=input_spec),
            client_optimizer_fn=client_optimizer_fn,
            server_optimizer_fn=server_optimizer_fn,
        )
        iterative_process = compression_process_adapter.CompressionProcessAdapter(iterative_process)
        
</code></pre>
<ol start=""4"">
<li>trackback error</li>
</ol>
<pre><code>
    Traceback (most recent call last):
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\IPython\core\interactiveshell.py&quot;, line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File &quot;&lt;ipython-input-2-47998fd56829&gt;&quot;, line 1, in &lt;module&gt;
    runfile('B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py', args=['--experiment_name=temp', '--client_batch_size=20', '--client_optimizer=sgd', '--client_learning_rate=0.2', '--server_optimizer=sgd', '--server_learning_rate=1.0', '--total_rounds=200', '--rounds_per_eval=1', '--rounds_per_checkpoint=50', '--rounds_per_profile=0', '--root_output_dir=B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/logs/fed_out/'], wdir='B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection')
  File &quot;B:\tools and software\PyCharm 2020.1\plugins\python\helpers\pydev\_pydev_bundle\pydev_umd.py&quot;, line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File &quot;B:\tools and software\PyCharm 2020.1\plugins\python\helpers\pydev\_pydev_imps\_pydev_execfile.py&quot;, line 18, in execfile
    exec(compile(contents+&quot;\n&quot;, file, 'exec'), glob, loc)
  File &quot;B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py&quot;, line 306, in &lt;module&gt;
    app.run(main)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\absl\app.py&quot;, line 299, in run
    _run_main(main, args)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\absl\app.py&quot;, line 250, in _run_main
    sys.exit(main(argv))
  File &quot;B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py&quot;, line 299, in main
    train_main()
  File &quot;B:/projects/openProjects/githubprojects/BotnetTrafficAnalysisFederaedLearning/anomaly-detection/train_v04.py&quot;, line 262, in train_main
    server_optimizer_fn=server_optimizer_fn,
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\learning\federated_averaging.py&quot;, line 211, in build_federated_averaging_process
    stateful_delta_aggregate_fn, stateful_model_broadcast_fn)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\learning\framework\optimizer_utils.py&quot;, line 521, in build_model_delta_optimizer_process
    model_broadcast_state_type=model_broadcast_state_type)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\learning\framework\optimizer_utils.py&quot;, line 368, in _build_one_round_computation
    @tff.tf_computation(dataset_type, model_weights_type)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\core\impl\wrappers\computation_wrapper.py&quot;, line 337, in &lt;lambda&gt;
    return lambda fn: _wrap(fn, arg_type, self._wrapper_fn)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\core\impl\wrappers\computation_wrapper.py&quot;, line 89, in _wrap
    concrete_fn = wrapper_fn(fn, parameter_type, unpack=None)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\core\impl\wrappers\computation_wrapper_instances.py&quot;, line 51, in _tf_wrapper_fn
    target_fn, parameter_type, ctx_stack)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\core\impl\tensorflow_serialization.py&quot;, line 274, in serialize_py_fn_as_tf_computation
    result = target(*args)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\core\impl\utils\function_utils.py&quot;, line 517, in &lt;lambda&gt;
    return lambda arg: _unpack_and_call(fn, arg_types, kwarg_types, arg)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\core\impl\utils\function_utils.py&quot;, line 510, in _unpack_and_call
    return fn(*args, **kwargs)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\learning\framework\optimizer_utils.py&quot;, line 381, in _compute_local_training_and_client_delta
    client_output = client_delta_fn(dataset, initial_model_weights)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\eager\def_function.py&quot;, line 580, in __call__
    result = self._call(*args, **kwds)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\eager\def_function.py&quot;, line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\eager\def_function.py&quot;, line 506, in _initialize
    *args, **kwds))
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\framework\func_graph.py&quot;, line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\eager\def_function.py&quot;, line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\eager\function.py&quot;, line 3299, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File &quot;B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\framework\func_graph.py&quot;, line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
</code></pre>
<ol start=""5"">
<li>Additional Error list:</li>
</ol>
<pre><code>
    AttributeError: in user code:
    B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow_federated\python\learning\federated_averaging.py:90 __call__  *
        num_examples_sum = dataset.reduce(
    B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py:1932 reduce  **
        add_to_graph=False)
    B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py:3210 __init__
        self._input_structure),
    B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\data\util\structure.py:270 get_flat_tensor_specs
        nest.flatten(element_spec), [])
    B:\tools and software\Anaconda\envs\bookProjects\lib\site-packages\tensorflow\python\data\util\structure.py:269 &lt;lambda&gt;
        return functools.reduce(lambda state, value: state + value._flat_tensor_specs,
    AttributeError: 'list' object has no attribute '_flat_tensor_specs'
</code></pre>
<p><a href=""https://github.com/GIGA-Money/FederatedLearningAnalysis"" rel=""nofollow noreferrer"">GitHub link</a></p>
",13716568,,13716568,,44972.05347,44972.05347,"get_flat_tensor_specs nest.flatten(element_spec), []) results in AttributeError: 'list' object has no attribute '_flat_tensor_specs'",<python><python-3.x><tensorflow><tensorflow-federated>,0,8,,,,CC BY-SA 4.0
62544709,1,62615079,,44005.93611,,1,190,"<p>As a beginner to differential privacy, I would like to why the variance for noise mechanisms needs to be calibrated with sensitivity? What is the purpose of that? What happens if we don't calibrate it and add a random variance?</p>
<p>Example scenario <a href=""https://en.wikipedia.org/wiki/Additive_noise_mechanisms"" rel=""nofollow noreferrer"">here</a> In Laplacian noise, why scale parameter is calibrated?</p>
",9799778,,,,,44186.86042,Why additive noise needs to be calibrated with sensitivity in differential privacy?,<security><cryptography><privacy><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
62578714,1,,,44007.6375,,1,1142,"<p>Would anyone know how to implement the FedProx optimisation algorithm with TensorFlow Federated? The only implementation that seems to be available online was developed directly with TensorFlow. A TFF implementation would enable an easier comparison with experiments that utilise FedAvg which the framework supports.</p>
<p>This is the link to the FedProx repo: <a href=""https://github.com/litian96/FedProx"" rel=""nofollow noreferrer"">https://github.com/litian96/FedProx</a></p>
<p>Link to the paper: <a href=""https://arxiv.org/abs/1812.06127"" rel=""nofollow noreferrer"">https://arxiv.org/abs/1812.06127</a></p>
",13208966,,13208966,,44008.34306,44407.61667,FedProx with TensorFlow Federated,<tensorflow-federated>,2,0,,,,CC BY-SA 4.0
62598087,1,62598558,,44008.64861,,2,129,"<p>If I have a federated value, say <code>{int32}@CLIENTS</code> that I'd like to cast to <code>{float32}@CLIENTS</code> is there an easy way to do this? Thanks!</p>
",13820055,,,,,44011.67986,Is there a way to cast a federated value?,<tensorflow-federated>,2,0,,,,CC BY-SA 4.0
62657818,1,,,44012.53264,,0,49,"<p>To resolve the problem of non-iid data in federated learning, I read a paper which add a new node with a different data domain and transfer knowledge from decentralized nodes. My question is what is the information transfered, is that updates or data ?</p>
",12682667,,12682667,,44012.55069,44012.58403,transfer knowledge learned from distributed source domains,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
62694286,1,,,44014.43681,,1,225,"<p>To implement my code with TFF, I use the method</p>
<pre><code>tff.learning.build_federated_evaluation()
</code></pre>
<p>But I'm not understanding how this method evaluate accuracy across clients. So, like my question indicates, I would like to change the metrics and code of this evaluation funtion in TFF, so how I can proceed, link please of code fucntion.
Thanks!!</p>
",12682667,,12682667,,44015.39861,44015.61875,TFF: How Can I change the evaluation function of Federated learning,<tensorflow-federated>,1,1,,,,CC BY-SA 4.0
72335489,1,,,44703.29514,,2,120,"<p>I want to use pre_trained model in federated learning as following code:</p>
<p>first I build my model and set the weights on model and then I freeze convolutional layers and remove 4 last layer.</p>
<pre><code>def create_keras_model():
    model = Sequential()
    model.add(Conv2D(16, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=(226,232,1)))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Conv2D(256, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))
    model.add(MaxPooling2D((2,2), strides=(2,2), padding='same'))
    model.add(Flatten())
    model.add(Dense(256, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(10, activation='softmax'))
    return model

keras_model = create_keras_model()

server_state=FileCheckpointManager(root_dir= '/content/drive/MyDrive',
    prefix=  'federated_clustering',
    step= 1,
    keep_total= 1,
    keep_first= True).load_checkpoint(structure=server_state,round_num=10)

keras_model.set_weights(server_state)

for layer in keras_model.layers[:-4]:
  layer.trainable = False

model_pre = Model(inputs=keras_model.input,outputs=keras_model.layers[14].output)
</code></pre>
<p>next, I build new model.</p>
<pre><code>def create_keras_model1():
    model = Sequential()
    model.add(model_pre)
    model.add(Dense(256, activation='relu'))
    model.add(Dense(128, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(2, activation='softmax'))
    return model

def model_fn():
  # We _must_ create a new model here, and _not_ capture it from an external
  # scope. TFF will call this within different graph contexts.
  keras_model = create_keras_model1()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=preprocessed_example_dataset.element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>but I get ValueError when I want to use tff.learning.build_federated_averaging_process.</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.001),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

ValueError: Your Layer or Model is in an invalid state. This can happen for the following cases:
 1. You might be interleaving estimator/non-estimator models or interleaving models/layers made in tf.compat.v1.Graph.as_default() with models/layers created outside of it. Converting a model to an estimator (via model_to_estimator) invalidates all models/layers made before the conversion (even if they were not the model converted to an estimator). Similarly, making a layer or a model inside a a tf.compat.v1.Graph invalidates all layers/models you previously made outside of the graph.
2. You might be using a custom keras layer implementation with  custom __init__ which didn't call super().__init__.  Please check the implementation of &lt;class 'keras.engine.functional.Functional'&gt; and its bases.
</code></pre>
<p>please help me to fix it.</p>
",19129842,,19129842,,44703.52431,44704.39722,Get ValueError when apply transfer learning in federated learning (TFF),<python><tensorflow><transfer-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72384343,1,,,44706.89167,,1,417,"<p>Suppose we want to minimize the following equation using gradient descent:</p>
<p><a href=""https://i.sstatic.net/9gTjq.png"" rel=""nofollow noreferrer""><code>min f(alpha * v + (1-alpha)*w)</code></a> with <code>v</code> and <code>w</code> the model weights and <code>alpha</code> the weight, between 0 and 1, for the sum resulting in the combined model <code>v_bar</code> or <code>Å«</code> (here referred to as <code>m</code>).</p>
<pre><code>alpha = tf.Variable(0.01, name='Alpha', constraint=lambda t: tf.clip_by_value(t, 0, 1))
w_weights = tff.learning.ModelWeights.from_model(w)
v_weights = tff.learning.ModelWeights.from_model(v)
m_weights = tff.learning.ModelWeights.from_model(m)

m_weights_trainable = tf.nest.map_structure(lambda v, w: alpha*v + (tf.constant(1.0) - alpha)*w, v_weights.trainable, w_weights.trainable)
tf.nest.map_structure(lambda v, t: v.assign(t), m_weights.trainable, m_weights_trainable)
</code></pre>
<p>In the <a href=""https://arxiv.org/pdf/2003.13461v3.pdf"" rel=""nofollow noreferrer"">paper of Adaptive Personalized Federated Learning</a>, <a href=""https://i.sstatic.net/Z7Tso.jpg"" rel=""nofollow noreferrer"">formula with update step for alpha</a> suggests updating alpha based on the gradients of model <code>m</code> applied on a minibatch. I tried it with the watch or without, but it always leads to <code>No gradients provided for any variable</code></p>
<pre><code>with tf.GradientTape(watch_accessed_variables=False) as tape:
   tape.watch([alpha])
   outputs_m = m.forward_pass(batch)
grad = tape.gradient(outputs_m.loss, alpha)
optimizer.apply_gradients(zip([grad], [alpha]))
</code></pre>
<p>Some more information about the initialization of the models:</p>
<p>The <code>m.forward_pass(batch)</code> is the default implementation from <code>tff.learning.Model</code> (found <a href=""https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model#forward_pass"" rel=""nofollow noreferrer"">here</a>) by creating a model with <code>tff.learning.from_keras_model</code> and a <code>tf.keras.Sequential</code> model.</p>
<pre><code>def model_fn():
   keras_model = create_keras_model()
   return tff.learning.from_keras_model(
     keras_model,
     input_spec = element_spec,
     loss = tf.keras.losses.MeanSquaredError(),
     metrics = [tf.keras.metrics.MeanSquaredError(),
                tf.keras.metrics.MeanAbsoluteError()],
   )
w = model_fn()
v = model_fn()
m = model_fn()
</code></pre>
<p>Some more experimenting as suggested below by Zachary Garrett:</p>
<p>It seems that whenever this weighted sum is calculated, and the new weights for the model are assigned, then it loses track of the previous trainable variables of both summed models. Again, it leads to the <code>No gradients provided for any variable</code> whenever <code>optimizer.apply_gradients(zip([grad], [alpha]))</code> is called. All gradients seem to be <code>None</code>.</p>
<pre><code>with tf.GradientTape() as tape:
   alpha = tf.Variable(0.01, name='Alpha', constraint=lambda t: tf.clip_by_value(t, 0, 1))

   m_weights_t = tf.nest.map_structure(lambda w, v: tf.math.scalar_mul(alpha, v, name=None) + tf.math.scalar_mul(tf.constant(1.0) - alpha, w, name=None),
                                w.trainable,
                                v.trainable)

   m_weights = tff.learning.ModelWeights.from_model(m)
   tf.nest.map_structure(lambda v, t: v.assign(t), m_weights.trainable,
                  m_weights_trainable)

   outputs_m = m.forward_pass(batch)

grad = tape.gradient(outputs_m.loss, alpha)
optimizer.apply_gradients(zip([grad], [alpha]))
</code></pre>
<p>Another edit:
I think I have a strategy to get it working, but it is bad practice as manually setting <code>trainable_weights</code> or <code>_trainable_weights</code> does not work. Any tips on improving this?</p>
<pre class=""lang-py prettyprint-override""><code>  def do_weighted_combination():

    def _mapper(target_layer, v_layer, w_layer):
      target_layer.kernel = v_layer.kernel * alpha + w_layer.kernel * (1-alpha)
      target_layer.bias = v_layer.bias * alpha + w_layer.bias * (1-alpha)

    tf.nest.map_structure(_mapper, m.layers, v.layers, w.layers)


  with tf.GradientTape(persistent=True) as tape: 
    do_weighted_combination()

    predictions = m(x_data)
    loss = m.compiled_loss(y_data, predictions)


  g1 = tape.gradient(loss, v.trainable_weights) # Not None
  g2 = tape.gradient(loss, alpha) # Not None
</code></pre>
",19087072,,19087072,,44731.66736,44731.66736,GradientTape for variable weighted sum of two Sequential models in TensorFlow,<tensorflow><gradient-descent><tensorflow-federated><gradienttape>,1,1,,,,CC BY-SA 4.0
72428317,1,72428865,,44711.05208,,0,897,"<p>I follow the instructions in the github that says to install Tensorflow Federated with Collab we need to install version 0.20.0 but I get this error when I try to run the toturials.</p>
<pre><code>!pip install --quiet tensorflow-federated==0.20.0 # The latest version of tensorflow-federated is not working with the colab python version
!pip install --quiet --upgrade nest-asyncio
</code></pre>
<pre><code>from __future__ import absolute_import, division, print_function

import collections

from six.moves import range
import numpy as np
import tensorflow as tf
# from tensorflow import compat

from tensorflow_federated import python as tff

np.random.seed(0)

tf.compat.v1.enable_v2_behavior()

tff.federated_computation(lambda: 'Hello, World!')()
</code></pre>
<p>Error:</p>
<pre><code>module 'tensorflow_federated.python' has no attribute 'federated_computation'
</code></pre>
<p>What is the problem I don't understand? How can I install it on google colab. There is no resource for this problem.</p>
",7182459,,,,,44711.14375,module 'tensorflow_federated.python' has no attribute 'federated_computation',<python><tensorflow><google-colaboratory><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
72428249,1,72428376,,44711.03611,,0,781,"<p>I am trying to install Tensorflow federated on google collab, but there is a conflict with versions, I either get this error if I install previous versions or similar errors.</p>
<pre><code>module tensorflow_federated.python has no attribute federated_computation
</code></pre>
<p>If I want to install the new version it gives the &quot;this requires this version but you have this version&quot; during the installation.
I am very confused. Is there an easy way to use Tensorflow federated learning? I tried to install it locally but that also didn't work.
Why is it so hard to use it?</p>
<p><a href=""https://i.sstatic.net/A619y.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/A619y.png"" alt=""enter image description here"" /></a></p>
<p><a href=""https://i.sstatic.net/kzYrP.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/kzYrP.png"" alt=""enter image description here"" /></a></p>
<p>If I uninstalled all packages and installed them again it gives me the error mentioned above</p>
<p>If I try to import it ignoring the errors in the pictures it gives me this error with a newer version</p>
<pre><code>'type' object is not subscribable

</code></pre>
<p>And this error with version 20</p>
<pre><code>module 'tensorflow_federated.python' has no attribute 'federated_computation'
</code></pre>
",7182459,,7182459,,44879.18472,44879.18472,What version of Tensorflow federated has the module 'federated_computation'?,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
72467705,1,72493791,,44713.85347,,2,375,"<p>I am applying federated learning on multiple files using Tensoflow Federated. The problem is, that the size of data (number of records) in each file is different.</p>
<ol>
<li>Is it a problem in federated learning training to have different sizes for each client? if there is how can I overcome it?</li>
<li>Is there a way that I can see how each client performing while federated computation training?</li>
</ol>
<p><a href=""https://i.sstatic.net/2wRQb.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/2wRQb.png"" alt=""The chart describing the variety of number of records in each client"" /></a></p>
",18358769,,,,,45593.6125,Unbalanced client size in federated learning,<tensorflow><tensorflow-federated><federated-learning>,2,0,,,,CC BY-SA 4.0
72484653,1,,,44715.17708,,0,167,"<p>I have a model implemented in tensorflow federated, trained to solve a classification problem on the cifar10 dataset. The dataset is made with the TestClientData.</p>
<p>The model is a MobileNetV2 from the module <code>tf.keras.applications.mobilenet_v2.MobileNetV2</code>. I initialize a state with the data and model in the proper form and call to <code>state.next</code> on each iteration, plus the training and test metrics are printed. Training metrics show improvement, however test metrics get stucked at 0.1 accuracy and the loss is stucked as well.</p>
<p>Test is done by defining a keras dummy model of the same architecture and specifications, which receives the weights from the state via <code>state.model.assign_weights_to(keras_model)</code>.</p>
<p>I've been careful to use the same loss, optimizer and accuracy on the federated model and the centralized keras model used for evaluation. I'll add a print of what I get from the training loop, I print some weights of the state and the corresponding ones on the keras model just to check that the weights assignment works, and it does. I donâ€™t know what else to check.</p>
<pre><code>-------------------------------ROUND 0 ------------------------------------
Initial weights in state: [-0.00721832  0.01982944  0.08157757]

 Train metrics OrderedDict([('sparse_categorical_accuracy', 0.21346854), ('loss', 2.220433), ('num_examples', 49998), ('num_batches', 1563)]), round time 81.32 seconds

After training weights in state: [-0.00548685  0.01842782  0.0898697 ]

Initial weights in dummy model: tf.Tensor([0.12715222 0.00962208 0.1222005 ], shape=(3,), dtype=float32)

Weights in dummy model after assign weights: tf.Tensor([-0.00548685  0.01842782  0.0898697   0.0580997   0.00205497], shape=(5,), dtype=float32)

 Test metrics [2.3025963306427, 0.10000000149011612]
-------------------------------ROUND 1 ------------------------------------
Initial weights in state: [-0.00548685  0.01842782  0.0898697 ]

 Train metrics OrderedDict([('sparse_categorical_accuracy', 0.27069083), ('loss', 1.9941559), ('num_examples', 49998), ('num_batches', 1563)]), round time 80.71 seconds

After training weights in state: [0.00415337 0.01833635 0.1140746 ]

Initial weights in dummy model: tf.Tensor([ 0.03019264 -0.0810149  -0.01419063], shape=(3,), dtype=float32)

Weights in dummy model after assign weights: tf.Tensor([ 0.00415337  0.01833635  0.1140746   0.05260698 -0.00449031], shape=(5,), dtype=float32)

 Test metrics [2.3026626110076904, 0.10000000149011612]
-------------------------------ROUND 2 ------------------------------------
Initial weights in state: [0.00415337 0.01833635 0.1140746 ]

 Train metrics OrderedDict([('sparse_categorical_accuracy', 0.299912), ('loss', 1.8942232), ('num_examples', 49998), ('num_batches', 1563)]), round time 82.39 seconds

After training weights in state: [0.01262705 0.03320389 0.0952585 ]

Initial weights in dummy model: tf.Tensor([0.12944148 0.07921356 0.11308451], shape=(3,), dtype=float32)

Weights in dummy model after assign weights: tf.Tensor([0.01262705 0.03320389 0.0952585  0.02912883 0.00987563], shape=(5,), dtype=float32)

 Test metrics [2.3031070232391357, 0.10000000149011612]
</code></pre>
<p>------------CODE------------------</p>
<p>The setup is like this:</p>
<pre><code>EPOCHS = 1
BATCH_SIZE = 32

# ROUND_CLIENTS &lt;= NUM_CLIENTS
ROUND_CLIENTS = 3
NUM_CLIENTS = 3

NUM_ROUNDS = 3

    
def make_client(num_clients,X, y):
    total_image_count = len(X)
    image_per_set = int(np.floor(total_image_count/num_clients))

    client_train_dataset = collections.OrderedDict()
    for i in range(1, num_clients+1):
        client_name = i-1
        start = image_per_set * (i-1)
        end = image_per_set * i

        print(f&quot;Adding data from {start} to {end} for client : {client_name}&quot;)
        data = collections.OrderedDict((('label', y[start:end]), ('pixels', X[start:end])))
        client_train_dataset[client_name] = data
    
    train_dataset = tff.simulation.datasets.TestClientData(client_train_dataset)
    
    return train_dataset

(X_train, y_train), (X_test, y_test) = cifar10.load_data()
cifarFedTrain = make_client(NUM_CLIENTS,X_train,y_train)

def map_fn(example):
    return collections.OrderedDict(
      x=example['pixels'], 
        y=example['label']
    )


def client_data(client_id):
    ds = cifarFedTrain.create_tf_dataset_for_client(cifarFedTrain.client_ids[client_id])
    return ds.repeat(EPOCHS).shuffle(500).batch(BATCH_SIZE).map(map_fn)


train_data = [client_data(n) for n in range(ROUND_CLIENTS)]
element_spec = train_data[0].element_spec

OPTIMIZER = tf.keras.optimizers.Adam()
LOSS = tf.keras.losses.SparseCategoricalCrossentropy()
METRICS=[tf.keras.metrics.SparseCategoricalAccuracy()]

def model_fn():
    model = tf.keras.applications.MobileNetV2((32, 32, 3), classes=10, weights=None)
    return tff.learning.from_keras_model(
            model,
            input_spec=element_spec,
            loss=tf.keras.losses.SparseCategoricalCrossentropy(), 
            metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]
            )


trainer = tff.learning.build_federated_averaging_process(model_fn, client_optimizer_fn=lambda:tf.keras.optimizers.Adam())
</code></pre>
<p>The function performing the training-evaluation loop is this one, I call on the function on 3 rounds, 3 fixed clients and 1 epoch per client:</p>
<pre><code>def evaluate(state, num_rounds=NUM_ROUNDS): 
    state = trainer.initialize()
    
    for i in range(num_rounds):
        print(f&quot;-------------------------------ROUND {i} ------------------------------------&quot;)
        
        print(&quot;Initial weights in state:&quot;,state.model.trainable[0][0][0][0][:3])
        t1 = time.time()
        state, metrics = trainer.next(state, train_data)
        t2 = time.time()
        print('\n Train metrics {m}, round time {t:.2f} seconds'.format(
            m=metrics['train'], t=t2 - t1))
        
        print(&quot;\nAfter training weights in state:&quot;,state.model.trainable[0][0][0][0][:3])
        
        model = tf.keras.applications.MobileNetV2((32, 32, 3), classes=10, weights=None, classifier_activation='softmax')
        
        OPTIMIZER = tf.keras.optimizers.Adam()
        LOSS = tf.keras.losses.SparseCategoricalCrossentropy()
        METRICS=[tf.keras.metrics.SparseCategoricalAccuracy()]

        model.compile(OPTIMIZER, LOSS, METRICS)
        print(&quot;\nInitial weights in dummy model:&quot;,model.weights[0][0][0][0][:3])

        
        
        state.model.assign_weights_to(model)  # Update model with the latest parameters
        
        print(&quot;\nWeights in dummy model after assign weights:&quot;,model.weights[0][0][0][0][:5])
        metrics_test = model.evaluate(test_data, test_labels, verbose = False)
          
        print('\n Test metrics {m}'.format(m=metrics_test))
    return state, model
</code></pre>
",18982150,,,,,44715.17708,Problem when evaluating a model in tensorflow federated. Accuracy stucked at 0.1 only on evaluation,<tensorflow><machine-learning><keras><deep-learning><tensorflow-federated>,0,2,,,,CC BY-SA 4.0
72495342,1,72570797,,44715.89583,,0,258,"<p>How could I transform my dataset (composed of images) in a federated dataset?
I am trying to create something similar to emnist but for my own dataset.</p>
<blockquote>
<p>tff.simulation.datasets.emnist.load_data(
only_digits=True, cache_dir=None )</p>
</blockquote>
",19267153,,,,,44722.56875,How can I prepare my image dataset for a federated model?,<python><scikit-learn><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
72501778,1,,,44716.72778,,0,422,"<p>I am trying to use Tensorflow's tutorial of doing image classification using Federated Learning over <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">here</a></p>
<p>Firstly, there were some pip dependency resolver errors popping up, but I installed the required libraries with the versions it asked for.</p>
<p>However, I am facing one of 2 issues:</p>
<ul>
<li>If I try to import <code>tensorflow_federated</code> , it gives the following error:</li>
</ul>
<pre><code>   263 
   264 def to_odict(struct: Struct,
--&gt; 265              recursive: bool = False) -&gt; collections.OrderedDict[str, Any]:
   266   &quot;&quot;&quot;Returns `struct` as an `OrderedDict`, if possible.
   267 

TypeError: 'type' object is not subscriptable
</code></pre>
<ul>
<li>I found a forum suggesting to downgrade to tensorflow-federated==0.22. However, when I do that and run the import statement, it throws an error again because it's is implicitly importing a class which is no longer there in Keras (OptimizerV1).</li>
</ul>
<p>I am really fond of Tensorflow's workflow. Is there any workaround of making it work on Windows?</p>
<p>PS: I tried it in both Google Colab and Jupyter Notebook.</p>
",12575770,,,,,44728.86736,How to use Tensorflow Federated on Windows?,<tensorflow><machine-learning><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
72514759,1,72651892,,44718.33819,,1,278,"<p>I am having a multi-class classification problem and trying to evaluate the federated learning model by analyzing the True and Predicted values and producing the classification report.</p>
<p>But I am stuck with the y_true and y_pred, I don't know how to extract them for the federated computation.
The block of my federated model training:</p>
<pre><code>  for round_num in range(0, NUM_ROUNDS):
    train_metrics = eval_process(state.model, test_data)['eval']
    state, _= iterative_process.next(state, train_data)

    print(f'Round {round_num:3d}: {train_metrics}')
    data_frame = data_frame.append({'Round': round_num,
                                      **train_metrics}, ignore_index=True)
  

  test_metrics = eval_process(state.model, test_data)
  print(&quot;The final evaluation is: &quot;)
  print(test_metrics)

  return data_frame
  
</code></pre>
<p>The classification report I want to reach to:</p>
<pre><code>from sklearn.metrics import classification_report

y_pred = model.predict(x_test, batch_size=64, verbose=1)
y_pred_bool = np.argmax(y_pred, axis=1)

print(classification_report(y_test, y_pred_bool))
</code></pre>
<p>Any help will be so much appreciated.
Thanks</p>
",17534198,,,,,44728.87986,Find the true and predicted labels in Tensorflow Federated,<python><tensorflow><machine-learning><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
72514941,1,72548903,,44718.35139,,1,324,"<p>I have a dataset with numeric features and labels. I am building a federated learning model using TensorFlow (TFF).
Basically, the model that I have is the (neural network) which is always explained in the TFF tutorials.
I want to ask if there is a chance to build another model for the local clients, such as SVM? since it suits my dataset.</p>
<p>My neural network:</p>
<pre><code>def create_keras_model():
  initializer = tf.keras.initializers.Zeros()
  return tf.keras.models.Sequential([
      tf.keras.layers.Input(shape=(18,)),
      tf.keras.layers.Dense(128),
      tf.keras.layers.Dense(4, kernel_initializer= initializer),
      tf.keras.layers.Softmax(),
  ])
def model_fn():
  keras_model = create_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=train_data[0].element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]
      )
</code></pre>
",18358769,,,,,44720.66944,Train local model with SVM instead of NN in federated learning,<python><tensorflow><keras><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
62711362,1,,,44015.34861,,2,75,"<p>In <a href=""https://arxiv.org/pdf/1909.12488.pdf"" rel=""nofollow noreferrer"">this</a> paper, the authors choose 2500  training clients and 900 clients for evaluation</p>
<p>but in this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">tutorial</a>, they split the dataset of each client into training and test. So, I would like to know which is better ? and what is the importance of spliting clients into training and evaluation ?
Thanks!!</p>
",12682667,,,,,44015.625,TFF : Difference between split clients into train and test or split each client dataset into train and test,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
62754913,1,62756833,,44018.47083,,2,7378,"<p>I am getting 'Attempting to capture an EagerTensor without building a function' error while trying to build my federated averaging process. I have tried all remedies for compatibility of v1 &amp; v2 given in other other similar stack overflow questions, viz., using tf.compat.v1.enable_eager_execution() , tf.disable_v2_behaviour(), etc. But, nothing worked. My revelvant code extract is given below. My complete code in a Python notebook is given here <a href=""https://gist.github.com/aksingh2411/60796ee58c88e0c3f074c8909b17b5a1"" rel=""nofollow noreferrer"">https://gist.github.com/aksingh2411/60796ee58c88e0c3f074c8909b17b5a1</a>.</p>
<pre><code>#Making a Tensorflow Model
from tensorflow import keras

def create_keras_model():
 return tf.keras.models.Sequential([
  hub.KerasLayer(encoder, input_shape=[],dtype=tf.string,trainable=True),
  keras.layers.Dense(32, activation='relu'),
  keras.layers.Dense(16, activation='relu'),
  keras.layers.Dense(1, activation='sigmoid'),
])

def model_fn():
# We _must_ create a new model here, and _not_ capture it from an external
# scope. TFF will call this within different graph contexts.
keras_model = create_keras_model()
return tff.learning.from_keras_model(
  keras_model,
  input_spec=preprocessed_example_dataset.element_spec,
  loss=tf.keras.losses.BinaryCrossentropy(),
  metrics=[tf.keras.metrics.Accuracy()])

# Building the Federated Averaging Process
iterative_process = tff.learning.build_federated_averaging_process(
model_fn,
client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
&lt;ipython-input-23-68fa27e65b7e&gt; in &lt;module&gt;()
  3     model_fn,
  4     client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
  --&gt;5     server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

 9 frames
 /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in 
wrapper(*args, **kwargs)
263       except Exception as e:  # pylint:disable=broad-except
264         if hasattr(e, 'ag_error_metadata'):
--&gt; 265           raise e.ag_error_metadata.to_exception(e)
266         else:
267           raise

RuntimeError: in user code:

/usr/local/lib/python3.6/dist-packages/tensorflow_hub/keras_layer.py:222 call  *
    result = f()
/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py:486 _call_attribute  **
    return instance.__call__(*args, **kwargs)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:580 __call__
    result = self._call(*args, **kwds)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:618 _call
    results = self._stateful_fn(*args, **kwds)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:2420 __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1665 _filtered_call
    self.captured_inputs)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1760 _call_flat
    flat_outputs = forward_function.call(ctx, args_with_tangents)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:627 call
    executor_type=executor_type)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py:1148 partitioned_call
    args = [ops.convert_to_tensor(x) for x in args]
/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py:1148 &lt;listcomp&gt;
    args = [ops.convert_to_tensor(x) for x in args]
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1307 convert_to_tensor
    raise RuntimeError(&quot;Attempting to capture an EagerTensor without &quot;

RuntimeError: Attempting to capture an EagerTensor without building a function.
</code></pre>
",12008239,,,,,44018.54861,'Attempting to capture an EagerTensor without building a function' Error: While building Federated Averaging Process,<tensorflow><tensorflow2.0><tf.keras><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
62786889,1,62816642,,44020.12569,,1,605,"<p>An error is being generated while training a federated model that uses hub.KerasLayer. The details of error and stack trace is given below. The complete code is available of gist <a href=""https://gist.github.com/aksingh2411/60796ee58c88e0c3f074c8909b17b5a1"" rel=""nofollow noreferrer"">https://gist.github.com/aksingh2411/60796ee58c88e0c3f074c8909b17b5a1</a>. Help and suggestion in this regard would be appreciated. Thanks.</p>
<pre><code>from tensorflow import keras

def create_keras_model():
 encoder = hub.load(&quot;https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1&quot;)
 return tf.keras.models.Sequential([
  hub.KerasLayer(encoder, input_shape=[],dtype=tf.string,trainable=True),
  keras.layers.Dense(32, activation='relu'),
  keras.layers.Dense(16, activation='relu'),
  keras.layers.Dense(1, activation='sigmoid'),
])

def model_fn():
# We _must_ create a new model here, and _not_ capture it from an external
# scope. TFF will call this within different graph contexts.
keras_model = create_keras_model()
return tff.learning.from_keras_model(
  keras_model,
  input_spec=preprocessed_example_dataset.element_spec,
  loss=tf.keras.losses.BinaryCrossentropy(),
  metrics=[tf.keras.metrics.Accuracy()])

# Building the Federated Averaging Process
iterative_process = tff.learning.build_federated_averaging_process(
 model_fn,
 client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
 server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

str(iterative_process.initialize.type_signature)
state = iterative_process.initialize()

state, metrics = iterative_process.next(state, federated_train_data)
print('round  1, metrics={}'.format(metrics))

UnimplementedError                        Traceback (most recent call last)
&lt;ipython-input-80-39d62fa827ea&gt; in &lt;module&gt;()
----&gt; 1 state, metrics = iterative_process.next(state, federated_train_data)
  2 print('round  1, metrics={}'.format(metrics))

119 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in 
quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
 58     ctx.ensure_initialized()
 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---&gt; 60                                         inputs, attrs, num_outputs)
 61   except core._NotOkStatusException as e:
 62     if name is not None:

UnimplementedError:    Cast string to float is not supported
 [[{{node StatefulPartitionedCall_1/StatefulPartitionedCall/Cast_1}}]]
 [[StatefulPartitionedCall_1]]
 [[import/StatefulPartitionedCall_3/ReduceDataset]] [Op:__inference_wrapped_function_65986]

Function call stack:
wrapped_function -&gt; wrapped_function -&gt; wrapped_function
</code></pre>
",12008239,,,,,44021.58472,'Error While Encoding with Hub.KerasLayer' while using TFF,<tensorflow><tensorflow2.0><tf.keras><tensorflow-federated>,1,3,,,,CC BY-SA 4.0
62832704,1,,,44022.45069,,1,427,"<p>My Tensorflow Federated model is taking too long to converge. When I use the same model without TFF wrapping, training it with tensoflow 2.0, the accuracy reaches 0.97 within few epochs. However, with TFF training the same model is able to reach only 0.03 in 30 epochs. What could be the reason for such low accuracy during TFF training. Is there a way to improve this. My code is given below:</p>
<pre class=""lang-py prettyprint-override""><code># Building the Federated Averaging Process
iterative_process = tff.learning.build_federated_averaging_process(
  model_fn,
  client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
  server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0))

str(iterative_process.initialize.type_signature)

state = iterative_process.initialize()

state, metrics = iterative_process.next(state, federated_train_data)
print('round  1, metrics={}'.format(metrics))

NUM_ROUNDS = 1000
for round_num in range(2, NUM_ROUNDS):
  state, metrics = iterative_process.next(state, federated_train_data)
  print('round {:2d}, metrics={}'.format(round_num, metrics))
</code></pre>
",12008239,,14692,,44023.16319,44023.16319,Accuracy is Decreasing Too Slowly with each Epoch in Tensorflow Federated Training,<tensorflow><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
62840937,1,,,44022.80139,,1,83,"<p>I would like to implement a code of image classification with tensorflow-federated, So when I create the model and I pass it to federated averaging process, I find error that I can't understand here. Here is a part of my code implemented with TFF</p>
<pre class=""lang-py prettyprint-override""><code>input_shape = (224,224,3)
def create_compiled_keras_model(input_shape, base_model='resnet18'):
    inputs = tf.keras.layers.Input(shape=(input_shape))

    base_encoder = tf.keras.applications.ResNet50(
      include_top=False, weights=None, input_tensor=None,
      input_shape=None, pooling='avg')
    base_encoder.training = True

    h = base_encoder(inputs)
    x = tf.keras.layers.Dense(2)(h)
    x = tf.keras.layers.Activation('relu')(x)
    x = tf.keras.layers.Dense(2)(x)

    model = tf.keras.Model(inputs=inputs, outputs=[h, x])
    model.compile(
      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
      loss=tf.keras.losses.CategoricalCrossentropy(),
      metrics=[tf.keras.metrics.CategoricalAccuracy()])
    return model

def model_fn():
    keras_model = create_compiled_keras_model(input_shape, base_model='resnet18')
    return tff.learning.from_compiled_keras_model(keras_model, sample_batch) 

iterative_process = tff.learning.build_federated_averaging_process(model_fn, server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),client_weight_fn=None)
</code></pre>
<p>The error was:</p>
<pre><code>ValueError: Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), for inputs ['resnet50', 'dense_1'] but instead got the following list of 1 arrays: [&lt;tf.Tensor 'Const_1:0' shape=(2, 2) dtype=float32&gt;]...
</code></pre>
<p>Thanks for help!!</p>
",12682667,,14692,,44023.35139,44023.35139,TFF :ValueError Error when checking model target,<tensorflow><tensorflow-federated>,0,3,,,,CC BY-SA 4.0
62893523,1,62927659,,44026.45278,,3,1812,"<p>I have the following codes and problem when trying to create OrderedDict for multiple feature inputs (i.e., features a-g) and one label h.</p>
<pre><code>
def preprocess(dataset):

  def batch_format_fn(element):

    return collections.OrderedDict(
        x=collections.OrderedDict(
            a=tf.TensorSpec(shape=[None,], dtype=tf.int32),
            b=tf.TensorSpec(shape=[None,], dtype=tf.int32),
            c=tf.TensorSpec(shape=[None,], dtype=tf.int32),
            d=tf.TensorSpec(shape=[None,], dtype=tf.int32),
            e=tf.TensorSpec(shape=[None,], dtype=tf.int32),
            f=tf.TensorSpec(shape=[None,], dtype=tf.int32),
            g=tf.TensorSpec(shape=[None,], dtype=tf.int32)),
        y=tf.TensorSpec(shape=[None,], dtype=tf.int32))
  return dataset.map(batch_format_fn).prefetch(PREFETCH_BUFFER)

preprocessed_sample_dataset = preprocess(example_dataset)

def create_keras_model():
    model = Sequential([
    feature_layer,
    Dense(64, activation='relu'),
    Dense(64, activation='relu'),
    Dense(3, activation='softmax') #classification 3 outputs
    ])
    return model

def model_fn():

  keras_model = create_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=preprocessed_sample_dataset.element_spec,
      loss=losses.SparseCategoricalCrossentropy(),
      metrics=[metrics.SparseCategoricalAccuracy()])

</code></pre>
<p>It shows an error like this when executing <code>input_spec=preprocessed_sample_dataset.element_spec</code>:</p>
<pre><code>TypeError: Unsupported return value from function passed to Dataset.map(): OrderedDict([('x', OrderedDict([('a', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('b', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('c', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('d', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('e', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('f', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('g', TensorSpec(shape=(None,), dtype=tf.int32, name=None))])), ('y', TensorSpec(shape=(None,), dtype=tf.int32, name=None))]).
</code></pre>
<p>I have read this alternative <a href=""https://stackoverflow.com/questions/61458419/solved-tensorflow-federated-tff-learning-from-keras-model-with-a-model-wit"">solution</a>, however it is not clear how to implement it in my case. Hence, how to correctly assign ordered dict for the multiple features in TFF?</p>
<p>The current example_dataset.element_spec is as follows:</p>
<pre><code>OrderedDict([
('a', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('b', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('c', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('d', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('e', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('f', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('g', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('y', TensorSpec(shape=(None,), dtype=tf.int32, name=None))])
</code></pre>
<p>I want the element_spec becomes like this:</p>
<pre><code>OrderedDict([('x', OrderedDict([
('a', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('b', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('c', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('d', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('e', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('f', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), 
('g', TensorSpec(shape=(None,), dtype=tf.int32, name=None))])), 
('y', TensorSpec(shape=(None,), dtype=tf.int32, name=None))])
</code></pre>
<p>How to make the element_spec as the latter one using the batch_format_fn?</p>
",10988616,,10988616,,44028.22569,44028.58403,How to build a model using multiple features in Tensorflow Federated?,<python><tensorflow><tensorflow-federated>,1,4,,,,CC BY-SA 4.0
72556795,1,72574434,,44721.33958,,1,167,"<p>I was following this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">Image classification tutorial</a> and <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation"" rel=""nofollow noreferrer"">Text Generation tutorial</a>. So I've implemented transfer learning with fine-tuning on my dataset but I don't know how to access labels whenever I am doing predictions.
I transformed my data into the right shape (tf.data.Dataset) so I am using the Keras model for predictions. So for example if I want just to predict one label: <code>keras_model.predict(federated_train_data[0]) </code></p>
<p>federated_train_data consists of following elements:</p>
<pre><code>(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name=None),
 TensorSpec(shape=(None,), dtype=tf.int64, name=None))
</code></pre>
<p>First Tensor is an image shape and the second one represents encoded labels.</p>
<p>My goal is to illustrate what are true and predicted labels of an image, for example:(<a href=""https://i.sstatic.net/p5KwL.png"" rel=""nofollow noreferrer"">Predicted classes</a>)</p>
<p>TLDR: Is there a way that you can access just labels when you have tf.data.Dataset?</p>
",11776320,,11776320,,44721.675,44722.52569,How to access labels with TFF,<python-3.x><tensorflow><tensorflow-federated><federated-learning><federated>,1,1,,,,CC BY-SA 4.0
72561857,1,,,44721.59167,,2,75,"<p>I am trying to implement a simple binary classifier for the <a href=""https://www.kaggle.com/datasets/hassan06/nslkdd/code"" rel=""nofollow noreferrer"">KDD</a> dataset using Tensorflow's federated learning framework.
Following <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">this</a> tutorial what i have done so far is :</p>
<ol>
<li><p>implemented a classical centralized model(outside of tff) achieving convergence and accurate results</p>
</li>
<li><p>Tried to integrate this approach wthin the Federated framework as seen below :</p>
</li>
</ol>
<h1>Functions</h1>
<pre><code>def make_federated_data(client_data, client_ids):
  return [
      preprocess(client_data.create_tf_dataset_for_client(x))
      for x in client_ids]

def create_keras_model():
  return tf.keras.models.Sequential([
      tf.keras.layers.InputLayer(input_shape=(41,)),
      tf.keras.layers.Dense(82, activation='relu'),
      tf.keras.layers.Dense(41, activation='relu'),
      tf.keras.layers.Dense(1, activation= 'sigmoid')])


def model_fn():
  # We _must_ create a new model here, and _not_ capture it from an external
  # scope. TFF will call this within different graph contexts.
  keras_model = create_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=preprocessed_example_dataset.element_spec,
      loss=tf.keras.losses.BinaryCrossentropy(),
      metrics=[tf.keras.metrics.Accuracy()])

def create_tf_dataset_for_client_fn(client_id):
      dataset = tf.data.Dataset.from_tensor_slices(train_set.to_dict(&quot;list&quot;))
      return dataset
    
    
def create_tf_dataset_for_client_fn_2(client_id):
      dataset = tf.data.Dataset.from_tensor_slices(test.to_dict(&quot;list&quot;))
      return dataset
    def preprocess(dataset):

def preprocess(dataset):
  def batch_format_fn(element):
    &quot;&quot;&quot;converting each sample to an `OrderedDict` and then formatting it&quot;&quot;&quot;
    
    return collections.OrderedDict(
          x =  tf.reshape(tf.concat([element[i] for i in element.keys() if i!='class'],0), [-1, 41]) ,
        y = tf.reshape(element['class'], [-1, 1]))

  return dataset.repeat(5).shuffle(100, seed=1).batch(  # Repeat = number of rounds
      12).map(batch_format_fn).prefetch(10)
</code></pre>
<h1>Main</h1>
<pre><code>    # train_Set and test_Set are dataframes(scaled) with 41 features 
#and 1 label
    #adding client number to each sample
n_clients = 10
train_set['id'] = np.random.randint(0, n_clients ,train_set.shape[0])
test_set['id'] = np.random.randint(0, n_clients , test_set.shape[0])
# DataFrame  conversion
    train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(
            client_ids = list(client_ids),
            serializable_dataset_fn=create_tf_dataset_for_client_fn
        )
    
    test_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(
            client_ids = list(client_ids),
            serializable_dataset_fn=create_tf_dataset_for_client_fn_2
        )

    # Sampling for tff
    example_dataset = train_data.create_tf_dataset_for_client(
                 train_data.client_ids[0])
    preprocessed_example_dataset = preprocess(example_dataset)
    iterative_process = tff.learning.build_federated_averaging_process(
        model_fn,
        client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.001),
        server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.001))

     federated_train_data = make_federated_data(train_data, train_data.client_ids) 
</code></pre>
<p>Where we have 41 features and a label.I have also checked the labels here and they correctly are between 0 and 1.
At this point federated data signature is :</p>
<pre><code>&lt;PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 41), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])&gt;,
 &lt;PrefetchDataset element_spec=OrderedDict([('x', TensorSpec(shape=(None, 41), dtype=tf.float32, name=None)), ('y', TensorSpec(shape=(None, 1), dtype=tf.float32, name=None))])&gt;,
         ...
</code></pre>
<p>Finally,</p>
<pre><code>state = iterative_process.initialize()
NUM_ROUNDS = 10
for round_num in range(0, NUM_ROUNDS):
  state, metrics = iterative_process.next(state, federated_train_data)
  print('round {:2d}, metrics={}'.format(round_num, metrics))
</code></pre>
<p>The result of the loop above is 0.0 accuracy for each iteration and  loss that is not really changing.<br />
The problem is probably related to the model and the training process since i think the dataset is in correct format but i can't figure out what it is.<br />
The results mentioned probably indicate that the model is not training at all and also that it outputs something completely different from (0,1).<br />
It is also noted that the state(model's weights) do change after each iteration.<br />
Any ideas?</p>
",19307370,,19307370,,44721.59722,44721.59722,0 Accuracy for federated training,<tensorflow><tensorflow-federated>,0,0,,,,CC BY-SA 4.0
72617036,1,,,44726.52153,,0,123,"<p>I am wondering, in federated machine learning, when we train our local models, and intend to update the cloud model, what protocol we use to transmit those weight? Also, when we use the tensorflow federated machine learning, how we transmit the weight (using which library and protocol)?</p>
<p>Kind regards,</p>
",4554243,,,,,45024.56181,Weight transmission protocol in Federated Machine Learning,<machine-learning><protocols><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
72652038,1,72981298,,44728.89167,,1,371,"<p>I am training a tensorflow federated learning model. I cannot see the output of epochs. Details are as follows:</p>
<pre><code>split = 4
NUM_ROUNDS = 5
NUM_EPOCHS = 10
BATCH_SIZE = 2
PREFETCH_BUFFER = 5
</code></pre>
<pre class=""lang-py prettyprint-override""><code>
for round_num in range(1, NUM_ROUNDS+1):
    state, tff_metrics = iterative_process.next(state, federated_train_data) 
    print('round {:2d}, metrics{}'.format(round_num,tff_metrics['train'].items()))
    
    eval_model = create_keras_model()
    eval_model.compile(optimizer=optimizers.Adam(learning_rate=client_lr),
                       loss=losses.BinaryCrossentropy(),
                       metrics=[tf.keras.metrics.Accuracy()])
    
    #tff.learning.assign_weights_to_keras_model(eval_model, state.model)
    state.model.assign_weights_to(eval_model)
    
    ev_result = eval_model.evaluate(x_val, y_val, verbose=2)
    train_metrics = tff_metrics['train']
      for name, value in tff_metrics['train'].items():
            tf.summary.scalar(name,value, step=round_num)
    
    tff_val_acc.append(ev_result[1])
    tff_val_loss.append(ev_result[0])
</code></pre>
<p>And my output looks as follows:</p>
<pre><code>
    round  1, metrics=odict_items([('accuracy', 0.0), ('loss', 1.2104079)])
    1/1 - 1s - loss: 0.7230 - accuracy: 0.0000e+00 - 1s/epoch - 1s/step
    round  2, metrics=odict_items([('accuracy', 0.0007142857), ('loss', 1.2233553)])
    1/1 - 1s - loss: 0.6764 - accuracy: 0.0000e+00  - 646ms/epoch - 646ms/step
    round  3, metrics=odict_items([('accuracy', 0.0),  ('loss', 1.1939998)])
    1/1 - 1s - loss: 0.6831 - accuracy: 0.0000e+00  - 635ms/epoch - 635ms/step
    round  4, metrics=odict_items([('accuracy', 0.0), ('loss', 1.2829995)])
    1/1 - 1s - loss: 0.6830 - accuracy: 0.0000e+00  - 641ms/epoch - 641ms/step
    round  5, metrics=odict_items([('accuracy', 0.0),  ('loss', 1.2051892)])
    1/1 - 1s - loss: 0.7135 - accuracy: 0.0000e+00 - 621ms/epoch - 621ms/step

</code></pre>
<p>Are these values for global model after each round? How can I plot the curves for validation accuracy of the global model for the 100 epochs (10 rounds, 10 local epochs per round)? (Not in tensorboard)</p>
",10543101,,,,,44756.55903,Why can't I see the local epochs output when training tensorflow federated learning model?,<python-3.x><tensorflow2.0><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72674232,1,,,44731.17569,,3,349,"<p>I am running the code in tensorflow federated learning (10 epochs, 100 rounds), but the accuracy is not increasing and it's around 0.5. Part of my code is as follows:</p>
<pre class=""lang-py prettyprint-override""><code>def create_compiled_keras_model():
    layer1 = tf.keras.layers.GlobalAveragePooling2D()(output)
    layer1 = tf.keras.layers.Dense(units=256)(output)
    model_output = tf.keras.layers.Dense(units=2, activation='relu')(layer1)
    model = tf.keras.Model(model.input, model_output)
    return model

def model_fn():
     keras_model = create_compiled_keras_model()
     return tff.learning.from_keras_model(keras_model, sample_batch, loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[tf.keras.metrics.CategoricalAccuracy()]) 
</code></pre>
<p>And,</p>
<pre class=""lang-py prettyprint-override""><code>for round_num in range(1, NUM_ROUNDS+1):
    state, tff_metrics = iterative_process.next(state, federated_train_data) 
    print('round {:2d}, metrics{}'.format(round_num,tff_metrics['train'].items()))
    
    eval_model = create_keras_model()
    eval_model.compile(optimizer=optimizers.Adam(learning_rate=client_lr),
                       loss=losses.BinaryCrossentropy(),
                       metrics=[tf.keras.metrics.Accuracy()])
    
    state.model.assign_weights_to(eval_model)
    
    ev_result = eval_model.evaluate(x_val, y_val, verbose=2)
    train_metrics = tff_metrics['train']
      for name, value in tff_metrics['train'].items():
            tf.summary.scalar(name,value, step=round_num)
</code></pre>
<p>I saw few questions on stackoverflow on this, but couldn't find the solution anywhere.I would appreciate any help.</p>
",10543101,,10543101,,44732.97083,44733.60972,Accuracy does not increase in Tensorflow Federated Learning,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
72698170,1,72698704,,44733.38472,,-3,740,"<p>I am getting the following error related to this function definition what is wrong?</p>
<p>Convert_to_client_data() is a function in federated learning where I am trying to convert a dataset into the federated dataset.</p>
<p>Here is the declaration of the class Distribute which is used in the function which gives the error</p>
<p>#Declaration of Class Distribute</p>
<pre><code>def partition_list (list_in, n):
    random.shuffle(list_in)
    return [list_in[i::n] for i in range(n)]

class Distribute:
    def __init__(self, data, data_type):

        self.data = data
        self.data_type = data_type.lower()
        self.selected_feature = -1
        self.type = 'iid'
        self.client_no = 10
        self.data_sample_fraction = 0.1
        self.min_user_number = 10
        self.max_user_number = 20
        self.train_data_fraction = 0.9
        self.random_sampling_seed = 4
        self.random_split_seed = 1
        self.split_type = 'sample'

    def __shuffle(self, data, label):
        random.Random(self.random_sampling_seed).shuffle(data)

    def _iid_no_clint(self):
        size = random.randrange(2, len(self.data))
        self.__shuffle(self.data)

        glist = []
        group_size = int(len(self.data) / size)
        for i in range(size):
            glist.append(self.data[group_size * i: group_size * (i + 1)])

        return glist

    def _iid_clint(self, number_of_clients):

        self.__shuffle(self.data)

        glist = []
        group_size = int(len(self.data) / number_of_clients)

        for i in range(number_of_clients):
            glist.append(self.data[group_size * i: group_size * (i + 1)])

        return glist

    def _iid(self, **kwargs):
        number_of_clients = kwargs.get('number_of_clients')
        if number_of_clients:
            return self._iid_clint(number_of_clients)
        else:
            return self._iid_no_clint()

    def _niid(self, **kwargs):

        selected_feature = kwargs.get('selected_feature', self.selected_feature)
        min_user_number = kwargs.get('min_user_number', self.min_user_number)
        max_user_number = kwargs.get('max_user_number', self.max_user_number)
        number_of_clients = kwargs.get('number_of_clients')

        data_type = kwargs.get('data_type')

        if data_type == 'image':
            if number_of_clients:
                if number_of_clients &gt; len(self.data):
                    raise ValueError('Total number of data:', len(self.data),
                                     'is less than total number of clients specified:', number_of_clients)
                else:
                    data = self.__select_feature_image_client(number_of_clients)
            else:
                data = self.__select_feature_image_no_client(min_user_number, max_user_number)

        elif data_type == 'text':
            if number_of_clients:
                if number_of_clients &gt; len(self.data):
                    raise ValueError('Total number of data:', len(self.data),
                                     'is less than total number of clients specified:', number_of_clients)
                else:
                    data = self.__select_feature_text_client(number_of_clients)
            else:
                data = self.__select_feature_text_no_client(min_user_number, max_user_number)

        elif data_type == 'csv':
            if number_of_clients:
                if number_of_clients &gt; len(self.data):
                    raise ValueError('Total number of data:', len(self.data),
                                     'is less than total number of clients specified:', number_of_clients)
                else:
                    data = self.__select_feature_csv_client(number_of_clients)
            else:
                data = self.__select_feature_csv_no_client(min_user_number, max_user_number)
        else:
            raise ValueError(
                f'Given data type: &quot;{data_type}&quot; is not correct, choose between options &quot;text&quot; or &quot;image&quot;.')

        return data

    def distribute_data(self, **kwargs):
        if kwargs.get('dist_type', self.type) == 'iid':
            return self._iid(**kwargs)
        else:
            return self._niid(**kwargs)

    def __select_feature_image_no_client(self, min_user_number, max_user_number):

        client_size = random.randint(min_user_number, max_user_number)
        grouped_data = partition_list (self.data, client_size)

        return grouped_data

    def __select_feature_image_client(self, number_of_clients):

        grouped_data = np.array_split(self.data, number_of_clients)

        return grouped_data

    def __select_feature_text_no_client(self, min_user_number, max_user_number):

        client_size = random.randint(min_user_number, max_user_number)
        grouped_data = partition_list (self.data, client_size)

        return grouped_data

    def __select_feature_text_client(self, number_of_clients):

        grouped_data = np.array_split(self.data, number_of_clients)

        return grouped_data

    def __select_feature_csv_no_client(self, min_user_number, max_user_number):

        client_size = random.randint(min_user_number, max_user_number)
        grouped_data = partition_list (self.data, client_size)

        return grouped_data

    def __select_feature_csv_client(self, number_of_clients):

        grouped_data = np.array_split(self.data, number_of_clients)

        return grouped_data

        
    def split_data(self, x, y, **kwargs):
        train_data_fraction = kwargs.get('train_data_fraction', self.train_data_fraction)
        if kwargs.get('type', self.type) == 'sample':
            return self._sample_split(x, y, train_data_fraction)
        else:
            return self._user_split(train_data_fraction)

    def _user_split(self, train_data_fraction):
        rng_seed = (self.random_split_seed if (self.random_split_seed is not None and self.random_split_seed &gt;= 0)
                    else int(time.time()))
        rng = random.Random(rng_seed)
        # randomly sample from user_files to pick training set users
        num_users = self.client_no
        num_train_users = int(train_data_fraction * num_users)
        indices = [i for i in range(num_users)]
        train_indices = rng.sample(indices, num_train_users)
        train_blist = [False for i in range(num_users)]
        for i in train_indices:
            train_blist[i] = True
        train_user_files = []
        test_user_files = []
        train_labels = []
        test_labels = []

        for i in range(num_users):
            if train_blist[i]:
                train_user_files.append(self.data[i])
                train_labels.append(self.label[i])
            else:
                test_user_files.append(self.data[i])
                test_labels.append(self.label[i])

        return train_user_files, test_user_files, train_labels, test_labels

    def _sample_split(self, x, y, train_data_fraction):
        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=train_data_fraction)
        return x_train, x_test, y_train, y_test


#DATA variable


    data_type = 'text'
    input_path = '/content/drive/MyDrive/Divya-Yasaman/v2/data/text/topics_sample'  # accepts either folder or csv file
    
    obj = Reader(data_type, input_path)
    
    %%time
    data = obj.read_data()
  
</code></pre>
<p>#function DEFINITION which gives the error</p>
<pre><code>def convert_to_client_data(data, data_type, **kwargs):

    distributor_obj = Distribute(data, data_type)

    distributed_data = distributor_obj.distribute_data(data_type=data_type, **kwargs)
    

    client_train_dataset = collections.OrderedDict()

    for i in range(len(distributed_data)):
        client_name = &quot;client_&quot; + str(i)
        data = collections.OrderedDict('data', distributed_data[i])
       # data = collections.OrderedDict( distributed_data[i])
        client_train_dataset[client_name] = data

    print(f'Converting data to {len(distributed_data)} client data...')

    train_dataset = tff.simulation.datasets.TestClientData(client_train_dataset)

    print(f'Data successfully converted to {len(distributed_data)} client data.')

    return train_dataset
</code></pre>
<p>ERROR STATEMENT for the function definition</p>
<pre><code>&lt;decorator-gen-53&gt; in time(self, line, cell, local_ns)

&lt;timed exec&gt; in &lt;module&gt;()

&lt;ipython-input-60-7b390d37230c&gt; in convert_to_client_data(data, data_type, **kwargs)
     13     for i in range(len(distributed_data)):
     14         client_name = &quot;client_&quot; + str(i)
---&gt; 15         data = collections.OrderedDict('data', distributed_data[i])
     16        # data = collections.OrderedDict( distributed_data[i])
     17         client_train_dataset[client_name] = data

TypeError: expected at most 1 arguments, got 2
</code></pre>
",13352824,,13352824,,44733.39514,44733.40972,"TypeError: expected at most 1 arguments, got 2....... data = collections.OrderedDict('data', distributed_data[i])",<python><ordereddictionary><tensorflow-federated><federated-learning><ordereddict>,1,9,,45545.85417,,CC BY-SA 4.0
72713816,1,72981108,,44734.43542,,1,63,"<p>I am currently stuck in a dead end. I am trying to make an image caption generator from a federated approach. My initial idea was to have a different tokenizer for each client. That poses these issues however:</p>
<ol>
<li><p>Every client will have a different sized vocabulary, and thus a
different shape of y, which will cause issues with the global model
configuration.</p>
</li>
<li><p>To counter the above issue, I could make size of y in each client
equivalent to the largest size across all clients, and fill the
extra columns in each client with 0. <strong>Example:</strong> [0,1,1,1] mapped to a size
of 6 would become [0,1,1,1,0,0]</p>
</li>
<li><p>This brings me to the last possible flaw, which is that the same
words in different clients will be having different indices. A word
&quot;rock&quot; in client 1 might have an index of 6, while the same can have
an index of 9 in another client. While training the global model, it
will cause issues since the model is trying to learn different label
indices for the same word, which will impact the accuracy?</p>
</li>
</ol>
<p><strong>This brings me to the final question</strong>: Is it against the idea of Federated Learning to tokenize all the words of all the training clients in a single tokenizer?</p>
",12575770,,,,,44758.07917,Is it against privacy of clients if I have a global tokenizer in Federated Learning (TFF)?,<tensorflow><nlp><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72734353,1,,,44735.72986,,2,510,"<p>I've been working on the tutorial for <em>Federated Learning for Image Classification</em>, and while running the tutorial code on Google colab its giving me error while importing <em>tensorflow_federated</em></p>
<p><a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">Federated Learning for Image Classification</a></p>
<p>Code (getting error on line 4):</p>
<pre><code>import collections
import numpy as np
import tensorflow as tf
import tensorflow_federated as tff

np.random.seed(0)

tff.federated_computation(lambda: 'Hello, World!')()
</code></pre>
<p>Error:</p>
<pre><code>    ---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-35-a23308ec3f7c&gt; in &lt;module&gt;()
      3 import numpy as np
      4 import tensorflow as tf
----&gt; 5 import tensorflow_federated as tff
      6 
      7 np.random.seed(0)

6 frames
/usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/common_libs/structure.py in &lt;module&gt;()
    263 
    264 def to_odict(struct: Struct,
--&gt; 265              recursive: bool = False) -&gt; collections.OrderedDict[str, Any]:
    266   &quot;&quot;&quot;Returns `struct` as an `OrderedDict`, if possible.
    267 

TypeError: 'type' object is not subscriptable
</code></pre>
<p>I've tried updating the python version to 3.9 (as mentioned in some of the fixes available) but it didn't work.</p>
<p><em><strong>Solved:</strong></em></p>
<p>I followed this <a href=""https://github.com/tensorflow/federated/issues/2748#issuecomment-1107437271"" rel=""nofollow noreferrer"">issue</a> and installed the 0.20.0 version of <em>tensorflow-federated</em> which worked for me</p>
<pre><code>!pip install --quiet tensorflow-federated==0.20.0
#!pip install --quiet --upgrade tensorflow-federated
!pip install --quiet --upgrade nest-asyncio

import nest_asyncio
nest_asyncio.apply()
</code></pre>
",17405676,,14692,,44756.54236,44756.54236,Error while importing 'tensorflow_federated' on Google Colab Tutorial,<google-colaboratory><tensorflow-federated>,0,0,,,,CC BY-SA 4.0
72777309,1,,,44739.80278,,0,104,"<p>I'm trying to switch from a federated setting to centralized learning. I've created a federated dataset, but I want to create a dataset for centralized learning with the <em>create_tf_dataset_from_all_clients</em> function. When I googled the error I found out that maybe versions of NumPy and TensorFlow are not correct for this function, my current versions are :</p>
<ul>
<li>python == 3.9</li>
<li>tensorflow==2.8.2</li>
<li>numpy==1.21.6</li>
<li>tensorflow-federated==0.24.0</li>
</ul>
<p>I haven't found some recent posts about TensorFlow 2.8 and matching NumPy version</p>
<p>Also, the error might come from a function that I used to create the clientData object:</p>
<pre><code> def parse_image(filename):
    parts = tf.strings.split(filename, os.sep)
    label_str = parts[-2]

    label_int = tf.where(labels_tf == label_str)[0][0]

    image = tf.io.read_file(filename)
    image = tf.io.decode_jpeg(image, channels=3)
    image = tf.image.convert_image_dtype(image, tf.float32)
    image = tf.image.resize(image, [32, 32])
    image = tf.keras.applications.resnet50.preprocess_input(image)

    if base_model == &quot;VGG16&quot;:
        print(&quot;-------- preprocessing image for base_model VGG16 --------&quot;)

        image = tf.keras.applications.vgg16.preprocess_input(image)

    elif base_model == &quot;ResNet&quot;:
        print(&quot;-------- preprocessing image for base_model  ResNet --------&quot;)

        image = tf.keras.applications.resnet.preprocess_input(image)

    return image, label_int

def create_dataset(client_id):

    df = train_set

    client_id = int(client_id)

    file = df.loc[df[&quot;client_id&quot;] == client_id]
    # print(file)
    path = file[&quot;path&quot;]

    # print(path)
    list_ds = tf.data.Dataset.list_files(path)

    images_ds = list_ds.map(parse_image)

    return images_ds
</code></pre>
<p>Error:</p>
<pre><code>TypeError                                 Traceback (most recent call last)
Input In [7], in &lt;cell line: 1&gt;()
----&gt; 1 train_dataset = client_data.create_tf_dataset_from_all_clients()

File ~/master_venv/lib/python3.9/site-packages/tensorflow_federated/python/simulation/datasets/client_data.py:231, in ClientData.create_tf_dataset_from_all_clients(self, seed)
    227 nested_dataset = tf.data.Dataset.from_tensor_slices(client_ids)
    228 # We apply serializable_dataset_fn here to avoid loading all client datasets
    229 # in memory, which is slow. Note that tf.data.Dataset.map implicitly wraps
    230 # the input mapping in a tf.function.
--&gt; 231 example_dataset = nested_dataset.flat_map(self.serializable_dataset_fn)
    232 return example_dataset

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2092, in DatasetV2.flat_map(self, map_func, name)
   2058 def flat_map(self, map_func, name=None):
   2059   &quot;&quot;&quot;Maps `map_func` across this dataset and flattens the result.
   2060 
   2061   The type signature is:
   (...)
   2090     Dataset: A `Dataset`.
   2091   &quot;&quot;&quot;
-&gt; 2092   return FlatMapDataset(self, map_func, name=name)

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:5327, in FlatMapDataset.__init__(self, input_dataset, map_func, name)
   5325 &quot;&quot;&quot;See `Dataset.flat_map()` for details.&quot;&quot;&quot;
   5326 self._input_dataset = input_dataset
-&gt; 5327 self._map_func = structured_function.StructuredFunctionWrapper(
   5328     map_func, self._transformation_name(), dataset=input_dataset)
   5329 if not isinstance(self._map_func.output_structure, DatasetSpec):
   5330   raise TypeError(
   5331       &quot;The `map_func` argument must return a `Dataset` object. Got &quot;
   5332       f&quot;{_get_type(self._map_func.output_structure)!r}.&quot;)

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:271, in StructuredFunctionWrapper.__init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)
    264       warnings.warn(
    265           &quot;Even though the `tf.config.experimental_run_functions_eagerly` &quot;
    266           &quot;option is set, this option does not apply to tf.data functions. &quot;
    267           &quot;To force eager execution of tf.data functions, please use &quot;
    268           &quot;`tf.data.experimental.enable_debug_mode()`.&quot;)
    269     fn_factory = trace_tf_function(defun_kwargs)
--&gt; 271 self._function = fn_factory()
    272 # There is no graph to add in eager mode.
    273 add_to_graph &amp;= not context.executing_eagerly()

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2567, in Function.get_concrete_function(self, *args, **kwargs)
   2558 def get_concrete_function(self, *args, **kwargs):
   2559   &quot;&quot;&quot;Returns a `ConcreteFunction` specialized to inputs and execution context.
   2560 
   2561   Args:
   (...)
   2565        or `tf.Tensor` or `tf.TensorSpec`.
   2566   &quot;&quot;&quot;
-&gt; 2567   graph_function = self._get_concrete_function_garbage_collected(
   2568       *args, **kwargs)
   2569   graph_function._garbage_collector.release()  # pylint: disable=protected-access
   2570   return graph_function

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2533, in Function._get_concrete_function_garbage_collected(self, *args, **kwargs)
   2531   args, kwargs = None, None
   2532 with self._lock:
-&gt; 2533   graph_function, _ = self._maybe_define_function(args, kwargs)
   2534   seen_names = set()
   2535   captured = object_identity.ObjectIdentitySet(
   2536       graph_function.graph.internal_captures)

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2711, in Function._maybe_define_function(self, args, kwargs)
   2708   cache_key = self._function_cache.generalize(cache_key)
   2709   (args, kwargs) = cache_key._placeholder_value()  # pylint: disable=protected-access
-&gt; 2711 graph_function = self._create_graph_function(args, kwargs)
   2712 self._function_cache.add(cache_key, cache_key_deletion_observer,
   2713                          graph_function)
   2715 return graph_function, filtered_flat_args

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2627, in Function._create_graph_function(self, args, kwargs)
   2622 missing_arg_names = [
   2623     &quot;%s_%d&quot; % (arg, i) for i, arg in enumerate(missing_arg_names)
   2624 ]
   2625 arg_names = base_arg_names + missing_arg_names
   2626 graph_function = ConcreteFunction(
-&gt; 2627     func_graph_module.func_graph_from_py_func(
   2628         self._name,
   2629         self._python_function,
   2630         args,
   2631         kwargs,
   2632         self.input_signature,
   2633         autograph=self._autograph,
   2634         autograph_options=self._autograph_options,
   2635         arg_names=arg_names,
   2636         capture_by_value=self._capture_by_value),
   2637     self._function_attributes,
   2638     spec=self.function_spec,
   2639     # Tell the ConcreteFunction to clean up its graph once it goes out of
   2640     # scope. This is not the default behavior since it gets used in some
   2641     # places (like Keras) where the FuncGraph lives longer than the
   2642     # ConcreteFunction.
   2643     shared_func_graph=False)
   2644 return graph_function

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1141, in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)
   1138 else:
   1139   _, original_func = tf_decorator.unwrap(python_func)
-&gt; 1141 func_outputs = python_func(*func_args, **func_kwargs)
   1143 # invariant: `func_outputs` contains only Tensors, CompositeTensors,
   1144 # TensorArrays and `None`s.
   1145 func_outputs = nest.map_structure(
   1146     convert, func_outputs, expand_composites=True)

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:248, in StructuredFunctionWrapper.__init__.&lt;locals&gt;.trace_tf_function.&lt;locals&gt;.wrapped_fn(*args)
    242 @eager_function.defun_with_attributes(
    243     input_signature=structure.get_flat_tensor_specs(
    244         self._input_structure),
    245     autograph=False,
    246     attributes=defun_kwargs)
    247 def wrapped_fn(*args):  # pylint: disable=missing-docstring
--&gt; 248   ret = wrapper_helper(*args)
    249   ret = structure.to_tensor_list(self._output_structure, ret)
    250   return [ops.convert_to_tensor(t) for t in ret]

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:177, in StructuredFunctionWrapper.__init__.&lt;locals&gt;.wrapper_helper(*args)
    175 if not _should_unpack(nested_args):
    176   nested_args = (nested_args,)
--&gt; 177 ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)
    178 if _should_pack(ret):
    179   ret = tuple(ret)

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:692, in convert.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(*args, **kwargs)
    690 except Exception as e:  # pylint:disable=broad-except
    691   if hasattr(e, 'ag_error_metadata'):
--&gt; 692     raise e.ag_error_metadata.to_exception(e)
    693   else:
    694     raise

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:689, in convert.&lt;locals&gt;.decorator.&lt;locals&gt;.wrapper(*args, **kwargs)
    687 try:
    688   with conversion_ctx:
--&gt; 689     return converted_call(f, args, kwargs, options=options)
    690 except Exception as e:  # pylint:disable=broad-except
    691   if hasattr(e, 'ag_error_metadata'):

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py:439, in converted_call(f, args, kwargs, caller_fn_scope, options)
    437 try:
    438   if kwargs is not None:
--&gt; 439     result = converted_f(*effective_args, **kwargs)
    440   else:
    441     result = converted_f(*effective_args)

File /var/folders/w2/fcxhc9j52tb9hymgw1b8_dmh0000gn/T/__autograph_generated_filepc7z792y.py:11, in outer_factory.&lt;locals&gt;.inner_factory.&lt;locals&gt;.tf__create_dataset(client_id)
      9 retval_ = ag__.UndefinedReturnValue()
     10 client_id = ag__.converted_call(ag__.ld(int), (ag__.ld(client_id),), None, fscope)
---&gt; 11 files = ag__.ld(df).loc[ag__.ld(df)['client_id'] == ag__.ld(client_id)]
     12 path = ag__.ld(files)['path']
     13 list_ds = ag__.converted_call(ag__.ld(tf).data.Dataset.list_files, (ag__.ld(path),), None, fscope)

File ~/master_venv/lib/python3.9/site-packages/pandas/core/ops/common.py:70, in _unpack_zerodim_and_defer.&lt;locals&gt;.new_method(self, other)
     66             return NotImplemented
     68 other = item_from_zerodim(other)
---&gt; 70 return method(self, other)

File ~/master_venv/lib/python3.9/site-packages/pandas/core/arraylike.py:40, in OpsMixin.__eq__(self, other)
     38 @unpack_zerodim_and_defer(&quot;__eq__&quot;)
     39 def __eq__(self, other):
---&gt; 40     return self._cmp_method(other, operator.eq)

File ~/master_venv/lib/python3.9/site-packages/pandas/core/series.py:5625, in Series._cmp_method(self, other, op)
   5622 with np.errstate(all=&quot;ignore&quot;):
   5623     res_values = ops.comparison_op(lvalues, rvalues, op)
-&gt; 5625 return self._construct_result(res_values, name=res_name)

File ~/master_venv/lib/python3.9/site-packages/pandas/core/series.py:3017, in Series._construct_result(self, result, name)
   3013     return (res1, res2)
   3015 # We do not pass dtype to ensure that the Series constructor
   3016 #  does inference in the case where `result` has object-dtype.
-&gt; 3017 out = self._constructor(result, index=self.index)
   3018 out = out.__finalize__(self)
   3020 # Set the result's name after __finalize__ is called because __finalize__
   3021 #  would set it back to self.name

File ~/master_venv/lib/python3.9/site-packages/pandas/core/series.py:442, in Series.__init__(self, data, index, dtype, name, copy, fastpath)
    440     index = default_index(len(data))
    441 elif is_list_like(data):
--&gt; 442     com.require_length_match(data, index)
    444 # create/copy the manager
    445 if isinstance(data, (SingleBlockManager, SingleArrayManager)):

File ~/master_venv/lib/python3.9/site-packages/pandas/core/common.py:556, in require_length_match(data, index)
    552 def require_length_match(data, index: Index):
    553     &quot;&quot;&quot;
    554     Check the length of data matches the length of the index.
    555     &quot;&quot;&quot;
--&gt; 556     if len(data) != len(index):
    557         raise ValueError(
    558             &quot;Length of values &quot;
    559             f&quot;({len(data)}) &quot;
    560             &quot;does not match length of index &quot;
    561             f&quot;({len(index)})&quot;
    562         )

File ~/master_venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:932, in Tensor.__len__(self)
    931 def __len__(self):
--&gt; 932   raise TypeError(f&quot;len is not well defined for a symbolic Tensor &quot;
    933                   f&quot;({self.name}). Please call `x.shape` rather than &quot;
    934                   f&quot;`len(x)` for shape information.&quot;)

TypeError: in user code:

    File &quot;/var/folders/w2/fcxhc9j52tb9hymgw1b8_dmh0000gn/T/ipykernel_2264/3413278942.py&quot;, line 7, in create_dataset  *
        files = df.loc[df['client_id']==client_id]
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/ops/common.py&quot;, line 70, in new_method
        return method(self, other)
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/arraylike.py&quot;, line 40, in __eq__
        return self._cmp_method(other, operator.eq)
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/series.py&quot;, line 5625, in _cmp_method
        return self._construct_result(res_values, name=res_name)
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/series.py&quot;, line 3017, in _construct_result
        out = self._constructor(result, index=self.index)
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/series.py&quot;, line 442, in __init__
        com.require_length_match(data, index)
    File &quot;/Users/admin/master_venv/lib/python3.9/site-packages/pandas/core/common.py&quot;, line 556, in require_length_match
        if len(data) != len(index):

    TypeError: len is not well defined for a symbolic Tensor (Equal:0). Please call `x.shape` rather than `len(x)` for shape information.
</code></pre>
",11776320,,,,,44749.21458,When switching from federated to centralized dataset -Error may indicate that you're trying to pass a Tensor to a NumPy call,<python><numpy><tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72792770,1,,,44740.85139,,1,135,"<p>I want to save weights only when loss is getting lower and reuse them for evaluation.</p>
<pre><code>lowest_loss = Inf

    if loss[round] &lt; lowest_loss:
        lowest_loss = loss[round]

        model_weights = transfer_learning_iterative_process.get_model_weights(state)



eval_metric = federated_eval(model_weights, [fed_valid_data])
</code></pre>
<p>where:</p>
<pre><code>  federated_eval = tff.learning.build_federated_evaluation(model_fn)
</code></pre>
<p>Is there a possible way to save server weights in hdf5 format or as a checkpoint and reuse it?</p>
",11776320,,,,,44749.20625,How to save weights in tensorflow federated,<python><tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72818097,1,,,44742.62917,,0,164,"<p>I do some some experiments with the tensorflow federated learning API. Actualy I try to train a simple ResNet on 10 Clients. Based on the data and metrics, the training seems to be successful. But the evaluation as well as local and federated fails.</p>
<p>Does  anyone have an advice?</p>
<p>The model:</p>
<pre><code>def create_keras_resnet_model(): 

    inputs = tf.keras.layers.Input(shape=(28,28,1))
    bn0 = tf.keras.layers.BatchNormalization(scale=True)(inputs)

    conv1 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(7,7), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(bn0)
    conv1 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(7,7), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(conv1)
    bn1 = tf.keras.layers.BatchNormalization(scale=True)(conv1)
    max_pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding = 'same')(bn1)


    conv2 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(max_pool1)
    conv2 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(conv2)
    conv2 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(conv2)
    bn2 = tf.keras.layers.BatchNormalization(scale=True)(conv2)

    res1_conv = tf.keras.layers.Conv2D(filters = 32,
                                  kernel_size = (3,3),
                                  padding = 'same',
                                  kernel_initializer='uniform')(max_pool1)
    res1_bn = tf.keras.layers.BatchNormalization(scale=True)(res1_conv)

    add1 = tf.keras.layers.Add()([res1_bn, bn2])


    act1 = tf.keras.layers.Activation('relu')(add1)
    max_pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding = 'same')(act1)

    conv3 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(max_pool2)
    conv3 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(conv3)
    conv3 = tf.keras.layers.Conv2D(filters=32, 
                               kernel_size=(5,5), 
                               padding='same', 
                               activation='relu', 
                               kernel_initializer='uniform')(conv3)
    bn2 = tf.keras.layers.BatchNormalization(scale=True)(conv3)

    res2_conv = tf.keras.layers.Conv2D(filters = 32,
                                  kernel_size = (3,3),
                                  padding = 'same',
                                  kernel_initializer='uniform')(max_pool2)
    res2_bn = tf.keras.layers.BatchNormalization(scale=True)(res2_conv)

    add2 = tf.keras.layers.Add()([res2_bn, bn2])

    act2 = tf.keras.layers.Activation('relu')(add2)
    max_pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2), padding = 'same')(act2)

    flatten = tf.keras.layers.Flatten()(max_pool3)

    dense1 = tf.keras.layers.Dense(128, activation='relu')(flatten)

    do = tf.keras.layers.Dropout(0.20)(dense1)
    dense2 = tf.keras.layers.Dense(10, activation='softmax')(do)

    model = tf.keras.models.Model(inputs=[inputs], outputs=[dense2])

    return model
</code></pre>
<p>The model is just a simple ResNet.
For the training I use the Tensorflow Federated Simulation Dataset for emnist and here 10 clients for 10 epochs.
<a href=""https://i.sstatic.net/cykYX.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/cykYX.jpg"" alt=""enter image description here"" /></a></p>
<p>Everything looks fine so far...</p>
<p>I have adjusted the provided function for preparing the data. I have already tested the whole process with a simple CNN and all works quiet well.</p>
<pre><code>def preprocess(dataset):

def batch_format_fn(element):
    return collections.OrderedDict(
        x=tf.reshape(element['pixels'], [-1, 28, 28, 1]),
        y=tf.reshape(element['label'], [-1, 1])
    )
    
return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=42).batch(BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)
</code></pre>
<p>Doing the evaluation process with tensorflow shows a strange result. The accuracy will be at around 11 percent and the loss has something between 7 and 8.</p>
<p>If I copy the weights to a local model and do the evaluation local, the same result. If I try to predict a single image from the test data an exception is thrown:</p>
<pre><code>ValueError: Input 0 of layer dense_10 is incompatible with the layer: expected axis -1 of input shape to have value 512 but received input with shape (None, 128)
</code></pre>
<p>Here the model summaray:</p>
<pre><code>Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_13 (InputLayer)           [(None, 28, 28, 1)]  0                                            
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 28, 28, 1)    4           input_13[0][0]                   
__________________________________________________________________________________________________
conv2d_120 (Conv2D)             (None, 28, 28, 32)   1600        batch_normalization_72[0][0]     
__________________________________________________________________________________________________
conv2d_121 (Conv2D)             (None, 28, 28, 32)   50208       conv2d_120[0][0]                 
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 28, 28, 32)   128         conv2d_121[0][0]                 
__________________________________________________________________________________________________
max_pooling2d_36 (MaxPooling2D) (None, 14, 14, 32)   0           batch_normalization_73[0][0]     
__________________________________________________________________________________________________
conv2d_122 (Conv2D)             (None, 14, 14, 32)   25632       max_pooling2d_36[0][0]           
__________________________________________________________________________________________________
conv2d_123 (Conv2D)             (None, 14, 14, 32)   25632       conv2d_122[0][0]                 
__________________________________________________________________________________________________
conv2d_125 (Conv2D)             (None, 14, 14, 32)   9248        max_pooling2d_36[0][0]           
__________________________________________________________________________________________________
conv2d_124 (Conv2D)             (None, 14, 14, 32)   25632       conv2d_123[0][0]                 
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 14, 14, 32)   128         conv2d_125[0][0]                 
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 14, 14, 32)   128         conv2d_124[0][0]                 
__________________________________________________________________________________________________
add_24 (Add)                    (None, 14, 14, 32)   0           batch_normalization_75[0][0]     
                                                                 batch_normalization_74[0][0]     
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 14, 14, 32)   0           add_24[0][0]                     
__________________________________________________________________________________________________
max_pooling2d_37 (MaxPooling2D) (None, 7, 7, 32)     0           activation_24[0][0]              
__________________________________________________________________________________________________
conv2d_126 (Conv2D)             (None, 7, 7, 32)     25632       max_pooling2d_37[0][0]           
__________________________________________________________________________________________________
conv2d_127 (Conv2D)             (None, 7, 7, 32)     25632       conv2d_126[0][0]                 
__________________________________________________________________________________________________
conv2d_129 (Conv2D)             (None, 7, 7, 32)     9248        max_pooling2d_37[0][0]           
__________________________________________________________________________________________________
conv2d_128 (Conv2D)             (None, 7, 7, 32)     25632       conv2d_127[0][0]                 
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 7, 7, 32)     128         conv2d_129[0][0]                 
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 7, 7, 32)     128         conv2d_128[0][0]                 
__________________________________________________________________________________________________
add_25 (Add)                    (None, 7, 7, 32)     0           batch_normalization_77[0][0]     
                                                                 batch_normalization_76[0][0]     
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 7, 7, 32)     0           add_25[0][0]                     
__________________________________________________________________________________________________
max_pooling2d_38 (MaxPooling2D) (None, 4, 4, 32)     0           activation_25[0][0]              
__________________________________________________________________________________________________
flatten_12 (Flatten)            (None, 512)          0           max_pooling2d_38[0][0]           
__________________________________________________________________________________________________
dense_24 (Dense)                (None, 128)          65664       flatten_12[0][0]                 
__________________________________________________________________________________________________
dropout_12 (Dropout)            (None, 128)          0           dense_24[0][0]                   
__________________________________________________________________________________________________
dense_25 (Dense)                (None, 10)           1290        dropout_12[0][0]                 
==================================================================================================
Total params: 291,694
Trainable params: 291,372
Non-trainable params: 322
__________________________________________________________________________________________________
</code></pre>
<p>I did not convert the labels with with to_categorical function from the karas util package. But why is the exception, the input of the dense layer is wrong? And why does the training work?</p>
",4828378,,,,,44747.41042,Tensorflow Federated Learning on ResNet failse,<python><tensorflow><machine-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
72874108,1,,,44747.775,,1,108,"<p>I am trying to make a centralized dataset from a federated one. Data contains path, client_id and label</p>
<p>So first I create a clientdata object using a function that accepts the client's id</p>
<pre><code>def extract_file_paths(dataset):
  return [item[&quot;path&quot;] for item in dataset]

@tf.function
def create_dataset(client_id):
    new_datset = tf.data.Dataset.from_tensor_slices(dict(df_aml))
    client_id = int(client_id)
    client_id = tf.cast(client_id, dtype=tf.int64)

    files = new_datset.filter(lambda x: x['client_id'] == client_id)


    list_ds = tf.data.Dataset.list_files(tf.py_function(func=extract_file_paths,inp=[files], Tout = tf.string ))
    
    
    images_ds = list_ds.map(parse_image)

        
    return images_ds
</code></pre>
<p>creating clientdata:</p>
<pre><code>client_ids = ['0', '1', '2']


client_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(client_ids,
create_dataset)

centralized = client_data.create_tf_dataset_from_all_clients()
</code></pre>
<p>I expected a dataset with different labels and files but this code is producing a dataset with only one file in it. Is it because I am trying to implement the graph execution method?</p>
<p>I tried using a similar function for creating a clientdata object that works for federated settings and produces the expected dataset, but using the same function gives me an error when I try to produce a centralized dataset</p>
",11776320,,11776320,,44747.77986,44747.77986,how to define create_tf_dataset_from_all_clients() function,<python><tensorflow><machine-learning><tensorflow-federated>,0,2,,,,CC BY-SA 4.0
72876080,1,,,44747.92569,,0,94,"<pre><code>def hinge_accuracy(y_true, y_pred):
     y_true = tf.squeeze(y_true) &gt; 0.0
     y_pred = tf.squeeze(y_pred) &gt; 0.0
     result = tf.cast(y_true == y_pred, tf.float32)

     return tf.reduce_mean(result)

def model_fn():

     keras_model_clone = create_baseline_model()
     return tff.learning.from_keras_model(
          keras_model_clone,
          input_spec=preprocessed_example_dataset.element_spec,
          loss=tf.keras.losses.Hinge(),
           metrics=[hinge_accuracy])
</code></pre>
<p>It throws an AttributeError: in converted code: <code>/home/bhatia87/.conda/envs/cent7/5.1.0-py36/tff/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py:496 report_local_outputs  *outputs[metric.name] = [v.read_value() for v in metric.variables]</code></p>
<p>AttributeError: <code>'function' object has no attribute 'variables'</code></p>
",18157505,,5602871,,44749.20139,44749.20139,how to use custom accuracy in tensorflow federated,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
62906596,1,62936973,,44027.09236,,1,1460,"<p>I have a problem when inputting multiple feature inputs as follows:</p>
<pre><code>feature_layer = tf.keras.layers.DenseFeatures(feature_cols)

feature_layer_inputs = {}
feature_layer_inputs['a'] = tf.keras.Input(shape=(1,), name='a', dtype=tf.int32)
feature_layer_inputs['b'] = tf.keras.Input(shape=(1,), name='b', dtype=tf.int32)

model = feature_layer(feature_layer_inputs)

for units in [64, 64]:
    model = tf.keras.layers.Dense(units, activation='relu')(model)
c_pred = tf.keras.layers.Dense(3, activation='softmax')(model) #classification 3 outputs

keras_model = tf.keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=c_pred)

input_spec = collections.OrderedDict(
        x=collections.OrderedDict(
            a=tf.TensorSpec(shape=[None,], dtype=tf.int32),
            b=tf.TensorSpec(shape=[None,], dtype=tf.int32),
        y=tf.TensorSpec(shape=[None,], dtype=tf.int32))

def model_fn():
  # We _must_ create a new model here, and _not_ capture it from an external
  # scope. TFF will call this within different graph contexts.

  return tff.learning.from_keras_model(
      keras_model,
      #input_spec=preprocessed_sample_dataset.element_spec,
      input_spec=input_spec,
      loss=losses.SparseCategoricalCrossentropy(),
      metrics=[metrics.SparseCategoricalAccuracy()])


iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: optimizers.Adam(learning_rate=client_lr),
    server_optimizer_fn=lambda: optimizers.SGD(learning_rate=server_lr))

state = iterative_process.initialize()

for round_num in range(1, NUM_ROUNDS+1):
    #state, tff_metrics = iterative_process.next(state, federated_train_data)
    state, tff_metrics = iterative_process.next(state, train_data)
    eval_model = keras_model
    eval_model.compile(optimizer=optimizers.Adam(learning_rate=client_lr),
                       loss=losses.SparseCategoricalCrossentropy(),
                       metrics=[metrics.SparseCategoricalAccuracy()])

    tff.learning.assign_weights_to_keras_model(eval_model, state.model)

    ev_result = eval_model.evaluate(x_test, y_test, verbose=0)
</code></pre>
<p>I get this code from this <a href=""https://stackoverflow.com/questions/54375298/how-to-use-tensorflow-feature-columns-as-input-to-a-keras-model"">solution</a>. However, I got the full traceback as follows. Eventually, I get an error 'AttributeError: Tensor.op is meaningless when eager execution'. It seems that there is something wrong with the built model especially the inputs inside the tf.keras.model function.</p>
<pre><code>Traceback (most recent call last):
  File &quot;accident_modify_uk_final3b.py&quot;, line 323, in &lt;module&gt;
    server_optimizer_fn=lambda: optimizers.SGD(learning_rate=server_lr))
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/learning/federated_averaging.py&quot;, line 212, in build_federated_averaging_process
    stateful_delta_aggregate_fn, stateful_model_broadcast_fn)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py&quot;, line 360, in build_model_delta_optimizer_process
    @tff.tf_computation
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/core/api/computations.py&quot;, line 152, in tf_computation
    return computation_wrapper_instances.tensorflow_wrapper(*args)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py&quot;, line 333, in __call__
    self._wrapper_fn)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py&quot;, line 91, in _wrap
    concrete_fn = wrapper_fn(fn, parameter_type, unpack=None)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper_instances.py&quot;, line 52, in _tf_wrapper_fn
    target_fn, parameter_type, ctx_stack)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/tensorflow_serialization.py&quot;, line 275, in serialize_py_fn_as_tf_computation
    result = target(*args)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py&quot;, line 455, in &lt;lambda&gt;
    return lambda: fn()  # pylint: disable=unnecessary-lambda
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py&quot;, line 364, in tf_init_fn
    stateful_model_broadcast_fn.initialize())
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py&quot;, line 227, in server_init
    _, optimizer_vars = _build_server_optimizer(model, optimizer)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py&quot;, line 123, in _build_server_optimizer
    apply_delta(delta=weights_delta)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 580, in __call__
    result = self._call(*args, **kwds)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 627, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 506, in _initialize
    *args, **kwds))
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 2446, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 2777, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py&quot;, line 2667, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py&quot;, line 441, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File &quot;/home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py&quot;, line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
AttributeError: in user code:

    /home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py:112 apply_delta  *
        optimizer.apply_gradients(grads_and_vars, name='server_update')
    /home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:508 apply_gradients  **
        &quot;name&quot;: name,
    /home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2420 merge_call
        return self._merge_call(merge_fn, args, kwargs)
    /home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2427 _merge_call
        return merge_fn(self._strategy, *args, **kwargs)
    /home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:590 _distributed_apply  **
        &quot;update_&quot; + var.op.name, skip_on_eager=True):
    /home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:581 op
        return self._handle.op
    /home/anaconda3/envs/env1_TF2.1/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1113 op
        &quot;Tensor.op is meaningless when eager execution is enabled.&quot;)

    AttributeError: Tensor.op is meaningless when eager execution is enabled.

</code></pre>
<p>How to solve this issue?</p>
",10988616,,10988616,,44028.04375,44029.09514,AttributeError: Tensor.op is meaningless when eager execution is enabled when using multiple feature inputs in Tensorflow federated,<python><tensorflow><keras><tensorflow-federated>,1,5,,,,CC BY-SA 4.0
62993389,1,63046523,,44032.43472,,4,291,"<p>The problem is the change of the dataset from one type to another during different points of the execution stack. For example, if I add a new dataset class with more member properties of interest (which inherits from one of the classes in ops.data.dataset_ops like UnaryDataset), the result is at later execution point (client_update function), the dataset is converted to _VaraintDataset Type and hence any added attributes are lost. So the question is how to retain the member attributes of the newly defined dataset class over the course of execution. Below is the emnist example where the type changes from ParallelMapDataset to _VariantDataset.</p>
<p>In the function client_dataset of training_utils.py line 194, I modified it to show the type of the dataset as follows</p>
<pre><code>  def client_datasets(round_num):
    sampled_clients = sample_clients_fn(round_num)
    sampled_client_datasets = []
    for client in sampled_clients:
        d =  train_dataset.create_tf_dataset_for_client(client)
        sampled_client_datasets.append(train_dataset.create_tf_dataset_for_client(client))
        tf.print('CLIENT DATASETS: ', d, type(d))
    return sampled_client_datasets
</code></pre>
<p>The output is :</p>
<pre><code>CLIENT DATASETS:  &lt;ParallelMapDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'&gt;
CLIENT DATASETS:  &lt;ParallelMapDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'&gt;
CLIENT DATASETS:  &lt;ParallelMapDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'&gt;
CLIENT DATASETS:  &lt;ParallelMapDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'&gt;
CLIENT DATASETS:  &lt;ParallelMapDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'&gt;
CLIENT DATASETS:  &lt;ParallelMapDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'&gt;
CLIENT DATASETS:  &lt;ParallelMapDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'&gt;
CLIENT DATASETS:  &lt;ParallelMapDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'&gt;
CLIENT DATASETS:  &lt;ParallelMapDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'&gt;
CLIENT DATASETS:  &lt;ParallelMapDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops.ParallelMapDataset'&gt;
</code></pre>
<p>Then in the tf.function client_update which is invoked by the clients in the fed_avg_schedule.py line 178, the dataset is of different type</p>
<pre><code>@tf.function
  def client_update(model,
                    dataset,
                    initial_weights,
                    client_optimizer,
                    client_weight_fn=None):
    &quot;&quot;&quot;Updates client model.

    Args:
      model: A `tff.learning.Model`.
      dataset: A 'tf.data.Dataset'.
      initial_weights: A `tff.learning.Model.weights` from server.
      client_optimizer: A `tf.keras.optimizer.Optimizer` object.
      client_weight_fn: Optional function that takes the output of
        `model.report_local_outputs` and returns a tensor that provides the
        weight in the federated average of model deltas. If not provided, the
        default is the total number of examples processed on device.

    Returns:
      A 'ClientOutput`.
    &quot;&quot;&quot;

    tf.print('CLIENT UPDATE: ', dataset, type(dataset))
    ....
</code></pre>
<p>The output would be :</p>
<pre><code>CLIENT UPDATE:  &lt;_VariantDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;
CLIENT UPDATE:  &lt;_VariantDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;
CLIENT UPDATE:  &lt;_VariantDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;
CLIENT UPDATE:  &lt;_VariantDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;
CLIENT UPDATE:  &lt;_VariantDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;
CLIENT UPDATE:  &lt;_VariantDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;
CLIENT UPDATE:  &lt;_VariantDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;
CLIENT UPDATE:  &lt;_VariantDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;
CLIENT UPDATE:  &lt;_VariantDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;
CLIENT UPDATE:  &lt;_VariantDataset shapes: ((None, 28, 28, 1), (None,)), types: (tf.float32, tf.int32)&gt; &lt;class 'tensorflow.python.data.ops.dataset_ops._VariantDataset'&gt;
</code></pre>
<p>I might be wrong but I have done some tracking and found that at some point the function (_to_components(self, value) of DatasetSpec) is called which does the conversion:</p>
<pre><code>  def _to_components(self, value):
    return value._variant_tensor  # pylint: disable=protected-access
</code></pre>
<p><em>EDIT - following the suggested answer</em></p>
<p>Below are the changes i have introduced to the simpel_fedavg example after pulling the recent version of the federated repo</p>
<p>First, i add/modified the lines below to build_fed_avg_process of simple_fedavg_tff.py</p>
<pre><code>server_message_type = server_message_fn.type_signature.result
  tf_dataset_type = tff.SequenceType(dummy_model.input_spec)
  meta_data_type = tff.SequenceType(tf.string)

  @tff.tf_computation(tf_dataset_type, meta_data_type, server_message_type)
  def client_update_fn(tf_dataset, meta_data, server_message):
    model = model_fn()
    client_optimizer = client_optimizer_fn()
    return client_update(model, tf_dataset, meta_data, server_message, client_optimizer)

@tff.tf_computation((tf_dataset_type, meta_data_type))
  def extract_data_metadata_fn(tf_dataset_metadata_tuple):
    x, y = tf_dataset_metadata_tuple
    return x, y

  federated_server_state_type = tff.FederatedType(server_state_type, tff.SERVER)
  federated_dataset_type = tff.FederatedType( (tf_dataset_type, meta_data_type), tff.CLIENTS)
  @tff.federated_computation(federated_server_state_type,
                             federated_dataset_type)
  def run_one_round(server_state, federated_dataset):
    &quot;&quot;&quot;Orchestration logic for one round of computation.

    Args:
      server_state: A `ServerState`.
      federated_dataset: A federated `tf.data.Dataset` with placement
        `tff.CLIENTS`.

    Returns:
      A tuple of updated `ServerState` and `tf.Tensor` of average loss.
    &quot;&quot;&quot;
    server_message = tff.federated_map(server_message_fn, server_state)
    server_message_at_client = tff.federated_broadcast(server_message)

    data_set, meta_data = tff.federated_map(extract_data_metadata_fn, federated_dataset)

    #client_outputs = tff.federated_map(client_update_fn, (federated_dataset, server_message_at_client))
    client_outputs = tff.federated_map(client_update_fn, (data_set, meta_data, server_message_at_client))
</code></pre>
<p>In the simple_fedavg_tf.py, I have added the following print line of the meta_data</p>
<pre><code>@tf.function
def client_update(model, dataset, meta_data, server_message, client_optimizer):
  &quot;&quot;&quot;Performans client local training of `model` on `dataset`.

  Args:
    model: A `tff.learning.Model`.
    dataset: A 'tf.data.Dataset'.
    server_message: A `BroadcastMessage` from server.
    client_optimizer: A `tf.keras.optimizers.Optimizer`.

  Returns:
    A 'ClientOutput`.
  &quot;&quot;&quot;
  tf.print(meta_data)

  model_weights = model.weights
  initial_weights = server_message.model_weights
  client_ids = server_message.client_ids
  tff.utils.assign(model_weights, initial_weights)
</code></pre>
<p>In the main file emnist_simple_fedavg.py, I modifed the following lines of the main training loop in main function:</p>
<pre><code>meta_data = ['a','b','c','d']
server_state, train_metrics = iterative_process.next(server_state, (sampled_train_data, meta_data))
</code></pre>
<p>Which did not work out and i am getting the following error:</p>
<pre><code>  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.py&quot;, line 176, in &lt;module&gt;
    app.run(main)
  File &quot;/usr/local/lib/python3.6/dist-packages/absl/app.py&quot;, line 299, in run
    _run_main(main, args)
  File &quot;/usr/local/lib/python3.6/dist-packages/absl/app.py&quot;, line 250, in _run_main
    sys.exit(main(argv))
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.py&quot;, line 166, in main
    server_state, train_metrics = iterative_process.next(server_state, (sampled_train_data, sampled_clients.tolist()))
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/utils/function_utils.py&quot;, line 563, in __call__
    return context.invoke(self, arg)
  File &quot;/usr/local/lib/python3.6/dist-packages/retrying.py&quot;, line 49, in wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)
  File &quot;/usr/local/lib/python3.6/dist-packages/retrying.py&quot;, line 206, in call
    return attempt.get(self._wrap_exception)
  File &quot;/usr/local/lib/python3.6/dist-packages/retrying.py&quot;, line 247, in get
    six.reraise(self.value[0], self.value[1], self.value[2])
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/six/__init__.py&quot;, line 693, in reraise
    raise value
  File &quot;/usr/local/lib/python3.6/dist-packages/retrying.py&quot;, line 200, in call
    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/execution_context.py&quot;, line 215, in invoke
    _ingest(executor, unwrapped_arg, arg.type_signature)))
  File &quot;/usr/lib/python3.6/asyncio/base_events.py&quot;, line 484, in run_until_complete
    return future.result()
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/tracing.py&quot;, line 388, in _wrapped
    return await coro
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/execution_context.py&quot;, line 99, in _ingest
    ingested = await asyncio.gather(*ingested)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/execution_context.py&quot;, line 104, in _ingest
    return await executor.create_value(val, type_spec)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/tracing.py&quot;, line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/reference_resolving_executor.py&quot;, line 289, in create_value
    value, type_spec))
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/caching_executor.py&quot;, line 245, in create_value
    await cached_value.target_future
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/tracing.py&quot;, line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/thread_delegating_executor.py&quot;, line 111, in create_value
    self._target_executor.create_value(value, type_spec))
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/thread_delegating_executor.py&quot;, line 105, in _delegate
    result_value = await _delegate_with_trace_ctx(coro, self._event_loop)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/tracing.py&quot;, line 388, in _wrapped
    return await coro
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/tracing.py&quot;, line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/federating_executor.py&quot;, line 383, in create_value
    return await self._strategy.compute_federated_value(value, type_spec)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/federated_resolving_strategy.py&quot;, line 275, in compute_federated_value
    for v, c in zip(value, children)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/tracing.py&quot;, line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/reference_resolving_executor.py&quot;, line 282, in create_value
    *[self.create_value(val, t) for (_, val), t in zip(v_el, type_spec)])
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/tracing.py&quot;, line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/reference_resolving_executor.py&quot;, line 289, in create_value
    value, type_spec))
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/caching_executor.py&quot;, line 245, in create_value
    await cached_value.target_future
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/tracing.py&quot;, line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/thread_delegating_executor.py&quot;, line 111, in create_value
    self._target_executor.create_value(value, type_spec))
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/thread_delegating_executor.py&quot;, line 105, in _delegate
    result_value = await _delegate_with_trace_ctx(coro, self._event_loop)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/tracing.py&quot;, line 388, in _wrapped
    return await coro
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/tracing.py&quot;, line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/eager_tf_executor.py&quot;, line 464, in create_value
    return EagerValue(value, self._tf_function_cache, type_spec, self._device)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/eager_tf_executor.py&quot;, line 367, in __init__
    type_spec, device)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/core/impl/executors/eager_tf_executor.py&quot;, line 335, in to_representation_for_type
    type_conversions.TF_DATASET_REPRESENTATION_TYPES)
  File &quot;/root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/py_typecheck.py&quot;, line 41, in check_type
    type_string(type_spec), type_string(type(target))))
TypeError: Expected tensorflow.python.data.ops.dataset_ops.DatasetV2 or tensorflow.python.data.ops.dataset_ops.DatasetV1, found str.
E0721 23:53:29.388700 139706363909952 base_events.py:1285] Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /root/.cache/bazel/_bazel_root/13f956c768d751b1bc658674921e5be9/execroot/org_tensorflow_federated/bazel-out/k8-opt/bin/tensorflow_federated/python/examples/simple_fedavg/emnist_fedavg_main.runfiles/org_tensorflow_federated/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7f0f7c07eca8&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7f0f7c07e648&gt;()]&gt;
</code></pre>
",7042424,,7042424,,44034.00625,44035.16042,Change of the dataset type in the execution stack,<python><tensorflow><tensorflow-federated>,2,2,,,,CC BY-SA 4.0
63043501,1,63066774,,44034.89583,,5,628,"<p>I went through the Federated Learning tutorial. I was wondering how .next function work when we call it on an iterative process.
Assuming that we have train data which is a list of lists. The outer list is a list of clients and the inner lists are batches of data for each client. Then, we create an iterative process, for example, a federated averaging process and we initialize the state.
What exactly happens when we call IterativeProcess.next on this training data. Does it take from these data randomly in each round? Or just take data from each client one batch at a time?</p>
<p>Assume that I have a list of tf.data.Datasets each representing a client data. How can I add some randomness to sampling from this list for the next iteration of federated learning?</p>
<p>My datasets are not necessarily the same length. When one of them is completely iterated over, does this dataset waits for all other datasets to completely iterate over their data or not?</p>
",9705037,,,,,44036.18403,What exactly happens when we call IterativeProcess.next on federated training data?,<tensorflow-federated>,2,0,,,,CC BY-SA 4.0
63090535,1,,,44037.67153,,1,453,"<p>TensorFlow Federated (TFF) is an open-source framework for ML and other computations on decentralized data.</p>
<p>As per Stack overflow <a href=""https://stackoverflow.com/questions/57323598/is-tensorflow-federated-learning-only-for-simulating-federated-learning-on-one-m"">link</a></p>
<blockquote>
<p>TFF only provides a simulation environment for use in Federated
Learning (FL) research. There is not yet a &quot;real world&quot; FL deployment
platform.</p>
</blockquote>
<p>But, tensorFlow release history shows that now there are many release versions for TF 2.x as well.</p>
<pre><code>https://github.com/tensorflow/federated/releases
</code></pre>
<p>Can anybody comment, if TFF is still or simulation environment or can be used as &quot;real world&quot; FL deployment platform?</p>
",3141903,,,,,44038.6875,Tensorflow Federated TFF still a Simulation Environment?,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
63201833,1,,,44044.19375,,0,282,"<p>I failed running &quot;bazel run tensorflow_federated/python/research/gans/experiments/emnist:run_experiments&quot;, which gives me the error: &quot;The 'run' command is only supported from within a workspace (below a directory having a WORKSPACE file).&quot;</p>
<p><a href=""https://i.sstatic.net/mLjg1.png"" rel=""nofollow noreferrer"">Error Information</a></p>
<p>There is a WORKSPACE empty file in my &quot;federated&quot; git repo, and I run &quot;touch WORKSPACE&quot;.
<a href=""https://i.sstatic.net/mQwgA.png"" rel=""nofollow noreferrer"">My git repo folder</a></p>
<p>My test of installation by running &quot;python -c &quot;import tensorflow_federated as tff; print(tff.federated_computation(lambda: 'Hello World')())&quot; succeeds.</p>
<p>I can also run &quot;bazel run tensorflow_federated/python/research/gans/experiments/emnist:train&quot;.</p>
<p>Here is my configuration:</p>
<p>Python 3.6.9</p>
<p>Tensorflow 2.2.0</p>
<p>Tensorflow-Federated 0.16.1</p>
<p>Bazel 3.4.1</p>
<p>I build the TensorFlow Federated python package from source using Bazel from this link: <a href=""https://github.com/tensorflow/federated/blob/master/docs/install.md#build-the-tensorflow-federated-python-package-from-source"" rel=""nofollow noreferrer"">https://github.com/tensorflow/federated/blob/master/docs/install.md#build-the-tensorflow-federated-python-package-from-source</a></p>
",14031724,,,,,44102.87222,"Error when running ""gans/experiments/emnist:run_experiments"" using Bazel: The 'run' command is only supported from within a workspace",<bazel><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
72887912,1,,,44748.74236,,0,331,"<p>When I try to import tensorflow_federated I got this error, anyone has the idea why?</p>
<pre><code>    ImportError                               Traceback (most recent call last)
&lt;ipython-input-6-a23308ec3f7c&gt; in &lt;module&gt;()
      3 import numpy as np
      4 import tensorflow as tf
----&gt; 5 import tensorflow_federated as tff
      6 
      7 np.random.seed(0)

17 frames
/usr/local/lib/python3.7/dist-packages/keras/api/_v1/keras/mixed_precision/experimental/__init__.py in &lt;module&gt;()
      6 import sys as _sys
      7 
----&gt; 8 from keras.mixed_precision.loss_scale_optimizer import LossScaleOptimizerV1 as LossScaleOptimizer
      9 from tensorflow.python.util import module_wrapper as _module_wrapper
     10 

ImportError: cannot import name 'LossScaleOptimizerV1' from 'keras.mixed_precision.loss_scale_optimizer' (/usr/local/lib/python3.7/dist-packages/keras/mixed_precision/loss_scale_optimizer.py)
</code></pre>
",19379785,,,,,44748.75069,cannot import tensorflow_federated as tff,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
72899013,1,73041526,,44749.575,,1,274,"<p>I need some function or api which belongs to the newest version of Tensorflow Federated. According to the tutorial of official website, I type the following to install the newest version.</p>
<pre><code>pip install --upgrade pip
pip install --upgrade tensorflow-federated
</code></pre>
<p>Unfortunately, when the installation has been finished, the version is 0.17.0, which was published in 2020. Therefore, I just want to know how to install Tensorflow-Federated 0.28.0 on win10.</p>
",11484590,,,,,44761.74722,How to install Tensorflow-Federated 0.28.0 on win10?,<python-3.x><tensorflow2.0><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
72915271,1,,,44750.74792,,0,740,"<p>I am using <code>tensorflow-federated</code> version 0.28. I tried to implement <a href=""https://www.tensorflow.org/federated/api_docs/python/tff/learning/algorithms/build_weighted_fed_avg_with_optimizer_schedule"" rel=""nofollow noreferrer"">build_weighted_fed_avg_with_optimizer_schedule</a> but I am getting the following error:</p>
<pre><code>
Traceback (most recent call last):
  File &quot;/home/Desktop/FL/fedopt.py&quot;, line 340, in &lt;module&gt;
    iterative_process = build_weighted_fed_avg_with_optimizer_schedule(
  File &quot;/home/anaconda3/envs/fl/lib/python3.9/site-packages/tensorflow_federated/python/learning/algorithms/fed_avg_with_optimizer_schedule.py&quot;, line 276, in build_weighted_fed_avg_with_optimizer_schedule
    client_work = build_scheduled_client_work(model_fn, client_learning_rate_fn,
  File &quot;/home/anaconda3/envs/fl/lib/python3.9/site-packages/tensorflow_federated/python/learning/algorithms/fed_avg_with_optimizer_schedule.py&quot;, line 98, in build_scheduled_client_work
    whimsy_optimizer = optimizer_fn(1.0)
TypeError: &lt;lambda&gt;() takes 0 positional arguments but 1 was given
</code></pre>
<p>My code is as follows:</p>
<pre><code>iterative_process = build_weighted_fed_avg_with_optimizer_schedule(
    model_fn,
    client_learning_rate_fn = lambda x: 0.001,
    client_optimizer_fn=lambda: optimizers.Adam(learning_rate= client_lr, beta_1 = 0.9, beta_2 = 0.999,epsilon = 1e-07),
    server_optimizer_fn=lambda: optimizers.SGD(learning_rate= server_lr), 
    use_experimental_simulation_loop=True)
</code></pre>
<p>Can someone please tell me what I am doing wrong here?</p>
",10543101,,,,,44750.76319,tensorflow-federated: TypeError: <lambda>() takes 0 positional arguments but 1 was given,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
73007445,1,,,44758.85208,,1,636,"<p>I am trying to run the <a href=""https://colab.research.google.com/github/tensorflow/federated/blob/v0.5.0/docs/tutorials/federated_learning_for_image_classification.ipynb#scrollTo=coAumH42q9nz"" rel=""nofollow noreferrer"">Tensorflow federated tutorial on colab</a>.</p>
<p>However, so far, the <code>from tensorflow_federated import python as tff</code> code is giving the following error:</p>
<pre class=""lang-py prettyprint-override""><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-3-af7e4c5121d6&gt; in &lt;module&gt;()
      1 import tensorflow as tf
----&gt; 2 from tensorflow_federated import python as tff

6 frames
/usr/local/lib/python3.7/dist-packages/tensorflow_federated/python/common_libs/structure.py in &lt;module&gt;()
    263 
    264 def to_odict(struct: Struct,
--&gt; 265              recursive: bool = False) -&gt; collections.OrderedDict[str, Any]:
    266   &quot;&quot;&quot;Returns `struct` as an `OrderedDict`, if possible.
    267 

TypeError: 'type' object is not subscriptable
</code></pre>
<p>Any suggestion would be greatly appreciated. Thanks for your time.</p>
",14073151,,4913143,,44761.1,45111.29097,Tensorflow federated-learning giving error in colab,<python><tensorflow><machine-learning><google-colaboratory><tensorflow-federated>,3,0,,,,CC BY-SA 4.0
73024656,1,,,44760.63472,,2,199,"<p>In federated averaging, does the client optimizer have to be 'SGD' only?</p>
<p>In this paper <a href=""https://arxiv.org/abs/2003.00295"" rel=""nofollow noreferrer"">ADAPTIVE FEDERATED OPTIMIZATION</a> it states &quot;One such method is FEDAVG (McMahan et al., 2017), in which clients perform multiple epochs of SGD on their local datasets.&quot;   Based on this statement, if the clients run Adam on their own loss function, it is not federated averaging?</p>
<p>What is the difference between 'federated averaging (FedAvg)' and 'Adaptive federated optimization (FedOpt) (paper linked above)'?</p>
<p>In other words what is the different between <code>tff.learning.algorithms.build_weighted_fed_avg</code> and <code>tff.learning.algorithms.build_weighted_fed_avg_with_optimizer_schedule</code>?</p>
",10543101,,10543101,,44760.64375,44760.64375,In FedAvg what is the client optimizer?,<tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
73032606,1,,,44761.30139,,1,49,"<p>I am trying to do transfer learning on my own dataset. I managed to do transfer learning with resnet and I got decent accuracy. But when I try VGG16 my accuracy stays the same all the time and loss is changing. I preprocessed my images with  tf.keras.applications.vgg16.preprocess_input. Also, I tried to do transfer learning in a centralized manner and it works fine.</p>
<pre><code>if base_model == &quot;VGG16&quot;:
            base_model = tf.keras.applications.vgg16.VGG16(
                include_top=False,
                weights=&quot;imagenet&quot;,
                input_tensor=tf.keras.layers.Input(shape=(input_shape, input_shape, 3)),
                pooling=None,
            )

 base_model.trainable = False

        inputs = tf.keras.Input(shape=(input_shape, input_shape, 3))
        x = base_model(inputs, training=False)

        x = tf.keras.layers.GlobalAveragePooling2D()(x)

        outputs = tf.keras.layers.Dense(num_classes, activation=&quot;softmax&quot;)(x)
        model = tf.keras.Model(inputs, outputs)

        return model

    def create_FL_model():

        &quot;&quot;&quot;create_FL_model_test _summary_

        Returns:
            tff.learning.Model: _description_
        &quot;&quot;&quot;
        keras_model = load_model(name, base_model)
        return tff.learning.from_keras_model(
            keras_model,
            input_spec=input_spec.element_spec,
            loss=tf.keras.losses.SparseCategoricalCrossentropy(),
            metrics=[
                tf.keras.metrics.SparseCategoricalAccuracy(),
            ],
        )

    # check again
    if fed_alg == &quot;FedAvg&quot;:

        transfer_learning_iterative_process = (
            tff.learning.build_federated_averaging_process(
                create_FL_model,
                client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
                server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),
            )
        )


    keras_model = load_model(name, base_model)

    state_transfer = transfer_learning_iterative_process.initialize()

    state = tff.learning.state_with_new_model_weights(
        state_transfer,
        trainable_weights=[v.numpy() for v in keras_model.trainable_weights],
        non_trainable_weights=[v.numpy() for v in keras_model.non_trainable_weights],
    )
</code></pre>
<p>Training round:</p>
<pre><code>   for epoch in range(num_epochs):

    client_data_train, client_data_valid = client_data.train_test_client_split(
        client_data, num_test_clients=1, seed=12345
    )
    fed_valid_data = preprocess(
        client_data_valid.create_tf_dataset_for_client(
            client_data_valid.client_ids[0]
        )
    )

    random_clients_ids = random.sample(client_data_train.client_ids, k=2)

    federated_train_data = make_federated_data(
        client_data_train, random_clients_ids
    )
    state, metrics = transfer_learning_iterative_process.next(
        state, federated_train_data
    )
</code></pre>
",11776320,,11776320,,44761.35347,44761.35347,VGG16 doesn't increase accuracy in TFF,<python-3.x><tensorflow><tf.keras><tensorflow-federated>,0,0,,,,CC BY-SA 4.0
73041436,1,73046667,,44761.74236,,2,55,"<p>I am learning Tensorflow-Federated, while I don't know how to explain the syntax <code>tff.to_type((tf.int64, [2]))</code>. I consider <code>tff.to_type</code> can create a tff data type, but I don't know the meaning of [2].</p>
",11484590,,9657861,,44762.61944,44762.61944,"How to explain ""tff.to_type((tf.int64, [2]))""?",<python><tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
73053135,1,76226648,,44762.58681,,0,229,"<p>I am following <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">this</a> tutorial for image classification using tff. The only difference is that i am using 3d images of size 128x128x3.<br />
During the training process i evaluate the model in each training round as seen below:</p>
<pre><code>for round_num in range(0, NUM_ROUNDS):
  state, train_metrics = iterative_process.next(state, federated_train_data)
  metrics = eval(state.model, federated_test_data)

  print(' TRAINING round {:2d}, metrics={}, loss={}'.format(round_num, train_metrics['train']['binary_accuracy'],train_metrics['train']['loss']))
  print(' TESTING round {:2d}, metrics={}, loss={}'.format(round_num, metrics['eval']['binary_accuracy'],metrics['eval']['loss']))
</code></pre>
<p>where :</p>
<pre><code>eval = tff.learning.build_federated_evaluation(model_fn)
</code></pre>
<p>In such a case i get results like the ones below :</p>
<pre><code>TRAINING round  0, metrics=0.4614659249782562, loss=1.136414647102356
 TESTING round  0, metrics=0.25431033968925476, loss=1.3862652778625488
 TRAINING round  1, metrics=0.5336836576461792, loss=1.0317342281341553
 TESTING round  1, metrics=0.25538793206214905, loss=1.3862823247909546
 TRAINING round  2, metrics=0.6359471678733826, loss=0.8686623573303223
 TESTING round  2, metrics=0.25538793206214905, loss=1.3865610361099243
 TRAINING round  3, metrics=0.6370250582695007, loss=0.8408811092376709
 TESTING round  3, metrics=0.25646552443504333, loss=1.3872325420379639
 TRAINING round  4, metrics=0.7109943628311157, loss=0.6903313994407654
 TESTING round  4, metrics=0.25538793206214905, loss=1.3889813423156738
 TRAINING round  5, metrics=0.7504715919494629, loss=0.6067320704460144
 TESTING round  5, metrics=0.25538793206214905, loss=1.3922673463821411
 TRAINING round  6, metrics=0.7718943953514099, loss=0.540172815322876
 TESTING round  6, metrics=0.25646552443504333, loss=1.3983343839645386
</code></pre>
<p>We can clearly see that the model is learning producing better training accuracy but the validation is frozen. What i suspect is that somehow only one class is predicted ( my problem has 4 classes).
The weird thing is this :<br />
If i change <code>federated_test_data</code> to <code>federated_train_data</code> in <code>eval()</code> i still get the same evaluation results but i can clearly see that for the training data the results are different.
Any ideas about this?<br />
Is tff doing internally any preprocessing for the evaluation step?</p>
",19336534,,,,,45057.43958,Evaluation of model tensorflow federated,<python><python-3.x><tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
73068175,1,73069316,,44763.61042,,-1,94,"<p>I am learning about the function of Differential Privacy in Tensorflow-federated. The following is the display of the first training.
<a href=""https://i.sstatic.net/5owGj.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/5owGj.png"" alt=""enter image description here"" /></a>
The break happened  in the 2nd loop like the following.
<a href=""https://i.sstatic.net/x4bko.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/x4bko.png"" alt=""enter image description here"" /></a>
Please tell me how to deal with that.</p>
",11484590,,,,,44763.66458,OSError: [Errno 24] Too many open files when training differential privacy in tensorflow-federated,<python><tensorflow2.0><tensorflow-federated>,1,2,,,,CC BY-SA 4.0
73112324,1,,,44767.675,,0,94,"<p>I have created a centralized differential privacy system according to the official manual of Tensorflow-federated. However, my research need a local differential privacy system based on Tensorflow-federated. Does anyone know how to do it?</p>
",11484590,,,,,44773.89931,How to create a tensorflow-federated system by local differential privacy?,<python><tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
63229611,1,,,44046.52708,,5,640,"<p>I'm carrying out a federated learning process and use the function  tff.learning.build_federated_averaging_process to create an iterative process of federated learning. As mentioned in the TFF tutorial,  this function has two arguments called client_optimizer_fn and server_optimizer_fn, which in my opinion, represent the optimizer for client and server, respectively. But in the FedAvg paper, it seems that only clients carry out the optimization while the server only do the averaging operation, so what exactly is the server_optimizer_fn doing and what does its learning rate mean?</p>
",14041835,,,,,44047.35764,Learning rate setting when calling the function tff.learning.build_federated_averaging_process,<tensorflow-federated>,2,0,,,,CC BY-SA 4.0
63456076,1,,,44060.74236,,1,75,"<p>I try to implement a demo of my object detection model that is trained with tensorflow federated.</p>
<p>Right now im a bit lost because I try to figure out how to modify the model_lib_v2 train_loop so that it inclused the tff client code. In the train_loop I alread have the optimizer and the model_fn but to build the tff <a href=""https://www.tensorflow.org/federated/api_docs/python/tff/learning/from_keras_model"" rel=""nofollow noreferrer"">model from keras</a> I also need a Keras loss function.</p>
<p>Furthermore I'm right now not sure if it is even possible to add TFF functions to the Object detection Api or if its more a simulation for basic Keras models.</p>
<p>Has anyone already tried to train a object detection model with TFF ?</p>
",10228129,,,,,44060.74236,Tensorflow Federated with Object Detection API,<tensorflow><object-detection-api><tensorflow-federated>,0,0,,,,CC BY-SA 4.0
63456963,1,63468730,,44060.78542,,3,369,"<p>I noticed that the Gradient Quantization compression method is already implemented in TFF framework. How about non-traditional compression methods where we select a sub-model by dropping some parts of the global model? I come across the &quot;Federated Dropout&quot; compression method in the paper &quot;Expanding the Reach of Federated Learning by Reducing Client Resource Requirements&quot; (<a href=""https://arxiv.org/abs/1812.07210"" rel=""nofollow noreferrer"">https://arxiv.org/abs/1812.07210</a>). Any idea if Federated Dropout method is already supported in Tensorflow Federated. If not, any insights how to implement it (the main idea of the method is dropping a fixed percentage of the activations and filters in the global model to exchange and train a smaller sub-model)?</p>
",11472601,,,,,44767.07083,Other compression methods for Federated Learning,<tensorflow-federated>,2,0,,,,CC BY-SA 4.0
63460420,1,,,44061.0375,,2,296,"<p>I'm trying to do federated learning using tensorflow.
I've created a model based on <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">this tutorial for MNIST</a>. Now I change it: I supply it with images of size 112x112 with 3 channels each (I.e. the size of the input layer is 112x112x3). When I try to use multiple models (around 50 with about 100 images each), I get &quot;out of memory&quot; exception. Looking at output of <code>nvidia-smi</code>, it makes sense: for some reason my program takes memory only from a single GPU. How can I avoid it?</p>
<p>Some comments:</p>
<ul>
<li>I use <code>allow_growth</code>, so I'm pretty sure that the shown memory usage is the actual memory usage. And I do can see it growing over time.</li>
<li>TensorFlow recognizes other GPUs: before I run the program, they have 0MB occupied. Also there is line <code>Adding visible gpu devices: 0, 1, 2, 3, 4, 5, 6, 7</code> in logs.</li>
</ul>
<p><a href=""https://i.sstatic.net/0sYJV.jpg"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/0sYJV.jpg"" alt=""enter image description here"" /></a></p>
",,user12463032,,user12463032,44061.05764,44061.69931,Federated Tensorflow memory-overloads a single GPU,<python><tensorflow><out-of-memory><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
73184351,1,,,44773.62431,,0,100,"<p>I have a tensorflow model like this</p>
<pre><code>def input_spec():
return(
      tf.TensorSpec([None, 122], tf.float64),
      tf.TensorSpec([None, 5],tf.uint8))

def model_fn():
    model=tf.keras.models.Sequential([
          tf.keras.layers.Dense(64,input_shape=(122,)),
          tf.keras.layers.Dense(32,activation='relu'),
          tf.keras.layers.Dropout(.15),
          tf.keras.layers.Dense(32,activation='relu'),
          tf.keras.layers.Dropout(.15),
          tf.keras.layers.Dense(32,activation='relu'),
          tf.keras.layers.Dropout(.15),
          tf.keras.layers.Dense(5,activation='softmax')])
    return tff.learning.from_keras_model(
           model,
           input_spec=input_spec(),
           loss=tf.keras.losses.CategoricalCrossentropy(),
           metrics=[tf.keras.metrics.CategoricalAccuracy()])
</code></pre>
<p>I set the iterative_process in the following</p>
<pre><code>iterative_process=tff.learning.algorithms.build_weighted_fed_avg(
                  model_fn,
                  client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),
                  server_optimizer_fn=lambda: tf.keras.optimizers.Adam())
</code></pre>
<p>I have learnt that we can obtain the aggregated weight by <code>model_weights=iterative_process.get_model_weights(state)</code>, but I still need to know how to obtain the aggregated gradients.</p>
",11484590,,,,,44773.86944,How to extract the aggregated gradient from tensorflow_federated?,<python-3.x><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
73198156,1,73257326,,44774.77431,,2,309,"<p>I am building a federated learning model using Tensorflow Federated.
Based on what I have read in the tutorials and papers, I understood that the state-of-the-art method (FedAvg) is working by selecting a random subset of clients at each round.</p>
<p>My concern is:</p>
<ul>
<li>I am having a small number of clients. Totally I have 8 clients, I select 6 clients for training and I kept 2 for testing.</li>
<li>All of the data are provided on my local device, so I am using the TFF as the simulation environment.</li>
<li>If I use all of the 6 clients in all of the rounds during federated communication rounds, would this be a wrong execution of the FedAvg method?</li>
<li>Note that I am planning also to use the same experiment used in this <a href=""https://arxiv.org/abs/2003.00295"" rel=""nofollow noreferrer"">paper</a>. That aims to use different server optimization methods and compare their performance. So, would (all clients participating procedure) works here or not?</li>
</ul>
<p>Thanks in advance</p>
",18358769,,,,,44779.21389,Client participation in the federated computation rounds,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
73199007,1,73257292,,44774.83611,,1,375,"<p>I find the term <code>NoiseMultiplier</code> in the following part of tensorflow-federated tutorial.</p>
<pre><code>def train(rounds, noise_multiplier, clients_per_round, data_frame):
  # Using the `dp_aggregator` here turns on differential privacy with adaptive
  # clipping.
  aggregation_factory = tff.learning.model_update_aggregator.dp_aggregator(
      noise_multiplier, clients_per_round)
</code></pre>
<p>I have read the paper about differential privacy with adaptive clipping <a href=""https://arxiv.org/abs/1905.03871"" rel=""nofollow noreferrer"">Andrew et al. 2021, Differentially Private Learning with Adaptive Clipping</a>. I guess <code>NoiseMultiplier</code> is the noise we input to the system. However, I find the <code>NoiseMultiplier</code> is a scalar we set. Actually, the different noise should be put into the corresponding weight_variables, so I am so confused about that.</p>
",11484590,,,,,44779.20833,"What does ""noisemultiplier"" mean in tensorflow-federated tutorial?",<python-3.x><tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
73303926,1,,,44783.39722,,0,187,"<p>Currently I'm working on implementing code in &quot;Differentially Private Federated Learning: A Client Level Perspective&quot; where the GitHub link is <a href=""https://github.com/SAP-samples/machine-learning-diff-private-federated-learning"" rel=""nofollow noreferrer"">LINK</a>.
However, I follow the instruction but got an error which is</p>
<pre><code>Traceback (most recent call last):
  File &quot;sample.py&quot;, line 5, in &lt;module&gt;
    from MNIST_reader import Data
  File &quot;/content/drive/MyDrive/Colab_Notebooks/machine-learning-diff-private-federated-learning-main/MNIST_reader.py&quot;, line 20
    raise ValueError, &quot;dataset must be 'testing' or 'training'&quot;
SyntaxError: invalid syntax
</code></pre>
<p>I just run <code>bash RUNME.sh</code> and follow the instruction but still get an error!</p>
<pre><code>!python sample.py â€”-m 100, sigma 1
</code></pre>
<p>You're welcome if you want to check the full code <a href=""https://colab.research.google.com/drive/1TiejY0efe1gDsdvLNg9ePM3FVViWPtRj?usp=sharing"" rel=""nofollow noreferrer"">here</a>.
Thanks a lot!!</p>
",19343418,,19343418,,44783.41042,44783.52014,"FedL - raise ValueError, ""dataset must be 'testing' or 'training'""",<python><tensorflow-federated>,1,2,,,,CC BY-SA 4.0
73326892,1,,,44784.87917,,1,258,"<p>I am very interested in federated systems and i was trying one of the pre trained multilingual models such as this notebook <a href=""https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.2_Multi_Lingual_Training_and_models.ipynb"" rel=""nofollow noreferrer"">Multi_Lingual_Training_and_models</a>.</p>
<p>I was looking for any tutorials using TFF or Flower frameworks that handle csv datasets.</p>
<p>So could you suggest any tutorials or github repositories to help me do that with TFF or Flower!</p>
",14208343,,14208343,,44784.88125,45319.37361,How to build a federated system with CSV dataset with SparkNL library?,<tensorflow-federated><flower><federated-learning><johnsnowlabs-spark-nlp>,0,0,,,,CC BY-SA 4.0
73346020,1,,,44786.69167,,0,133,"<pre><code>class BinaryTruePositives(tf.keras.metrics.Metric):

    def __init__(self, name='binary_true_positives', **kwargs):
        super(BinaryTruePositives, self).__init__(name=name, **kwargs)
        self.true_positives = self.add_weight(name='tp', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
    
        y_true = tf.squeeze(y_true)
   
        y_pred = tf.sign(y_pred)

        y_pred=tf.reshape(y_pred,[-1])
  
    
        self.true_positives.assign_add(tf.keras.backend.mean(tf.keras.backend.equal(y_true, 
        y_pred)))

    def result(self):
        return self.true_positives

    def reset_states(self):
        self.true_positives.assign(0)


    def model_fn():
        keras_model = create_keras_model()
        return tff.learning.from_keras_model(keras_model,
        input_spec=preprocessed_example_dataset.element_spec,
        loss=tf.keras.losses.MSE,
        metrics=[BinaryTruePositives()])
</code></pre>
<pre><code>TypeError: Expected tensorflow.python.keras.losses.Loss or collections.abc.Sequence, found function.
</code></pre>
",18157505,,11989081,,44786.69375,44792.67153,Custom accuracy in tff federated learning using keras.metric,<python><tensorflow><keras><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
73407373,1,,,44791.73819,,1,207,"<p>I want to build a TFF model for speech recognition systems. For this, I use the CNN-GRU model architecture with a CTC loss function. but I got error when I wanted to build_federated_averaging_process and think it's about the ctc_loss function but I cant fix it.</p>
<p>part of my code is:</p>
<pre><code>def CTCLoss(y_true, y_pred):
    # Compute the training-time loss value
    batch_len = tf.cast(tf.shape(y_true)[0], dtype=&quot;int64&quot;)
    input_length = tf.cast(tf.shape(y_pred)[1], dtype=&quot;int64&quot;)
    label_length = tf.cast(tf.shape(y_true)[1], dtype=&quot;int64&quot;)

    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=&quot;int64&quot;)
    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=&quot;int64&quot;)

    loss = keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)
    return loss

def create_compiled_keras_model():
    &quot;&quot;&quot;Model similar to DeepSpeech2.&quot;&quot;&quot;
    # Model's input
    input_spectrogram = layers.Input((None, fft_length // 2 + 1), name=&quot;input&quot;)
    # Expand the dimension to use 2D CNN.
    x = layers.Reshape((-1, fft_length // 2 + 1 , 1), name=&quot;expand_dim&quot;)(input_spectrogram)
    # Convolution layer 1
    x = layers.Conv2D(
        filters=32,
        kernel_size=[11, 41],
        strides=[2, 2],
        padding=&quot;same&quot;,
        use_bias=False,
        name=&quot;conv_1&quot;,
    )(x)
    x = layers.BatchNormalization(name=&quot;conv_1_bn&quot;)(x)
    x = layers.ReLU(name=&quot;conv_1_relu&quot;)(x)
    # Convolution layer 2
    x = layers.Conv2D(
        filters=32,
        kernel_size=[11, 21],
        strides=[1, 2],
        padding=&quot;same&quot;,
        use_bias=False,
        name=&quot;conv_2&quot;,
    )(x)
    x = layers.BatchNormalization(name=&quot;conv_2_bn&quot;)(x)
    x = layers.ReLU(name=&quot;conv_2_relu&quot;)(x)
    # Reshape the resulted volume to feed the RNNs layers
    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)
    # RNN layers
    for i in range(1, 2 + 1):
        recurrent = layers.GRU(
            units=128,
            activation=&quot;tanh&quot;,
            recurrent_activation=&quot;sigmoid&quot;,
            use_bias=True,
            return_sequences=True,
            reset_after=True,
            name=f&quot;gru_{i}&quot;,
        )
        x = layers.Bidirectional(
            recurrent, name=f&quot;bidirectional_{i}&quot;, merge_mode=&quot;concat&quot;
        )(x)
        if i &lt; 2:
            x = layers.Dropout(rate=0.5)(x)
    # Dense layer
    x = layers.Dense(units=128 * 2, name=&quot;dense_1&quot;)(x)
    x = layers.ReLU(name=&quot;dense_1_relu&quot;)(x)
    x = layers.Dropout(rate=0.5)(x)
    # Classification layer
    output = layers.Dense(units= output_dim + 1, activation=&quot;softmax&quot;)(x)
    # Model
    model = keras.Model(input_spectrogram, output, name=&quot;DeepSpeech_2&quot;)
    
    return model

def model_fn():
  # We _must_ create a new model here, and _not_ capture it from an external
  # scope. TFF will call this within different graph contexts.
  keras_model = create_compiled_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=layers.Input((None, fft_length // 2 + 1)),
      loss=CTCLoss)
</code></pre>
<p>and I got error in this step :</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda:keras.optimizers.Adam(learning_rate=1e-4))

TypeError: Expected keras.losses.Loss, found function.
</code></pre>
<p>how do I fix it?</p>
",17945316,,,,,44801.19236,"TypeError: Expected keras.losses.Loss, found function",<tensorflow><keras><tensorflow-federated><federated-learning><ctc>,1,0,,,,CC BY-SA 4.0
63498907,1,63543036,,44063.23542,,3,341,"<p>The code in the TFF tutorials and in the research projects I see generally only keep track of server states.  Iâ€™d like there to be internal client states (for instance, additional client internal neural networks which are completely decentralized and donâ€™t update in a federated manner) that would influence the federated client computations.</p>
<p>However, in the client computations I have seen, they are only functions of the server states and the data.  Is it possible to accomplish the above?</p>
",12346446,,,,,44433.61389,Is there a way for TFF clients to have internal states?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
63539599,1,63562335,,44065.76181,,2,375,"<p>My dataset is class imbalanced, so I want to use class_weight which enables the classifier heavily weight minor class. In general setting, I can assign class weight as below:</p>
<pre class=""lang-py prettyprint-override""><code>weighted_history = weighted_model.fit(
    train_features,
    train_labels,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    callbacks=[early_stopping],
    validation_data=(val_features, val_labels),
    # The class weights go here
    class_weight=class_weight) 
</code></pre>
<p>Is there any way that I can assign class_weight in tensorflow federated learning? My code for federated learning is below:</p>
<pre class=""lang-py prettyprint-override""><code>def create_keras_model(output_bias=None):
    return tf.keras.models.Sequential([
        tf.keras.layers.Dense(12, activation='relu', input_shape(5,)),
        tf.keras.layers.Dense(8, activation='relu'),
        tf.keras.layers.Dense(5, activation='relu'),
        tf.keras.layers.Dense(3, activation='relu'),
        tf.keras.layers.Dense(1, activation='sigmoid')])

def model_fn():
    keras_model = create_keras_model()
    return tff.learning.from_keras_model(
        keras_model,
        input_spec=preprocessed_example_dataset.element_spec,
        loss=tf.keras.losses.BinaryCrossentropy(),
        metrics=[tf.keras.metrics.BinaryAccuracy()])
</code></pre>
",14149159,,157336,,44065.78542,44067.57431,Can I use class_weight in keras model in Tensorflow Federated Learning (TFF),<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
63577775,1,,,44068.47431,,1,130,"<p>I am a beginner in federated learning using tff. I have a server and two remote clients. Using gRPC I have sent and received .h5 files with bidirectional byte streaming. I would like to load these two .h5 as two clients and run federated averaging on the weights. How do I do this ?</p>
<p>@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)
def federated_eval(model, data):
return tff.federated_mean(
tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))</p>
<p>Is there a way to implement federated computation on loaded weights ?</p>
",14163232,,,,,44068.47431,Is there a way to load multiple .h5 model files as corresponding clients(tff.Clients) and run federated averaging?,<tensorflow-federated>,0,2,,,,CC BY-SA 4.0
63723518,1,,,44077.51181,,3,546,"<p>I have trialled TFF tutorial (MNIST) on my single machine and now I am trying to perform a multi-machine process using MNIST data.</p>
<p>Clearly, I cannot use <code>create_tf_dataset_for_client</code> so I have used GRPC to learn how to pass data from one machine to another.</p>
<p>My scenario is that Server will dispatch the initial model (with zeroes) to all the participating clients where the model will run on local data. Each client will dispatch the new weights to the server that will perform federated_mean.</p>
<p>I was thinking of using <code>tff.learning.build_federated_averaging_process</code> where I could hopefully customise the <code>next</code> function (2nd argument) but I failed... I am not even sure if we use this approach to send the model and get the weights back from remote clients.</p>
<p>Then I thought I could use <code>tff.federated_mean</code> under <code>@tff.federated_computation</code> decorator. However, since weights are arrays and I have a list of them (as I have a number of clients), I am unable to understand how do I create a <code>tff.FederatedType</code> that points to that a list of lists. Any help from someone who has modelled federation on distributed dataset will be handy to understand.</p>
<p>Regards,
Dev.</p>
",14214871,,,,,44435.00139,TensorFlowFederated: Passing tensor to tff.federated_computation,<tensorflow-federated>,2,0,,,,CC BY-SA 4.0
73502727,1,,,44799.60972,,1,222,"<p>I am planning to use Opacus to implement differential privacy in my federated learning model but I have a very basic doubt that I would love to have cleared before that.</p>
<p>So as far as my understanding goes, using Opacus, we use an optimizer like DPSGD that adds differential noise to each batch of each clientâ€™s dataset while they are in â€œlocal trainingâ€. And in federated learning, we train client models for a few â€œlocal epochsâ€ before sending their weights out to a central server for aggregation, and we add differential noise before sending out the model weights.</p>
<p>So my question is, why do we use DPSGD to add noise to every single batch of every single client dataset during local training when we could just add noise to the local weights before they are sent out? Why do we not let the local training epochs happen as is and simply add noise to the outbound weights at the time of departure? What am I missing?</p>
",1655033,,,,,45313.55833,Noise addition to weights using Opacus in a Federated Learning setting,<pytorch><gradient-descent><privacy><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
73655593,1,,,44812.93819,,2,332,"<p>I am working on tensorflow federated (tff). The problem arises when I call the iterative process and pass on the instance of the model created.</p>
<p>I have declared a keras model which is used at both the server and at the client. I basically want to modify the client model's weights and biases in order to perform mathematical functions on them. These mathematical functions are performed on the models' weights and biases by using function named  'processed'.
The processed function can return weights and layers both in tf or numpy format (the funtion 'processed' just uses tf.convert_to_tensor command to convert the numpy returned weights/biases from the get/set_weights command used)</p>
<pre class=""lang-py prettyprint-override""><code>def create_keras_model():
   return tf.keras.models.Sequential([
     tf.keras.layers.Conv2D(filters=32, kernel_size=[5, 5],name='conv2d_1',activation=tf.nn.relu, use_bias=True, bias_initializer =tf.initializers.lecun_normal(seed=137), input_shape=(28 ,28 ,1 )),
     tf.keras.layers.MaxPool2D(pool_size=[2, 2], strides=2),
     tf.keras.layers.Conv2D(filters=32, kernel_size=[5 5],name='conv2d_2',activation=tf.nn.relu, use_bias = True, bias_initializer=tf.initializers.lecun_normal(seed=137)),
     tf.keras.layers.MaxPool2D(pool_size=[2 2], strides=2),
     tf.keras.layers.Reshape(target_shape=(4 * 3 * 3)),
     tf.keras.layers.Dense(units= 50, activation=tf.nn.relu, use_bias=True, bias_initializer=tf.initializers.lecun_normal(seed=137), name='dense_1'),
     tf.keras.layers.Dense(units=10 , use_bias=True, bias_initializer=tf.initializers.lecun_normal(seed=137), activation=tf.nn.softmax, name='dense_2'   ),
    ])
</code></pre>
<p>I create an instant of the above Keras model named as</p>
<pre class=""lang-py prettyprint-override""><code>net_1 = create_keras_model()
</code></pre>
<p>Now I am accessing the weights and biases by using the following function (proccessed) and assigning them new weights and biases after some mathmatical operations</p>
<pre class=""lang-py prettyprint-override""><code>def processed(net_1,L_norm):
              a=net_1.get_layer('conv2d_1').get_weights()[0]
              b=net_1.get_layer('conv2d_1').get_weights()[1]
              c= net_1.get_layer('conv2d_2').get_weights()[0]
              d=net_1.get_layer('conv2d_2').get_weights()[1]
              e= net_1.get_layer('dense_1').get_weights()[0]
              f= net_1.get_layer('dense_1').get_weights()[1]
              g=net_1.get_layer('dense_2').get_weights()[0]
              h= net_1.get_layer('dense_2').get_weights()[1]
              L1,B1,L2,B2,L3,B3,L4,B4 = processing_work(a,b,c,d,e,f,g,h,L_norm)
             
              L1=tf.convert_to_tensor(L1)
              B1=tf.convert_to_tensor(B1)
              L2=tf.convert_to_tensor(L2)
              B2=tf.convert_to_tensor(B2)
              L3=tf.convert_to_tensor(L3)
              B3=tf.convert_to_tensor(B3)
              L4=tf.convert_to_tensor(L4)
              B4=tf.convert_to_tensor(B4)
              net_1.get_layer('conv2d_1').set_weights([L1,B1])
              net_1.get_layer('conv2d_2').set_weights([L2,B2])
              net_1.get_layer('dense_1').set_weights([L3,B3])
              net_1.get_layer('dense_2').set_weights([L4,B4])
              return net_1
</code></pre>
<p>Following that, I use the following function</p>
<pre class=""lang-py prettyprint-override""><code>def model_fn_of():
  # We _must_ create a new model here, and _not_ capture it from an external
  # scope. TFF will call this within different graph contexts.
  local_model = processed(create_keras_model(),L_norm)
  return tff.learning.from_keras_model(
      local_model,
      input_spec=preprocessed_example_dataset.element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>Then I call the iterator of tff.</p>
<pre class=""lang-py prettyprint-override""><code>iterative_process = tff.learning.algorithms.build_weighted_fed_avg(
    model_fn_of,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.00)) 
</code></pre>
<p>However I get the following error:</p>
<pre><code>---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
&lt;ipython-input-32-651e903cc722&gt; in &lt;module&gt;
      2     model_fn_of,
      3     client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
----&gt; 4     server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.00))

8 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in __getattr__(self, name)
    511         from tensorflow.python.ops.numpy_ops import np_config
    512         np_config.enable_numpy_behavior()&quot;&quot;&quot;.format(type(self).__name__, name))
--&gt; 513     self.__getattribute__(name)
    514 
    515   @staticmethod

AttributeError: 'Tensor' object has no attribute 'numpy'
</code></pre>
<p>Can someone please help me with this. I dont know what is wrong and from which part of the code the error is even popping out. Please note that the dtype of weights/biases of model layers before and after using the 'processed' function are same.
Thanks in Advance</p>
",19953155,,14692,,44835.53472,44835.53472,'Tensor' object has no attribute 'numpy',<tensorflow><numpy-ndarray><tf.keras><tensorflow-federated>,0,3,,,,CC BY-SA 4.0
73671061,1,,,44814.43472,,0,345,"<p>Going over the tutorials for TFF (tensorflow-federated), it seems that performing federated averaging and gradient descent iterations using TFF is well understood and can accomplished easily. However, for other training scenarios such as decision tree training it is not clear to me whether such an implementation is readily available. In particular, does the TF-DF (tensorflow decision forest) integrates well with TFF. If so, does anyone have an example for implementing a regression tree training? Thanks.</p>
",19964019,,,,,45046.02014,Does tensorflow-federated support decision tree training model?,<python><tensorflow><tensorflow-federated>,2,1,,,,CC BY-SA 4.0
73720935,1,,,44818.725,,0,156,"<p>I am working on tensorflow federated.
I have the following imports</p>
<pre><code>!pip install --quiet tensorflow-federated==0.20.0 # The latest version of tensorflow-federated is not working with the colab python version
!pip install --quiet --upgrade nest-asyncio
import nest_asyncio
nest_asyncio.apply()
%load_ext tensorboard
tf.compat.v1.enable_eager_execution()
import tensorflow as tf
import tensorflow_federated as tff
import collections
import os
import random
import math
import time
import numpy as np
from numpy import sqrt
from numpy.fft import fft, ifft
from numpy.random import rand
import inspect
import tensorflow_probability as tfp
from matplotlib import pyplot as plt

from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import AveragePooling2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import Activation
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Flatten
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import concatenate
from tensorflow.keras import initializers
from keras import layers, initializers
from tensorflow.python.eager import backprop
from tensorflow.python.eager import context
from tensorflow.python.eager import function
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import indexed_slices
from tensorflow.python.framework import ops
from tensorflow.python.ops import embedding_ops
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import resource_variable_ops
from tensorflow.python.ops import resources
from tensorflow.python.ops import variables
from tensorflow.python.platform import test
from tensorflow.python.training import gradient_descent



</code></pre>
<p>Consider the following model</p>
<pre><code>def create_model():
  x_1=tf.Variable(24)
  bias_initializer = tf.keras.initializers.HeNormal()
  model = Sequential()
  model.add(Conv2D(2, (5, 5),  input_shape=(28,28,1),activation=&quot;relu&quot;, name='conv2d_1', use_bias=True,bias_initializer=bias_initializer))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Conv2D(1, (5, 5), activation=&quot;relu&quot;,name='conv2d_2',  use_bias=True,bias_initializer=bias_initializer))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Flatten())
  model.add(Dense(2, name='dense_1',activation=&quot;relu&quot;, use_bias=True,bias_initializer=bias_initializer),)
  model.add(Dense(10, name='dense_2', activation=&quot;softmax&quot;, use_bias=True,bias_initializer=bias_initializer),)

  a=model.weights[0]
  b=model.weights[1]
  c=model.weights[2]
  d=model.weights[3]
  e=model.weights[4]
  f=model.weights[5]
  g=model.weights[6]
  h=model.weights[7]
  print(h)
  print(type(a))
  L1,B1,L2,B2,L3,B3,L4,B4=processing_work(a,b,c,d,e,f,g,h,x_1)
  print('L1 is',L1)
  print(type(L1))
  print(type(h))
  kk=resource_variable_ops.ResourceVariable(L1)
  print(type(kk))
  KB=resource_variable_ops.ResourceVariable(B1)
  print(type(KB))
  L1=tf.Variable(L1, dtype='float32')#, name='conv2d_1/kernel:0')
  B1=tf.Variable(B1, dtype='float32')#, name='conv2d_1/bias:0')
  L2=tf.Variable(L2, dtype='float32')#, name='conv2d_2/kernel:0')
  B2=tf.Variable(B2, dtype='float32')#, name='conv2d_2/bias:0')
  L3=tf.Variable(L3, dtype='float32')#, name='dense_1/kernel:0')
  B3=tf.Variable(B3, dtype='float32')#, name='dense_1/bias:0')
  L4=tf.Variable(L4, dtype='float32')#, name='dense_2/kernel:0')
  B4=tf.Variable(B4, dtype='float32')#, name='dense_2/bias:0')
  model.get_layer('conv2d_1').set_weights([L1,B1])
  model.get_layer('conv2d_2').set_weights([L2,B2])
  model.get_layer('dense_1').set_weights([L3,B3])
  model.get_layer('dense_2').set_weights([L4,B4])
  return model 
</code></pre>
<p>What I am doing in this model is; extracting the weights and biases of all the layers, performing various operations on them and re-assigning the processed/modified weights and biases to their respective layers.
I make an instance of the model here:</p>
<pre><code>def model_fn():
  # We _must_ create a new model here, and _not_ capture it from an external
  # scope. TFF will call this within different graph contexts.
  local_model = create_model()
  return tff.learning.from_keras_model(
      local_model,
      input_spec=preprocessed_example_dataset.element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>I then call the following algo:</p>
<pre><code>
iterative_process = tff.learning.algorithms.build_weighted_fed_avg(
    model_fn, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.00))
</code></pre>
<p>However, I get the following error.</p>
<pre><code>&lt;tf.Variable 'dense_2/bias:0' shape=(10,) dtype=float32&gt;
&lt;class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'&gt;
&lt;function reshape at 0x7efde367c830&gt;
L1 is Tensor(&quot;Reshape_41:0&quot;, shape=(5, 5, 1, 2), dtype=float32)
&lt;class 'tensorflow.python.framework.ops.Tensor'&gt;
&lt;class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'&gt;
&lt;class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'&gt;
&lt;class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'&gt;
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
&lt;ipython-input-33-e5ea47468ee2&gt; in &lt;module&gt;
      1 iterative_process = tff.learning.algorithms.build_weighted_fed_avg(
      2     model_fn, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
----&gt; 3     server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.00))

8 frames
/usr/local/lib/python3.7/dist-packages/keras/backend.py in batch_set_value(tuples)
   4024         feed_dict = {}
   4025         for x, value in tuples:
-&gt; 4026           value = np.asarray(value, dtype=dtype_numpy(x))
   4027           tf_dtype = tf.as_dtype(x.dtype.name.split('_')[0])
   4028           if hasattr(x, '_assign_placeholder'):

NotImplementedError: numpy() is only available when eager execution is enabled.
</code></pre>
<p>I have tried both types , i.e., L1 and B1 and kk and KB in</p>
<pre><code>model.get_layer('conv2d_1').set_weights([L1,B1])
</code></pre>
<p>But I am getting the same error. Also at the start of the notebook, I added the following</p>
<pre><code>tf.compat.v1.enable_eager_execution()
</code></pre>
<p>What might be causing this error?</p>
",19953155,,19953155,,44818.89444,44818.89444,Getting error even after enabling eager execution,<numpy><tensorflow><keras><tensorflow-federated>,0,8,,,,CC BY-SA 4.0
73734072,1,,,44819.65903,,0,159,"<p>I am using tensorflow federated with following imports.</p>
<pre><code>import tensorflow as tf
import tensorflow_federated as tff
import collections
import os
import random
import math
import time
import numpy as np
from numpy import sqrt
from numpy.fft import fft, ifft
from numpy.random import rand
import inspect
import tensorflow_probability as tfp
from matplotlib import pyplot as plt
from tensorflow.keras.models import Model
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import  BatchNormalization, AveragePooling2D, MaxPooling2D, Conv2D, Activation, Dropout,Flatten,Input,Dense,concatenate
from tensorflow.keras import layers, initializers
from tensorflow.python.eager import backprop, context, function
from tensorflow.python.framework import constant_op, dtypes, indexed_slices, ops
from tensorflow.python.ops import embedding_ops, math_ops, resource_variable_ops, resources, variables
from tensorflow.python.platform import test
from tensorflow.python.training import gradient_descent
</code></pre>
<p>Consider the following keras model</p>
<pre><code>def create_keras_model():
   return tf.keras.models.Sequential([
     tf.keras.layers.Conv2D(filters=64, kernel_size=[5, 5],name='conv2d_1',activation=tf.nn.relu, use_bias=True, bias_initializer =tf.initializers.lecun_normal(seed=137), input_shape=(28 ,28 ,1)),
     tf.keras.layers.MaxPool2D(pool_size=[2,2], strides=2),
     tf.keras.layers.Conv2D(filters=32, kernel_size=[5,5 ],name='conv2d_2',activation=tf.nn.relu, use_bias = True, bias_initializer=tf.initializers.lecun_normal(seed=137)),
     tf.keras.layers.MaxPool2D(pool_size=[2,2], strides=2),
     tf.keras.layers.Reshape(target_shape=(4 * 4 * 32,)),
     tf.keras.layers.Dense(units= 150, activation=tf.nn.relu, use_bias=True, bias_initializer=tf.initializers.lecun_normal(seed=137), name='dense_1'),
     tf.keras.layers.Dense(units=10 , use_bias=True, bias_initializer=tf.initializers.lecun_normal(seed=137), activation=tf.nn.softmax, name='dense_2'   ),
  ])

</code></pre>
<p>I made an instance of the create_keras_model, i.e.,</p>
<pre><code>net_1 = create_keras_model()
</code></pre>
<p>I then call the following function</p>
<pre><code>def model_fn():
  # We _must_ create a new model here, and _not_ capture it from an external
  # scope. TFF will call this within different graph contexts.
  global_model = create_keras_model()
  global_model.set_weights(net_1.get_weights())
  return tff.learning.from_keras_model(
      global_model,
      input_spec=preprocessed_example_dataset.element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>Following that, I call upon the iterative process</p>
<pre><code>iterative_process = tff.learning.algorithms.build_weighted_fed_avg(
    model_fn, 
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.00))
</code></pre>
<p>Which gives the following error</p>
<pre><code>AttributeError                            Traceback (most recent call last)
&lt;ipython-input-31-777247538e22&gt; in &lt;module&gt;
      2     model_fn,
      3     client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
----&gt; 4     server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.00))

5 frames
/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py in get_weights(self)
    155     &quot;&quot;&quot;
    156     strategy = (self._distribution_strategy or
--&gt; 157                 self._compile_time_distribution_strategy)
    158     if strategy:
    159       with strategy.scope():

AttributeError: 'Sequential' object has no attribute '_compile_time_distribution_strategy'
</code></pre>
<p>Any suggestion for removing the error?</p>
",19953155,,,,,44819.65903,Replacing of weights with set_weights or any other method,<numpy><tensorflow><keras><tensorflow-datasets><tensorflow-federated>,0,6,,,,CC BY-SA 4.0
63809453,1,63840420,,44083.425,,2,239,"<p>New to Tensorflow so not sure if this is a specific question for Tensorflow Federated.</p>
<p>I'm studying adversarial attack on federated learning in this <a href=""https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/research/targeted_attack/attacked_fedavg.py"" rel=""nofollow noreferrer"">code</a>. I'm curious how the weights received from the server are updated at the client.</p>
<p>For example, here is the code for a 'benign' update:</p>
<pre><code>@tf.function
def compute_benign_update():
  &quot;&quot;&quot;compute benign update sent back to the server.&quot;&quot;&quot;
  tf.nest.map_structure(lambda a, b: a.assign(b), model_weights,
                        initial_weights)

  num_examples_sum = benign_dataset.reduce(initial_state=tf.constant(0),
                                           reduce_func=reduce_fn)

  weights_delta_benign = tf.nest.map_structure(lambda a, b: a - b,
                                               model_weights.trainable,
                                               initial_weights.trainable)

  aggregated_outputs = model.report_local_outputs()
  return weights_delta_benign, aggregated_outputs, num_examples_sum
</code></pre>
<p>I can see that the initial weights received from the server are assigned to <code>model_weights</code> then <code>reduce_fn</code> is used to train on a batch of data on the local client.</p>
<pre><code>@tf.function
def reduce_fn(num_examples_sum, batch):
  &quot;&quot;&quot;Runs `tff.learning.Model.train_on_batch` on local client batch.&quot;&quot;&quot;
  with tf.GradientTape() as tape:
    output = model.forward_pass(batch)
  gradients = tape.gradient(output.loss, model.trainable_variables)
  optimizer.apply_gradients(zip(gradients, model.trainable_variables))
  return num_examples_sum + tf.shape(output.predictions)[0]
</code></pre>
<p>Inside this function training occurs and (I think) <code>model.trainable_variables</code> is updated. The part that doesn't make sense to me is how the <code>weights_delta_benign</code> is calculated:</p>
<pre><code>weights_delta_benign = tf.nest.map_structure(lambda a, b: a - b,
                                             model_weights.trainable,
                                             initial_weights.trainable)
</code></pre>
<p>It seems that the difference between <code>model_weights.trainable</code> and <code>initial_weights.trainable</code> is used, but didn't we originally set these to be equal in the first line of the <code>compute_benign_update()</code> function? I'm assuming the <code>reduce_fn</code> alters <code>initial_weights</code> somehow but I don't see the connection between <code>model.trainable_variables</code> used in the reduce function and <code>initial_weights.trainable_variables</code>.</p>
<p>Thanks, any help appreciated!</p>
",2623004,,,,,44085.14653,How does Tensorflow Federated update model from server,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
63917893,1,,,44090.42847,,2,358,"<p>Is there a way to <strong>use the GPU provided by Colab</strong> to run the <strong>training sessions of TFF</strong> faster?
Training Federated Models requires more than 1 hour and it seems that using a GPU runtime does not provide any benefit at all.</p>
<p>The TFF page of High-Performance Simulation is still empty and I cannot find any guide to use the GPU with TFF.</p>
<p>Any suggestion?
Thank you!</p>
<p>tf and tff versions:</p>
<pre><code>2.4.0-dev20200917 
0.16.1
</code></pre>
<p>Number of clients at each round:</p>
<pre><code>70
</code></pre>
<p>Input data element spec:</p>
<pre><code>OrderedDict([('x',
          OrderedDict([('start_place',
                        TensorSpec(shape=(8, 8), dtype=tf.int32, name=None)),
                       ('start_hour_sin',
                        TensorSpec(shape=(8, 8), dtype=tf.float64, name=None)),
                       ('start_hour_cos',
                        TensorSpec(shape=(8, 8), dtype=tf.float64, name=None)),
                       ('week_day_sin',
                        TensorSpec(shape=(8, 8), dtype=tf.float64, name=None)),
                       ('week_day_cos',
                        TensorSpec(shape=(8, 8), dtype=tf.float64, name=None)),
                       ('weekend',
                        TensorSpec(shape=(8, 8), dtype=tf.int32, name=None)),
                       ('month',
                        TensorSpec(shape=(8, 8), dtype=tf.int32, name=None))])),
         ('y', TensorSpec(shape=(8, 8), dtype=tf.int32, name=None))])
</code></pre>
<p>Similarly to the text generation tutorial i'm working with sequence of places, the model is quite similar:</p>
<pre><code>    # Create a model
def create_keras_model(number_of_places, batch_size):
  
        # Shortcut to the layers package
  l = tf.keras.layers


  # Now we need to define an input dictionary.
    # Where the keys are the column names
    # This is a model with multiple inputs, so we need to declare and input layer for each feature
  feature_inputs = {
    'start_hour_sin': tf.keras.Input((N-1, ), batch_size=batch_size, name='start_hour_sin'),
    'start_hour_cos': tf.keras.Input((N-1, ), batch_size=batch_size, name='start_hour_cos'),
    'weekend': tf.keras.Input((N-1, ), batch_size=batch_size, name='weekend'),
    'week_day_sin': tf.keras.Input((N-1, ), batch_size=batch_size, name='week_day_sin'),
    'week_day_cos': tf.keras.Input((N-1, ), batch_size=batch_size, name='week_day_cos'),
  }

  
  # We cannot use anarray of features as always because we have sequences and we cannot match the shape otherwise
  # We have to do one by one
  start_hour_sin = feature_column.numeric_column(&quot;start_hour_sin&quot;, shape=(N-1))
  hour_sin_feature = l.DenseFeatures(start_hour_sin)(feature_inputs)

  start_hour_cos = feature_column.numeric_column(&quot;start_hour_cos&quot;, shape=(N-1))
  hour_cos_feature = l.DenseFeatures(start_hour_cos)(feature_inputs)

  weekend = feature_column.numeric_column(&quot;weekend&quot;, shape=(N-1))
  weekend_feature = l.DenseFeatures(weekend)(feature_inputs)
  
  week_day_sin = feature_column.numeric_column(&quot;week_day_sin&quot;, shape=(N-1))
  week_day_sin_feature = l.DenseFeatures(week_day_sin)(feature_inputs)

  week_day_cos = feature_column.numeric_column(&quot;week_day_cos&quot;, shape=(N-1))
  week_day_cos_feature = l.DenseFeatures(week_day_cos)(feature_inputs)

  
    # We have also to add a dimension to then concatenate
  hour_sin_feature = tf.expand_dims(hour_sin_feature, -1)
  hour_cos_feature = tf.expand_dims(hour_cos_feature, -1)
  weekend_feature = tf.expand_dims(weekend_feature, -1)
  week_day_sin_feature = tf.expand_dims(week_day_sin_feature, -1)
  week_day_cos_feature = tf.expand_dims(week_day_cos_feature, -1)

  # Declare the dictionary for the places sequence as before
  sequence_input = {
      'start_place': tf.keras.Input((N-1,), batch_size=batch_size, dtype=tf.dtypes.int32, name='start_place') # add batch_size=batch_size in case of stateful GRU
  }


  # Handling the categorical feature sequence using one-hot
  places_one_hot = feature_column.sequence_categorical_column_with_vocabulary_list(
      'start_place', [i for i in range(number_of_places)])
  
  # Embed the one-hot encoding
  places_embed = feature_column.embedding_column(places_one_hot, embedding_dim)


  # With an input sequence we can't use the DenseFeature layer, we need to use the SequenceFeatures
  sequence_features, sequence_length = tf.keras.experimental.SequenceFeatures(places_embed)(sequence_input)

  input_sequence = l.Concatenate(axis=2)([ sequence_features, hour_sin_feature, hour_cos_feature, weekend_feature, week_day_sin_feature, week_day_cos_feature])

  # Rnn
  recurrent = l.GRU(rnn_units,
                        batch_size=batch_size, #in case of stateful
                        return_sequences=True,
                        dropout=0.5,
                        stateful=True,
                        recurrent_initializer='glorot_uniform')(input_sequence)


    # Last layer with an output for each places
  dense_1 = layers.Dense(number_of_places)(recurrent)

    # Softmax output layer
  output = l.Softmax()(dense_1)
    
    # To return the Model, we need to define it's inputs and outputs
    # In out case, we need to list all the input layers we have defined 
  inputs = list(feature_inputs.values()) + list(sequence_input.values())

    # Return the Model
  return tf.keras.Model(inputs=inputs, outputs=output)
</code></pre>
<p>Function to create the model:</p>
<pre><code>def create_tff_model():
  # TFF uses an `input_spec` so it knows the types and shapes
  # that your model expects.
  input_spec = preprocessed_example_dataset.element_spec
  keras_model_clone = create_keras_model(number_of_places, batch_size=BATCH_SIZE)
  return tff.learning.from_keras_model(
      keras_model_clone,
      input_spec=input_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
</code></pre>
<p>Federated Avg</p>
<pre><code># This command builds all the TensorFlow graphs and serializes them: 
fed_avg = tff.learning.build_federated_averaging_process(
    model_fn=create_tff_model,
    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.001),
    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.06))
          metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>State init:</p>
<pre><code>state = fed_avg.initialize()
</code></pre>
<p>Training Loop:</p>
<pre><code>NUM_ROUNDS = 10

  for round_num in range(1, NUM_ROUNDS + 1):
    print('Round {r}'.format(r=round_num))
    state, metrics = fed_avg.next(state, train_data)
    train_metrics = metrics['train']
    print('\tTrain: loss={l:.3f}, accuracy={a:.3f}'.format(l=train_metrics['loss'], a=train_metrics['sparse_categorical_accuracy']))
</code></pre>
",8527872,,8527872,,44091.49653,44099.62569,Run TensorFlow Federated on GPU with Colab,<tensorflow><google-colaboratory><tensorflow-federated>,1,6,,,,CC BY-SA 4.0
63955527,1,,,44092.50694,,2,217,"<p>I would like to point the federated_train_data to remote client data as shown in the code below.Is this possible? How ?</p>
<p>If not what further implementation is required for me to try this out. Kindly point me to the relevant code.</p>
<pre><code>factory = tff.framework.create_executor_factory(make_remote_executor)
context = tff.framework.ExecutionContext(factory)
tff.framework.set_default_context(context)

state = iterative_process.initialize()

state, metrics = iterative_process.next(state, federated_train_data)
</code></pre>
<pre><code>def make_remote_executor(inferred_cardinalities):
  &quot;&quot;&quot;Make remote executor.&quot;&quot;&quot;

  def create_worker_stack(ex):
    ex = tff.framework.ThreadDelegatingExecutor(ex)
    return tff.framework.ReferenceResolvingExecutor(ex)

  client_ex = []
  num_clients = inferred_cardinalities.get(tff.CLIENTS, None)
  if num_clients:
    print('Inferred that there are {} clients'.format(num_clients))
  else:
    print('No CLIENTS placement provided')

  for _ in range(num_clients or 0):
    channel = grpc.insecure_channel('{}:{}'.format(FLAGS.host, FLAGS.port))
    remote_ex = tff.framework.RemoteExecutor(channel, rpc_mode='STREAMING')
    worker_stack = create_worker_stack(remote_ex)
    client_ex.append(worker_stack)

  federating_strategy_factory = tff.framework.FederatedResolvingStrategy.factory(
      {
          tff.SERVER: create_worker_stack(tff.framework.EagerTFExecutor()),
          tff.CLIENTS: client_ex,
      })
  unplaced_ex = create_worker_stack(tff.framework.EagerTFExecutor())
  federating_ex = tff.framework.FederatingExecutor(federating_strategy_factory,
                                                   unplaced_ex)
  return tff.framework.ReferenceResolvingExecutor(federating_ex)
</code></pre>
<p>This is from <a href=""https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/examples/remote_execution/remote_executor_example.py"" rel=""nofollow noreferrer"">https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/examples/remote_execution/remote_executor_example.py</a></p>
",14163232,,14163232,,44099.59792,44102.86667,Tensorflow federated : How to map the remote-worker with remote datasets in iterative_process.next?,<tensorflow-federated>,1,4,,,,CC BY-SA 4.0
63990564,1,,,44095.44028,,0,126,"<p>I am still a beginner in federated learning- I would like to clarify my understanding in a remote client-server scenario given the remote_executor_example.py.</p>
<p><a href=""https://i.sstatic.net/oGelj.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/oGelj.png"" alt=""REMOTE_SERVICE_CLARIFY"" /></a></p>
<p>I hope the image is clear, Kindly clarify if the above components are in the right place in the context of a remote client-server scenario.</p>
<p>If the above understanding is correct, else please correct me:</p>
<p>how do we map the factory to the remote- 'make_remote_executor()' method on the client side?</p>
",14163232,,,,,44102.39097,How to map the make_remote_executor() method defined on the client from the server- tff.framework.create_executor_factor(make_remote_executor),<tensorflow-federated>,2,0,,,,CC BY-SA 4.0
64046242,1,64050355,,44098.51042,,0,463,"<p>I was trying to use Tensorflow Privacy with TFF following the two examples provided in <a href=""https://github.com/tensorflow/federated/tree/master/tensorflow_federated/python/research/differential_privacy"" rel=""nofollow noreferrer"">here</a> with my own dataset.
I made sure that samples and target were formatted correctly and everything worked before adding the DP process with clipping and noise.
Unfortunately, in any execution with dp enable the model diverge instead of converging, with both train and validation loss increasing at each round.</p>
<pre><code>Round  0, 68.89s per round in average.
    Train: loss=5.172, accuracy=0.222
    Validation: loss=6.181, accuracy=0.002

Round  1, 61.52s per round in average.
    Train: loss=4.087, accuracy=0.328
    Validation: loss=6.747, accuracy=0.002

Round  2, 57.98s per round in average.
    Train: loss=4.659, accuracy=0.227
    Validation: loss=7.475, accuracy=0.002

Round  3, 56.62s per round in average.
    Train: loss=5.354, accuracy=0.198
    Validation: loss=8.409, accuracy=0.002
     Updating the best state...

Round  4, 55.25s per round in average.
    Train: loss=6.181, accuracy=0.172
    Validation: loss=9.330, accuracy=0.004

Round  5, 54.36s per round in average.
    Train: loss=7.739, accuracy=0.095
    Validation: loss=10.311, accuracy=0.006

Round  6, 53.83s per round in average.
    Train: loss=9.188, accuracy=0.037
    Validation: loss=11.243, accuracy=0.006

Round  7, 53.63s per round in average.
    Train: loss=9.581, accuracy=0.080
    Validation: loss=12.214, accuracy=0.009
</code></pre>
<p>I have tried with different combinations of clip and noise_multiplier but without achieving any results..
Here is an example:</p>
<pre><code>  'clients_per_round' : 20,
  'client_epochs_per_round' : 2,
  'uniform_weighting' : True,
  'server_optimizer': 'adam',
  'client_optimizer': 'adam',

  'clip':0.05, #l2 norm
  'noise_multiplier' : 1.0,
  'adaptive_clip_learning_rate' : 0,
  'target_unclipped_quantile' : 0.5,
  'clipped_count_budget_allocation' : 0.1,
  'per_vector_clipping' : False,
</code></pre>
<p>Any idea on what could be the problem? With 'noise_multiplier' : False everything was working properly..
The definition of the DP_query and the averaging process is basically the same used in the example:</p>
<pre><code>dp_query = tff.utils.build_dp_query(
      clip=FLAGS.clip,
      noise_multiplier=FLAGS.noise_multiplier,
      expected_total_weight=FLAGS.clients_per_round,
      adaptive_clip_learning_rate=FLAGS.adaptive_clip_learning_rate,
      target_unclipped_quantile=FLAGS.target_unclipped_quantile,
      clipped_count_budget_allocation=FLAGS.clipped_count_budget_allocation,
      expected_clients_per_round=FLAGS.clients_per_round,
      per_vector_clipping=FLAGS.per_vector_clipping,
      model=model_fn())

  weights_type = tff.learning.framework.weights_type_from_model(model_fn)
  aggregation_process = tff.utils.build_dp_aggregate_process(
      weights_type.trainable, dp_query)
</code></pre>
<p>Thank you!</p>
",8527872,,8527872,,44098.51597,44098.67569,Applying Differential Privacy in TensorFlow Federated,<tensorflow><tensorflow-federated>,1,2,,,,CC BY-SA 4.0
64053996,1,,,44098.85556,,0,356,"<p><a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">This</a> tutorial describes how to build a TFF computation from keras model.
<a href=""https://www.tensorflow.org/federated/tutorials/custom_federated_algorithms_2"" rel=""nofollow noreferrer"">This</a> tutorial describes how to build a custom TFF computation from scratch, possibly with a custom federated learning algorithm.</p>
<p>What I need is a combination of these: I want to build a custom federated learning algorithm, and I want to use an existing keras model. <strong>Q.</strong> How can it be done?</p>
<p>The second tutorial requires <code>MODEL_TYPE</code> which is based on <code>MODEL_SPEC</code>, but I don't know how to get it. I can see some variables in <code>model.trainable_variables</code> (where <code>model = tff.learning.from_keras_model(keras_model, ...</code>), but I doubt it's what I need.</p>
<p>Of course, I can implement the model by hand (as in the second tutorial), but I want to avoid it.</p>
",,user12463032,,,,44105.20903,TensorFlow Federated: Keras model with custom learning algorithm,<python><tensorflow><keras><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
64183256,1,,,44107.44028,,0,137,"<p>I'm trying to use tensorflow federated to simulate a federated learning algorithm in a hierarchical topology. For what I've read, only a few strategies are implemented (such as tff.learning.build_federated_averaging_process), which relies on a single aggregation server. Is there any way to have networks that are more complex than the standard n-clients 1-server?</p>
",14366506,,14366506,,44202.92639,44525.18819,Tensorflow Federated in a hierarchical fashion,<tensorflow><tensorflow2.0><tf.keras><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
64196780,1,64211418,,44108.66111,,1,146,"<p>Is there any way in federated-tensorflow to make clients train the model for multiple epochs on their dataset? I found on the tutorials that a solution could be modifying the dataset by running dataset.repeat(NUMBER_OF_EPOCHS), but why should I modify the dataset?</p>
",14366506,,,,,44109.63472,Running multiple epochs in clients of federated-tensorflow,<tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
64280312,1,,,44113.52917,,1,150,"<p>I use TFF <em><strong>0.12.0</strong></em> and I run a code of federated learning for image classification with VGG16, and here is a part of my code:</p>
<pre><code>def create_compiled_keras_model():
    layer1 = tf.keras.layers.GlobalAveragePooling2D()(output)
    layer1 = tf.keras.layers.Dense(units=256)(output)
    model_output = tf.keras.layers.Dense(units=2, activation='relu')(layer1)
    model = tf.keras.Model(model.input, model_output)
    return model

def model_fn():
     keras_model = create_compiled_keras_model()
     return tff.learning.from_keras_model(keras_model, sample_batch, loss=tf.keras.losses.CategoricalCrossentropy(),metrics=[tf.keras.metrics.CategoricalAccuracy()]) 

</code></pre>
<p>After running, I see that accuracy does not increase, knowing that I initialize 100 rounds.</p>
<pre><code>round  1, metrics=&lt;categorical_accuracy=0.5,loss=8.059043884277344,keras_training_time_client_sum_sec=0.0&gt;
round  2, metrics=&lt;categorical_accuracy=0.5,loss=8.059045791625977,keras_training_time_client_sum_sec=0.0&gt;
round  3, metrics=&lt;categorical_accuracy=0.5,loss=8.05904769897461,keras_training_time_client_sum_sec=0.0&gt;
round  4, metrics=&lt;categorical_accuracy=0.5,loss=8.059043884277344,keras_training_time_client_sum_sec=0.0&gt;
round  5, metrics=&lt;categorical_accuracy=0.5,loss=8.059045791625977,keras_training_time_client_sum_sec=0.0&gt;
round  6, metrics=&lt;categorical_accuracy=0.5,loss=8.059045791625977,keras_training_time_client_sum_sec=0.0&gt;
</code></pre>
",14253961,,14253961,,44131.56528,44131.56528,Why accuracy does not increase,<tensorflow-federated>,0,4,,,,CC BY-SA 4.0
64331370,1,,,44117.34931,,1,653,"<p>I use TFF 0.12.0, in this line :</p>
<pre><code>model = tff.learning.ModelWeights.from_model('model.h5')
</code></pre>
<p>I find this error:</p>
<pre><code>AttributeError: module 'tensorflow_federated.python.learning' has no attribute 'ModelWeights'
</code></pre>
<p>How can I change this line to be functional with version 0.12.0
Thanks</p>
",14253961,,,,,44117.34931,AttributeError: module 'tensorflow_federated.python.learning' has no attribute 'ModelWeights',<tensorflow-federated>,0,0,,,,CC BY-SA 4.0
73776503,1,73778967,,44823.68333,,0,68,"<p>Consider the following model</p>
<pre><code>def create_model():
  x_1=tf.Variable(24)
  bias_initializer = tf.keras.initializers.HeNormal()
  model = Sequential()
  model.add(Conv2D(64, (5, 5),  input_shape=(28,28,1),activation=&quot;relu&quot;, name='conv2d_1', use_bias=True,bias_initializer=bias_initializer))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Conv2D(32, (5, 5), activation=&quot;relu&quot;,name='conv2d_2',  use_bias=True,bias_initializer=bias_initializer))
  model.add(MaxPooling2D(pool_size=(2, 2)))
  model.add(Flatten())
  model.add(Dense(120, name='dense_1',activation=&quot;relu&quot;, use_bias=True,bias_initializer=bias_initializer),)
  model.add(Dense(10, name='dense_2', activation=&quot;softmax&quot;, use_bias=True,bias_initializer=bias_initializer),)
</code></pre>
<p>Is there any way I can get the shape/size/dimensions of the all the layer(s) of a model ?
For example in the above model, 'conv2d_1' has shape of (64,1,5,5) while 'conv2d_2' has shape of (32,64,5,5)?</p>
",19953155,,,,,44823.85486,How to get shapes of all the layers in a model?,<python><tensorflow><keras><tf.keras><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
73845079,1,73918522,,44829.58194,,-2,176,"<p>I am trying to use the tensorflow_federated library in google colab but cannot figure out how to do this. I have searched a lot on the internet for the same, but everywhere it's given, you don't need to install this library in google colab and you can use it directly, but I am not able to do so. Can anyone who has used this library in google colab tell me how to install/directly use it?</p>
",17743898,,,,,44835.54653,How to use tensorflow federated library in google colab?,<python><tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
73889434,1,,,44833.07361,,0,143,"<p>federated_algorithm = tff.templates.IterativeProcess(
initialize_fn = initialize_fn, next_fn = next_fn)</p>
<p>TF=2.1.0
Tff=0.13.0</p>
<p>they are showing attribute error.</p>
",18157505,,,,,44835.55,AttributeError: module 'tensorflow_federated' has no attribute 'templates',<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
74031314,1,74044548,,44845.68681,,0,2874,"<p>I am trying to run the code given by Tensorflow <a href=""https://www.tensorflow.org/federated"" rel=""nofollow noreferrer"">in their official documentation</a>, pertaining to Tensorflow-Federated.
The code is as follows:</p>
<pre><code>import tensorflow as tf
import tensorflow_federated as tff

def model_fn():
  model = tf.keras.models.Sequential([
      tf.keras.layers.Dense(10, tf.nn.softmax, input_shape=(784,),
                            kernel_initializer='zeros')
  ])

trainer = tff.learning.algorithms.build_weighted_fed_avg(
  model_fn,
  client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.1))
</code></pre>
<p>However, I am getting the following error:</p>
<pre><code>Traceback (most recent call last):
  File &quot;G:/pythonproject2/main.py&quot;, line 43, in &lt;module&gt;
    trainer = tff.learning.algorithms.build_weighted_fed_avg(
AttributeError: module 'tensorflow_federated.python.learning' has no attribute 'algorithms'
</code></pre>
<p>Could someone please help me out?</p>
",12661027,,,,,45016.13194,AttributeError: module 'tensorflow_federated.python.learning' has no attribute 'algorithms',<python><tensorflow><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
74413904,1,,,44877.61597,,0,55,"<p>I have a next word prediction model based on federated learning with tensorflow model. My server need to calculate the distance between the model weigtht I receive in each round. Do you have any idea how to do it?</p>
",7381696,,13302,,44877.62222,44896.72431,Tensorflow Federated: given a model train it with 2 different datsets and calcaulate euclidian distance between these models,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
74572371,1,,,44890.49167,,1,137,"<p>I'm attempting to download and use the Google Landmark v2 dataset using TensoFlow Federated with the following code:</p>
<p><code>train, test = tff.simulation.datasets.gldv2.load_data(gld23k=True)</code></p>
<p>At some point during the download this error occurs:</p>
<p><strong>ValueError: Incomplete or corrupted file detected. The md5 file hash does not match the provided value of 825975950b2e22f0f66aa8fd26c1f153  images_000.tar.</strong></p>
<p>I've tried on Google CoLab and my personal machine but the same error occurs.</p>
<p>Is there anyway to get around this issue?</p>
<p>Thanks any help appreciated.</p>
",2623004,,,,,44890.49167,How to download the Google Landmark v2 dataset using TensorFlow Federated,<tensorflow><tensorflow-federated>,0,0,,,,CC BY-SA 4.0
74624325,1,,,44895.32153,,1,1198,"<p>Hello i'm working on google colab and i have an issue with importing tensorflow_federated as tff it was working fine earlier and i don't know what is the problem now.</p>
<p>here is my code:
I installed all the nessacery pip libaries and everything was working fine with version 0.20.0 of tff. I also tried to install the latest version 0.33.0 but it's not working could anyone help me please what is wrong???</p>
<pre><code>!pip install --quiet --upgrade tensorflow-federated
!pip install --quiet --upgrade tensorflow-model-optimization
!pip install --quiet --upgrade nest-asyncio

import nest_asyncio
nest_asyncio.apply()
</code></pre>
<pre><code>%load_ext tensorboard
</code></pre>
<pre><code>!pip install h5py
!pip install typing-extensions
!pip install wheel
!pip install tensorflow
</code></pre>
<pre><code>!pip install --quiet tensorflow-federated==0.20.0
</code></pre>
<p>here is my imports:</p>
<pre><code>import pandas as pd 
import collections 
import numpy as np
np.random.seed(0)
import tensorflow as tf
from tensorflow.python.keras.optimizer_v2 import gradient_descent
import tensorflow_federated as tff
from random import choices
import matplotlib.pyplot as plt
from google.colab import drive 
import functools
from absl import app
from absl import flags
from absl import logging
import abc
from typing import Any, Callable, Iterable, List, Optional, Sequence, Tuple, Union
from tensorflow_federated.python.common_libs import py_typecheck
</code></pre>
<p>here is my error when i try to import tff :</p>
<pre><code>---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
&lt;ipython-input-17-bcd46adc5a91&gt; in &lt;module&gt;
      5 import tensorflow as tf
      6 from tensorflow.python.keras.optimizer_v2 import gradient_descent
----&gt; 7 import tensorflow_federated as tff
      8 from random import choices
      9 import matplotlib.pyplot as plt

/usr/local/lib/python3.7/dist-packages/tensorflow_federated/__init__.py in &lt;module&gt;
     79 # the directory structure. The python import statements above implicitly add
     80 # these to locals().
---&gt; 81 del python  # pylint:disable=undefined-variable
     82 del proto  # pylint:disable=undefined-variable

NameError: name 'python' is not defined
</code></pre>
<p>Also there is an error when i try the first pip:</p>
<p>ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
pymc 4.1.4 requires cachetools&gt;=4.2.1, but you have cachetools 3.1.1 which is incompatible.
grpcio-status 1.48.2 requires grpcio&gt;=1.48.2, but you have grpcio 1.46.5 which is incompatible.
google-colab 1.0.0 requires portpicker~=1.3.1, but you have portpicker 1.5.2 which is incompatible.
google-cloud-bigquery 3.3.6 requires grpcio&lt;2.0dev,&gt;=1.47.0, but you have grpcio 1.46.5 which is incompatible.</p>
",20065340,,,,,44917.1875,import tensorflow_federated as tff error in google colab,<python><tensorflow><google-colaboratory><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
74635696,1,,,44896.02569,,1,66,"<p>I am following <a href=""https://www.tensorflow.org/federated/tutorials/building_your_own_federated_learning_algorithm"" rel=""nofollow noreferrer"">this tutorial</a>.</p>
<p>Here I perform training on federated train data:</p>
<pre class=""lang-py prettyprint-override""><code>for round in range(15):
    server_state = federated_algorithm.next(server_state, federated_train_data)
</code></pre>
<p>and then evaluate the testing set.</p>
<p>How can I get the tff training (accuracy/loss) metrics in custom code of federated learning?</p>
<p>Earlier, I was using:</p>
<pre class=""lang-py prettyprint-override""><code>iterative_process = tff.learning.algorithms.build_weighted_fed_avg(MnistModel, client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02))
</code></pre>
<p>and then I was able to print tff metrics:</p>
<pre class=""lang-py prettyprint-override""><code>print('round  1, metrics={}'.format(metrics))
</code></pre>
<p>But I don't understant how I can show tff metrics in my custom tensorflow federated training process.</p>
",18157505,,1256347,,44896.49444,44896.49444,Training tff metrics on federated training data of clients,<python><tensorflow><tensorflow-federated>,0,0,,,,CC BY-SA 4.0
64367417,1,,,44119.34167,,0,372,"<p>I am trying to run the Google Colab <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">found here</a>, which is a tutorial for <code>tensorflow-federated</code>. First of all, there is an error in the Colab section <strong>Displaying model metrics on Tensorboard</strong>, in the cell:</p>
<pre><code>#@test {&quot;skip&quot;: true}
with summary_writer.as_default():
  for round_num in range(1, NUM_ROUNDS):
    state, metrics = iterative_process.next(state, federated_train_data)
    for name, value in metrics.train._asdict().items():
      tf.summary.scalar(name, value, step=round_num)
</code></pre>
<p>which gets solved in the following way:</p>
<pre><code>#@test {&quot;skip&quot;: true}
with summary_writer.as_default():
  for round_num in range(1, NUM_ROUNDS):
    state, metrics = iterative_process.next(state, federated_train_data)
    for name, value in metrics['train'].items():
      tf.summary.scalar(name, value, step=round_num)
</code></pre>
<p>However I am stuck in the same section because, when trying to run tensorboard I get the error:</p>
<pre><code>ERROR: Failed to launch TensorBoard (exited with 1).
Contents of stderr:
2020-10-15 07:50:26.425571: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia
2020-10-15 07:50:26.425634: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Traceback (most recent call last):
  File &quot;/usr/local/bin/tensorboard&quot;, line 8, in &lt;module&gt;
    sys.exit(run_main())
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorboard/main.py&quot;, line 75, in run_main
    app.run(tensorboard.main, flags_parser=tensorboard.configure)
  File &quot;/usr/local/lib/python3.6/dist-packages/absl/app.py&quot;, line 299, in run
    _run_main(main, args)
  File &quot;/usr/local/lib/python3.6/dist-packages/absl/app.py&quot;, line 250, in _run_main
    sys.exit(main(argv))
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorboard/program.py&quot;, line 289, in main
    return runner(self.flags) or 0
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorboard/program.py&quot;, line 305, in _run_serve_subcommand
    server = self._make_server()
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorboard/program.py&quot;, line 419, in _make_server
    ingester.deprecated_multiplexer,
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py&quot;, line 149, in TensorBoardWSGIApp
    experimental_middlewares,
  File &quot;/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py&quot;, line 257, in __init__
    &quot;Duplicate plugins for name %s&quot; % plugin.plugin_name
ValueError: Duplicate plugins for name projector
</code></pre>
<p>Searching for the error, as other posts suggested, I tried to uninstall/reinstall the packages <code>tf-nightly</code> and <code>tensorflow</code>, but it did not solve. Assuming the problem is generated by package conflicts, the versions of the most relevant Colab packages are the following:</p>
<pre><code>tb-nightly                    2.4.0a20201014          
tblib                         1.7.0                   
tensorboard-plugin-wit        1.7.0                   
tensorboardcolab              0.0.22                  
tensorflow                    2.3.0                   
tensorflow-addons             0.8.3                   
tensorflow-datasets           2.1.0                   
tensorflow-estimator          2.3.0                   
tensorflow-federated-nightly  0.16.1.dev20201014      
tensorflow-gcs-config         2.3.0                   
tensorflow-hub                0.9.0                   
tensorflow-metadata           0.24.0                  
tensorflow-model-optimization 0.4.1                   
tensorflow-privacy            0.5.1                   
tensorflow-probability        0.11.0                  
termcolor                     1.1.0                   
terminado                     0.9.1                   
testpath                      0.4.4                   
text-unidecode                1.3                     
textblob                      0.15.3                  
textgenrnn                    1.4.1                   
tf-estimator-nightly          2.4.0.dev2020101401     
tf-nightly                    2.4.0.dev20201014       
tfa-nightly                   0.12.0.dev20201012231340
</code></pre>
<p>Does anyone know how to solve this?</p>
",1714692,,,,,44204.14306,Google-Colab tutorial on Tensorflow-federated failing when launching Tensorboard,<python><tensorflow><google-colaboratory><tensorboard><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
64374989,1,,,44119.64722,,1,532,"<p>We are setting up a federated scenario with Server and Client on different physical machines.</p>
<p><a href=""https://i.sstatic.net/tTazg.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/tTazg.png"" alt=""Setup Diagram"" /></a>
On the server, we have used the docker container to kickstart:</p>
<p><a href=""https://i.sstatic.net/pcUQT.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/pcUQT.png"" alt=""enter image description here"" /></a></p>
<p>The above has been borrowed from <a href=""https://www.tensorflow.org/federated/tutorials/high_performance_simulation_with_kubernetes"" rel=""nofollow noreferrer"">Kubernetes tutorial</a>. <strong>We believe this creates a 'local executor' [Ref 1]  which helps create a gRPC server [Ref 2].</strong></p>
<p>Ref 1:</p>
<p><a href=""https://i.sstatic.net/C0iEU.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/C0iEU.png"" alt=""enter image description here"" /></a></p>
<p>Ref 2:</p>
<p><a href=""https://i.sstatic.net/u9jKT.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/u9jKT.png"" alt=""enter image description here"" /></a></p>
<p>Next on the client 1, we are calling tff.framework.RemoteExecutor that connects to the gRPC server.</p>
<p><a href=""https://i.sstatic.net/yhksj.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/yhksj.png"" alt=""enter image description here"" /></a></p>
<p><strong>Our understanding based on the above is that the Remote Executor runs on the client which connects to the gRPC server.</strong></p>
<p>Assuming the above is correct, how can we send a</p>
<blockquote>
<p>tff.tf_computation</p>
</blockquote>
<p>from the server to the client and print the output on the client side to ensure the whole setup works well.</p>
",14214871,,,,,44226.52431,TFF: Remote Executor,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
64398484,1,64416793,,44121.10625,,1,343,"<p>I'm following <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">this tutorial</a> to get started with tensorflow federated. My aim is to run federated sgd (not federated avg) with some manipulations on client gradient values before they are sent to the server.</p>
<p>Before moving forward, to briefly reiterate the federated sgd process, for each turn clients will send their computed gradients (not updated weights) to the server, the server aggregates them and broadcasts the updated model to the clients.</p>
<p>Now from what I've gathered so far, I can use the function <a href=""https://www.tensorflow.org/federated/api_docs/python/tff/learning/build_federated_sgd_process"" rel=""nofollow noreferrer""><code>build_federated_sgd_process</code></a> instead of <code>build_federated_averaging_process</code> in the mentioned tutorial to perform federated sgd the way described above.</p>
<p>Where I'm lost is, I need to clip the client gradients and add some noise to them (independently generated for each gradient value) before sending the gradients to the server and I'm not sure how to do it. Generating the noise is straightforward enough, but which function should I modify/implement to be able to do apply the noise to the gradients?</p>
",139256,,,,,44122.76528,How to manipulate client gradients in tensorflow federated sgd,<python><tensorflow><tensorflow-federated><sgd>,1,0,,,,CC BY-SA 4.0
64698402,1,,,44140.56875,,0,63,"<p>I try to run the tff example code.
This is the example code link in tff website <a href=""https://tensorflow.google.cn/federated?authuser=0"" rel=""nofollow noreferrer"">https://tensorflow.google.cn/federated?authuser=0</a></p>
<p>But i get some problem, bug as follows</p>
<pre><code>Unexpected keyword argument 'dummy_batch' in function call
No value for argument 'input_spec' in function call
trainer.next is not callable
</code></pre>
<p>When i following the tutorials to learn,it's on the right way until i meet</p>
<pre><code>state, metrics = iterative_process.next(state, federated_train_data)
</code></pre>
<p>It's the same problem next is not callable.</p>
<p>Please help me ,thank you very much!!!</p>
",14583342,,,,,44140.56875,TFF trainer.next is not callable,<tensorflow-federated>,0,3,,,,CC BY-SA 4.0
64698895,1,,,44140.58889,,2,236,"<p>I use TFF 0.12.0</p>
<p>each client has in train 38 images and in test 16 images, I have 4 clients,</p>
<p>I write a simple code of federated learning :</p>
<pre><code>.....

def create_compiled_keras_model():

    base_model = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet', input_shape=(224,224,3,))
    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
    prediction_layer = tf.keras.layers.Dense(2, activation='softmax')

    model = tf.keras.Sequential([
                               base_model,
                               global_average_layer,
                               prediction_layer
                               ])
    return model
    

def model_fn():
    
    keras_model = create_compiled_keras_model()
  
    return tff.learning.from_keras_model(keras_model, sample_batch, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()]) 

iterative_process = tff.learning.build_federated_averaging_process(model_fn, server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0), client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.001), client_weight_fn=None)

state = iterative_process.initialize()
</code></pre>
<p>I can't understand why I find those lines in execution:</p>
<pre><code>2020-11-05 15:00:16.642666: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 32 in the outer inference context.
2020-11-05 15:00:16.642724: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 23 in the outer inference context.
2020-11-05 15:00:16.643344: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 51 in the outer inference context.
2020-11-05 15:00:16.643400: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 41 in the outer inference context.
2020-11-05 15:00:16.643545: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 69 in the outer inference context.
2020-11-05 15:00:16.643589: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 60 in the outer inference context.
2020-11-05 15:00:16.643696: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 97 in the outer inference context.
2020-11-05 15:00:16.643756: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 86 in the outer inference context.
2020-11-05 15:00:16.643923: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 106 in the outer inference context.
2020-11-05 15:00:16.643988: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 116 in the outer inference context.
2020-11-05 15:00:16.644071: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 79 in the outer inference context.
2020-11-05 15:00:16.644213: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 134 in the outer inference context.
</code></pre>
<p>Knowing that If I change Resnet50 with VGG16, those lines disappear.
Help please !! what does this mean ?</p>
",14253961,,,,,44140.58889,Function instantiation has undefined input shape at index: 116 in the outer inference context,<tensorflow-federated>,0,3,,,,CC BY-SA 4.0
64714113,1,,,44141.49167,,0,482,"<p>In federated learning task, I found those two method:</p>
<pre><code>
def model_fn():
    keras_model = create_compiled_keras_model()
    return tff.learning.from_compiled_keras_model(keras_model, sample_batch) 
</code></pre>
<p>and</p>
<pre><code>def model_fn():
    keras_model = create_keras_model()
    return tff.learning.from_keras_model(keras_model, sample_batch, loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()]) 
</code></pre>
<p>I would like to know which is better  and if it can influence on result (accuracy, loss) ?
Thanks</p>
",14253961,,,,,44142.1125,difference between tff.learning.from_compiled_keras_model and tff.learning.from_keras_model,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
64750708,1,,,44144.47361,,0,348,"<p>In order to manipulate metrics of my model , I would like to know, I saw loss on <code>federated_train_data</code> or loss on <code>federated_test_data</code> ?
I read this :</p>
<blockquote>
<p>Training loss looks much better than evaluation loss: when using Federated Averaging (the optimization algorithm used in the Federated Learning for Image Classification tutorial) one needs to be careful interpreting metrics as they have nuanced differences from centralized model training. Especially training loss, which is the average over many sequence steps or batches. This means after one round, each client may have fit the model to their local data very well (obtaining a high accuracy), but after averaging these updates into the global model the global model may still be far away from &quot;good&quot;, resulting in a low test accuracy. Additionally, 10 rounds may be too few; one of the original academic papers on Federated Learning demonstrated at least 20 rounds until 99% accuracy (McMahan 2016) with IID data, and more than 100 rounds in with non-IID data.</p>
</blockquote>
<p>So I would like to know which is better for evaluation metrcis using this code :</p>
<pre><code>evaluation = tff.learning.build_federated_evaluation(model_fn)
    test_metrics = evaluation(state.model, federated_test_data)
</code></pre>
<p>Or this one :</p>
<pre><code>evaluation = tff.learning.build_federated_evaluation(model_fn)
    metrics = evaluation(state.model, federated_train_data)
</code></pre>
<p>Thanks</p>
",12682667,,,,,44146.33681,Training loss or test loss?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
64760396,1,64770354,,44144.95278,,4,1267,"<p>I am working on a project with Tensorflow federated. I have managed to use the libraries provided by TensorFlow  Federated Learning simulations in order to load,  train, and test some datasets.</p>
<p>For example, i load the emnist dataset</p>
<pre><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()
</code></pre>
<p>and it got the data sets returned by load_data() as instances of tff.simulation.ClientData. This is an interface that allows me to iterate over client ids and allow me to select subsets of the data for simulations.</p>
<pre><code>len(emnist_train.client_ids)

3383


emnist_train.element_type_structure


OrderedDict([('pixels', TensorSpec(shape=(28, 28), dtype=tf.float32, name=None)), ('label', TensorSpec(shape=(), dtype=tf.int32, name=None))])


example_dataset = emnist_train.create_tf_dataset_for_client(
    emnist_train.client_ids[0])
</code></pre>
<p>I am trying to load the fashion_mnist dataset with Keras to perform some federated operations:</p>
<pre><code>fashion_train,fashion_test=tf.keras.datasets.fashion_mnist.load_data()
</code></pre>
<p>but I get this error</p>
<pre><code>AttributeError: 'tuple' object has no attribute 'element_spec'
</code></pre>
<p>because Keras returns a Tuple of Numpy arrays instead of a tff.simulation.ClientData like before:</p>
<pre><code>def tff_model_fn() -&gt; tff.learning.Model:
    return tff.learning.from_keras_model(
        keras_model=factory.retrieve_model(True),
        input_spec=fashion_test.element_spec,
        loss=loss_builder(),
        metrics=metrics_builder())

iterative_process = tff.learning.build_federated_averaging_process(
    tff_model_fn, Parameters.server_adam_optimizer_fn, Parameters.client_adam_optimizer_fn)
server_state = iterative_process.initialize()
</code></pre>
<p>To sum up,</p>
<ol>
<li><p>Is any way to create tuple elements of <code>tff.simulation.ClientData</code> from Keras Tuple Numpy arrays?</p>
</li>
<li><p>Another solution that comes to my mind is to use the
<code>tff.simulation.HDF5ClientData</code> and load
manually the appropriate files in a<code>HDF5</code>format <code>(train.h5,   test.h5)</code> in order to get the <code>tff.simulation.ClientData</code>, but my problem is that i cant find the url for fashion_mnist  <code>HDF5</code> file format i mean something like that for both train and test:</p>
<pre><code>      fileprefix = 'fed_emnist_digitsonly'
      sha256 = '55333deb8546765427c385710ca5e7301e16f4ed8b60c1dc5ae224b42bd5b14b'
      filename = fileprefix + '.tar.bz2'
      path = tf.keras.utils.get_file(
          filename,
          origin='https://storage.googleapis.com/tff-datasets-public/' + filename,
          file_hash=sha256,
          hash_algorithm='sha256',
          extract=True,
          archive_format='tar',
          cache_dir=cache_dir)

      dir_path = os.path.dirname(path)
      train_client_data = hdf5_client_data.HDF5ClientData(
          os.path.join(dir_path, fileprefix + '_train.h5'))
      test_client_data = hdf5_client_data.HDF5ClientData(
          os.path.join(dir_path, fileprefix + '_test.h5'))

      return train_client_data, test_client_data
</code></pre>
</li>
</ol>
<p>My final goal is to make the fashion_mnist dataset work with the TensorFlow federated learning.</p>
",3163824,,730754,,44163.68611,44163.68611,How to load Fashion MNIST dataset in Tensorflow Fedarated?,<python><tensorflow><keras><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
74830029,1,,,44911.90486,,0,46,"<p>TFF's <a href=""https://github.com/tensorflow/federated/blob/main/tensorflow_federated/cc/core/impl/executors/threading.h"" rel=""nofollow noreferrer"">threading libraries</a> start a new thread from <a href=""https://github.com/tensorflow/federated/blob/main/tensorflow_federated/cc/core/impl/executors/threading.h#L93"" rel=""nofollow noreferrer""><code>ThreadRun</code> by default</a>, and the only usage (as of TFF 0.42.0) of the optional ThreadPool parameter is in the implementation of a single executor. Why is this the case?</p>
",7507932,,,,,44911.90694,Why is there only limited usage of thread pools in TensorFlow-Federated?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
74886418,1,,,44917.3875,,0,140,"<p>I want to try a simple federated learning example in python. For it, I need to import tensorflow_federated package.</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow_federated as tff
</code></pre>
<p>Here is the stack trace</p>
<pre class=""lang-py prettyprint-override""><code>TypeError                                 Traceback (most recent call last)
&lt;ipython-input-6-961ae1555cfa&gt; in &lt;module&gt;
----&gt; 1 import tensorflow_federated as tff

14 frames
/usr/lib/python3.8/typing.py in _type_check(arg, msg, is_argument)
    147         return arg
    148     if not callable(arg):
--&gt; 149         raise TypeError(f&quot;{msg} Got {arg!r:.100}.&quot;)
    150     return arg
    151 

TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis.
</code></pre>
<p>How should I resolve this error?<br />
BTW, I read in a forum that the problem might be resolved by updating the python version, however it still exists despite I updated it to v3.9<br />
The full stack trace is as follows (I had to submit a screenshot of it was misinterpreted by stackoverflow as some quotes and codes that are not in the right format)
<a href=""https://i.sstatic.net/Skmez.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/Skmez.png"" alt=""enter image description here"" /></a></p>
",3415597,,1910920,,44920.46806,44920.46806,Cannot install and import tensorflow_federated in colab,<python><tensorflow-federated><federated-learning>,0,3,,,,CC BY-SA 4.0
74985672,1,,,44928.75139,,2,483,"<p>I've been trying to import TensorFlow_federated but have stumbled across an error. After extensively searching the Internet I am yet to find anyone who has encountered the same:</p>
<pre><code>import collections
import numpy as np
import tensorflow as tf
import tensorflow_federated as tff

np.random.seed(0)

tff.federated_computation(lambda: 'Hello, World!')()
</code></pre>
<p>The above returns the following, has anyone experienced anything similar:</p>
<pre><code>/usr/local/lib/python3.8/dist-packages/tensorflow_federated/python/learning/metrics/keras_utils.py in &lt;module&gt;
 38     metrics_constructor: Union[MetricConstructor, MetricsConstructor,
 39                                MetricConstructors]
 ---&gt; 40 ) -&gt; Tuple[Callable[[], StateVar], Callable[[StateVar, ...], StateVar],
 41            Callable[[StateVar], Any]]:
 42   &quot;&quot;&quot;Turn a Keras metric construction method into a tuple of pure functions.

/usr/lib/python3.8/typing.py in __getitem__(self, params)
814                                 f&quot; Got {args}&quot;)
815             params = (tuple(args), result)
--&gt; 816         return self.__getitem_inner__(params)
817 
818     @_tp_cache

/usr/lib/python3.8/typing.py in inner(*args, **kwds)
259         except TypeError:
260             pass  # All real errors (not unhashable args) are raised below.
--&gt; 261         return func(*args, **kwds)
262     return inner
263 

/usr/lib/python3.8/typing.py in __getitem_inner__(self, params)
837                 return self.copy_with((_TypingEllipsis, result))
838             msg = &quot;Callable[[arg, ...], result]: each arg must be a type.&quot;
--&gt; 839             args = tuple(_type_check(arg, msg) for arg in args)
840             params = args + (result,)
841             return self.copy_with(params)

/usr/lib/python3.8/typing.py in &lt;genexpr&gt;(.0)
837                 return self.copy_with((_TypingEllipsis, result))
838             msg = &quot;Callable[[arg, ...], result]: each arg must be a type.&quot;
---&gt; 839             args = tuple(_type_check(arg, msg) for arg in args)
840             params = args + (result,)
841             return self.copy_with(params)

/usr/lib/python3.8/typing.py in _type_check(arg, msg, is_argument)
147         return arg
148     if not callable(arg):
--&gt; 149         raise TypeError(f&quot;{msg} Got {arg!r:.100}.&quot;)
150     return arg
151 

TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis.
</code></pre>
",19002832,,,,,44989.58958,TypeError when importing tensorflow_federated,<python><tensorflow><tensorflow-federated>,1,2,,,,CC BY-SA 4.0
64791796,1,,,44146.75417,,3,174,"<p>I'm trying to do a demonstration of federated learning with tff. And I've got this far but the error messages I get are just too confusing. The important part is that I want to demostrate that the data is in the remote engine, which is why I use the <code>tf.data.experimental.CsvDataset</code> and I could not find anything similar in any tutorial. I've managed to do a mini experiment where data was read in the remote site, but I can't get this larger example to work.</p>
<p>Currently it complains about 'p = x * w + b', I believe because x is not a federated_value. But I've tried many many variations and just can't get it to work. The Salary.csv is from a tutorial here <a href=""https://www.kaggle.com/karthickveerakumar/salary-data-simple-linear-regression?select=Salary_Data.csv"" rel=""nofollow noreferrer"">https://www.kaggle.com/karthickveerakumar/salary-data-simple-linear-regression?select=Salary_Data.csv</a></p>
<pre><code>import pandas as pd
import matplotlib.pyplot as plt

import tensorflow as tf
import tensorflow_federated as tff

import grpc

ip_address = '127.0.0.1'
port = 8000

channels = [grpc.insecure_channel(f'{ip_address}:{port}') for _ in range(10)]

tff.backends.native.set_remote_execution_context(channels, rpc_mode='STREAMING')

@tf.function()
def load_data():
    return tf.data.experimental.CsvDataset('data/Salary.csv', [tf.float64,tf.float64], header=True)


W_TYPE = tff.FederatedType(tf.float64, tff.CLIENTS, all_equal=True)
B_TYPE = tff.FederatedType(tf.float64, tff.CLIENTS, all_equal=True)
@tff.federated_computation(W_TYPE, B_TYPE)
def train(w, b):
    data = load_data()
    loss = tf.Variable(0.0, dtype=tf.float64)
    with tf.GradientTape() as tape:
        for x, y in data:
            p = x * w + b
            loss = loss + tf.square(p - y)

    g_w, g_b = tape.gradient(loss, [w, b])
    w.assign_sub(0.0001 * g_w)
    b.assign_sub(0.0001 * g_b)
    return [w, b]

w = tf.Variable(2.0, dtype=tf.float64)
b = tf.Variable(3.0, dtype=tf.float64)
for _ in range(1000):
    w, b = train(data, tff.federated_broadcast(w), tff.federated_broadcast(b))

</code></pre>
",14621089,,,,,44153.20694,Linear regression using tf.data with federated core API and data on remote execution client,<tensorflow2.0><tensorflow-datasets><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
64959332,1,,,44157.8625,,1,210,"<p>I'm currently implementing federated learning using <code>tff</code>.</p>
<p>Because the dataset is very large, we split it into many npy files, and I'm currently putting the dataset together using <a href=""https://www.tensorflow.org/federated/api_docs/python/tff/simulation/FilePerUserClientData"" rel=""nofollow noreferrer""><code>tff.simulation.FilePerUserClientData</code></a>.</p>
<p>This is what I'm trying to do</p>
<pre><code>client_ids_to_files = dict()
for i in range(len(train_filepaths)):
  client_ids_to_files[str(i)] = train_filepaths[i]

def dataset_fn(filepath):
  print(filepath)
  dataSample = np.load(filepath)
  label = filepath[:-4].strip().split('_')[-1]
  return tf.data.Dataset.from_tensor_slices((dataSample, label))
train_filePerClient = tff.simulation.FilePerUserClientData(client_ids_to_files,dataset_fn)
</code></pre>
<p>However, it doesn't seem to work well, the <code>filepath</code> in the callback function has is a tensor with dtype of string. The value of <code>filepath</code> is: <code>Tensor(&quot;hash_table_Lookup/LookupTableFindV2:0&quot;, shape=(), dtype=string)</code></p>
<p>Instead of containing a path in <code>client_ids_to_files</code>, the tensor seems to contains error messages? Am I doing something wrong? How can I write a proper dataset_fn for <code>tff.simulation.FilePerUserClientData</code> using npy files?</p>
<p><em>EDIT</em>:
Here is the error log. The error itself is not really related to the question I'm asking, but you can find the called functions:</p>
<pre><code>---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
&lt;ipython-input-46-e61ddbe06cdb&gt; in &lt;module&gt;
     22     return tf.data.Dataset.from_tensor_slices(filepath)
     23 
---&gt; 24 train_filePerClient = tff.simulation.FilePerUserClientData(client_ids_to_files,dataset_fn)
     25 

~/fasttext-venv/lib/python3.6/site-packages/tensorflow_federated/python/simulation/file_per_user_client_data.py in __init__(self, client_ids_to_files, dataset_fn)
     52       return dataset_fn(client_ids_to_files[client_id])
     53 
---&gt; 54     @computations.tf_computation(tf.string)
     55     def dataset_computation(client_id):
     56       client_ids_to_path = tf.lookup.StaticHashTable(

~/fasttext-venv/lib/python3.6/site-packages/tensorflow_federated/python/core/impl/wrappers/computation_wrapper.py in __call__(self, tff_internal_types, *args)
    405                                             parameter_type)
    406       args, kwargs = unpack_arguments_fn(next(wrapped_fn_generator))
--&gt; 407       result = fn_to_wrap(*args, **kwargs)
    408       if result is None:
    409         raise ComputationReturnedNoneError(fn_to_wrap)

~/fasttext-venv/lib/python3.6/site-packages/tensorflow_federated/python/simulation/file_per_user_client_data.py in dataset_computation(client_id)
     59               list(client_ids_to_files.values())), '')
     60       client_path = client_ids_to_path.lookup(client_id)
---&gt; 61       return dataset_fn(client_path)
     62 
     63     self._create_tf_dataset_fn = create_dataset_for_filename_fn

&lt;ipython-input-46-e61ddbe06cdb&gt; in dataset_fn(filepath)
     17         filepath = tf.print(filepath)
     18     print(filepath)
---&gt; 19     dataSample = np.load(filepath)
     20     print(dataSample)
     21     label = filepath[:-4].strip().split('_')[-1]

~/fasttext-venv/lib/python3.6/site-packages/numpy/lib/npyio.py in load(file, mmap_mode, allow_pickle, fix_imports, encoding)
    426         own_fid = False
    427     else:
--&gt; 428         fid = open(os_fspath(file), &quot;rb&quot;)
    429         own_fid = True
    430 

TypeError: expected str, bytes or os.PathLike object, not Operation
</code></pre>
",5082124,,5082124,,44160.11806,44160.92986,How to write a proper dataset_fn in tff.simulation.FilePerUserClientData?,<python><tensorflow><tensorflow-federated>,1,2,,,,CC BY-SA 4.0
64962547,1,,,44158.18472,,0,405,"<p>I am trying to convert my CSV dataset into a federated data. Please find the code and the error I am getting while I am running my code</p>
<p>code: import collections</p>
<pre><code>import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_federated as tff

np.random.seed(0)
df = pd.read_csv('path to my csv file')

client_id_colname = 'aratio: continuous.' 
SHUFFLE_BUFFER = 1000
NUM_EPOCHS = 1

client_ids = df[client_id_colname].unique()
train_client_ids = sample(client_ids.tolist(),500)
test_client_ids = [x for x in client_ids if x not in train_client_ids]

def create_tf_dataset_for_client_fn(client_id):
  client_data = df[df[client_id_colname] == client_id]
  dataset = tf.data.Dataset.from_tensor_slices(client_data.to_dict('list'))
  dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)
  return dataset

train_data = tff.simulation.ClientData.from_clients_and_fn(
        client_ids=train_client_ids,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
test_data = tff.simulation.ClientData.from_clients_and_fn(
        client_ids=test_client_ids,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
</code></pre>
<p>Error: ---------------------------------------------------------------------------</p>
<pre><code>NameError                                 Traceback (most recent call last)
&lt;ipython-input-7-9d85508920a8&gt; in &lt;module&gt;
     15 # split client id into train and test clients
     16 client_ids = df[client_id_colname].unique()
---&gt; 17 train_client_ids = sample(client_ids.tolist(),500)
     18 test_client_ids = [x for x in client_ids if x not in train_client_ids]
     19 

NameError: name 'sample' is not defined
</code></pre>
",14689654,,730754,,44163.45278,44163.46667,Converting CSV file data into federated data,<python><pandas><tensorflow><tensorflow-federated><federated-learning>,2,0,,,,CC BY-SA 4.0
64970504,1,64996971,,44158.60833,,4,689,"<p>I am testing some algorithms in TensorFlow Federated (TFF). In this regard, I would like to test and compare them on the same federated dataset with different &quot;levels&quot; of data heterogeneity, i.e. non-IIDness.</p>
<p>Hence, I would like to know whether there is any way to control and tune the &quot;level&quot; of non-IIDness in a specific federated dataset, in an automatic or semi-automatic fashion, e.g. by means of TFF APIs or just traditional TF API (maybe inside the Dataset utils).</p>
<p>To be more practical: for instance, the EMNIST federated dataset provided by TFF has 3383 clients with each one of them having their handwritten characters. However, these local dataset seems to be quite balanced in terms of number of local examples and in terms of represented classes (all classes are, more or less, represented locally).
If I would like to have a federated dataset (e.g., starting by the TFF's EMNIST one) that is:</p>
<ul>
<li>Patologically non-IID, for example having clients that hold only one class out of N classes (always referring to a classification task). Is this the purpose of <code>tff.simulation.datasets.build_single_label_dataset</code> <a href=""https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets/build_single_label_dataset"" rel=""nofollow noreferrer"">documentation here</a>. If so, how should I use it from a federated dataset such as the ones already provided by TFF?;</li>
<li>Unbalanced in terms of the amount of local examples (e.g., one client has 10 examples, another one has 100 examples);</li>
<li>Both the possibilities;</li>
</ul>
<p>how should I proceed inside the TFF framework to prepare a federated dataset with those characteristics?</p>
<p>Should I do all the stuff by hand? Or do some of you have some advices to automate this process?</p>
<p>An additional question: in this paper <a href=""https://arxiv.org/pdf/1909.06335.pdf"" rel=""nofollow noreferrer"">&quot;Measuring the Effects of Non-Identical Data Distribution for Federated Visual Classification&quot;</a>, by Hsu et al., they exploit the Dirichlet distribution to synthesize a population of non-identical clients, and they use a <em>concentration parameter</em> to control the identicalness among clients. This seems an wasy-to-tune way to produce datasets with different levels of heterogeneity. Any advice about how to implement this strategy (or a similar one) inside the TFF framework, or just in TensorFlow (Python) considering a simple dataset such as the EMNIST, would be very useful too.</p>
<p>Thank you a lot.</p>
",10651544,,,,,44160.03194,TensorFlow Federated: How to tune non-IIDness in federated dataset?,<python><tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
65071335,1,,,44165.41181,,0,146,"<p>I would like to know if new version of TFF (0.17.0) is completely GPU ? because on old version, I find that TFF run CPU and GPU .</p>
",14253961,,,,,44165.80347,Tensorflow-federated 0.17.0 is totally GPU or GPU and CPU?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
65178310,1,65383575,,44172.35625,,1,418,"<p>I have been trying to implement this <a href=""https://www.mdpi.com/1424-8220/20/14/4048"" rel=""nofollow noreferrer"">paper</a> . Basically what I want to do is sum the per client loss and compare the same with previous epoch. Then for each constituent layer of the model compare the KL divergence between the weights of the server and the client model to get the layer specific parameter updates and then doing a softmax and  to decide whether an adaptive update or a normal FedAvg approach is needed.</p>
<p>The algorithm is as follows-
<a href=""https://i.sstatic.net/qDynd.png"" rel=""nofollow noreferrer"">FedMed</a></p>
<p>I tried to make use of the code <a href=""https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/examples/simple_fedavg/simple_fedavg_tff.py"" rel=""nofollow noreferrer"">here</a>  to build a custom federated avg process. I got the basic understanding that there are some tf.computations and some tff.computations which are involved. I get that I need to make changes in the orchestration logic in the run_one_round function and basically manipulate the client outputs to do adaptive averaging instead of the vanilla federated averaging. The <a href=""https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/examples/simple_fedavg/simple_fedavg_tf.py#L227"" rel=""nofollow noreferrer"">client_update</a>  tf.computation function  basically returns all the values that I need i.e the weights_delta (can be used for client based model weights), model_output(which can be used to calculate the loss).</p>
<p>But I am not sure where exactly I should make the changes.</p>
<pre class=""lang-py prettyprint-override""><code>@tff.federated_computation(federated_server_state_type,
                             federated_dataset_type)
  def run_one_round(server_state, federated_dataset):

    server_message = tff.federated_map(server_message_fn, server_state)
    server_message_at_client = tff.federated_broadcast(server_message)
  
  client_outputs = tff.federated_map(
        client_update_fn, (federated_dataset, server_message_at_client))

    weight_denom = client_outputs.client_weight

# todo
# instead of using tff.federated_mean I wish to do a adaptive aggregation based on the client_outputs.weights_delta and server_state model
    round_model_delta = tff.federated_mean(
        client_outputs.weights_delta, weight=weight_denom)


#client_outputs.weights_delta   has all the client model weights.
#client_outputs.client_weight has the number of examples per client.
#client_outputs.model_output has the output of the model per client example.
</code></pre>
<p>I want to make use of the server model weights using server_state object.
I want to calculate the KL divergence between the weights of server model and each client's model per layer. Then use a relative weight to aggregate the client weights instead of vanilla federated averaging.
Instead of using tff.federated_mean I wish to use a different strategy basically an adaptive one based on the algorithm above.
<br>
So I needed some suggestions on how to go about implementing this.
Basically what I want to do is :<br>
1)Sum all the values of client losses.<br>
2)Calculate the KL divergence per layerbasis of all the clients with server and then determine whether to use adaptive optimization or FedAvg. <br></p>
<p>Also is there a way to manipulate this value as a python value which will be helpful for debugging purposes( I tried to use tf.print but that was not helpful either). Thanks!</p>
",9336624,,9336624,,44175.27917,44185.78333,Customized aggregation algorithm for gradient updates in tensorflow federated,<tensorflow><tensorflow-federated>,1,2,,,,CC BY-SA 4.0
65273151,1,,,44178.29028,,1,805,"<p>I am using the example &quot;stateful_clients&quot; in tensorflow-federated examples. I want to use my pretrained model weights to initialize the model. I use the function <code>model.load_weights(init_weight)</code>. But it seems that it doesn't work. The validation accuracy in the first round is still low. How can I solve the problem?</p>
<pre><code>def tff_model_fn():
    &quot;&quot;&quot;Constructs a fully initialized model for use in federated averaging.&quot;&quot;&quot;
    keras_model = get_five_layers_cnn([28, 28, 1])
    keras_model.load_weights(init_weight)
    loss = tf.keras.losses.SparseCategoricalCrossentropy()
    return stateful_fedavg_tf.KerasModelWrapper(keras_model,
                                                test_data.element_spec, loss)
</code></pre>
",14816634,,,,,44294.72917,How to initialize the model with certain weights?,<tensorflow2.0><tensorflow-federated>,1,2,,,,CC BY-SA 4.0
65274580,1,65362436,,44178.43958,,0,204,"<p>Does TFF have any way to save and load optimizer state similar to model weights. For model weights there are <code>ModelWeights.assign_weights_to()</code> and <code>tff.learning.state_with_new_model_weights()</code> functions, Is there a way to save and load optimizer state especially when using server side optimizer other than SGD.</p>
<p>I could not find anything to save and load state of optimizer.</p>
",2150690,,,,,44186.95833,How to load ServerState.optimizer_state to continue training in Tensorflow Federated,<tensorflow-federated>,2,0,,,,CC BY-SA 4.0
65411118,1,65413886,,44187.63194,,2,142,"<p>I'm trying to use tensorflow-federated to select different subset of weights at the server and send them to the clients. The clients then would train and send back the trained weights. The server aggregates the results and starts a new communication round.</p>
<p>The main problem is that I cannot access the numpy version of the weights and therefore I don't know how to access a subset of them for each layer. I tried using tf.gather_nd and tf.tensor_scatter_nd_update to perform selection and update, but they only work for tensors, and not lists of tensors (as the server_state is in tensorflow-federated).</p>
<p>Does anyone have any hint to solve this problem? Is it even possible to send <em>different</em> weights to each client?</p>
",14366506,,14692,,44187.95972,44187.95972,Is it possible to send different subset of weights to different clients?,<tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
65434193,1,65441984,,44189.21042,,3,343,"<p>I ran my code for an emotion detection model using Tensorflow Federated simulation. My code work perfectly fine using CPUs only. However, I received this error when trying to run TFF with GPU.</p>
<pre><code>ValueError: Detected dataset reduce op in multi-GPU TFF simulation: `use_experimental_simulation_loop=True` for `tff.learning`; or use `for ... in iter(dataset)` for your own dataset iteration.Reduce op will be functional after b/159180073.
</code></pre>
<p>What is this error about and how can I fix it? I tried to search many places but found no answer.</p>
<p>Here is the call stack if it help. It is very long so I pasted into this link: <a href=""https://pastebin.com/b1R93gf1"" rel=""nofollow noreferrer"">https://pastebin.com/b1R93gf1</a></p>
<p>EDIT:</p>
<p>Here is the code containing iterative_process</p>
<pre><code>def startTraining(output_file):
    
    iterative_process = tff.learning.build_federated_averaging_process(
        model_fn,
        client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.01),
        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),
        use_experimental_simulation_loop=True
    )
    
    flstate = iterative_process.initialize()
    evaluation = tff.learning.build_federated_evaluation(model_fn)
    
    output_file.write(
        'round,available_users,loss,sparse_categorical_accuracy,val_loss,val_sparse_categorical_accuracy,test_loss,test_sparse_categorical_accuracy\n')
    curr_round_result = [0,0,100,0,100,0]
    min_val_loss = 100
    for round in range(1,ROUND_COUNT + 1):
        available_users = fetch_available_users_and_increase_time(ROUND_DURATION_AVERAGE + random.randint(-ROUND_DURATION_VARIATION, ROUND_DURATION_VARIATION + 1))
        if(len(available_users) == 0):
            write_to_file(curr_round_result)
            continue
        train_data = make_federated_data(available_users, 'train')
        flstate, metrics = iterative_process.next(flstate, train_data)
        val_data = make_federated_data(available_users, 'val')
        val_metrics = evaluation(flstate.model, val_data)
        
        curr_round_result[0] = round
        curr_round_result[1] = len(available_users)
        curr_round_result[2] = metrics['train']['loss']
        curr_round_result[3] = metrics['train']['sparse_categorical_accuracy']
        curr_round_result[4] = val_metrics['loss']
        curr_round_result[5] = val_metrics['sparse_categorical_accuracy']
        write_to_file(curr_round_result)
</code></pre>
<p>Here is the code for make_federated_data</p>
<pre><code>def make_federated_data(users, dataset_type):
    offset = 0
    if(dataset_type == 'val'):
        offset = train_size
    elif(dataset_type == 'test'):
        offset = train_size + val_size
    
    global LOADED_USER
    for id in users:
        if(id + offset not in LOADED_USER):
            LOADED_USER[id + offset] = getDatasetFromFilePath(filepaths[id + offset])

    return [
        LOADED_USER[id + offset]
        for id in users
    ]
        
</code></pre>
",5082124,,5082124,,44194.22361,44196.25972,"Multi-GPU TFF simulation errors ""Detected dataset reduce op in multi-GPU TFF simulation""",<tensorflow><gpu><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
65447819,1,,,44190.49306,,3,1265,"<p>I use TFF version 0.12.0
In order to compute performance of model, I would like to add (with accuracy ) sensitivity and specificity metrics,</p>
<pre><code>def specificity
...
def create_compiled_keras_model():
    ....

    model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.001, momentum =0.9), 
             loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=([tf.keras.metrics.BinaryAccuracy()], sensitivity, specificity))
    return model
</code></pre>
<p>I found this error:</p>
<pre><code>TypeError: Type of `metrics` argument not understood. Expected a list or dictionary, found: ([&lt;tensorflow.python.keras.metrics.BinaryAccuracy object at 0x7fb5b0711748&gt;], &lt;function sensitivity at 0x7fb6adf45e18&gt;, &lt;function specificity at 0x7fb5fdaf5f28&gt;)
</code></pre>
<p>So how can I add metrics  in Tensorflow federated
Thanks</p>
",14253961,,14253961,,44194.44097,44194.44097,Add other metrics to compute performance,<tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
65458032,1,,,44191.65486,,3,550,"<p>Why in the federated learning task, we don't split our dataset to train, test and validation, we make only train and test .</p>
",12682667,,,,,44191.91181,TFF: How split data of each client,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
65471612,1,65472745,,44192.99792,,2,330,"<p>I am following this code <a href=""https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL"" rel=""nofollow noreferrer"">https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL</a> and trying to run the file same_OR.py</p>
<p>I also place input file &quot;initial_model_parameters.txt&quot;  and data folder &quot;MNIST_data&quot; in same folder</p>
<pre><code>from __future__ import absolute_import, division, print_function
import tensorflow_federated as tff
import tensorflow.compat.v1 as tf
import numpy as np
import time
from scipy.special import comb, perm

import os

# tf.compat.v1.enable_v2_behavior()
# tf.compat.v1.enable_eager_execution()

# NUM_EXAMPLES_PER_USER = 1000
BATCH_SIZE = 100
NUM_AGENT = 5


def get_data_for_digit(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence

def get_data_for_digit_test(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples)):
        output_sequence.append({
            'x': np.array(source[0][all_samples[i]].flatten() / 255.0,
                          dtype=np.float32),
            'y': np.array(source[1][all_samples[i]], dtype=np.int32)})
    return output_sequence

def get_data_for_federated_agents(source, num):
    output_sequence = []

    Samples = []
    for digit in range(0, 10):
        samples = [i for i, d in enumerate(source[1]) if d == digit]
        samples = samples[0:5421]
        Samples.append(samples)

    all_samples = []
    for sample in Samples:
        for sample_index in range(int(num * (len(sample) / NUM_AGENT)), int((num + 1) * (len(sample) / NUM_AGENT))):
            all_samples.append(sample[sample_index])

    # all_samples = [i for i in range(int(num*(len(source[1])/NUM_AGENT)), int((num+1)*(len(source[1])/NUM_AGENT)))]

    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence


BATCH_TYPE = tff.NamedTupleType([
    ('x', tff.TensorType(tf.float32, [None, 784])),
    ('y', tff.TensorType(tf.int32, [None]))])

MODEL_TYPE = tff.NamedTupleType([
    ('weights', tff.TensorType(tf.float32, [784, 10])),
    ('bias', tff.TensorType(tf.float32, [10]))])


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)
def batch_loss(model, batch):
    predicted_y = tf.nn.softmax(tf.matmul(batch.x, model.weights) + model.bias)
    return -tf.reduce_mean(tf.reduce_sum(
        tf.one_hot(batch.y, 10) * tf.log(predicted_y), axis=[1]))


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)
def batch_train(initial_model, batch, learning_rate):
    # Define a group of model variables and set them to `initial_model`.
    model_vars = tff.utils.create_variables('v', MODEL_TYPE)
    init_model = tff.utils.assign(model_vars, initial_model)

    # Perform one step of gradient descent using loss from `batch_loss`.
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    with tf.control_dependencies([init_model]):
        train_model = optimizer.minimize(batch_loss(model_vars, batch))

    # Return the model vars after performing this gradient descent step.
    with tf.control_dependencies([train_model]):
        return tff.utils.identity(model_vars)


LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)


@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)
def local_train(initial_model, learning_rate, all_batches):
    # Mapping function to apply to each batch.
    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)
    def batch_fn(model, batch):
        return batch_train(model, batch, learning_rate)

    l = tff.sequence_reduce(all_batches, initial_model, batch_fn)
    return l


@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)
def local_eval(model, all_batches):
    #
    return tff.sequence_sum(
        tff.sequence_map(
            tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),
            all_batches))


SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER, all_equal=True)
CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)


@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)
def federated_eval(model, data):
    return tff.federated_mean(
        tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))


SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER, all_equal=True)


@tff.federated_computation(
    SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)
def federated_train(model, learning_rate, data):
    l = tff.federated_map(
        local_train,
        [tff.federated_broadcast(model),
         tff.federated_broadcast(learning_rate),
         data])
    return l
    # return tff.federated_mean()


def readTestImagesFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot;\t&quot;)
        for i in p:
            if i != &quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)

def readTestLabelsFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot; &quot;)
        for i in p:
            if i!=&quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)


def getParmsAndLearningRate(agent_no):
    f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    parm_local = []
    learning_rate_list = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0:784]
            learning_rate_list.append(float(line[784].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        else:
            weights_line = line[1:785]
            learning_rate_list.append(float(line[785].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        valid_weights_line = []
        for l in weights_line:
            w_list = l.split(&quot;\t&quot;)
            w_list = w_list[0:len(w_list) - 1]
            w_list = [float(i) for i in w_list]
            valid_weights_line.append(w_list)
        parm_local.append(valid_weights_line)
    f.close()

    f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    bias_local = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0]
        else:
            weights_line = line[1]
        b_list = weights_line.split(&quot;\t&quot;)
        b_list = b_list[0:len(b_list) - 1]
        b_list = [float(i) for i in b_list]
        bias_local.append(b_list)
    f.close()
    ret = {
        'weights': np.asarray(parm_local),
        'bias': np.asarray(bias_local),
        'learning_rate': np.asarray(learning_rate_list)
    }
    return ret


def train_with_gradient_and_valuation(agent_list, grad, bi, lr, distr_type):
    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial_g = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial_g = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()
    model_g = {
        'weights': w_initial_g,
        'bias': b_initial_g
    }
    for i in range(len(grad[0])):
        # i-&gt;è¿­ä»£è½®æ•°
        gradient_w = np.zeros([784, 10], dtype=np.float32)
        gradient_b = np.zeros([10], dtype=np.float32)
        for j in agent_list:
            gradient_w = np.add(np.multiply(grad[j][i], 1/len(agent_list)), gradient_w)
            gradient_b = np.add(np.multiply(bi[j][i], 1/len(agent_list)), gradient_b)
        model_g['weights'] = np.subtract(model_g['weights'], np.multiply(lr[0][i], gradient_w))
        model_g['bias'] = np.subtract(model_g['bias'], np.multiply(lr[0][i], gradient_b))

    test_images = readTestImagesFromFile(False)
    test_labels_onehot = readTestLabelsFromFile(False)
    m = np.dot(test_images, np.asarray(model_g['weights']))
    test_result = m + np.asarray(model_g['bias'])
    y = tf.nn.softmax(test_result)
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.arg_max(test_labels_onehot, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    return accuracy.numpy()


def remove_list_indexed(removed_ele, original_l, ll):
    new_original_l = []
    for i in original_l:
        new_original_l.append(i)
    for i in new_original_l:
        if i == removed_ele:
            new_original_l.remove(i)
    for i in range(len(ll)):
        if set(ll[i]) == set(new_original_l):
            return i
    return -1


def shapley_list_indexed(original_l, ll):
    for i in range(len(ll)):
        if set(ll[i]) == set(original_l):
            return i
    return -1


def PowerSetsBinary(items):
    N = len(items)
    set_all = []
    for i in range(2 ** N):
        combo = []
        for j in range(N):
            if (i &gt;&gt; j) % 2 == 1:
                combo.append(items[j])
        set_all.append(combo)
    return set_all


if __name__ == &quot;__main__&quot;:
    start_time = time.time()

    #data_num = np.asarray([5923,6742,5958,6131,5842])
    #agents_weights = np.divide(data_num, data_num.sum())

    for index in range(NUM_AGENT):
        f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(index)+&quot;.txt&quot;), &quot;w&quot;)
        f.close()
        f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(index) + &quot;.txt&quot;), &quot;w&quot;)
        f.close()
    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()

    DISTRIBUTION_TYPE = &quot;SAME&quot;

    federated_train_data_divide = None
    federated_train_data = None
    if DISTRIBUTION_TYPE == &quot;SAME&quot;:
        federated_train_data_divide = [get_data_for_federated_agents(mnist_train, d) for d in range(NUM_AGENT)]
        federated_train_data = federated_train_data_divide

    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()

    initial_model = {
        'weights': w_initial,
        'bias': b_initial
    }
    model = initial_model
    learning_rate = 0.1
    for round_num in range(50):
        local_models = federated_train(model, learning_rate, federated_train_data)
        print(&quot;learning rate: &quot;, learning_rate)
        #print(local_models[0][0])#ç¬¬0ä¸ªagentçš„weightsçŸ©é˜µ
        #print(local_models[0][1])#ç¬¬0ä¸ªagentçš„biasçŸ©é˜µ
        #print(len(local_models))
        for local_index in range(len(local_models)):
            f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(local_index)+&quot;.txt&quot;),&quot;a&quot;,encoding=&quot;utf-8&quot;)
            for i in local_models[local_index][0]:
                line = &quot;&quot;
                arr = list(i)
                for j in arr:
                    line += (str(j)+&quot;\t&quot;)
                print(line, file=f)
            print(&quot;***&quot;+str(learning_rate)+&quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
            f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(local_index) + &quot;.txt&quot;), &quot;a&quot;, encoding=&quot;utf-8&quot;)
            line = &quot;&quot;
            for i in local_models[local_index][1]:
                line += (str(i) + &quot;\t&quot;)
            print(line, file=f)
            print(&quot;***&quot; + str(learning_rate) + &quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
        m_w = np.zeros([784, 10], dtype=np.float32)
        m_b = np.zeros([10], dtype=np.float32)
        for local_model_index in range(len(local_models)):
            m_w = np.add(np.multiply(local_models[local_model_index][0], 1/NUM_AGENT), m_w)
            m_b = np.add(np.multiply(local_models[local_model_index][1], 1/NUM_AGENT), m_b)
            model = {
                'weights': m_w,
                'bias': m_b
            }
        learning_rate = learning_rate * 0.9
        loss = federated_eval(model, federated_train_data)
        print('round {}, loss={}'.format(round_num, loss))
        print(time.time()-start_time)

    gradient_weights = []
    gradient_biases = []
    gradient_lrs = []
    for ij in range(NUM_AGENT):
        model_ = getParmsAndLearningRate(ij)
        gradient_weights_local = []
        gradient_biases_local = []
        learning_rate_local = []

        for i in range(len(model_['learning_rate'])):
            if i == 0:
                gradient_weight = np.divide(np.subtract(initial_model['weights'], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(initial_model['bias'], model_['bias'][i]),
                                          model_['learning_rate'][i])
            else:
                gradient_weight = np.divide(np.subtract(model_['weights'][i - 1], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(model_['bias'][i - 1], model_['bias'][i]),
                                          model_['learning_rate'][i])
            gradient_weights_local.append(gradient_weight)
            gradient_biases_local.append(gradient_bias)
            learning_rate_local.append(model_['learning_rate'][i])

        gradient_weights.append(gradient_weights_local)
        gradient_biases.append(gradient_biases_local)
        gradient_lrs.append(learning_rate_local)

    all_sets = PowerSetsBinary([i for i in range(NUM_AGENT)])
    group_shapley_value = []
    for s in all_sets:
        group_shapley_value.append(
            train_with_gradient_and_valuation(s, gradient_weights, gradient_biases, gradient_lrs, DISTRIBUTION_TYPE))
        print(str(s)+&quot;\t&quot;+str(group_shapley_value[len(group_shapley_value)-1]))

    agent_shapley = []
    for index in range(NUM_AGENT):
        shapley = 0.0
        for j in all_sets:
            if index in j:
                remove_list_index = remove_list_indexed(index, j, all_sets)
                if remove_list_index != -1:
                    shapley += (group_shapley_value[shapley_list_indexed(j, all_sets)] - group_shapley_value[
                        remove_list_index]) / (comb(NUM_AGENT - 1, len(all_sets[remove_list_index])))
        agent_shapley.append(shapley)
    for ag_s in agent_shapley:
        print(ag_s)
    print(&quot;end_time&quot;, time.time()-start_time)
</code></pre>
<p>I installed tensor flow federated with this command</p>
<pre><code>pip install --upgrade tensorflow_federated
</code></pre>
<p>and this line is also underlied with red color</p>
<pre><code>import tensorflow.compat.v1 as tf
</code></pre>
<p>when i tried to execute go this error</p>
<blockquote>
<p>File &quot;same_OR.py&quot;, line 94, in 
BATCH_TYPE = tff.NamedTupleType([ AttributeError: module 'tensorflow_federated' has no attribute 'NamedTupleType'</p>
</blockquote>
<p>where is the problem? anyone can help?</p>
",7996402,,,,,44193.15069,'tensorflow_federated' has no attribute 'NamedTupleType,<python><tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
65481370,1,65484988,,44193.71806,,1,310,"<p>I am following this code <a href=""https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL"" rel=""nofollow noreferrer"">https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL</a> and trying to run the file same_OR.py</p>
<p>there is a problem in <code>import tensorflow.compat.v1</code> as tf its show that unable to import &quot; tensorflow.compat.v1&quot; File &quot;sameOR.py&quot;</p>
<pre><code>from __future__ import absolute_import, division, print_function
import tensorflow_federated as tff
import tensorflow.compat.v1 as tf
import numpy as np
import time
from scipy.special import comb, perm

import os

# tf.compat.v1.enable_v2_behavior()
# tf.compat.v1.enable_eager_execution()

# NUM_EXAMPLES_PER_USER = 1000
BATCH_SIZE = 100
NUM_AGENT = 5


def get_data_for_digit(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence

def get_data_for_digit_test(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples)):
        output_sequence.append({
            'x': np.array(source[0][all_samples[i]].flatten() / 255.0,
                          dtype=np.float32),
            'y': np.array(source[1][all_samples[i]], dtype=np.int32)})
    return output_sequence

def get_data_for_federated_agents(source, num):
    output_sequence = []

    Samples = []
    for digit in range(0, 10):
        samples = [i for i, d in enumerate(source[1]) if d == digit]
        samples = samples[0:5421]
        Samples.append(samples)

    all_samples = []
    for sample in Samples:
        for sample_index in range(int(num * (len(sample) / NUM_AGENT)), int((num + 1) * (len(sample) / NUM_AGENT))):
            all_samples.append(sample[sample_index])

    # all_samples = [i for i in range(int(num*(len(source[1])/NUM_AGENT)), int((num+1)*(len(source[1])/NUM_AGENT)))]

    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence


BATCH_TYPE = tff.NamedTupleType([
    ('x', tff.TensorType(tf.float32, [None, 784])),
    ('y', tff.TensorType(tf.int32, [None]))])

MODEL_TYPE = tff.NamedTupleType([
    ('weights', tff.TensorType(tf.float32, [784, 10])),
    ('bias', tff.TensorType(tf.float32, [10]))])


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)
def batch_loss(model, batch):
    predicted_y = tf.nn.softmax(tf.matmul(batch.x, model.weights) + model.bias)
    return -tf.reduce_mean(tf.reduce_sum(
        tf.one_hot(batch.y, 10) * tf.log(predicted_y), axis=[1]))


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)
def batch_train(initial_model, batch, learning_rate):
    # Define a group of model variables and set them to `initial_model`.
    model_vars = tff.utils.create_variables('v', MODEL_TYPE)
    init_model = tff.utils.assign(model_vars, initial_model)

    # Perform one step of gradient descent using loss from `batch_loss`.
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    with tf.control_dependencies([init_model]):
        train_model = optimizer.minimize(batch_loss(model_vars, batch))

    # Return the model vars after performing this gradient descent step.
    with tf.control_dependencies([train_model]):
        return tff.utils.identity(model_vars)


LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)


@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)
def local_train(initial_model, learning_rate, all_batches):
    # Mapping function to apply to each batch.
    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)
    def batch_fn(model, batch):
        return batch_train(model, batch, learning_rate)

    l = tff.sequence_reduce(all_batches, initial_model, batch_fn)
    return l


@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)
def local_eval(model, all_batches):
    #
    return tff.sequence_sum(
        tff.sequence_map(
            tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),
            all_batches))


SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER, all_equal=True)
CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)


@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)
def federated_eval(model, data):
    return tff.federated_mean(
        tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))


SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER, all_equal=True)


@tff.federated_computation(
    SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)
def federated_train(model, learning_rate, data):
    l = tff.federated_map(
        local_train,
        [tff.federated_broadcast(model),
         tff.federated_broadcast(learning_rate),
         data])
    return l
    # return tff.federated_mean()


def readTestImagesFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot;\t&quot;)
        for i in p:
            if i != &quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)

def readTestLabelsFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot; &quot;)
        for i in p:
            if i!=&quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)


def getParmsAndLearningRate(agent_no):
    f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    parm_local = []
    learning_rate_list = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0:784]
            learning_rate_list.append(float(line[784].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        else:
            weights_line = line[1:785]
            learning_rate_list.append(float(line[785].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        valid_weights_line = []
        for l in weights_line:
            w_list = l.split(&quot;\t&quot;)
            w_list = w_list[0:len(w_list) - 1]
            w_list = [float(i) for i in w_list]
            valid_weights_line.append(w_list)
        parm_local.append(valid_weights_line)
    f.close()

    f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    bias_local = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0]
        else:
            weights_line = line[1]
        b_list = weights_line.split(&quot;\t&quot;)
        b_list = b_list[0:len(b_list) - 1]
        b_list = [float(i) for i in b_list]
        bias_local.append(b_list)
    f.close()
    ret = {
        'weights': np.asarray(parm_local),
        'bias': np.asarray(bias_local),
        'learning_rate': np.asarray(learning_rate_list)
    }
    return ret


def train_with_gradient_and_valuation(agent_list, grad, bi, lr, distr_type):
    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial_g = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial_g = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()
    model_g = {
        'weights': w_initial_g,
        'bias': b_initial_g
    }
    for i in range(len(grad[0])):
        # i-&gt;è¿­ä»£è½®æ•°
        gradient_w = np.zeros([784, 10], dtype=np.float32)
        gradient_b = np.zeros([10], dtype=np.float32)
        for j in agent_list:
            gradient_w = np.add(np.multiply(grad[j][i], 1/len(agent_list)), gradient_w)
            gradient_b = np.add(np.multiply(bi[j][i], 1/len(agent_list)), gradient_b)
        model_g['weights'] = np.subtract(model_g['weights'], np.multiply(lr[0][i], gradient_w))
        model_g['bias'] = np.subtract(model_g['bias'], np.multiply(lr[0][i], gradient_b))

    test_images = readTestImagesFromFile(False)
    test_labels_onehot = readTestLabelsFromFile(False)
    m = np.dot(test_images, np.asarray(model_g['weights']))
    test_result = m + np.asarray(model_g['bias'])
    y = tf.nn.softmax(test_result)
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.arg_max(test_labels_onehot, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    return accuracy.numpy()


def remove_list_indexed(removed_ele, original_l, ll):
    new_original_l = []
    for i in original_l:
        new_original_l.append(i)
    for i in new_original_l:
        if i == removed_ele:
            new_original_l.remove(i)
    for i in range(len(ll)):
        if set(ll[i]) == set(new_original_l):
            return i
    return -1


def shapley_list_indexed(original_l, ll):
    for i in range(len(ll)):
        if set(ll[i]) == set(original_l):
            return i
    return -1


def PowerSetsBinary(items):
    N = len(items)
    set_all = []
    for i in range(2 ** N):
        combo = []
        for j in range(N):
            if (i &gt;&gt; j) % 2 == 1:
                combo.append(items[j])
        set_all.append(combo)
    return set_all


if __name__ == &quot;__main__&quot;:
    start_time = time.time()

    #data_num = np.asarray([5923,6742,5958,6131,5842])
    #agents_weights = np.divide(data_num, data_num.sum())

    for index in range(NUM_AGENT):
        f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(index)+&quot;.txt&quot;), &quot;w&quot;)
        f.close()
        f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(index) + &quot;.txt&quot;), &quot;w&quot;)
        f.close()
    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()

    DISTRIBUTION_TYPE = &quot;SAME&quot;

    federated_train_data_divide = None
    federated_train_data = None
    if DISTRIBUTION_TYPE == &quot;SAME&quot;:
        federated_train_data_divide = [get_data_for_federated_agents(mnist_train, d) for d in range(NUM_AGENT)]
        federated_train_data = federated_train_data_divide

    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()

    initial_model = {
        'weights': w_initial,
        'bias': b_initial
    }
    model = initial_model
    learning_rate = 0.1
    for round_num in range(50):
        local_models = federated_train(model, learning_rate, federated_train_data)
        print(&quot;learning rate: &quot;, learning_rate)
        #print(local_models[0][0])#ç¬¬0ä¸ªagentçš„weightsçŸ©é˜µ
        #print(local_models[0][1])#ç¬¬0ä¸ªagentçš„biasçŸ©é˜µ
        #print(len(local_models))
        for local_index in range(len(local_models)):
            f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(local_index)+&quot;.txt&quot;),&quot;a&quot;,encoding=&quot;utf-8&quot;)
            for i in local_models[local_index][0]:
                line = &quot;&quot;
                arr = list(i)
                for j in arr:
                    line += (str(j)+&quot;\t&quot;)
                print(line, file=f)
            print(&quot;***&quot;+str(learning_rate)+&quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
            f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(local_index) + &quot;.txt&quot;), &quot;a&quot;, encoding=&quot;utf-8&quot;)
            line = &quot;&quot;
            for i in local_models[local_index][1]:
                line += (str(i) + &quot;\t&quot;)
            print(line, file=f)
            print(&quot;***&quot; + str(learning_rate) + &quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
        m_w = np.zeros([784, 10], dtype=np.float32)
        m_b = np.zeros([10], dtype=np.float32)
        for local_model_index in range(len(local_models)):
            m_w = np.add(np.multiply(local_models[local_model_index][0], 1/NUM_AGENT), m_w)
            m_b = np.add(np.multiply(local_models[local_model_index][1], 1/NUM_AGENT), m_b)
            model = {
                'weights': m_w,
                'bias': m_b
            }
        learning_rate = learning_rate * 0.9
        loss = federated_eval(model, federated_train_data)
        print('round {}, loss={}'.format(round_num, loss))
        print(time.time()-start_time)

    gradient_weights = []
    gradient_biases = []
    gradient_lrs = []
    for ij in range(NUM_AGENT):
        model_ = getParmsAndLearningRate(ij)
        gradient_weights_local = []
        gradient_biases_local = []
        learning_rate_local = []

        for i in range(len(model_['learning_rate'])):
            if i == 0:
                gradient_weight = np.divide(np.subtract(initial_model['weights'], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(initial_model['bias'], model_['bias'][i]),
                                          model_['learning_rate'][i])
            else:
                gradient_weight = np.divide(np.subtract(model_['weights'][i - 1], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(model_['bias'][i - 1], model_['bias'][i]),
                                          model_['learning_rate'][i])
            gradient_weights_local.append(gradient_weight)
            gradient_biases_local.append(gradient_bias)
            learning_rate_local.append(model_['learning_rate'][i])

        gradient_weights.append(gradient_weights_local)
        gradient_biases.append(gradient_biases_local)
        gradient_lrs.append(learning_rate_local)

    all_sets = PowerSetsBinary([i for i in range(NUM_AGENT)])
    group_shapley_value = []
    for s in all_sets:
        group_shapley_value.append(
            train_with_gradient_and_valuation(s, gradient_weights, gradient_biases, gradient_lrs, DISTRIBUTION_TYPE))
        print(str(s)+&quot;\t&quot;+str(group_shapley_value[len(group_shapley_value)-1]))

    agent_shapley = []
    for index in range(NUM_AGENT):
        shapley = 0.0
        for j in all_sets:
            if index in j:
                remove_list_index = remove_list_indexed(index, j, all_sets)
                if remove_list_index != -1:
                    shapley += (group_shapley_value[shapley_list_indexed(j, all_sets)] - group_shapley_value[
                        remove_list_index]) / (comb(NUM_AGENT - 1, len(all_sets[remove_list_index])))
        agent_shapley.append(shapley)
    for ag_s in agent_shapley:
        print(ag_s)
    print(&quot;end_time&quot;, time.time()-start_time)
</code></pre>
<p>and these are list of errors .. can anyone help?</p>
<blockquote>
<p>Traceback (most recent call last):   File &quot;samOR.py&quot;, line 331, in

local_models = federated_train(model, learning_rate, federated_train_data)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\utils\function_utils.py&quot;,
line 561, in <strong>call</strong>
return context.invoke(self, arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 49, in
wrapped_f
return Retrying(*dargs, **dkw).call(f, *args, **kw)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 206, in
call
return attempt.get(self._wrap_exception)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 247, in
get
six.reraise(self.value[0], self.value[1], self.value[2])   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\six.py&quot;, line 703, in reraise
raise value   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 200, in
call
attempt = Attempt(fn(*args, **kwargs), attempt_number, False)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py&quot;,
line 213, in invoke
arg = event_loop.run_until_complete(   File &quot;C:\Users\Aw\Anaconda3\lib\asyncio\base_events.py&quot;, line 616, in
run_until_complete
return future.result()   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py&quot;,
line 99, in
_ingest
ingested = await asyncio.gather(*ingested)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py&quot;,
line 104, in _ingest
return await executor.create_value(val, type_spec)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 286, in create_value
return ReferenceResolvingExecutorValue(await   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py&quot;,
line 245, in create_value
await cached_value.target_future   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 110, in create_value
return await self._delegate(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 105, in _delegate
result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(<em>fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federating_executor.py&quot;,
line 383, in create_value
return await self._strategy.compute_federated_value(value, type_spec)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federated_resolving_strategy.py&quot;,
line 272, in compute_federated_value
result = await asyncio.gather(</em>[   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 281, in create_value
vals = await asyncio.gather(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 286, in create_value
return ReferenceResolvingExecutorValue(await   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py&quot;,
line 245, in create_value
await cached_value.target_future   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 110, in create_value
return await self._delegate(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 105, in _delegate
result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 464, in create_value
return EagerValue(value, self._tf_function_cache, type_spec, self._device)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 366, in <strong>init</strong>   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 326, in to_representation_for_type
raise TypeError( TypeError: The apparent type float32[10] of a tensor [-0.9900856  -0.9902875  -0.99910086 -0.9972545  -0.99561495
-0.99766624  -0.9964327  -0.99897027 -0.9960221  -0.99313617] does not match the expected type float32[784,10]. ERROR:asyncio:Task was
destroyed but it is pending! task: &lt;Task pending name='Task-7'
coro=&lt;trace..async_trace() running at
C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py:200&gt;
wait_for=&lt;Future pending
cb=[_chain_future.._call_check_cancel() at
C:\Users\Aw0000282F4DFE3D0&gt;()]&gt;</p>
</blockquote>
",7996402,,14161847,,44193.925,44193.94097,Size mismatch in tensorflow_federated eager executor,<python><tensorflow><machine-learning><tensorflow-federated><federated-learning>,1,2,,,,CC BY-SA 4.0
65491416,1,,,44194.47917,,2,116,"<p>I use TFF 0.12.0 and image dataset for dog and cat(2 labels), If I test with VGG16, Ifind accuracy 0.9 but If I change to ResNet50, accuracy decrease to 0.4, Here is what I write:</p>
<pre class=""lang-py prettyprint-override""><code>def create_compiled_keras_model():
   
    baseModel = tf.keras.applications.ResNet50(include_top=False, weights=&quot;imagenet&quot;, input_tensor=tf.keras.Input(shape=(224, 224, 3)))

   resnet_output = baseModel.output
   layer1 = tf.keras.layers.GlobalAveragePooling2D()(resnet_output)
   layer2 = tf.keras.layers.Flatten(name=&quot;flatten&quot;)(layer1)
   layer2 = tf.keras.layers.Dense(units=256, name='nonlinear', activation=&quot;relu&quot;)(layer2)
   dropout_layer = tf.keras.layers.Dropout(0.5)(layer2)
   model_output = tf.keras.layers.Dense(2, activation=&quot;softmax&quot;)(dropout_layer)
   model = tf.keras.Model(inputs=baseModel.input, outputs=model_output)
   for layer in baseModel.layers:
       layer.trainable = False
   model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.001, momentum =0.9), 
            loss=tf.keras.losses.CategoricalCrossentropy(),
             metrics=([tf.keras.metrics.CategoricalAccuracy()]))
   return model

def model_fn():
   keras_model = create_compiled_keras_model()
   return tff.learning.from_compiled_keras_model(keras_model, sample_batch) 

iterative_process = tff.learning.build_federated_averaging_process(model_fn, server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),client_weight_fn=None)

state = iterative_process.initialize()
evaluation = tff.learning.build_federated_evaluation(model_fn)
</code></pre>
<p>but accuracy does not exceed 0.46 even after 100 rounds. here is a part of the result :</p>
<pre class=""lang-py prettyprint-override""><code>round  1, metrics=&lt;categorical_accuracy=0.500249981880188,loss=0.7735000252723694,keras_training_time_client_sum_sec=0.0&gt;
round  2, metrics=&lt;categorical_accuracy=0.47187501192092896,loss=0.7735000252723694,keras_training_time_client_sum_sec=0.0&gt;
....
round 99, metrics=&lt;categorical_accuracy=0.4632812440395355,loss=0.7622881531715393,keras_training_time_client_sum_sec=0.0&gt;
round 100, metrics=&lt;categorical_accuracy=0.46015626192092896,loss=0.7622881531748393,keras_training_time_client_sum_sec=0.0&gt;
</code></pre>
<p>Help Please!!!</p>
",14253961,,14692,,44416.58472,44416.58472,Why Resnet50 with TFF does not give good results,<tensorflow-federated><federated-learning>,0,3,,,,CC BY-SA 4.0
75171118,1,,,44945.45069,,0,46,"<p>I got &quot;module '0b1a516c7ccf3157373118bcf0f434168745c8a4' has no attribute 'entropy_decode_index' error after a clean intall of tensorflow federated (TFF) on Ubuntu 22.04. System: AMD 6900HS, Nvidia3050ti. The first &quot;import tensorflow_federated&quot; line fails.</p>
<p>There is not even a single entry on google concerning this error message and I am shocked.</p>
<p>The detailed error message is:
File &quot;/home/egosis/venv/lib/python3.9/site-packages/tensorflow_compression/python/ops/<strong>init</strong>.py&quot;, line 17, in </p>
<pre><code>from tensorflow_compression.python.ops.gen_ops import *
</code></pre>
<p>AttributeError: module '0b1a516c7ccf3157373118bcf0f434168745c8a4' has no attribute 'entropy_decode_index'</p>
<p>Every answer is gladly appreciated.</p>
<p>I tried installing TFF v0.46.0, v0.45.0 and v0.44.0 of tff but it did not help.</p>
",21042714,,,,,44945.45069,"How to resolve ""module has no attribute 'entropy_decode_index' error in ubuntu for TFF?",<tensorflow><tensorflow-federated><federated-learning>,0,3,,,,CC BY-SA 4.0
75205546,1,,,44949.1625,,0,51,"<p>I have two PCs that want to share tensorflow models &quot;hdf5 format&quot; in a federated learning manner via a PostgresSQL database.</p>
<p>The models will be trained locally on both machines, and then transferred to the database along with the training history. The transfer will be done for multiple cycles in a specific schedule.</p>
<p>I searched online for solutions to transfer the files via PostgresSQL database, but all solutions suggest a tabulated data transfer, e.g. csv file data, not arbitrary file extensions, like hdf5.</p>
<p>Can anyone help me, even with a roadmap, for the solution?
If any tutorials or examples for similar scenarios would be suggested, that would be also appreciated.</p>
<p>Thanks for your help in advance!</p>
",10797562,,10797562,,44950.08889,44950.08889,Transferring models between two PCs via PostgresSQL database,<postgresql><tensorflow-federated><federated-learning>,0,2,,,,CC BY-SA 4.0
75409716,1,,,44967.42917,,0,142,"<p>TypeError                                 Traceback (most recent call last)
 in 
5 import numpy as np
6 import tensorflow as tf
----&gt; 7 import tensorflow_federated as tff</p>
<p>14 frames
/usr/lib/python3.8/typing.py in _type_check(arg, msg, is_argument)
147         return arg
148     if not callable(arg):
--&gt; 149         raise TypeError(f&quot;{msg} Got {arg!r:.100}.&quot;)
150     return arg
151</p>
<p>TypeError: Callable[[arg, ...], result]: each arg must be a type. Got Ellipsis.</p>
<p>I'm getting this error while trying to import tensorflow_federated in Colab.</p>
<p>I have tried installing lower compatible versions of tensorflow and tensorflow_federated, but nothing works. Can someone else also faced this problem? and Do anyone know how to fix it?</p>
",13960884,,,,,45069.04028,compatibility issues for Tensorflow federated in Google colab,<tensorflow><google-colaboratory><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
75614269,1,,,44987.44167,,0,65,"<p>I have a tensorflow federated model  as seen below:</p>
<pre><code>state = iterative_process.initialize()
</code></pre>
<p>where state is the state of the server encapsulating the model.</p>
<p>Printing it we have:</p>
<pre><code>ServerState(model=ModelWeights(trainable=[array([[ 0.01307054,  0.05205479,  0.16566667, ...,
       [0.],
       [0.],
       [0.],
       [0.]], dtype=float32), array([0.], dtype=float32)]), ..., ('zeroed_count_agg', ())]), model_broadcast_state=())
</code></pre>
<p>which is the server state.<br />
I can access the model's parameters with:</p>
<pre><code>state.model.trainable
</code></pre>
<p>which is a list.<br />
What i would like to do is save this and reload it in the future.<br />
Ideally i would like to update a future state of the process (each federated iteration returns a new state) with this model.<br />
Any ideas?</p>
<p>P.S. i also found <a href=""https://stackoverflow.com/questions/58785825/how-to-save-model-in-tensorflow-federated"">this</a> SO thread but everything there seems to be deprecated.</p>
",19336534,,19336534,,44987.45417,44987.50903,Saving a tensorflow federated model,<tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
75636817,1,,,44989.6625,,0,125,"<p>I tried everything, even the below commands, but nothing is working!</p>
<pre><code>!pip install tensorflow==1.14
!pip install tensorflow-federated==0.4.0
# The latest version of tensorflow-federated is not working with the colab python version.
!pip install --quiet --upgrade nest-asyncio
</code></pre>
<p>Can somebody explain it or give the steps from the beginning on how to use tensorflow-federated without any errors on Google Colab only?</p>
",16620222,,16620222,,44989.66319,45111.78472,How to use tensorflow_federated in Google Colab?,<python><tensorflow><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
75800724,1,,,45006.48681,,0,741,"<p>I am trying to install tensorflow federated using command: pip install tensorflow_federated
The installation completes successfuly, but when I am import the package using command
import tensorflow_federated as tff
I get below error:</p>
<p>Traceback (most recent call last):
File &quot;&quot;, line 1, in 
File &quot;/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/<strong>init</strong>.py&quot;, line 25, in 
from tensorflow_federated.python import *
File &quot;/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/<strong>init</strong>.py&quot;, line 25, in 
from tensorflow_federated.python.core import *
File &quot;/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/core/<strong>init</strong>.py&quot;, line 21, in 
from tensorflow_federated.python.core import utils
File &quot;/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/core/utils/<strong>init</strong>.py&quot;, line 26, in 
from tensorflow_federated.python.core.utils.computation_utils import IterativeProcess
File &quot;/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/core/utils/computation_utils.py&quot;, line 21, in 
from tensorflow_federated.python.core import api as tff
File &quot;/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/core/api/<strong>init</strong>.py&quot;, line 22, in 
from tensorflow_federated.python.core.api.computation_types import FederatedType
File &quot;/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/core/api/computation_types.py&quot;, line 26, in 
from tensorflow_federated.python.common_libs import anonymous_tuple
File &quot;/home/dgholam/.local/lib/python3.10/site-packages/tensorflow_federated/python/common_libs/anonymous_tuple.py&quot;, line 28, in 
nest = tf.contrib.framework.nest
AttributeError: module 'tensorflow' has no attribute 'contrib'</p>
<p>I will appreciate to you, if you can help me with this issue.
Python: 3.10.2
tensorflow-federated  0.1.0
tensorflow  2.11.0</p>
<p>I tried to install it with python 3.9.2 and 3.9.7 but I got another errors during installation. It seems tensorflow-federated needs tensorflow 2 and in tensorflow 2 there no contrib anymore. (contrib belongs to tensforlow 1.x.x)</p>
",10238608,,,,,45393.48611,Error when I am installing TensorFlow Federated Learning. (error: module 'tensorflow' has no attribute 'contrib'),<tensorflow><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
75874823,1,,,45014.35278,,0,124,"<p>I've been playing for some time with FL + DP for my thesis.
I am using TFF in case someone is wondering.</p>
<p>I load my data as:</p>
<pre><code>train_data = tff.simulation.datasets.ClientData.from_clients_and_fn(
        client_ids=train_data_paths,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )

test_data = tff.simulation.datasets.ClientData.from_clients_and_fn(
        client_ids=test_data_paths,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
</code></pre>
<p>And I set Q as sampling ratio</p>
<pre><code>def get_training_Q(Q):
    size = int(Q*len(train_data.client_ids))
    sampled_clients = np.random.choice(
            train_data.client_ids,
            size=size,
            replace=False)
    
    sampled_train_data = [
            train_data.create_tf_dataset_for_client(client)
            for client in sampled_clients
        ]
    
    return sampled_train_data

def get_test_Q(Q):
    size = int(Q*len(test_data.client_ids))
    sampled_clients = np.random.choice(
            test_data.client_ids,
            size=size,
            replace=False)
    
    ids = [_id.split('/')[-3] for _id in sampled_clients]
    print(ids)
    
    sampled_test_data = [
            test_data.create_tf_dataset_for_client(client)
            for client in sampled_clients
        ]
    return sampled_test_data
</code></pre>
<p>Given this I define my DP parameters:</p>
<ul>
<li>Noise = 0.5</li>
<li>Q = 0.015</li>
<li>n_clients_per_round = int(Q*len(train_data.client_ids))</li>
</ul>
<p>I define my aggregation factory:</p>
<p><code>aggregation_factory = tff.learning.model_update_aggregator.dp_aggregator(noise_multiplier=Noise,clients_per_round=n_clients_per_round)</code></p>
<p>And the iterative process:</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(
    model_tff,
    client_optimizer_fn=lambda: keras.optimizers.Adam(),
    server_optimizer_fn=lambda: keras.optimizers.SGD(learning_rate=1),
    model_update_aggregation_factory=aggregation_factory,
    use_experimental_simulation_loop=True)


evaluation = tff.learning.build_federated_evaluation(model_tff,use_experimental_simulation_loop=True)
</code></pre>
<p>My training happens in rounds as follows:</p>
<pre><code>train_set = get_training_Q(Q)
test_set = get_test_Q(Q)

state, metrics = iterative_process.next(state, train_set)
test_metrics = evaluation(state.model, test_set)    
</code></pre>
<p>The main issue here is that the training metrics looks good and the model learns at a slow but steady rate but <strong>the test metrics are horrendous</strong>. It looks like the model is overfitting while using DP (known to be a regulariser). I am absolutely confused.
<a href=""https://i.sstatic.net/NiqxZ.png"" rel=""nofollow noreferrer"">performance plot</a></p>
<p>I've tried several changes in the noise and learning structure so as modifying the internal rounds of training and the batch size.
I started with a model that trains well without DP to later add DP.</p>
<p>Any ideas why this is happening?</p>
<p>Best regards,</p>
",19726243,,19726243,,45014.35764,45021.45833,Federated learning with Differential Privacy - Bad test performance,<python><privacy><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
65498670,1,65526829,,44194.87222,,2,350,"<p>I am following this code <a href=""https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL"" rel=""nofollow noreferrer"">https://github.com/BUAA-BDA/FedShapley/tree/master/TensorflowFL</a> and trying to run the file <code>same_OR.py</code> with some required changes</p>
<pre><code>from __future__ import absolute_import, division, print_function
import tensorflow_federated as tff
import tensorflow.compat.v1 as tf
import numpy as np
import time
from scipy.special import comb, perm
import collections
import os

# tf.compat.v1.enable_v2_behavior()
# tf.compat.v1.enable_eager_execution()

# NUM_EXAMPLES_PER_USER = 1000
BATCH_SIZE = 100
NUM_AGENT = 5


def get_data_for_digit(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence

def get_data_for_digit_test(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples)):
        output_sequence.append({
            'x': np.array(source[0][all_samples[i]].flatten() / 255.0,
                          dtype=np.float32),
            'y': np.array(source[1][all_samples[i]], dtype=np.int32)})
    return output_sequence

def get_data_for_federated_agents(source, num):
    output_sequence = []

    Samples = []
    for digit in range(0, 10):
        samples = [i for i, d in enumerate(source[1]) if d == digit]
        samples = samples[0:5421]
        Samples.append(samples)

    all_samples = []
    for sample in Samples:
        for sample_index in range(int(num * (len(sample) / NUM_AGENT)), int((num + 1) * (len(sample) / NUM_AGENT))):
            all_samples.append(sample[sample_index])

    # all_samples = [i for i in range(int(num*(len(source[1])/NUM_AGENT)), int((num+1)*(len(source[1])/NUM_AGENT)))]

    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence


BATCH_TYPE = tff.StructType([
    ('x', tff.TensorType(tf.float32, [None, 784])),
    ('y', tff.TensorType(tf.int32, [None]))])

MODEL_TYPE = tff.StructType([
    ('weights', tff.TensorType(tf.float32, [784, 10])),
    ('bias', tff.TensorType(tf.float32, [10]))])


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)
def batch_loss(model, batch):
    predicted_y = tf.nn.softmax(tf.matmul(batch.x, model.weights) + model.bias)
    return -tf.reduce_mean(tf.reduce_sum(
        tf.one_hot(batch.y, 10) * tf.log(predicted_y), axis=[1]))


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)
def batch_train(initial_model, batch, learning_rate):
    # Define a group of model variables and set them to `initial_model`.
    model_vars = tff.utils.create_variables('v', MODEL_TYPE)
    init_model = tff.utils.assign(model_vars, initial_model)

    # Perform one step of gradient descent using loss from `batch_loss`.
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    with tf.control_dependencies([init_model]):
        train_model = optimizer.minimize(batch_loss(model_vars, batch))

    # Return the model vars after performing this gradient descent step.
    with tf.control_dependencies([train_model]):
        return tff.utils.identity(model_vars)


LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)


@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)
def local_train(initial_model, learning_rate, all_batches):
    # Mapping function to apply to each batch.
    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)
    def batch_fn(model, batch):
        return batch_train(model, batch, learning_rate)

    l = tff.sequence_reduce(all_batches, initial_model, batch_fn)
    return l


@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)
def local_eval(model, all_batches):
    #
    return tff.sequence_sum(
        tff.sequence_map(
            tff.federated_computation(lambda b: batch_loss(model, b), BATCH_TYPE),
            all_batches))


SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER, all_equal=True)
CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)


@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)
def federated_eval(model, data):
    return tff.federated_mean(
        tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))


SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER, all_equal=True)


@tff.federated_computation(
    SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)
def federated_train(model, learning_rate, data):
    l = tff.federated_map(
        local_train,
        [tff.federated_broadcast(model),
         tff.federated_broadcast(learning_rate),
         data])
    return l
    # return tff.federated_mean()


def readTestImagesFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot;\t&quot;)
        for i in p:
            if i != &quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)

def readTestLabelsFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__), &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot; &quot;)
        for i in p:
            if i!=&quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)


def getParmsAndLearningRate(agent_no):
    f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    parm_local = []
    learning_rate_list = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0:784]
            learning_rate_list.append(float(line[784].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        else:
            weights_line = line[1:785]
            learning_rate_list.append(float(line[785].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        valid_weights_line = []
        for l in weights_line:
            w_list = l.split(&quot;\t&quot;)
            w_list = w_list[0:len(w_list) - 1]
            w_list = [float(i) for i in w_list]
            valid_weights_line.append(w_list)
        parm_local.append(valid_weights_line)
    f.close()

    f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(&quot;***\n--------------------------------------------------&quot;)
    bias_local = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0]
        else:
            weights_line = line[1]
        b_list = weights_line.split(&quot;\t&quot;)
        b_list = b_list[0:len(b_list) - 1]
        b_list = [float(i) for i in b_list]
        bias_local.append(b_list)
    f.close()
    ret = {
        'weights': np.asarray(parm_local),
        'bias': np.asarray(bias_local),
        'learning_rate': np.asarray(learning_rate_list)
    }
    return ret


def train_with_gradient_and_valuation(agent_list, grad, bi, lr, distr_type):
    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial_g = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial_g = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()
    model_g = {
        'weights': w_initial_g,
        'bias': b_initial_g
    }
    for i in range(len(grad[0])):
        # i-&gt;è¿­ä»£è½®æ•°
        gradient_w = np.zeros([784, 10], dtype=np.float32)
        gradient_b = np.zeros([10], dtype=np.float32)
        for j in agent_list:
            gradient_w = np.add(np.multiply(grad[j][i], 1/len(agent_list)), gradient_w)
            gradient_b = np.add(np.multiply(bi[j][i], 1/len(agent_list)), gradient_b)
        model_g['weights'] = np.subtract(model_g['weights'], np.multiply(lr[0][i], gradient_w))
        model_g['bias'] = np.subtract(model_g['bias'], np.multiply(lr[0][i], gradient_b))

    test_images = readTestImagesFromFile(False)
    test_labels_onehot = readTestLabelsFromFile(False)
    m = np.dot(test_images, np.asarray(model_g['weights']))
    test_result = m + np.asarray(model_g['bias'])
    y = tf.nn.softmax(test_result)
    correct_prediction = tf.equal(tf.argmax(y, 1), tf.arg_max(test_labels_onehot, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    return accuracy.numpy()


def remove_list_indexed(removed_ele, original_l, ll):
    new_original_l = []
    for i in original_l:
        new_original_l.append(i)
    for i in new_original_l:
        if i == removed_ele:
            new_original_l.remove(i)
    for i in range(len(ll)):
        if set(ll[i]) == set(new_original_l):
            return i
    return -1


def shapley_list_indexed(original_l, ll):
    for i in range(len(ll)):
        if set(ll[i]) == set(original_l):
            return i
    return -1


def PowerSetsBinary(items):
    N = len(items)
    set_all = []
    for i in range(2 ** N):
        combo = []
        for j in range(N):
            if (i &gt;&gt; j) % 2 == 1:
                combo.append(items[j])
        set_all.append(combo)
    return set_all


if __name__ == &quot;__main__&quot;:
    start_time = time.time()

    #data_num = np.asarray([5923,6742,5958,6131,5842])
    #agents_weights = np.divide(data_num, data_num.sum())

    for index in range(NUM_AGENT):
        f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(index)+&quot;.txt&quot;), &quot;w&quot;)
        f.close()
        f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(index) + &quot;.txt&quot;), &quot;w&quot;)
        f.close()
    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()

    DISTRIBUTION_TYPE = &quot;SAME&quot;

    federated_train_data_divide = None
    federated_train_data = None
    if DISTRIBUTION_TYPE == &quot;SAME&quot;:
        federated_train_data_divide = [get_data_for_federated_agents(mnist_train, d) for d in range(NUM_AGENT)]
        federated_train_data = federated_train_data_divide

    f_ini_p = open(os.path.join(os.path.dirname(__file__), &quot;initial_model_parameters.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()

    initial_model =  collections.OrderedDict(
        'weights': w_initial 
        'bias':b_initial)
    
    model = initial_model
    learning_rate = 0.1
    for round_num in range(50):
        local_models = federated_train(model, learning_rate, federated_train_data)
        print(&quot;learning rate: &quot;, learning_rate)
        #print(local_models[0][0])#ç¬¬0ä¸ªagentçš„weightsçŸ©é˜µ
        #print(local_models[0][1])#ç¬¬0ä¸ªagentçš„biasçŸ©é˜µ
        #print(len(local_models))
        for local_index in range(len(local_models)):
            f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot;+str(local_index)+&quot;.txt&quot;),&quot;a&quot;,encoding=&quot;utf-8&quot;)
            for i in local_models[local_index][0]:
                line = &quot;&quot;
                arr = list(i)
                for j in arr:
                    line += (str(j)+&quot;\t&quot;)
                print(line, file=f)
            print(&quot;***&quot;+str(learning_rate)+&quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
            f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; + str(local_index) + &quot;.txt&quot;), &quot;a&quot;, encoding=&quot;utf-8&quot;)
            line = &quot;&quot;
            for i in local_models[local_index][1]:
                line += (str(i) + &quot;\t&quot;)
            print(line, file=f)
            print(&quot;***&quot; + str(learning_rate) + &quot;***&quot;,file=f)
            print(&quot;-&quot;*50,file=f)
            f.close()
        m_w = np.zeros([784, 10], dtype=np.float32)
        m_b = np.zeros([10], dtype=np.float32)
        for local_model_index in range(len(local_models)):
            m_w = np.add(np.multiply(local_models[local_model_index][0], 1/NUM_AGENT), m_w)
            m_b = np.add(np.multiply(local_models[local_model_index][1], 1/NUM_AGENT), m_b)
            model = {
                'weights': m_w,
                'bias': m_b
            }
        learning_rate = learning_rate * 0.9
        loss = federated_eval(model, federated_train_data)
        print('round {}, loss={}'.format(round_num, loss))
        print(time.time()-start_time)

    gradient_weights = []
    gradient_biases = []
    gradient_lrs = []
    for ij in range(NUM_AGENT):
        model_ = getParmsAndLearningRate(ij)
        gradient_weights_local = []
        gradient_biases_local = []
        learning_rate_local = []

        for i in range(len(model_['learning_rate'])):
            if i == 0:
                gradient_weight = np.divide(np.subtract(initial_model['weights'], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(initial_model['bias'], model_['bias'][i]),
                                          model_['learning_rate'][i])
            else:
                gradient_weight = np.divide(np.subtract(model_['weights'][i - 1], model_['weights'][i]),
                                            model_['learning_rate'][i])
                gradient_bias = np.divide(np.subtract(model_['bias'][i - 1], model_['bias'][i]),
                                          model_['learning_rate'][i])
            gradient_weights_local.append(gradient_weight)
            gradient_biases_local.append(gradient_bias)
            learning_rate_local.append(model_['learning_rate'][i])

        gradient_weights.append(gradient_weights_local)
        gradient_biases.append(gradient_biases_local)
        gradient_lrs.append(learning_rate_local)

    all_sets = PowerSetsBinary([i for i in range(NUM_AGENT)])
    group_shapley_value = []
    for s in all_sets:
        group_shapley_value.append(
            train_with_gradient_and_valuation(s, gradient_weights, gradient_biases, gradient_lrs, DISTRIBUTION_TYPE))
        print(str(s)+&quot;\t&quot;+str(group_shapley_value[len(group_shapley_value)-1]))

    agent_shapley = []
    for index in range(NUM_AGENT):
        shapley = 0.0
        for j in all_sets:
            if index in j:
                remove_list_index = remove_list_indexed(index, j, all_sets)
                if remove_list_index != -1:
                    shapley += (group_shapley_value[shapley_list_indexed(j, all_sets)] - group_shapley_value[
                        remove_list_index]) / (comb(NUM_AGENT - 1, len(all_sets[remove_list_index])))
        agent_shapley.append(shapley)
    for ag_s in agent_shapley:
        print(ag_s)
    print(&quot;end_time&quot;, time.time()-start_time)
</code></pre>
<pre><code>File &quot;SameOR-elb.py&quot;, line 352, in &lt;module&gt;
    local_models = federated_train(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\utils\function_utils.py&quot;,
line 561, in __call__
    return context.invoke(self, arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 49, in
wrapped_f
    return Retrying(*dargs, **dkw).call(f, *args, **kw)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 206, in
call
    return attempt.get(self._wrap_exception)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 247, in
get
    six.reraise(self.value[0], self.value[1], self.value[2])   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\six.py&quot;, line 703, in reraise
    raise value   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\retrying.py&quot;, line 200, in
call
    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py&quot;,
line 217, in invoke
    return event_loop.run_until_complete(   File &quot;C:\Users\Aw\Anaconda3\lib\asyncio\base_events.py&quot;, line 616, in
run_until_complete
    return future.result()   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
    return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\execution_context.py&quot;,
line 123, in _invoke
    result = await executor.create_call(comp, arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 343, in create_call
    return await comp_repr.invoke(self, arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 155, in invoke
    return await executor._evaluate(comp_lambda.result, new_scope)  # pylint: disable=protected-access   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 513, in _evaluate
    return await self._evaluate_block(comp, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 477, in _evaluate_block
    value = await self._evaluate(loc.value, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 507, in _evaluate
    return await self._evaluate_call(comp, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 446, in _evaluate_call
    return await self.create_call(func, arg=arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 339, in create_call
    return ReferenceResolvingExecutorValue(await   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py&quot;,
line 281, in create_call
    target_value = await cached_value.target_future   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 120, in create_call
    return await self._delegate(self._target_executor.create_call(comp, arg))   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 105, in _delegate
    result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
    return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federating_executor.py&quot;,
line 445, in create_call
    return await self._strategy.compute_federated_intrinsic(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federating_executor.py&quot;,
line 139, in compute_federated_intrinsic
    return await fn(arg)  # pylint: disable=not-callable   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federated_resolving_strategy.py&quot;,
line 453, in compute_federated_map
    return await self._map(arg, all_equal=False)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\federated_resolving_strategy.py&quot;,
line 320, in _map
    results = await asyncio.gather(*[   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 343, in create_call
    return await comp_repr.invoke(self, arg)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 155, in invoke
    return await executor._evaluate(comp_lambda.result, new_scope)  # pylint: disable=protected-access   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 513, in _evaluate
    return await self._evaluate_block(comp, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 477, in _evaluate_block
    value = await self._evaluate(loc.value, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 507, in _evaluate
    return await self._evaluate_call(comp, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 445, in _evaluate_call
    func, arg = await asyncio.gather(func, get_arg())   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 501, in _evaluate
    return await self._evaluate_to_delegate(comp, scope)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\reference_resolving_executor.py&quot;,
line 410, in _evaluate_to_delegate
    await self._target_executor.create_value(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\caching_executor.py&quot;,
line 245, in create_value
    await cached_value.target_future   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 110, in create_value
    return await self._delegate(   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\thread_delegating_executor.py&quot;,
line 105, in _delegate
    result_value = await _delegate_with_trace_ctx(coro, self._event_loop)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 388, in _wrapped
    return await coro   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\common_libs\tracing.py&quot;,
line 200, in async_trace
    result = await fn(*fn_args, **fn_kwargs)   File &quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 464, in create_value
    return EagerValue(value, self._tf_function_cache, type_spec, self._device)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 366, in __init__
    self._value = to_representation_for_type(value, tf_function_cache,   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 287, in to_representation_for_type
    embedded_fn = embed_tensorflow_computation(value, type_spec, device)   File
&quot;C:\Users\Aw\Anaconda3\lib\site-packages\tensorflow_federated\python\core\impl\executors\eager_tf_executor.py&quot;,
line 153, in embed_tensorflow_computation
    raise TypeError('Expected a TensorFlow computation, found {}.'.format( TypeError: Expected a TensorFlow computation, found
intrinsic.
</code></pre>
<p>I got these errors. I need suggestions.</p>
<p>I am using  <code>tf 2.2.1</code></p>
<p>Python 3.8.3 version</p>
",7996402,,,user15801675,44425.17778,44425.17778,"Expected a TensorFlow computation, found intrinsic",<python><tensorflow><machine-learning><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
65553960,1,,,44199.80764,,2,583,"<p>My problem is a continue to this question <a href=""https://stackoverflow.com/questions/58965488/how-to-create-federated-dataset-from-a-csv-file"">How to create federated dataset from a CSV file?</a></p>
<p>i manage to load a federated dataset from a given csv file and load both the train and the test data.</p>
<p>My question now is how to reproduce a working example to build an iterative process that performs a custom federated averaging on this data.</p>
<p>Here is my code but it's not working:</p>
<pre><code>import os

import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_federated as tff
from absl import app
from tensorflow.keras import layers

from src.main import Parameters


def main(args):
    working_dir = &quot;D:/User/Documents/GitHub/TriaBaseMLBackup/input/fakehdfs/nms/ystr=2016/ymstr=1/ymdstr=26&quot;
    client_id_colname = 'counter'
    SHUFFLE_BUFFER = 1000
    NUM_EPOCHS = 1

    for root, dirs, files in os.walk(working_dir):
        file_list = []

        for filename in files:
            if filename.endswith('.csv'):
                file_list.append(os.path.join(root, filename))
        df_list = []
        for file in file_list:
            df = pd.read_csv(file, delimiter=&quot;|&quot;, usecols=[1, 2, 6, 7], header=None, na_values=[&quot;NIL&quot;],
                             na_filter=True, names=[&quot;meas_info&quot;, &quot;counter&quot;, &quot;value&quot;, &quot;time&quot;], index_col='time')
            df_list.append(df[[&quot;value&quot;]])

        if df_list:
            rawdata = pd.concat(df_list)

    client_ids = df.get(client_id_colname)
    train_client_ids = client_ids.sample(frac=0.5).tolist()
    test_client_ids = [x for x in client_ids if x not in train_client_ids]

    def create_tf_dataset_for_client_fn(client_id):
        # a function which takes a client_id and returns a
        # tf.data.Dataset for that client
        client_data = df[df['value'] == client_id]
    features = ['meas_info', 'counter']
    LABEL_COLUMN = 'value'
    dataset = tf.data.Dataset.from_tensor_slices(
        (collections.OrderedDict(client_data[features].to_dict('list')),
         client_data[LABEL_COLUMN].to_list())
    )
    global input_spec
    input_spec = dataset.element_spec
    dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)
    return dataset

    train_data = tff.simulation.ClientData.from_clients_and_fn(
        client_ids=train_client_ids,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
    test_data = tff.simulation.ClientData.from_clients_and_fn(
        client_ids=test_client_ids,
        create_tf_dataset_for_client_fn=create_tf_dataset_for_client_fn
    )
    example_dataset = train_data.create_tf_dataset_for_client(
        train_data.client_ids[0]
    )
    # split client id into train and test clients
    loss_builder = tf.keras.losses.SparseCategoricalCrossentropy
    metrics_builder = lambda: [tf.keras.metrics.SparseCategoricalAccuracy()]
    tff_model = tf.keras.Sequential([
        layers.Dense(64),
        layers.Dense(1)
    ])

    def retrieve_model():
    model = tf.keras.models.Sequential([
        tf.keras.layers.LSTM(2, input_shape=(1,2), return_sequences=True),
        tf.keras.layers.Dense(256, activation=tf.nn.relu),
        tf.keras.layers.Activation(tf.nn.softmax),
    ])

    return model

    def tff_model_fn() -&gt; tff.learning.Model:
        return tff.learning.from_keras_model(
            keras_model=retrieve_model(),
            input_spec=example_dataset.element_spec,
            loss=loss_builder(),
            metrics=metrics_builder())

    iterative_process = tff.learning.build_federated_averaging_process(
        tff_model_fn, Parameters.server_adam_optimizer_fn, Parameters.client_adam_optimizer_fn)
    server_state = iterative_process.initialize()

    for round_num in range(Parameters.FLAGS.total_rounds):
        sampled_clients = np.random.choice(
            train_data.client_ids,
            size=Parameters.FLAGS.train_clients_per_round,
            replace=False)
        sampled_train_data = [
            train_data.create_tf_dataset_for_client(client)
            for client in sampled_clients
        ]
        server_state, metrics = iterative_process.next(server_state, sampled_train_data)
        train_metrics = metrics['train']
        print(metrics)


if __name__ == '__main__':
    app.run(main)


def start():
    app.run(main)
</code></pre>
<p>This is the error that I got but I think my problem is more than this error. what I am doing wrong here ??</p>
<pre><code>ValueError: The top-level structure in `input_spec` must contain exactly two top-level elements, as it must specify type information for both inputs to and predictions from the model. You passed input spec {'meas_info': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'counter': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'value': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}.
</code></pre>
<p><a href=""https://i.sstatic.net/w1t2L.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/w1t2L.png"" alt=""enter image description here"" /></a></p>
<p>thnx to @Zachary Garrett
i solve the above error with his help by adding these line of code</p>
<pre><code> client_data = df[df['value'] == client_id]
        features = ['meas_info', 'counter']
        LABEL_COLUMN = 'value'
        dataset = tf.data.Dataset.from_tensor_slices(
            (collections.OrderedDict(client_data[features].to_dict('list')),
             client_data[LABEL_COLUMN].to_list())
        )
        global input_spec
        input_spec = dataset.element_spec
        dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)
        return dataset
</code></pre>
<p>My problem now that is throwing in the <code>tff.learning.build_federated_averaging_process</code> is this</p>
<pre><code>ValueError: Layer sequential expects 1 inputs, but it received 2 input tensors. Inputs received: [&lt;tf.Tensor 'batch_input:0' shape=() dtype=float32&gt;, &lt;tf.Tensor 'batch_input_1:0' shape=() dtype=float32&gt;]
</code></pre>
<p>what i miss again? maybe something in the layer sequential here</p>
<pre><code>def retrieve_model():
        model = tf.keras.models.Sequential([
            tf.keras.layers.LSTM(2, input_shape=(1,2), return_sequences=True),
            tf.keras.layers.Dense(256, activation=tf.nn.relu),
            tf.keras.layers.Activation(tf.nn.softmax),
        ])

        return model
</code></pre>
",3163824,,3163824,,44205.55139,44205.55139,How to build federated_averaging_process from custom federated dataset that loads from CSV file,<python><tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
65578020,1,,,44201.47847,,3,712,"<p>My question is : How can I predict a label of such image with Tensorflow Federated ?</p>
<p>After completing the evaluation of the model, I would like to predict the label of a given image. Like in Keras we do this :</p>
<pre><code># new instance where we do not know the answer
Xnew = array([[0.89337759, 0.65864154]])
# make a prediction
ynew = model.predict_classes(Xnew)
# show the inputs and predicted outputs
print(&quot;X=%s, Predicted=%s&quot; % (Xnew[0], ynew[0]))
</code></pre>
<p>Output:</p>
<pre><code>X=[0.89337759 0.65864154], Predicted=[0]
</code></pre>
<p>here is how state and model_fn was created:</p>
<pre><code>
def model_fn():
    keras_model = create_compiled_keras_model()
    return tff.learning.from_compiled_keras_model(keras_model, sample_batch) 

iterative_process = tff.learning.build_federated_averaging_process(model_fn, server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),client_weight_fn=None)
state = iterative_process.initialize()
</code></pre>
<p>I find this error :</p>
<pre><code>list(self._name_to_index.keys())[:10]))
AttributeError: The tuple of length 2 does not have named field &quot;assign_weights_to&quot;. Fields (up to first 10): ['trainable', 'non_trainable']
</code></pre>
<p>Thanks</p>
",14253961,,14253961,,44208.55208,44209.22361,How to make prediction with TFF?,<tensorflow-federated>,1,1,,,,CC BY-SA 4.0
65578498,1,,,44201.50139,,2,176,"<p>I use TFF and My dataset has a binary_mode class,  this is how I declared my inputs :</p>
<pre><code>genv0 = img_genv.flow_from_directory(pathv0,(224, 224),'rgb', batch_size=2, class_mode='binary')
train_data = tf.data.Dataset.from_generator(genv0, output_types=(tf.float32, tf.float32), output_shapes = ([2,224,224,3],[2,1])
</code></pre>
<p>Here is my sample_batch :</p>
<pre><code>images, labels = next(img_gen.flow_from_directory(path0,target_size=(224, 224), batch_size=2, class_mode='binary'))
</code></pre>
<p>and I add this layer in my model</p>
<pre><code>model_output = tf.keras.layers.Dense(1, activation=&quot;sigmoid&quot;)(last_layer)
 model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.001)
             loss=tf.keras.losses.BinaryCrossentropy(),
              metrics=([tf.keras.metrics.BinaryAccuracy()))
</code></pre>
<p>When running my code, I find this error :</p>
<pre><code> ValueError: Shapes (None, 1) and (None,) are incompatible
</code></pre>
<p>I think the problem is that sample_batch does not take label with bainary mode.
How can I resolve this problem
Thanks</p>
",12682667,,12682667,,44202.39931,44202.39931,"TFF : ValueError: Shapes (None, 1) and (None,) are incompatible",<tensorflow><tensorflow2.0><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
65637227,1,,,44204.93403,,2,130,"<p>I'm trying to federate a keras model which has multiple outputs. There are two separate dense layers that perform a binary classification and a multi-class classification. I am getting the following ValueError when I try to build my federated averaging process <code>tff.learning.build_federated_averaging_process</code> from <code>model_fn()</code>. Following are the code snippets and error information. I am unable to understand what is going wrong and how to resolve it.</p>
<pre><code>ValueError: in user code:

/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/optimizer_utils.py:387 _compute_local_training_and_client_delta  *
    client_output = client_delta_fn(dataset, initial_model_weights)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow_federated/python/learning/federated_averaging.py:92 reduce_fn  *
    output = model.forward_pass(batch, training=True)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow_federated/python/learning/framework/dataset_reduce.py:28 _dataset_reduce_fn  *
    return dataset.reduce(initial_state=initial_state_fn(), reduce_func=reduce_fn)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py:365 forward_pass  *
    return self._forward_pass(batch_input, training=training)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow_federated/python/learning/keras_utils.py:357 _forward_pass  *
    metric.update_state(y_true=y_true, y_pred=predictions)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/keras/utils/metrics_utils.py:90 decorated  **
    update_op = update_state_fn(*args, **kwargs)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py:176 update_state_fn
    return ag_update_state(*args, **kwargs)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/keras/metrics.py:604 update_state  **
    y_pred = math_ops.cast(y_pred, self._dtype)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py:201 wrapper
    return target(*args, **kwargs)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:920 cast
    x = ops.convert_to_tensor(x, name=&quot;x&quot;)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1499 convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1502 _autopacking_conversion_function
    return _autopacking_helper(v, dtype, name or &quot;packed&quot;)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:1438 _autopacking_helper
    return gen_array_ops.pack(elems_as_tensors, name=scope)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py:6477 pack
    &quot;Pack&quot;, values=values, axis=axis, name=name)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:744 _apply_op_helper
    attrs=attr_protos, op_def=op_def)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py:593 _create_op_internal
    compute_device)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:3485 _create_op_internal
    op_def=op_def)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1975 __init__
    control_input_ops, op_def)
/home/usr/Envs/tf-fed/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1815 _create_c_op
    raise ValueError(str(e))

ValueError: Dimension 1 in both shapes must be equal, but are 1 and 3. Shapes are [?,1] and [?,3].
    From merging shape 0 with other shapes. for '{{node Cast_1/x}} = Pack[N=2, T=DT_FLOAT, axis=0](functional_1/eye_output/Sigmoid, functional_1/mouth_output/Softmax)' with input shapes: [?,1], [?,3].
</code></pre>
<p>My model_fn() looks like this:</p>
<pre><code>def model_fn():
    losses = [tf.keras.losses.BinaryCrossentropy(), tf.keras.losses.SparseCategoricalCrossentropy()]
    metrics = [tf.keras.metrics.BinaryAccuracy(),tf.keras.metrics.SparseCategoricalAccuracy()]

    keras_model = build_model()
    return tff.learning.from_keras_model(
        keras_model,
        input_spec=spec,
        loss=losses,
        metrics=metrics)
</code></pre>
<p>where build_model() creates the keras model:</p>
<pre><code>build_model():
  ...
  out1 = Dense(1, activation='sigmoid')(fc1)
  out2 = Dense(3, activation='softmax')(fc2)
  model =  Model(inputs=inputs, outputs=[out1, out2])
  return model
</code></pre>
<p>And input_specification that looks like this</p>
<pre><code>OrderedDict([('x',
          TensorSpec(shape=(None, 240, 320), dtype=tf.float32, name=None)),
         ('y',
          (TensorSpec(shape=(None, 1), dtype=tf.int64, name=None),
           TensorSpec(shape=(None, 1), dtype=tf.int64, name=None)))])
</code></pre>
<p>How can I build my TFF fedAvg process using such a model?</p>
",7034335,,,,,44399.33403,Getting ValueError for building fedAvg from multi-output keras model,<keras><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
65772509,1,65785821,,44214.42639,,1,309,"<p>I would like to know the easiest way to create a model, broadcast it with tensorflow federated, run a cycle and collect the weights returned by clients without aggregating them with the fedavg.</p>
",11431857,,1000551,,44214.43194,44215.22014,Collecting the weights returned by clients without aggregating them,<machine-learning><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
65794925,1,,,44215.66111,,1,252,"<p>I've been learning the <a href=""https://www.tensorflow.org/federated"" rel=""nofollow noreferrer"">TensorFlow Federated</a> framework recently but have run into a problem. I'd like to look at the trained client weights sent to the central server before aggregation.</p>
<p>For example, in <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">this</a> tutorial, I have access to the state variable:</p>
<pre><code>NUM_ROUNDS = 11
for round_num in range(2, NUM_ROUNDS):
  state, metrics = iterative_process.next(state, federated_train_data)
  print('round {:2d}, metrics={}'.format(round_num, metrics))
</code></pre>
<p>The state variables holds the weights of the central model (created by aggregating client weights). Is there anyway to inspect the weights that were sent by the clients prior to aggregation in TensorFlow Federated?</p>
<p>Thanks, any help appreciated.</p>
",2623004,,,,,44221.10139,How to inspect client model updates in Tensorflow Federated,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
65828005,1,,,44217.54236,,1,84,"<p>I've been using this function to load data from stackoverflow data_set. However, one problem occurs that every time I use this function and set cache_dir to the location of the keras/dataset or the location of the cache, it still tries to download the tar from the internet(Even when I have already the 8.5G tar file download in local). Is there a simple way to avoid downloading from the internet and access by local?</p>
<p>I've also tried to write the save and load function, but it seems they cannot be applied to HDF5ClientData type.</p>
",15052242,,,,,44217.54236,Question about tff.simulation.datasets.stackoverflow.load_data(cache_dir = None),<tensorflow><tensorflow-federated><loaddata><federated><federated-learning>,0,1,,,,CC BY-SA 4.0
65830370,1,65841812,,44217.63681,,3,222,"<p>In Tensorflow Federated (TFF), you can pass to the <code>tff.learning.build_federated_averaging_process</code> a <code>broadcast_process</code> and an <code>aggregation_process</code>, which can embed customized encoders e.g. to apply custom compressions.</p>
<p>Getting to the point of my question, I am trying to implement an encoder to sparsify model updates/model weights.</p>
<p>I am trying to build such an encoder by implementing the <code>EncodingStageInterface</code>, from <code>tensorflow_model_optimization.python.core.internal</code>.
However, I am struggling to implement a (local) state to accumulate the zeroed-out coordinates of model updates/model weights round by round. Note that this state should not be communicated, and just need to be maintained locally (so the <code>AdaptiveEncodingStageInterface</code> should not be helpful). In general, the question is how to maintain a local state inside an Encoder to be then passed to the fedavg process.</p>
<p>I attach the code of my encoder implementation (that, besides the state I would like to add, works fine as stateless as expected).
I then attach the excerpt of my code where I use the encoder implementation.
If I decomment the commented parts in <em>stateful_encoding_stage_topk.py</em> the code does not work: I can't figure out how manage the state (that is a Tensor) in TF non eager mode.</p>
<p><em>stateful_encoding_stage_topk.py</em></p>
<pre><code>import tensorflow as tf
import numpy as np
from tensorflow_model_optimization.python.core.internal import tensor_encoding as te


@te.core.tf_style_encoding_stage
class StatefulTopKEncodingStage(te.core.EncodingStageInterface):

  ENCODED_VALUES_KEY = 'stateful_topk_values'
  INDICES_KEY = 'indices'
  
  
  def __init__(self):
    super().__init__()
    # Here I would like to init my state
    #self.A = tf.zeros([800], dtype=tf.float32)

  @property
  def name(self):
    &quot;&quot;&quot;See base class.&quot;&quot;&quot;
    return 'stateful_topk'

  @property
  def compressible_tensors_keys(self):
    &quot;&quot;&quot;See base class.&quot;&quot;&quot;
    return [self.ENCODED_VALUES_KEY]

  @property
  def commutes_with_sum(self):
    &quot;&quot;&quot;See base class.&quot;&quot;&quot;
    return True

  @property
  def decode_needs_input_shape(self):
    &quot;&quot;&quot;See base class.&quot;&quot;&quot;
    return True

  def get_params(self):
    &quot;&quot;&quot;See base class.&quot;&quot;&quot;
    return {}, {}

  def encode(self, x, encode_params):
    &quot;&quot;&quot;See base class.&quot;&quot;&quot;
    del encode_params  # Unused.

    dW = tf.reshape(x, [-1])
    # Here I would like to retrieve the state
    A = tf.zeros([800], dtype=tf.float32)
    #A = self.residual
    
    dW_and_A = tf.math.add(A, dW)

    percentage = tf.constant(0.4, dtype=tf.float32)
    k_float = tf.multiply(percentage, tf.cast(tf.size(dW), tf.float32))
    k_int = tf.cast(tf.math.round(k_float), dtype=tf.int32)

    values, indices = tf.math.top_k(tf.math.abs(dW_and_A), k = k_int, sorted = False)
    indices = tf.expand_dims(indices, 1)
    sparse_dW = tf.scatter_nd(indices, values, tf.shape(dW_and_A))
    
    # Here I would like to update the state
    A_updated = tf.math.subtract(dW_and_A, sparse_dW)
    #self.A = A_updated
    
    encoded_x = {self.ENCODED_VALUES_KEY: values,
                 self.INDICES_KEY: indices}

    return encoded_x

  def decode(self,
             encoded_tensors,
             decode_params,
             num_summands=None,
             shape=None):
    &quot;&quot;&quot;See base class.&quot;&quot;&quot;
    del decode_params, num_summands  # Unused.
    
    indices = encoded_tensors[self.INDICES_KEY]
    values = encoded_tensors[self.ENCODED_VALUES_KEY]
    tensor = tf.fill([800], 0.0)
    decoded_values = tf.tensor_scatter_nd_update(tensor, indices, values)
    
    return tf.reshape(decoded_values, shape)



def sparse_quantizing_encoder():
  encoder = te.core.EncoderComposer(
      StatefulTopKEncodingStage() )  
  return encoder.make()
</code></pre>
<p><em>fedavg_with_sparsification.py</em></p>
<pre><code>[...]

def sparsification_broadcast_encoder_fn(value):
  spec = tf.TensorSpec(value.shape, value.dtype)
  return te.encoders.as_simple_encoder(te.encoders.identity(), spec)

def sparsification_mean_encoder_fn(value):
  spec = tf.TensorSpec(value.shape, value.dtype)
  
  if value.shape.num_elements() == 800:
    return te.encoders.as_gather_encoder(
        stateful_encoding_stage_topk.sparse_quantizing_encoder(), spec)

  else:
    return te.encoders.as_gather_encoder(te.encoders.identity(), spec)
  
encoded_broadcast_process = (
    tff.learning.framework.build_encoded_broadcast_process_from_model(
        model_fn, sparsification_broadcast_encoder_fn))

encoded_mean_process = (
    tff.learning.framework.build_encoded_mean_process_from_model(
        model_fn, sparsification_mean_encoder_fn))


iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.004),
    client_weight_fn=lambda _: tf.constant(1.0),
    broadcast_process=encoded_broadcast_process,
    aggregation_process=encoded_mean_process)

[...]
</code></pre>
<p>I am using:</p>
<ul>
<li>tensorflow 2.4.0</li>
<li>tensorflow-federated 0.17.0</li>
</ul>
",10651544,,,,,44218.36042,TensorFlow Federated Compression: How to implement a stateful encoder to be used in in TFF's build_federated_averaging_process?,<python><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
65871666,1,,,44220.59653,,1,301,"<p>I am having an OOM error while trying to run a Federated Learning simulation with Tensorflow Federated.
I want to train a model for multiclass text classification, I follow the <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification#preprocessing_the_input_data"" rel=""nofollow noreferrer"">Federated Tensorflow tutorial</a> and changed the model, and prepared my dataset to be a federated learning dataset.
The server I am running my simulations has 1 GPU available.</p>
<p>--I tried the allow memory growth, having a batch size in the power of two, and many other suggestions I found online but nothing worked for me until now.</p>
<p>--I am trying now to set the <code>clients_per_thread</code> parameter (as it is suggested) but it seems that is not an expected keyword argument.
the code I use is:</p>
<pre><code>tff.framework.sizing_executor_factory(clients_per_thread=5)
</code></pre>
<p>and the error I get is:</p>
<pre><code>File &quot;test.py&quot;, line 48, in &lt;module&gt;
    tff.framework.sizing_executor_factory(clients_per_thread=5)
TypeError: sizing_executor_factory() got an unexpected keyword argument 'clients_per_thread'
</code></pre>
<p>I believe that the problem is with the model, maybe it's too big:</p>
<pre><code>Model: &quot;model&quot;
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input_1 (InputLayer)            [(None, 10)]         0
__________________________________________________________________________________________________
embedding (Embedding)           (None, 10, 300)      17334000    input_1[0][0]
__________________________________________________________________________________________________
bi_lstm_0 (Bidirectional)       (None, 10, 256)      439296      embedding[0][0]
__________________________________________________________________________________________________
bi_lstm_1 (Bidirectional)       [(None, 10, 256), (N 394240      bi_lstm_0[0][0]
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 256)          0           bi_lstm_1[0][1]
                                                                 bi_lstm_1[0][3]
__________________________________________________________________________________________________
attention (Attention)           ((None, 256), (None, 5151        bi_lstm_1[0][0]
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 20)           5140        attention[0][0]
__________________________________________________________________________________________________
dropout (Dropout)               (None, 20)           0           dense_3[0][0]
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 3)            63          dropout[0][0]
==================================================================================================
Total params: 18,177,890
Trainable params: 843,890
Non-trainable params: 17,334,000
</code></pre>
<p>Do you have any suggestions?</p>
<p>Currently, I don't get the OOM error only when I run federated learning with less than 12 clients.</p>
<p>Logs:</p>
<pre><code>2021-01-24 16:09:00.752433: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] Stats:
Limit:                  1368653824
InUse:                  1368433664
MaxInUse:               1368653056
NumAllocs:                    2319
MaxAllocSize:            134217728

2021-01-24 16:09:00.752485: W tensorflow/core/common_runtime/bfc_allocator.cc:439] ***********************************************************x*****************xxx******xxxx******xxx*
2021-01-24 16:09:00.752505: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at training_ops.cc:564 : Resource exhausted: OOM when allocating tensor with shape[128,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
2021-01-24 16:09:00.752507: W tensorflow/core/common_runtime/bfc_allocator.cc:434] Allocator (GPU_0_bfc) ran out of memory trying to allocate 256.0KiB (rounded to 262144)
Current allocation summary follows.
2021-01-24 16:09:00.752536: I tensorflow/core/common_runtime/bfc_allocator.cc:934] BFCAllocator dump for GPU_0_bfc
2021-01-24 16:09:00.752545: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (256):   Total Chunks: 992, Chunks in use: 992. 248.0KiB allocated for chunks. 248.0KiB in use in bin. 25.9KiB client-requested in use in bin.
2021-01-24 16:09:00.752612: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (512):   Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-01-24 16:09:00.752644: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (1024):  Total Chunks: 76, Chunks in use: 76. 77.8KiB allocated for chunks. 77.8KiB in use in bin. 59.8KiB client-requested in use in bin.
2021-01-24 16:09:00.752656: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (2048):  Total Chunks: 102, Chunks in use: 101. 207.8KiB allocated for chunks. 205.8KiB in use in bin. 202.0KiB client-requested in use in bin.
2021-01-24 16:09:00.752666: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (4096):  Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-01-24 16:09:00.752677: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (8192):  Total Chunks: 77, Chunks in use: 75. 782.8KiB allocated for chunks. 764.8KiB in use in bin. 750.0KiB client-requested in use in bin.
2021-01-24 16:09:00.752687: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (16384):         Total Chunks: 54, Chunks in use: 54. 1.10MiB allocated for chunks. 1.10MiB in use in bin. 1.03MiB client-requested in use in bin.
2021-01-24 16:09:00.752698: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (32768):         Total Chunks: 1, Chunks in use: 1. 38.5KiB allocated for chunks. 38.5KiB in use in bin. 20.0KiB client-requested in use in bin.
2021-01-24 16:09:00.752707: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (65536):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-01-24 16:09:00.752715: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (131072):        Total Chunks: 1, Chunks in use: 0. 195.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2021-01-24 16:09:00.752726: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (262144):        Total Chunks: 86, Chunks in use: 86. 22.96MiB allocated for chunks. 22.96MiB in use in bin. 21.50MiB client-requested in use in bin.
2021-01-24 16:09:00.752736: I tensorflow/core/common_runtime/bfc_allocator.cc:941] Bin (524288):        Total Chunks: 127, Chunks in use: 127. 71.56MiB allocated for chunks. 71.56MiB in use in bin. 68.48MiB client-requested in use in bin.
.....


ERROR:concurrent.futures:exception calling callback for &lt;Future at 0x7fc4ca1943c8 state=finished raised InternalError&gt;
Traceback (most recent call last):
  File &quot;/usr/lib/python3.6/concurrent/futures/_base.py&quot;, line 324, in _invoke_callbacks
    callback(self)
  File &quot;/usr/lib/python3.6/asyncio/futures.py&quot;, line 417, in _call_set_state
    dest_loop.call_soon_threadsafe(_set_state, destination, source)
  File &quot;/usr/lib/python3.6/asyncio/base_events.py&quot;, line 641, in call_soon_threadsafe
    self._check_closed()
  File &quot;/usr/lib/python3.6/asyncio/base_events.py&quot;, line 381, in _check_closed
    raise RuntimeError('Event loop is closed')
RuntimeError: Event loop is closed
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc58853ed68&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc588020348&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc588301138&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58853ec48&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc588301768&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc588470258&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5883015e8&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36888&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc588301b28&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36a68&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5883015b8&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36858&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc588020708&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36d38&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc588020e88&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36fa8&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc588301c48&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36d98&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc4c9bcda38&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc5881ac768&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5880208e8&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be368e8&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5882c4108&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36e28&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5882d79d8&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36eb8&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5882d7ee8&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36ee8&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5882d72e8&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36a98&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5882d76a8&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be360a8&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5882d77f8&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36978&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5882d7bb8&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36f18&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc58841f9a8&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36d08&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5885d4378&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be36b88&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5885d4618&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc58be367f8&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5885d4348&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc5885d4528&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5882a0a68&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc5885d4f48&gt;()]&gt;
ERROR:asyncio:Task was destroyed but it is pending!
task: &lt;Task pending coro=&lt;trace.&lt;locals&gt;.async_trace() running at /home/.../lib/python3.6/site-packages/tensorflow_federated/python/common_libs/tracing.py:200&gt; wait_for=&lt;Future pending cb=[_chain_future.&lt;locals&gt;._call_check_cancel() at /usr/lib/python3.6/asyncio/futures.py:403, &lt;TaskWakeupMethWrapper object at 0x7fc5882a0828&gt;()]&gt; cb=[&lt;TaskWakeupMethWrapper object at 0x7fc5885d4438&gt;()]&gt;
</code></pre>
",9745740,,9745740,,44221.48542,44221.48542,Out of Memory (OOM) error in Tensorflow Federated learning simulation when I set federated clients more than 12,<tensorflow><out-of-memory><tensorflow-federated>,0,4,,,,CC BY-SA 4.0
65935511,1,,,44224.44792,,1,2163,"<p>I am running into an error after upgrading to TFF 0.17.0. The same code works perfectly in TFF 0.16.1. The training works just fine in both versions however when I try to copy weights from the FL state to model to evaluate it on test dataset, I get the following error:</p>
<pre><code>File &quot;fl/main_fl.py&quot;, line 166, in keras_evaluate                                                                 
    loss, accuracy = self.model.evaluate(test_dataset, verbose=0)                                                                             
  File &quot;/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_v1.py&quot;, line 905, in evaluate
    self._assert_built_as_v1()
  File &quot;/home/ubuntu/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer_v1.py&quot;, line 852, i$ _assert_built_as_v1
    (type(self),))
ValueError: Your Layer or Model is in an invalid state. This can happen for the following cases:
 1. You might be interleaving estimator/non-estimator models or interleaving models/layers made in tf.compat.v1.Graph.as_default() with model$/layers created outside of it. Converting a model to an estimator (via model_to_estimator) invalidates all models/layers made before the conv$rsion (even if they were not the model converted to an estimator). Similarly, making a layer or a model inside a a tf.compat.v1.Graph invalid$tes all layers/models you previously made outside of the graph.
2. You might be using a custom keras layer implementation with  custom __init__ which didn't call super().__init__.  Please check the impleme$tation of &lt;class 'tensorflow.python.keras.engine.functional.Functional'&gt; and its bases.
</code></pre>
<p>Below is my keras_evaluate method:</p>
<pre><code>    def keras_evaluate(self, test_dataset, mode='test', step=0):
        self.state.model.assign_weights_to(self.model)
        loss, accuracy = self.model.evaluate(test_dataset, verbose=0)
        print('Mode={}, Loss={}, Accuracy={}'.format(mode, loss, accuracy))

</code></pre>
<p>self.state is the state returned by tff.learning.build_federated_averaging_process i.e tff.templates.IterativeProcess, test_dataset is of type tf.data.Dataset and self.model is tf.keras.Model type i.e keras functional model. I have one custom layer however it does have super() method so point 2 in the error is misleading me.</p>
<p>Any help will be appreciated.</p>
",2150690,,,,,44224.44792,"""ValueError: Your Layer or Model is in an invalid state."" after upgrading to tensorflow federated 0.17.0 from 0.16.1",<tensorflow><tensorflow-federated>,0,2,,,,CC BY-SA 4.0
76106294,1,,,45042.00972,,0,525,"<p>I am trying to implement Federated Learning using Flower framework in python. I get the following error when I start the process.<a href=""https://i.sstatic.net/y9fJU.jpg"" rel=""nofollow noreferrer"">Snapshot of the error</a></p>
<p>Here is what I tried,</p>
<pre><code>NUM_CLIENTS = 10

#function to load data
def load_datasets(num_clients: int, train_loader, test_loader):

    
    # Split training set into `num_clients` partitions to simulate different local datasets
    partition_size = len(train_loader) // num_clients
    lengths = [partition_size] * num_clients
    datasets = random_split(train_loader, lengths, torch.Generator().manual_seed(42))

    # Split each partition into train/val and create DataLoader
    trainloaders = []
    valloaders = []
    for ds in datasets:
        len_val = len(ds) // 10  # 10 % validation set
        len_train = len(ds) - len_val
        lengths = [len_train, len_val]
        ds_train, ds_val = random_split(ds, lengths, torch.Generator().manual_seed(42))
        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))
        valloaders.append(DataLoader(ds_val, batch_size=32))
    testloader = DataLoader(test_loader, batch_size=32)
    return trainloaders, valloaders, testloader


trainloaders, valloaders, testloader = load_datasets(NUM_CLIENTS ,train_loader,test_loader)



#client function thats been passed to start the server 
def client_fn(cid) -&gt; CardiacClient:
    net = CardiacModel().to(DEVICE)
    trainloader = trainloaders[cid]
    valloader = valloaders[cid]
    return CardiacClient(cid, net, trainloader, valloader)

</code></pre>
<p>In the above code cid refers to the clientID,</p>
",21730317,,,,,45155.63125,How do I solve the error which I get during training the clients in flower framework for federated learning?,<python><machine-learning><tensorflow-federated><flower><federated-learning>,1,0,,,,CC BY-SA 4.0
76132039,1,,,45044.7375,,0,210,"<p>Trying to install tensorflow_federated in venv. But it always gives an error</p>
<pre><code>stating
subprocess-exited-with-error

Ã— Getting requirements to build wheel did not run successfully.
â”‚ exit code: 1
â•°â”€&gt; See above for output.

This is the error statement

 Getting requirements to build wheel ... error
  error: subprocess-exited-with-error

  Ã— Getting requirements to build wheel did not run successfully.
  â”‚ exit code: 1
  â•°â”€&gt; [21 lines of output]
      Traceback (most recent call last):
        File &quot;C:\Users\abdul\Desktop\AML_Lear\aml\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py&quot;, line 353, in &lt;module&gt;        
          main()
        File &quot;C:\Users\abdul\Desktop\AML_Lear\aml\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py&quot;, line 335, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File &quot;C:\Users\abdul\Desktop\AML_Lear\aml\Lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py&quot;, line 118, in get_requires_for_build_wheel
          return hook(config_settings)
                 ^^^^^^^^^^^^^^^^^^^^^
        File &quot;C:\Users\abdul\AppData\Local\Temp\pip-build-env-4bm49dlc\overlay\Lib\site-packages\setuptools\build_meta.py&quot;, line 341, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File &quot;C:\Users\abdul\AppData\Local\Temp\pip-build-env-4bm49dlc\overlay\Lib\site-packages\setuptools\build_meta.py&quot;, line 323, in _get_build_requires
          self.run_setup()
        File &quot;C:\Users\abdul\AppData\Local\Temp\pip-build-env-4bm49dlc\overlay\Lib\site-packages\setuptools\build_meta.py&quot;, line 488, in run_setup        
          self).run_setup(setup_script=setup_script)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
        File &quot;C:\Users\abdul\AppData\Local\Temp\pip-build-env-4bm49dlc\overlay\Lib\site-packages\setuptools\build_meta.py&quot;, line 338, in run_setup        
          exec(code, locals())
        File &quot;&lt;string&gt;&quot;, line 34, in &lt;module&gt;
      RuntimeError: Python version 2.7 or 3.4+ is required.
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Ã— Getting requirements to build wheel did not run successfully.
â”‚ exit code: 1
â•°â”€&gt; See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</code></pre>
<p><a href=""https://i.sstatic.net/wn2Kx.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
<p>tried to resolve it by Updating Python to 3.11.3 and pip to 23.1.2, deleted the venc then again created new venv, also updated setuptools and also installed ez_setup but none of that helps and still unable to install tensorflow_federated.</p>
<p>OS: Windows 11
Editor: VSCode</p>
",14888552,,11286032,,45044.73889,45136.70764,Unable to install tensorflow_federated in venv,<python><tensorflow><machine-learning><jupyter-notebook><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
65943395,1,65973072,,44224.78264,,3,418,"<p>I'm a bit new to TFF, I have checked github and followed the EMNIST example to train a differentially private federated model using <code>DP-FedAvg</code> algorithm. Mainly this is done by attaching a <code>dp-query</code> to the <code>aggregation_process</code> then train the federated model.</p>
<p>I have a question please:</p>
<p><strong>1. Given that attaching a <code>dp-query</code> to the aggregation process would result in a participant-level Central-DP ,  How would I track the privacy guarantee (eps, delta) during training ?</strong></p>
<p>below is a code snippet where a differentially private federated model is set up with 100 participants, that is why both <code>expected_total_weight</code> and <code>expected_clients_per_round</code> are set to 100</p>
<pre><code>def model_fn():
    keras_model = create_keras_model()
    return tff.learning.from_keras_model(
        keras_model=keras_model,
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        input_spec=preprocessed_first_client_dataset.element_spec,
        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])


dp_query = tff.utils.build_dp_query(
    clip=1.0,
    noise_multiplier=0.3,
    expected_total_weight=100,
    adaptive_clip_learning_rate=0,
    target_unclipped_quantile=0.5,
    clipped_count_budget_allocation=0.1,
    expected_clients_per_round=100
)


weights_type = tff.learning.framework.weights_type_from_model(model_fn)

aggregation_process = tff.utils.build_dp_aggregate_process(weights_type.trainable, dp_query)

iterative_process = tff.learning.build_federated_averaging_process(
    model_fn=model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.1),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),
    aggregation_process=aggregation_process
)
</code></pre>
<p>I came across several methods to compute epsilon and delta in TF-Privacy, but it seems they are meant to track privacy guarantee of the traditional <code>DP-SGD</code> algorithm and expect to receive parameters such as <code>steps</code>,  <code>n</code> and <code>batch_size</code></p>
<p>Thanks a lot in advance</p>
",15092004,,15092004,,44225.54583,44226.87222,Track privacy guarantees in a federated learning process with DP-query,<tensorflow2.0><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
65987943,1,65996231,,44228.25833,,2,45,"<p>I'm planning a TFF scheme in which the clients send to the sever data besides the weights, like their hardware information (e.g CPU frequency). To achieve that, I need to call functions of third-party python libraries, like psutils. Is it possible to serialize (using <code>tff.tf_computation</code>) such kind of functions?
If not, what could be a solution to achieve this objective in a scenario where I'm using a remote executor setting through gRPC?</p>
",15065223,,,,,44232.12569,Does TFF serializalize functions of another library?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66042534,1,,,44231.38333,,1,167,"<p>I work with TFF 0.12.0, with the same architecture of ResNet50, I execute an example of IID dataset, and an example with non-IID dataset, but I find that accuracy of non-IID dataset is better (high) than accuracy of IID dataset especially in the first rounds.</p>
",14253961,,,,,44231.38333,Accuracy of non IID is better than accuracy of IID data,<tensorflow-federated>,0,2,,,,CC BY-SA 4.0
66073393,1,,,44233.15903,,0,407,"<p>I want to add more layers in neural network how can I customize this code ? can any one suggest a better way</p>
<p>in model layer there is only one layer .. in this part , I can define other weights ?should I add other layers there but it would make no sense</p>
<pre><code>MODEL_TYPE = tff.StructType([
    ('weights', tff.TensorType(tf.float32, [784, 10])),
    ('bias', tff.TensorType(tf.float32, [10]))])
</code></pre>
<p>then in batch loss function they multiply by them in order to get the predicted y.. that's simply adding one layer..</p>
<pre><code>tff.tf_computation(MODEL_TYPE, BATCH_TYPE)
def batch_loss(model, batch):
    predicted_y = tf.nn.softmax(tf.matmul(batch.x, model.weights) + model.bias)
</code></pre>
<p>The full code is here</p>
<pre><code>from __future__ import absolute_import, division, print_function
import tensorflow_federated as tff
import tensorflow.compat.v1 as tf
import numpy as np
import time
from scipy.special import comb, perm
import collections
import os

tff.backends.reference.set_reference_context()

# tf.compat.v1.enable_v2_behavior()
# tf.compat.v1.enable_eager_execution()

# NUM_EXAMPLES_PER_USER = 1000
BATCH_SIZE = 100
NUM_AGENT = 5
DECAY_FACTOR = 0.8


def get_data_for_digit(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence


def get_data_for_digit_test(source, digit):
    output_sequence = []
    all_samples = [i for i, d in enumerate(source[1]) if d == digit]
    for i in range(0, len(all_samples)):
        output_sequence.append({
            'x': np.array(source[0][all_samples[i]].flatten() / 255.0,
                          dtype=np.float32),
            'y': np.array(source[1][all_samples[i]], dtype=np.int32)})
    return output_sequence


def get_data_for_federated_agents(source, num):
    output_sequence = []

    Samples = []
    for digit in range(0, 10):
        samples = [i for i, d in enumerate(source[1]) if d == digit]
        samples = samples[0:5421]
        Samples.append(samples)

    all_samples = []
    for sample in Samples:
        for sample_index in range(int(num * (len(sample) / NUM_AGENT)), int((num + 1) * (len(sample) / NUM_AGENT))):
            all_samples.append(sample[sample_index])

    # all_samples = [i for i in range(int(num*(len(source[1])/NUM_AGENT)), int((num+1)*(len(source[1])/NUM_AGENT)))]

    for i in range(0, len(all_samples), BATCH_SIZE):
        batch_samples = all_samples[i:i + BATCH_SIZE]
        output_sequence.append({
            'x': np.array([source[0][i].flatten() / 255.0 for i in batch_samples],
                          dtype=np.float32),
            'y': np.array([source[1][i] for i in batch_samples], dtype=np.int32)})
    return output_sequence


BATCH_TYPE = tff.StructType([
    ('x', tff.TensorType(tf.float32, [None, 784])),
    ('y', tff.TensorType(tf.int32, [None]))])

MODEL_TYPE = tff.StructType([
    ('weights', tff.TensorType(tf.float32, [784, 10])),
    ('bias', tff.TensorType(tf.float32, [10]))])


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE)
def batch_loss(model, batch):
    predicted_y = tf.nn.softmax(tf.matmul(batch.x, model.weights) + model.bias)
    return -tf.reduce_mean(tf.reduce_sum(
        tf.one_hot(batch.y, 10) * tf.log(predicted_y), axis=[1]))


@tff.tf_computation(MODEL_TYPE, BATCH_TYPE, tf.float32)
def batch_train(initial_model, batch, learning_rate):
    # Define a group of model variables and set them to `initial_model`.
    model_vars = tff.utils.create_variables('v', MODEL_TYPE)
    init_model = tff.utils.assign(model_vars, initial_model)

    # Perform one step of gradient descent using loss from `batch_loss`.
    optimizer = tf.train.GradientDescentOptimizer(learning_rate)
    with tf.control_dependencies([init_model]):
        train_model = optimizer.minimize(batch_loss(model_vars, batch))

    # Return the model vars after performing this gradient descent step.
    with tf.control_dependencies([train_model]):
        return tff.utils.identity(model_vars)


LOCAL_DATA_TYPE = tff.SequenceType(BATCH_TYPE)


@tff.federated_computation(MODEL_TYPE, tf.float32, LOCAL_DATA_TYPE)
def local_train(initial_model, learning_rate, all_batches):
    # Mapping function to apply to each batch.
    @tff.federated_computation(MODEL_TYPE, BATCH_TYPE)
    def batch_fn(model, batch):
        return batch_train(model, batch, learning_rate)

    l = tff.sequence_reduce(all_batches, initial_model, batch_fn)
    return l


@tff.federated_computation(MODEL_TYPE, LOCAL_DATA_TYPE)
def local_eval(model, all_batches):
    #
    return tff.sequence_sum(
        tff.sequence_map(
            tff.federated_computation(
                lambda b: batch_loss(model, b), BATCH_TYPE),
            all_batches))


SERVER_MODEL_TYPE = tff.FederatedType(MODEL_TYPE, tff.SERVER, all_equal=True)
CLIENT_DATA_TYPE = tff.FederatedType(LOCAL_DATA_TYPE, tff.CLIENTS)


@tff.federated_computation(SERVER_MODEL_TYPE, CLIENT_DATA_TYPE)
def federated_eval(model, data):
    return tff.federated_mean(
        tff.federated_map(local_eval, [tff.federated_broadcast(model), data]))


SERVER_FLOAT_TYPE = tff.FederatedType(tf.float32, tff.SERVER, all_equal=True)


@tff.federated_computation(
    SERVER_MODEL_TYPE, SERVER_FLOAT_TYPE, CLIENT_DATA_TYPE)
def federated_train(model, learning_rate, data):
    l = tff.federated_map(
        local_train,
        [tff.federated_broadcast(model),
         tff.federated_broadcast(learning_rate),
         data])
    return l
    # return tff.federated_mean()


def readTestImagesFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__),
                              &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__),
                              &quot;test_images1_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(
            &quot;\n&quot;, &quot;&quot;).split(&quot;\t&quot;)
        for i in p:
            if i != &quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)


def readTestLabelsFromFile(distr_same):
    ret = []
    if distr_same:
        f = open(os.path.join(os.path.dirname(__file__),
                              &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    else:
        f = open(os.path.join(os.path.dirname(__file__),
                              &quot;test_labels_.txt&quot;), encoding=&quot;utf-8&quot;)
    lines = f.readlines()
    for line in lines:
        tem_ret = []
        p = line.replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;).split(&quot; &quot;)
        for i in p:
            if i != &quot;&quot;:
                tem_ret.append(float(i))
        ret.append(tem_ret)
    return np.asarray(ret)


def getParmsAndLearningRate(agent_no):
    f = open(os.path.join(os.path.dirname(__file__),
                          &quot;weights_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(
        &quot;***\n--------------------------------------------------&quot;)
    parm_local = []
    learning_rate_list = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0:784]
            learning_rate_list.append(
                float(line[784].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        else:
            weights_line = line[1:785]
            learning_rate_list.append(
                float(line[785].replace(&quot;*&quot;, &quot;&quot;).replace(&quot;\n&quot;, &quot;&quot;)))
        valid_weights_line = []
        for l in weights_line:
            w_list = l.split(&quot;\t&quot;)
            w_list = w_list[0:len(w_list) - 1]
            w_list = [float(i) for i in w_list]
            valid_weights_line.append(w_list)
        parm_local.append(valid_weights_line)
    f.close()

    f = open(os.path.join(os.path.dirname(__file__),
                          &quot;bias_&quot; + str(agent_no) + &quot;.txt&quot;))
    content = f.read()
    g_ = content.split(
        &quot;***\n--------------------------------------------------&quot;)
    bias_local = []
    for j in range(len(g_) - 1):
        line = g_[j].split(&quot;\n&quot;)
        if j == 0:
            weights_line = line[0]
        else:
            weights_line = line[1]
        b_list = weights_line.split(&quot;\t&quot;)
        b_list = b_list[0:len(b_list) - 1]
        b_list = [float(i) for i in b_list]
        bias_local.append(b_list)
    f.close()
    ret = {
        'weights': np.asarray(parm_local),
        'bias': np.asarray(bias_local),
        'learning_rate': np.asarray(learning_rate_list)
    }
    return ret


def train_with_gradient_and_valuation(agent_list, grad, bi, lr, distr_type, iter_n, g_m):
    model_g = {
        'weights': g_m[0],
        'bias': g_m[1]
    }

    for i in range(iter_n-1, iter_n):
        # i-&gt;è¿­ä»£è½®æ•°
        gradient_w = np.zeros([784, 10], dtype=np.float32)
        gradient_b = np.zeros([10], dtype=np.float32)
        for j in agent_list:
            gradient_w = np.add(np.multiply(
                grad[j][i], 1 / len(agent_list)), gradient_w)
            gradient_b = np.add(np.multiply(
                bi[j][i], 1 / len(agent_list)), gradient_b)
        model_g['weights'] = np.subtract(
            model_g['weights'], np.multiply(lr[0][i], gradient_w))
        model_g['bias'] = np.subtract(
            model_g['bias'], np.multiply(lr[0][i], gradient_b))

    test_images = readTestImagesFromFile(False)
    test_labels_onehot = readTestLabelsFromFile(False)
    m = np.dot(test_images, np.asarray(model_g['weights']))
    test_result = m + np.asarray(model_g['bias'])
    y = tf.nn.softmax(test_result)
    correct_prediction = tf.equal(
        tf.argmax(y, 1), tf.arg_max(test_labels_onehot, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    return accuracy.numpy()


def remove_list_indexed(removed_ele, original_l, ll):
    new_original_l = []
    for i in original_l:
        new_original_l.append(i)
    for i in new_original_l:
        if i == removed_ele:
            new_original_l.remove(i)
    for i in range(len(ll)):
        if set(ll[i]) == set(new_original_l):
            return i
    return -1


def shapley_list_indexed(original_l, ll):
    for i in range(len(ll)):
        if set(ll[i]) == set(original_l):
            return i
    return -1


def PowerSetsBinary(items):
    N = len(items)
    set_all = []
    for i in range(2 ** N):
        combo = []
        for j in range(N):
            if (i &gt;&gt; j) % 2 == 1:
                combo.append(items[j])
        set_all.append(combo)
    return set_all


def loadHistoryModels(round_num):
    f = open(os.path.join(os.path.dirname(__file__),
                          &quot;gradientplus_models&quot; + str(round_num) + &quot;.txt&quot;), &quot;r&quot;)
    lines = f.readlines()
    ret_models = []

    f_ini_p = open(os.path.join(os.path.dirname(__file__),
                                &quot;initial_model_parameters&quot; + str(round_num-1) + &quot;.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()

    ret_models.append([w_initial, b_initial])

    tem_model = []
    for i, line in enumerate(lines):
        if i % 2 == 0:
            lis = line.strip().replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).split(&quot;,&quot;)
            lis = [float(i.strip()) for i in lis]
            lis = np.array(lis).reshape([784, 10])
            tem_model = [lis]
        else:
            lis = line.strip().replace(&quot;[&quot;, &quot;&quot;).replace(&quot;]&quot;, &quot;&quot;).split(&quot;,&quot;)
            lis = [float(i.strip()) for i in lis]
            lis = np.array(lis)
            tem_model.append(lis)
            ret_models.append(tem_model)
    f.close()
    return ret_models


if __name__ == &quot;__main__&quot;:
    start_time = time.time()
    # data_num = np.asarray([5923, 6742, 5958, 6131, 5842])
    # agents_weights = np.divide(data_num, data_num.sum())
    for index in range(NUM_AGENT):
        f = open(os.path.join(os.path.dirname(__file__),
                              &quot;weights_&quot; + str(index) + &quot;.txt&quot;), &quot;w&quot;)
        f.close()
        f = open(os.path.join(os.path.dirname(__file__),
                              &quot;bias_&quot; + str(index) + &quot;.txt&quot;), &quot;w&quot;)
        f.close()
    # f = open(os.path.join(os.path.dirname(__file__),
     #                     &quot;gradientplus_models.txt&quot;), &quot;w&quot;) #alice
    # f.close()
    f = open(os.path.join(os.path.dirname(__file__),
                          &quot;alice&quot; + &quot;.txt&quot;), &quot;w&quot;)
    f.close()
    mnist_train, mnist_test = tf.keras.datasets.mnist.load_data()

    DISTRIBUTION_TYPE = &quot;SAME&quot;

    federated_train_data_divide = None
    federated_train_data = None
    if DISTRIBUTION_TYPE == &quot;SAME&quot;:
        federated_train_data_divide = [get_data_for_federated_agents(
            mnist_train, d) for d in range(NUM_AGENT)]
        federated_train_data = federated_train_data_divide

    f_ini_p = open(os.path.join(os.path.dirname(__file__),
                                &quot;initial_model_parameters-1.txt&quot;), &quot;r&quot;)
    para_lines = f_ini_p.readlines()
    w_paras = para_lines[0].split(&quot;\t&quot;)
    w_paras = [float(i) for i in w_paras]
    b_paras = para_lines[1].split(&quot;\t&quot;)
    b_paras = [float(i) for i in b_paras]
    w_initial = np.asarray(w_paras, dtype=np.float32).reshape([784, 10])
    b_initial = np.asarray(b_paras, dtype=np.float32).reshape([10])
    f_ini_p.close()

    initial_model = collections.OrderedDict(
        weights=w_initial,
        bias=b_initial)

    model = initial_model
    learning_rate = 0.1
    for round_num in range(5):  
        f = open(os.path.join(os.path.dirname(__file__),
                              &quot;gradientplus_models&quot; + str(round_num) + &quot;.txt&quot;), &quot;w&quot;)  # alice
        f.close()
        local_models = federated_train(
            model, learning_rate, federated_train_data)
        print(&quot;learning rate: &quot;, learning_rate)

        # print(local_models[0][0])#ç¬¬0ä¸ªagentçš„weightsçŸ©é˜µ
        # print(local_models[0][1])#ç¬¬0ä¸ªagentçš„biasçŸ©é˜µ

        for local_index in range(len(local_models)):
            f = open(os.path.join(os.path.dirname(__file__), &quot;weights_&quot; +
                                  str(local_index) + &quot;.txt&quot;), &quot;a&quot;, encoding=&quot;utf-8&quot;)
            for i in local_models[local_index][0]:
                line = &quot;&quot;
                arr = list(i)

                for j in arr:
                    line += (str(j) + &quot;\t&quot;)

                print(line, file=f)

            print(&quot;***&quot; + str(learning_rate) + &quot;***&quot;, file=f)
            print(&quot;-&quot; * 50, file=f)
            f.close()
            f = open(os.path.join(os.path.dirname(__file__), &quot;bias_&quot; +
                                  str(local_index) + &quot;.txt&quot;), &quot;a&quot;, encoding=&quot;utf-8&quot;)
            line = &quot;&quot;
            for i in local_models[local_index][1]:
                line += (str(i) + &quot;\t&quot;)
            print(line, file=f)
            print(&quot;***&quot; + str(learning_rate) + &quot;***&quot;, file=f)
            print(&quot;-&quot; * 50, file=f)
            f.close()
        m_w = np.zeros([784, 10], dtype=np.float32)
        m_b = np.zeros([10], dtype=np.float32)
        for local_model_index in range(len(local_models)):
            m_w = np.add(np.multiply(
                local_models[local_model_index][0], 1 / NUM_AGENT), m_w)
            m_b = np.add(np.multiply(
                local_models[local_model_index][1], 1 / NUM_AGENT), m_b)
            model = {
                'weights': m_w,
                'bias': m_b
            }

        f_g = open(os.path.join(os.path.dirname(
            __file__), &quot;gradientplus_models&quot; + str(round_num) + &quot;.txt&quot;), &quot;a&quot;)
        g_w = list(model['weights'].reshape(-1))
        g_b = list(model['bias'].reshape(-1))

        print(g_w, file=f_g)
        print(g_b, file=f_g)
        f_g.close()
        f = open(os.path.join(os.path.dirname(__file__),
                              &quot;initial_model_parameters&quot; + str(round_num-1) + &quot;.txt&quot;), &quot;w&quot;)
        f.close()
        f = open(os.path.join(os.path.dirname(__file__),
                              &quot;initial_model_parameters&quot; + str(round_num-1) + &quot;.txt&quot;), &quot;a&quot;)
        s = &quot;&quot;
        for i in list(model['weights']):
            for j in i:
                s += str(j)+&quot;\t&quot;
        s = s[0:-1]

        print(s, file=f)

        s = &quot;&quot;
        for i in list(model['bias']):
            s += str(i)+&quot;\t&quot;
        s = s[0:-1]
        print(s, file=f)

        f.close()
        learning_rate = learning_rate * 0.9
        loss = federated_eval(model, federated_train_data)
        print('round {}, loss={}'.format(round_num, loss))
        print(time.time() - start_time)
        shapstart_time = time.time()  #change cal time
        gradient_weights = []
        gradient_biases = []
        gradient_lrs = []
        for ij in range(NUM_AGENT):
            model_ = getParmsAndLearningRate(ij)
            gradient_weights_local = []
            gradient_biases_local = []
            learning_rate_local = []

            for i in range(len(model_['learning_rate'])):
                if i == 0:
                    gradient_weight = np.divide(np.subtract(initial_model['weights'], model_['weights'][i]),
                                                model_['learning_rate'][i])
                    gradient_bias = np.divide(np.subtract(initial_model['bias'], model_['bias'][i]),
                                              model_['learning_rate'][i])
                else:
                    gradient_weight = np.divide(np.subtract(model_['weights'][i - 1], model_['weights'][i]),
                                                model_['learning_rate'][i])
                    gradient_bias = np.divide(np.subtract(model_['bias'][i - 1], model_['bias'][i]),
                                              model_['learning_rate'][i])
                gradient_weights_local.append(gradient_weight)
                gradient_biases_local.append(gradient_bias)
                learning_rate_local.append(model_['learning_rate'][i])

            gradient_weights.append(gradient_weights_local)
            gradient_biases.append(gradient_biases_local)
            gradient_lrs.append(learning_rate_local)

        all_sets = PowerSetsBinary([i for i in range(NUM_AGENT)])

        models_hository = loadHistoryModels(round_num)
        agent_shapley_history = []
        for iter_num in range(1, len(gradient_weights[0]) + 1):
            group_shapley_value = []
            for s in all_sets:
                group_shapley_value.append(
                    train_with_gradient_and_valuation(s, gradient_weights, gradient_biases, gradient_lrs, DISTRIBUTION_TYPE,
                                                      iter_num, models_hository[iter_num-1]))
                print(str(s) + &quot;\t&quot; +
                      str(group_shapley_value[len(group_shapley_value) - 1]))

            agent_shapley = []
            for index in range(NUM_AGENT):
                shapley = 0.0
                for j in all_sets:
                    if index in j:
                        remove_list_index = remove_list_indexed(
                            index, j, all_sets)
                        if remove_list_index != -1:
                            shapley += (group_shapley_value[shapley_list_indexed(j, all_sets)] - group_shapley_value[
                                remove_list_index]) / (comb(NUM_AGENT - 1, len(all_sets[remove_list_index])))
                agent_shapley.append(shapley)
            
            f = open(os.path.join(os.path.dirname(__file__),
                                  &quot;alice&quot; + &quot;.txt&quot;), &quot;a&quot;)

            print('round {}, loss={}'.format(round_num, agent_shapley), file=f)

            agent_shapley_history.append(agent_shapley)
            print('round {}, loss={}'.format(
                round_num, agent_shapley_history), file=f)
            f.close()
            print(&quot;end_time shap values&quot;, time.time() - shapstart_time)
    print(&quot;end_time&quot;, time.time() - start_time)
</code></pre>
",7996402,,,,,44233.26042,Adding more layers to neural network,<python><tensorflow><neural-network><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66088323,1,66095636,,44234.54861,,1,253,"<p>I have the following code:</p>
<pre><code>def model_fn():
keras_model = create_keras_model()
 return tff.learning.from_keras_model(
      keras_model,
      input_spec=federated_train_data[0].element_spec,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>In this code, I want to average by sorting 20% of the items corresponding to the loss in descending order.</p>
<pre><code> #server select in the top20% clients
selected_clients_weights = clinet_select(client_weights)
</code></pre>
<p>How can I extract loss for sorting clients?</p>
",15119954,,,,,44235.15347,How can I extract 20% descending loss in this code?,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66182614,1,,,44240.29167,,1,1626,"<p>Here is the cell that needs to be run before starting the tutorial.</p>
<pre><code>#@test {&quot;skip&quot;: true}

# tensorflow_federated_nightly also bring in tf_nightly, which
# can causes a duplicate tensorboard install, leading to errors.
!pip uninstall --yes tensorboard tb-nightly

!pip install --quiet --upgrade tensorflow_federated_nightly
!pip install --quiet --upgrade nest_asyncio
!pip install --quiet tb-nightly  # or tensorboard, but not both

import nest_asyncio
nest_asyncio.apply()
</code></pre>
<p>It is giving out following errors:</p>
<pre><code>ERROR: tensorflow 2.4.1 requires tensorboard~=2.4, which is not installed.
ERROR: tensorflow 2.4.1 has requirement gast==0.3.3, but you'll have gast 0.4.0 which is incompatible.
ERROR: tensorflow 2.4.1 has requirement grpcio~=1.32.0, but you'll have grpcio 1.34.1 which is incompatible.
ERROR: tensorflow 2.4.1 has requirement h5py~=2.10.0, but you'll have h5py 3.1.0 which is incompatible.
ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.
</code></pre>
<p>Need help resolving this. I am not much familiar with libraries and classes on Tensorflow.</p>
",12896561,,,,,44384.65833,Tensorflow Federated tutorial in Google Colab giving errors in the initialization code snippet,<python><tensorflow><tensorflow-federated>,2,2,,,,CC BY-SA 4.0
66206118,1,66212876,,44242.425,,3,633,"<p>I am getting the following error when i would like to migrate from TFF 0.12.0 to TFF 0.18.0,
Knowing that I have an image dataset, Here is my sample_batch</p>
<pre><code>images, labels = next(img_gen.flow_from_directory(path0,target_size=(224, 224), batch_size=2))
sample_batch = (images,labels)
...

def model_fn():

  keras_model = create_keras_model()
  return tff.learning.from_keras_model(
      keras_model,
      input_spec=sample_batch,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])
</code></pre>
<p>So how can I modifiy my sample_batch to be correct with this version ? please Help !! thanks</p>
",14253961,,,,,44242.7375,"TypeError: Expected tensorflow.python.framework.tensor_spec.TensorSpec, found numpy.ndarray",<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66223590,1,,,44243.48125,,1,174,"<p>When I read this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">tutorial</a> of tensorflow federated for image classification, I find <code>.repeat()</code>, I would like to understand the necessity of this preprocess function, especially when I increase the number in <code>.repeat()</code>, simulation takes a lot of time. So, if it is necessary to make <code>.repeat()</code> ,what number of epoch we can choose ?</p>
",12682667,,12682667,,44245.77292,44245.77292,TFF : What is the necessity of .repeat(),<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66259690,1,,,44245.50694,,3,205,"<p>I train a ResNet50 model with TFF, I use test accuracy on test data for evaluation, but I find many fluctuations as shown in the figure below, So please how can I avoid this fluctuation ?</p>
<p><a href=""https://i.sstatic.net/JDtmg.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/JDtmg.png"" alt=""enter image description here"" /></a></p>
",14253961,,14692,,44258.30694,44258.30694,TFF : test accuracy fluctuate,<tensorflow-federated><federated-learning>,2,0,,,,CC BY-SA 4.0
66265109,1,,,44245.72986,,2,562,"<p>I am using Tensorflow Federated to train a text classification model with the federated learning approach.
Is there any way to apply Early Stopping on the client-side? Is there an option for cross-validation in the API?
The only thing I was able to find is the evaluation:</p>
<pre><code>evaluation = tff.learning.build_federated_evaluation(model_fn)
</code></pre>
<p>Which is applied to the model by the end of a federated training round.</p>
<p>Am I missing something?</p>
",9745740,,,,,44247.21319,"Federated Learning in Tensorflow Federated, is there any way to apply Early stopping on the client side?",<tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66277072,1,,,44246.49375,,0,56,"<p>Let's suppose that we started our training with an image dataset of 500 images. So, I would like to know each time we increase the database, we have to increase the number of rounds to achieve good performance?</p>
<p>Thanks for giving me your opinions.</p>
",12682667,,,,,44247.24097,TFF : Is the increase in the size of the dataset proportional to the increase in number of rounds?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66277912,1,66288191,,44246.53542,,1,324,"<p>I use human activity recognition (HAR) dataset with 6 classes using federated learning (FL). In this case, I implement the non-IID dataset by assigning (1) each class dataset to different 6 workers, (2) two classes to 3 different workers, and (3) three classes to 2 different workers.</p>
<p>When I run the FL process, the validation accuracy for scenario (3) &gt; (2) &gt; (1). I expect that all scenarios will obtain almost the same validation accuracy. For each scenario, I use the same hyperparameter settings including batch size, shuffle buffer, and the model configuration.</p>
<p>Is it common in FL with the non-IID dataset or is there any problem with my result?</p>
",10988616,,,,,44247.59306,The validation accuracy gets lower when the number of workers increases in Federated Learning with non-IID dataset,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66288387,1,,,44247.23472,,0,108,"<p>I am trying to customize to average the weights of the clients by seleceting some of the clients based on each client's sorted loss sum in this <a href=""https://github.com/tensorflow/federated/blob/master/tensorflow_federated/python/examples/simple_fedavg/simple_fedavg_tff.py#L113"" rel=""nofollow noreferrer"">link</a>.</p>
<pre><code>def run_one_round(server_state, federated_dataset):
    
    server_message = tff.federated_map(server_message_fn, server_state)
    server_message_at_client = tff.federated_broadcast(server_message)

    client_outputs = tff.federated_map(
        client_update_fn, (federated_dataset, server_message_at_client))

    weight_denom = client_outputs.client_weight

    collected_output = tff.federated_collect(client_outputs)  # append     

    round_model_delta = tff.federated_map(selecting_fn,(collected_output,weight_denom))   #apppend
  
    server_state = tff.federated_map(server_update_fn,(server_state, round_model_delta))

    round_loss_metric = tff.federated_mean(client_outputs.model_output, weight=weight_denom)

    return server_state, round_loss_metric #append

@tff.tf_computation()  # append
def selecting_fn(collected_output,weight_denom):
            ...
            ...
    return round_model_delta
</code></pre>
<p>I'm trying to use <code>tf.math.top_k </code>for sorting and <code>tf.compat.v1.metrics.mean</code> for averaging.
But It doesn't work(TypError, ValueError...).
How can I construct <code>selecting_fn</code> and How to convert tensor to Federatedtype???</p>
",15119954,,,,,44247.23472,How can I construct function for client selection?,<tensorflow-federated>,0,2,,,,CC BY-SA 4.0
66304067,1,66304876,,44248.65486,,0,174,"<p>I am trying to follow this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_text_generation"" rel=""nofollow noreferrer"">tutorial</a> on federated learning TensorFlow and when executing this line I get an error:</p>
<pre><code>train_data, test_data = tff.simulation.datasets.shakespeare.load_data()
</code></pre>
<p>The error:</p>
<pre><code>    Downloading shakespeare.sqlite.lzma:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1048576/1329828 [00:00&lt;00:00, 12187174.26it/s]
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
&lt;ipython-input-12-f8f1fc62c096&gt; in &lt;module&gt;()
----&gt; 1 train_data, test_data = tff.simulation.datasets.shakespeare.load_data()

4 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py in _prewrite_check(self)
     86                                            &quot;File isn't open for writing&quot;)
     87       self._writable_file = _pywrap_file_io.WritableFile(
---&gt; 88           compat.path_to_bytes(self.__name), compat.as_bytes(self.__mode))
     89 
     90   def _prepare_value(self, val):

NotFoundError: /root/.tff/shakespeare.sqlite; No such file or directory
</code></pre>
<p><a href=""https://i.sstatic.net/7OWh2.png"" rel=""nofollow noreferrer"">enter image description here</a></p>
",8421958,,,,,44248.71458,Error while executing federated learning text generation tutorial in Colab,<tensorflow><google-colaboratory><tensorflow-datasets><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66309222,1,66309851,,44249.09444,,2,117,"<p>There are the following attributes in <code>client_output</code></p>
<pre><code>weights_delta = attr.ib()
client_weight = attr.ib()
model_output = attr.ib()
client_loss = attr.ib() 
</code></pre>
<p>After that, I made the <code>client_output</code> in the form of a sequence through
<code>a = tff.federated_collect(client_output)</code> and <code>round_model_delta = tff.federated_map(selecting_fn,a)</code>in <a href=""https://github.com/tensorflow/federated/blob/b13046fa47b2eab4f38c37fc41d7fba64f192bb1/tensorflow_federated/python/examples/simple_fedavg/simple_fedavg_tff.py#L131"" rel=""nofollow noreferrer"">here</a> . and I declared
`</p>
<pre><code>@tff.tf_computation()  # append
def selecting_fn(a):
    #TODO
    return round_model_delta
</code></pre>
<p>in <a href=""https://github.com/tensorflow/federated/blob/b13046fa47b2eab4f38c37fc41d7fba64f192bb1/tensorflow_federated/python/examples/simple_fedavg/simple_fedavg_tff.py#L107"" rel=""nofollow noreferrer"">here</a>. In the process of averaging on the server, I want to average the <code>weights_delta</code> by selecting some of the clients with a small loss value. So I try to access it via <code>a.weights_delta</code> but it doesn't work.</p>
",15119954,,15119954,,44250.45556,44250.45556,How can I access value in sequence type?,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66331850,1,66363417,,44250.45833,,2,347,"<p>Based on this <a href=""https://github.com/tensorflow/federated/tree/3c0852c5fef375198f5931ce31fd97f2df9c4d05/tensorflow_federated/python/examples/simple_fedavg"" rel=""nofollow noreferrer"">link</a> I am trying to write a new way of FL algorithm. I train all clients and send the model parameters of all clients to the server, and the server will weight average only the model parameters of 30% of all clients during the aggregation process. As a criterion for selecting model parameters of 30% of clients, I want to do a weighted average by using <code>weights_delta</code> of 30% of clients with less <code>loss_sum</code> of clients.</p>
<p>The code below is a modified code for this <a href=""https://github.com/tensorflow/federated/blob/3c0852c5fef375198f5931ce31fd97f2df9c4d05/tensorflow_federated/python/examples/simple_fedavg/simple_fedavg_tf.py#L191"" rel=""nofollow noreferrer"">link</a>.</p>
<pre><code>@tf.function
def client_update(model, dataset, server_message, client_optimizer):

model_weights = model.weights
initial_weights = server_message.model_weights
tff.utils.assign(model_weights, initial_weights)

num_examples = tf.constant(0, dtype=tf.int32)
loss_sum = tf.constant(0, dtype=tf.float32)

for batch in iter(dataset):
    with tf.GradientTape() as tape:
        outputs = model.forward_pass(batch)
    grads = tape.gradient(outputs.loss, model_weights.trainable)
    grads_and_vars = zip(grads, model_weights.trainable)
    client_optimizer.apply_gradients(grads_and_vars)
    batch_size = tf.shape(batch['x'])[0]
    num_examples += batch_size
    loss_sum += outputs.loss * tf.cast(batch_size, tf.float32)        

weights_delta = tf.nest.map_structure(lambda a, b: a - b,
                                      model_weights.trainable,
                                      initial_weights.trainable)
client_weight = tf.cast(num_examples, tf.float32)

client_loss = loss_sum #add

return ClientOutput(weights_delta, client_weight, loss_sum / client_weight,client_loss) 
</code></pre>
<p>There are the following attributes in <code>client_output</code></p>
<pre><code>weights_delta = attr.ib()
client_weight = attr.ib()
model_output = attr.ib()
client_loss = attr.ib() 
</code></pre>
<p>After that, I made the <code>client_output</code> in the form of a sequence through
<code>collected_output = tff.federated_collect(client_output)</code> and <code>round_model_delta = tff.federated_map(selecting_fn,(collected_output,weight_denom))</code>in <a href=""https://github.com/tensorflow/federated/blob/b13046fa47b2eab4f38c37fc41d7fba64f192bb1/tensorflow_federated/python/examples/simple_fedavg/simple_fedavg_tff.py#L111"" rel=""nofollow noreferrer"">here</a> .</p>
<pre><code>   @tff.federated_computation(federated_server_state_type,
                           federated_dataset_type)

    def run_one_round(server_state, federated_dataset):
    
    server_message = tff.federated_map(server_message_fn, server_state)
    server_message_at_client = tff.federated_broadcast(server_message)

    client_outputs = tff.federated_map(
        client_update_fn, (federated_dataset, server_message_at_client))

    weight_denom = client_outputs.client_weight

    collected_output = tff.federated_collect(client_outputs)  # add        
    
    round_model_delta = tff.federated_map(selecting_fn,(collected_output,weight_denom)) #add       

    server_state = tff.federated_map(server_update_fn,(server_state, round_model_delta))

    round_loss_metric = tff.federated_mean(client_outputs.model_output, weight=weight_denom)

    return server_state, round_loss_metric
</code></pre>
<p>Also, the following code is added <a href=""https://github.com/tensorflow/federated/blob/3c0852c5fef375198f5931ce31fd97f2df9c4d05/tensorflow_federated/python/examples/simple_fedavg/simple_fedavg_tff.py#L107"" rel=""nofollow noreferrer"">here</a> to implement the <code>selecting_fn</code> function.</p>
<pre><code>@tff.tf_computation()  # append
def selecting_fn(collected_output,weight_denom):
    #TODO
    return round_model_delta
</code></pre>
<p>I am not sure if it is correct to write the code in the above way.
I tried in various ways, but mainly <code>TypeError: The value to be mapped must be a FederatedType or implicitly convertible to a FederatedType (got a &lt;&lt;model_weights=&lt;trainable=&lt;float32[5,5,1,32],float32[32] ,float32[5,5,32,64],float32[64],float32[3136,512],float32[512],float32[512,10],float32[10]&gt;,non_trainable=&lt;&gt;&gt;,optimizer_state= &lt;int64&gt;,round_num=int32&gt;@SERVER,{&lt;float32[5,5,1,32],float32[32],float32[5,5,32,64],float32[64],float32[3136,512 ],float32[512],float32[512,10],float32[10]&gt;}@CLIENTS&gt;)</code> I get this error.</p>
<p>I wonder how the sequence type <code>collected_output</code> accesses each client's <code>client_loss(= loss_sum)</code> and sorts them, and also wonders what method to use when calculating the weighted average with <code>weight_denom</code> applied.</p>
",15119954,,,,,44252.26736,How do I create an FL algorithm that uses the weights of a few clients?,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66354417,1,67130017,,44251.66597,,1,79,"<p><a href=""https://i.sstatic.net/XyOXC.png"" rel=""nofollow noreferrer""><img src=""https://i.sstatic.net/XyOXC.png"" alt="""" /></a></p>
<p><code>collected_output=tff.federated_collect(client_outputs)</code>.
Please refer to this <a href=""https://stackoverflow.com/questions/66331850/how-do-i-create-an-fl-algorithm-that-uses-the-weights-of-a-few-clients"">question</a> for detailed code.</p>
<p>My question is the difference between the parts marked in red on the photo. In terms of the FL algorithm, I think <code>client_outputs</code> is a individual client' output and <code>collected_output</code> is <code>SequenceType</code> because each <code>client_outputs</code> is combined. Is this correct? If my guess is correct, is <code>member</code> a set of individual client members with <code>client_outputs</code>?</p>
",15119954,,,,,44302.74444,TFF: What is difference between two type?,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66395599,1,,,44254.18611,,0,407,"<p>I plan to use federated learning for an object detection algorithm I already developed for detecting weeds.
As I research, I see federated tensorflow examples on Image classification. Like the following link:
<a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification</a></p>
<p>My question is can we use federated learning and federated tensorflow for object detection algorithms?
If yes, would you please provide me with some links and examples?</p>
",8617125,,,,,44291.03958,Using federated learning for object detection,<object-detection><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66413948,1,66444249,,44255.88958,,1,142,"<p>I'm trying to train a differentially private federated model using EMNIST dataset, I have attached the <code>DP-Query</code> to the <code>aggregation_process</code>. Moreover, I'm resembling the <code>DP-FedAvg</code> algorithm by using <code>SGD</code> as both client and server optimizer with server learning rate set to 1.</p>
<p>The query is:</p>
<pre><code>dp_query = tff.utils.build_dp_query(
    clip=0.6
    noise_multiplier=1.2,
    expected_total_weight=100,
    adaptive_clip_learning_rate=0,
    target_unclipped_quantile=0.5,
    clipped_count_budget_allocation=0.1,
    expected_clients_per_round=100
)

</code></pre>
<p>What type of clipping does this query perform, is it <em>batch clipping</em>, or <em>per example clipping</em>?</p>
<p>In <code>TFP</code>, the option to use the per example clipping was to set the <code>num_microbatches</code> to <code>None</code> so it defaults to the <code>batch_size</code>.</p>
<p>How can I do something similar here, and switch between the batch clipping and per example clipping in Federated settings?</p>
",15092004,,15092004,,44256.83611,44257.72847,Per example clipping in TensorFlow Federated with DP-FedAvg,<tensorflow><tensorflow2.0><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
76192353,1,,,45053.23542,,0,43,"<p>Can anybody help me to replace this function? I am getting error for these code:</p>
<pre><code>tff.learning.assign_weights_to_keras_model(eval_model, state.model)
</code></pre>
",4885372,,,,,45240.59097,"Couldn't get any new function for ""module 'tensorflow_federated.python.learning' has no attribute 'assign_weights_to_keras_model'""",<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
76232799,1,,,45058.11181,,0,219,"<p>I am trying to install Tensorflow Federated on Google Colab but am getting error. Surprisingly, if I open new notebook, I can install Tensorflow Federated. Can anyone please help me?</p>
<p>However I used <code>!pip install --quiet --upgrade tensorflow-federated</code> too.</p>
<pre><code>ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
arviz 0.15.1 requires scipy&gt;=1.8.0, but you have scipy 1.7.3 which is incompatible.
chex 0.1.7 requires jax&gt;=0.4.6, but you have jax 0.3.15 which is incompatible.
flax 0.6.9 requires jax&gt;=0.4.2, but you have jax 0.3.15 which is incompatible.
google-colab 1.0.0 requires portpicker~=1.3.1, but you have portpicker 1.5.2 which is incompatible.
orbax-checkpoint 0.2.1 requires jax&gt;=0.4.8, but you have jax 0.3.15 which is incompatible.
pymc 5.1.2 requires cachetools&gt;=4.2.1, but you have cachetools 3.1.1 which is incompatible.
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
&lt;ipython-input-4-343245986933&gt; in &lt;cell line: 18&gt;()
     16 
     17 import tensorflow as tf
---&gt; 18 import tensorflow_federated as tff
     19 
     20 import collections

10 frames
/usr/local/lib/python3.10/dist-packages/attr/__init__.py in __getattr__(name)

IndexError: list index out of range
</code></pre>
",4885372,,4885372,,45067.04514,45067.04514,Getting error to install tensorflow federated on Colab like IndexError,<python><tensorflow><google-colaboratory><tensorflow-federated>,0,2,,,,CC BY-SA 4.0
76407619,1,,,45082.61528,,0,174,"<p>I'm doing federated learning with tensorflow federated</p>
<pre><code>for round_num in range(5):
    state, metrics = trainer.next(state, federated_train_data)
    print('Round {r}, Metrics: {m}'.format(r=round_num, m=metrics))

</code></pre>
<p>this is my code and it's give this error</p>
<pre><code>ValueError: Serialized size of Dataset (537613688 bytes) exceeds maximum allowed (104857600 bytes)
</code></pre>
<p>I have try the following code to increase the limit but the function doesn't exist anymore in the tensorflow federated version 0.58</p>
<pre><code>tf.data.experimental.serialization.set_serialization_options(
    total_bytes_limit=1073741824
)

</code></pre>
",15624337,,,,,45145.52917,Tensorflow federated increase default_serialization_limit_bytes,<serialization><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
76450661,1,,,45088.55625,,1,197,"<p>i try to install <strong>Tensorflow federated</strong> but it won't install</p>
<p>by using <code>pip install --upgrade tensorflow-federated</code> in Command Prompt it start to download version 0.48.0
but it says its trying to find a compatible version and starts to download all version down to 0.17.0, then <code>error: subprocess-exited-with-error</code> will rise</p>
<p>i have python 3.10.11(no anaconda or similar app)</p>
<p>anybody knows what should i do?</p>
<p><a href=""https://i.sstatic.net/4iEju.png"" rel=""nofollow noreferrer"">Command Prompt error picture</a></p>
",21716810,,,,,45088.55625,Tensorflow Federated - can't install,<python><tensorflow><tensorflow-federated>,0,0,,,,CC BY-SA 4.0
76716812,1,,,45125.92292,,0,43,"<p>So I'm creating a recommendation system using this Federated Reconstruction tutorial on Tensorflow Federated. I want to use and extract the model and the modelweights but I run into some problems. I get attribute errors whenever I try saving a model or modelweight saying 'ModelWeights doesn't have 'save' function' etc. Is there anyway I can save the model weights so I can build it onto a DNN or Sequential Model?</p>
<p>Source Code: <a href=""https://www.tensorflow.org/federated/tutorials/federated_reconstruction_for_matrix_factorization"" rel=""nofollow noreferrer"">https://www.tensorflow.org/federated/tutorials/federated_reconstruction_for_matrix_factorization</a></p>
<p>I tried model.save(), model_weights.save_weights(), model.save_weights()</p>
",22248957,,,,,45125.92292,Extracting a Federated Reconstruction Model and its Weights,<python-3.x><tensorflow><neural-network><model><tensorflow-federated>,0,2,,,,CC BY-SA 4.0
66451298,1,66534607,,44258.23056,,1,118,"<p>I'm performing few experiments with <code>TFF</code>. In this one, I would like to sample the participating clients at each training around according to <code>poisson subsampling</code> where each client is sampled with a probability of <code>p = users_per_round / num_users</code></p>
<p>At each round, <code>poisson subsampling</code> is performed until the list <code>sampled_ids</code> is filled with <em>unique ids</em> equal to the number of <code>users_per_round</code>.</p>
<pre class=""lang-py prettyprint-override""><code>total_rounds = 100
num_users = 500
users_per_round = 150
lambda_value = np.random.rand()

for round_num in range(total_rounds):

   sampled_ids = []

   while len(sampled_ids) &lt; users_per_round:

      subsampling = np.random.poisson(lambda_value, num_users)
      whether = subsampling &gt; 1 - users_per_round / num_users
      for i in np.arange(num_users):
          if whether[i] and len(sampled_ids) &lt; users_per_round and i 
             not in sampled_ids:
                  sampled_ids.append(i)


  sampled_clients = [train_data.client_ids[i] for i in sampled_ids]

  sampled_train_data = 
     [train_data.create_tf_dataset_for_client(client) for client in 
         sampled_clients]

  server_state, train_metrics = iterative_process.next(server_state, 
                                                 sampled_train_data)

</code></pre>
<p>Is there a better way of performing <code>poisson subsampling</code>, especially if the subsampling is applied in <code>differentially private FL</code>, so that the <code>RDP accountant</code> yields accurate privacy analysis results ?</p>
<p>What would be the best strategy to set the value of <code>lambda</code> other than <code>random</code> values ?</p>
",15092004,,15092004,,44258.32083,44264.93958,Federating learning process with poisson subsampling of participants,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66472157,1,,,44259.39375,,2,1624,"<p>I am working with federated learning. I am using a global server where I defined a cnn based classifier. The global server compiles the model with hyper-parameters and send it to the edge(clients), currently I am using two clients. Each client uses its local data (for now I am using same data, and model on each client). After training model, each client has above 95 percent accuracy, precision and recall in their local models. clients sends their trained  local model to the server. The server gets the model and and gets the weights from each received model and computes average according to <a href=""https://i.sstatic.net/iZxZr.png."" rel=""nofollow noreferrer"">this formula</a>. Below is the code I wrote to implement this formula in python. when I set the average weights to  models and try to predict, the accuracy, recall and precision fall below 20%.</p>
<p>Am I doing something wrong in implementation?</p>
<pre><code># initial weights of global model, set to zer0.  
  ave_weights=model.get_weights()
  ave_weights=[i * 0 for i in ave_weights]
  count=0
# Multithreaded Python server : TCP Server Socket Thread Pool
def ClientThread_send(conn,address,weights):
    # send model to client
    conn.send(model)

    print(&quot;Model Sent to :&quot;,address)
    print(&quot;waiting for weights&quot;)
    model_recv=conn.recv(1024)
    print(&quot;weights received from:&quot;,address)
    global count
    global ave_weights

    
    #receive weights from clients
    rec_weight=model.get_weights()
    #multiply the client weights by number of local data samples in client local data
    rec_weight=  [i * 100000 for i in rec_weight]
    # divide the weights by total number of samples of all participants
    rec_weight=  [i / 200000 for i in rec_weight]

    #sum the weights of all clients
    ave_weights=[x + y for x, y in zip(ave_weights,rec_weight)]
  
    count=count+1
    conn.close()
if count==2:
    # set the global model weights if the count(number of clients is two)
    model.set_weights(ave_weights)


 while True:
     conn, address = s.accept()
     start_new_thread(ClientThread_send,(conn,address,ave_weights))   
     
</code></pre>
",15313719,,4685471,,44259.39514,44393.63264,Federated averaging implementation in python,<python><machine-learning><artificial-intelligence><conv-neural-network><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
76750150,1,,,45130.84444,,0,91,"<p>In federated learning, I want to get weights of each local model every round, then I will cluster local clients based on their weights, but I can just use training_process.get_model_weights(train_state) to get global weights only.</p>
<p>I did use training_process.get_model_weights(train_state) to get global weights, but I haven't found any library or function to get weights of each clients yet.</p>
",22273170,,,,,45133.03264,Is there an library to get weights of each local model every round of Federated Learning?,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
76827472,1,,,45141.45972,,0,71,"<p>How can I obtain F1score, Recall, Confusion Matrix and precison in this code.I have used compile and obtained accuracy but i dont know how write the code to obtain these metrics from my model.I would be thankful te help me.
for comm_round in range(comms_round):</p>
<pre><code>global_weights = global_model.get_weights()

scaled_local_weight_list = list()

client_names= list(clients_batched.keys())
random.shuffle(client_names)

for client in client_names:
    local_model = Transformer
    local_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),
                        optimizer=tf.keras.optimizers.Adam(learning_rate = 0.001),
                        metrics='acc')

    global_model.set_weights(global_weights)

    local_model.set_weights(global_weights)

    history = local_model.fit(clients_batched[client], epochs=1, verbose=0, callbacks=[checkpoint_callback])

    scaling_factor = weight_scalling_factor(clients_batched, client)
    scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)
    scaled_local_weight_list.append(scaled_weights)

    K.clear_session()

average_weights = sum_scaled_weights(scaled_local_weight_list)

global_model.set_weights(average_weights)

for(X_test, Y_test) in test_batched:
    global_acc, global_loss = test_model(test_x, test_y, global_model, comm_round + 1)
</code></pre>
<p>Also I want to graph the performance of the model on the train and test sets recorded during training using a line plot, one for each of the loss and the classification accuracy.</p>
",19940495,,,,,45142.46944,"Obtain F1score, Recall, Confusion Matrix and precison",<matplotlib><keras><precision-recall><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
77116019,1,,,45185.05556,,0,569,"<p>Attempting to run federated learning on tff however, encountering the following:</p>
<p>AttributeError: module 'tensorflow_federated.python.learning' has no attribute 'from_keras_model'</p>
<p>Code:
trainer = tff.learning.algorithms.build_weighted_fed_avg(
model_fn,
client_optimizer_fn=lambda: tf.keras.optimizers.Adam(),
server_optimizer_fn=lambda: tf.keras.optimizers.Adam()
)</p>
<p>state = trainer.initialize()
train_hist = []
for i in range(EPOCHS):
state, metrics = trainer.next(state, train_data)
train_hist.append(metrics)</p>
<pre><code>print(f&quot;\rRun {i+1}/{EPOCHS}&quot;, end=&quot;&quot;)
</code></pre>
<p>Environment:
Using Google collab
python - 3.10.12
TensorFlow Federated version: 0.61.0</p>
<p>Any help appreciated.</p>
<p>Attempted to downgrade version of TFF</p>
",22572421,,,,,45605.63194,AttributeError: module 'tensorflow_federated.python.learning' has no attribute 'from_keras_model',<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
77244883,1,,,45205.5625,,0,150,"<p>I am trying to execute tensorflow federated &quot;Hello world&quot; in jupyter notebook on Visual Studio Code, however the code freezes and doesn't display anything.</p>
<p>Here is the code:</p>
<pre><code>import tensorflow as tf
import tensorflow_federated as tff

import nest_asyncio
nest_asyncio.apply()

print(tff.federated_computation(lambda: 'Hello, World!')())
</code></pre>
<p>Output looks something like:</p>
<pre><code>2023-10-06 06:34:20.644234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2023-10-06 06:34:20.644271: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)
2023-10-06 06:34:20.644299: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ab1clmll01): /proc/driver/nvidia/version does not exist
2023-10-06 06:34:20.644609: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2023-10-06 06:34:20.645058: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
</code></pre>
<p>Below are package version details:</p>
<ul>
<li>python: 3.9.16</li>
<li>tensorflow_federated: 0.48.0</li>
<li>tensorflow: 2.11.1</li>
<li>notebook: 7.0.4</li>
</ul>
<p>Can anyone suggest how can this be corrected?</p>
",7420991,,,,,45205.58125,"Unsuccessfully running tensorflow federated ""Hello world"" example",<tensorflow><jupyter-notebook><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66546336,1,,,44264.49306,,1,151,"<p>In the federated learning context, and like this <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">tutorial</a> shows, initial weights of global model (at server level) are initialized randomly with : <code> state = iterative_process.initialize()</code>. I want to have the hand to put these initial weights by downloading them from another model (<code>load_model()</code>). So please how can I proceed, I'm newer in TFF.
Thanks</p>
",14253961,,,,,44299.04167,the initialize computation to construct the server state,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66557738,1,66751811,,44265.125,,3,306,"<p>I'm running FL algorithm following the <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">image classification</a> tutorial. The number of participants vary at each round according to a predefined list of participants number.</p>
<pre class=""lang-py prettyprint-override""><code>number_of_participants_each_round = 
[108, 113, 93, 92, 114, 101, 94, 93, 107, 99, 118, 101, 114, 111, 88, 
101, 86, 96, 110, 80, 118, 84, 91, 120, 110, 109, 113, 96, 112, 107, 
119, 91, 97, 99, 97, 104, 103, 120, 89, 100, 104, 104, 103, 88, 108]

</code></pre>
<p>The federated data is preprocessed and batched before starting the training.</p>
<pre class=""lang-py prettyprint-override""><code>
NUM_EPOCHS = 5
BATCH_SIZE = 20
SHUFFLE_BUFFER = 418
PREFETCH_BUFFER = 10

def preprocess(dataset):
    def batch_format_fn(element):
        return collections.OrderedDict(
            x=tf.reshape(element['pixels'], [-1, 784]),
            y=tf.reshape(element['label'], [-1, 1]))

    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(
        BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)


def make_federated_data(client_data, client_ids):
    return [preprocess(client_data.create_tf_dataset_for_client(x)) for x in client_ids]

federated_train_data = make_federated_data(data_train, data_train.client_ids)

</code></pre>
<p>Participants are randomly sampled from <code>federated_train_data[0:expected_total_clients]</code> at each round according to the <code>number_of_participants_each_round</code>, then the <code>iterative_process</code> is executed for <code>45 rounds</code>.</p>
<pre class=""lang-py prettyprint-override""><code>expected_total_clients = 500
round_nums = 45

for round_num in range(0, round_nums):
   sampled_clients = 
       np.random.choice(a=federated_train_data[0:expected_total_clients],                          
                        size=number_of_participants_each_round[round_num], 
                        replace=False)
    
   state, metrics = iterative_process.next(state, list(sampled_clients))
   print('round {:2d}, metrics={}'.format(round_num + 1, metrics))

</code></pre>
<p>The problem is that the <code>VRAM</code> usage quickly explodes after few rounds, it reaches <code>5.5 GB</code> at round <code>6~7</code>, and keeps increasing with an approx rate of <code>0.8 GB/round</code> until the training eventually crashes at round <code>25~26</code> where the VRAM reaches <code>17 GB</code> with <code>+4000</code> python threads created.</p>
<p>Error message below</p>
<pre class=""lang-py prettyprint-override""><code>F tensorflow/core/platform/default/env.cc:72] Check failed: ret == 0 (35 vs. 0)Thread creation via pthread_create() failed.
</code></pre>
<p><strong>### Troubleshooting ###</strong></p>
<p>Reducing the <code>number_of_participants_each_round</code> to <code>20</code> allows the training to complete, but the memory consumption was still huge and growing.</p>
<p>Running the same code with fixed number of participants per round, memory consumption was fine with total of approx <code>1.5 ~ 2.0 GB</code> VRAM throughout the entire training.</p>
<pre class=""lang-py prettyprint-override""><code>expected_total_clients = 500
fixed_client_size_per_round = 100
round_nums = 45

for round_num in range(0, round_nums):
   sampled_clients =
      np.random.choice(a=federated_train_data[0:expected_total_clients],
                       size=fixed_client_size_per_round,
                       replace=False)
    
    state, metrics = iterative_process.next(state, list(sampled_clients))
    print('round {:2d}, metrics={}'.format(round_num + 1, metrics))
</code></pre>
<p>Extra details:</p>
<pre><code>OS: MacOS Mojave, 10.14.6
python -V: Python 3.8.5 then downgraded to Python 3.7.9
TF version: 2.4.1
TFF version: 0.18.0
Keras version: 2.4.3
</code></pre>
<p>Is this a normal memory behaviour or a <code>bug</code>? Are there any refactoring/hints to optimize memory consumption ?</p>
",15092004,,15092004,,44265.84514,44277.76667,Exploding memory consumption when training FL model with varying number of participants per round,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
66579541,1,,,44266.3875,,2,259,"<p>I'm new in Federated learning, I tried to implement the code of FL for image classification, but I can't understand this line : <code>state = iterative_process.initialize() </code>, Weights affected to the server from where ?</p>
",14253961,,,,,44290.32778,What state = iterative_process.initialize() dow in Federated learning,<tensorflow-federated><federated-learning>,1,2,,,,CC BY-SA 4.0
66581075,1,,,44266.45208,,2,1618,"<p>I implement the code of TFF of image classification. TFF version 0.18.0,
I write this :</p>
<pre><code>iterative_process = tff.learning.build_federated_averaging_process(model_fn, server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0), client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.001))

state = iterative_process.initialize()
</code></pre>
<p>But I find this warning:</p>
<pre><code>WARNING:tensorflow:AutoGraph could not transform &lt;function &lt;lambda&gt; at 0x7fca141a6d08&gt; and will run it as-is.
Cause: could not parse the source code of &lt;function &lt;lambda&gt; at 0x7fca141a6d08&gt;: found multiple definitions with identical signatures at the location. This error may be avoided by defining each lambda on a single line and with unique argument names.
Match 0:
(lambda : tf.keras.optimizers.SGD(learning_rate=1.0))

Match 1:
(lambda : tf.keras.optimizers.SGD(learning_rate=0.001))

To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
</code></pre>
<p>So please how can I avoid this warning. Thanks</p>
",14253961,,,,,44291.03125,WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fca141a6d08> and will run it as-is,<tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
66705900,1,,,44274.40903,,4,1063,"<p>I want install Tensorflow Federated in a macOS with Apple Silicon M1.</p>
<p>I have tried installing Python 3.9.1 with pyenv and create a virtual environment. Then I installed the package.</p>
<pre class=""lang-sh prettyprint-override""><code>pip install tensorflow-federated
</code></pre>
<p>Some errors raised because of dependency conflict when installed Tensorflow Federated. You can see partial of error logs below:</p>
<pre><code>...

    clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly
    clang: error: the clang compiler does not support 'faltivec', please use -maltivec and include altivec.h explicitly
    error: Command &quot;clang -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/Library/Developer/CommandLineTools/SDKs/MacOSX.sdk/usr/include -I/opt/homebrew/opt/openssl/include -I/opt/homebrew/opt/readline/include -DNPY_INTERNAL_BUILD=1 -DHAVE_NPY_CONFIG_H=1 -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE=1 -D_LARGEFILE64_SOURCE=1 -DNO_ATLAS_INFO=3 -DHAVE_CBLAS -Ibuild/src.macosx-11.2-arm64-3.9/numpy/core/src/umath -Ibuild/src.macosx-11.2-arm64-3.9/numpy/core/src/npymath -Ibuild/src.macosx-11.2-arm64-3.9/numpy/core/src/common -Inumpy/core/include -Ibuild/src.macosx-11.2-arm64-3.9/numpy/core/include/numpy -Inumpy/core/src/common -Inumpy/core/src -Inumpy/core -Inumpy/core/src/npymath -Inumpy/core/src/multiarray -Inumpy/core/src/umath -Inumpy/core/src/npysort -I/Users/user/projects/ucloud/federated/venv/include -I/Users/user/.pyenv/versions/3.9.1/include/python3.9 -Ibuild/src.macosx-11.2-arm64-3.9/numpy/core/src/common -Ibuild/src.macosx-11.2-arm64-3.9/numpy/core/src/npymath -c numpy/core/src/multiarray/array_assign_scalar.c -o build/temp.macosx-11.2-arm64-3.9/numpy/core/src/multiarray/array_assign_scalar.o -MMD -MF build/temp.macosx-11.2-arm64-3.9/numpy/core/src/multiarray/array_assign_scalar.o.d -faltivec -I/System/Library/Frameworks/vecLib.framework/Headers&quot; failed with exit status 1
    ----------------------------------------
    ERROR: Failed building wheel for numpy
  Failed to build numpy
  ERROR: Could not build wheels for numpy which use PEP 517 and cannot be installed directly
  ----------------------------------------
WARNING: Discarding https://files.pythonhosted.org/packages/15/fb/86d26128a5ea42d20f402109e76a63e59845d73171887a08a43a28b847dc/h5py-3.0.0.tar.gz#sha256=7d3803be1b530c68c2955faba726dc0f591079b68941a0c0269b5384a42ab519 (from https://pypi.org/simple/h5py/) (requires-python:&gt;=3.6). Command errored out with exit status 1: /Users/user/projects/ucloud/federated/venv/bin/python /Users/user/projects/ucloud/federated/venv/lib/python3.9/site-packages/pip install --ignore-installed --no-user --prefix /private/var/folders/14/3fhr7hps0yvfd43qp60rbw480000gn/T/pip-build-env-9ws6euzt/normal --no-warn-script-location --no-binary :none: --only-binary :none: -i https://pypi.org/simple -- 'numpy==1.12; python_version == &quot;3.6&quot;' pkgconfig 'numpy==1.19.3; python_version &gt;= &quot;3.9&quot;' 'numpy==1.14.5; python_version == &quot;3.7&quot;' 'numpy==1.17.5; python_version == &quot;3.8&quot;' 'Cython&gt;=0.29.14; python_version &gt;= &quot;3.8&quot;' 'Cython&gt;=0.29; python_version &lt; &quot;3.8&quot;' Check the logs for full command output.
ERROR: Cannot install tensorflow-federated==0.1.0, tensorflow-federated==0.10.0, tensorflow-federated==0.10.1, tensorflow-federated==0.11.0, tensorflow-federated==0.12.0, tensorflow-federated==0.13.0, tensorflow-federated==0.13.1, tensorflow-federated==0.14.0, tensorflow-federated==0.15.0, tensorflow-federated==0.16.0, tensorflow-federated==0.16.1, tensorflow-federated==0.17.0, tensorflow-federated==0.18.0, tensorflow-federated==0.2.0, tensorflow-federated==0.3.0, tensorflow-federated==0.4.0, tensorflow-federated==0.5.0, tensorflow-federated==0.6.0, tensorflow-federated==0.7.0 and tensorflow-federated==0.9.0 because these package versions have conflicting dependencies.

The conflict is caused by:
    tensorflow-federated 0.18.0 depends on tensorflow~=2.4.0
    tensorflow-federated 0.17.0 depends on tensorflow-addons~=0.11.1
    tensorflow-federated 0.16.1 depends on tensorflow~=2.2.0
    tensorflow-federated 0.16.0 depends on tensorflow~=2.2.0
    tensorflow-federated 0.15.0 depends on tensorflow~=2.2.0
    tensorflow-federated 0.14.0 depends on tensorflow~=2.2.0
    tensorflow-federated 0.13.1 depends on tensorflow~=2.1.0
    tensorflow-federated 0.13.0 depends on tensorflow~=2.1.0
    tensorflow-federated 0.12.0 depends on tensorflow-addons~=0.7.0
    tensorflow-federated 0.11.0 depends on tensorflow~=2.0.0
    tensorflow-federated 0.10.1 depends on tensorflow-addons~=0.6.0
    tensorflow-federated 0.10.0 depends on tensorflow-addons~=0.6.0
    tensorflow-federated 0.9.0 depends on tfa-nightly
    tensorflow-federated 0.7.0 depends on tf-nightly
    tensorflow-federated 0.6.0 depends on tf-nightly
    tensorflow-federated 0.5.0 depends on tf-nightly
    tensorflow-federated 0.4.0 depends on tensorflow~=1.13
    tensorflow-federated 0.3.0 depends on tensorflow~=1.13
    tensorflow-federated 0.2.0 depends on tensorflow~=1.13
    tensorflow-federated 0.1.0 depends on tensorflow&gt;=1.13.0rc2

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip attempt to solve the dependency conflict

ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies
</code></pre>
<p>I guess it happened because some required packages is not ready to satisfy the Apple Silicon M1 with the ARM architecture? Am I right?</p>
<p>Is there any solution to install Tensorflow Federated in a macOS with Apple Silicon M1 now?</p>
<hr />
<p>Edited on Mar 20, 2021:</p>
<p>Thanks for the <a href=""https://stackoverflow.com/questions/66705900/can-tensorflow-federated-be-installed-on-apple-silicon-m1#comment117928552_66705900"">answer</a> from the user <a href=""https://stackoverflow.com/users/7976758/phd"">phd</a>.</p>
<p>The problem of numpy is solved by following <a href=""https://github.com/numpy/numpy/issues/17807#issuecomment-731014921"" rel=""nofollow noreferrer"">this commend</a>.</p>
<p>But the dependency conflict is still here.</p>
<pre><code>    Preparing wheel metadata ... done
Collecting h5py
  Using cached h5py-3.2.1.tar.gz (368 kB)
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
  Installing backend dependencies ... |^[[-^[[done
    Preparing wheel metadata ... done
ERROR: Cannot install tensorflow-federated==0.1.0, tensorflow-federated==0.10.0, tensorflow-federated==0.10.1, tensorflow-federated==0.11.0, tensorflow-federated==0.12.0, tensorflow-federated==0.13.0, tensorflow-federated==0.13.1, tensorflow-federated==0.14.0, tensorflow-federated==0.15.0, tensorflow-federated==0.16.0, tensorflow-federated==0.16.1, tensorflow-federated==0.17.0, tensorflow-federated==0.18.0, tensorflow-federated==0.2.0, tensorflow-federated==0.3.0, tensorflow-federated==0.4.0, tensorflow-federated==0.5.0, tensorflow-federated==0.6.0, tensorflow-federated==0.7.0 and tensorflow-federated==0.9.0 because these package versions have conflicting dependencies.

The conflict is caused by:
    tensorflow-federated 0.18.0 depends on tensorflow~=2.4.0
    tensorflow-federated 0.17.0 depends on tensorflow~=2.3.0
    tensorflow-federated 0.16.1 depends on tensorflow-addons~=0.10.0
    tensorflow-federated 0.16.0 depends on tensorflow-addons~=0.10.0
    tensorflow-federated 0.15.0 depends on tensorflow-addons~=0.10.0
    tensorflow-federated 0.14.0 depends on tensorflow-addons~=0.9.1
    tensorflow-federated 0.13.1 depends on tensorflow~=2.1.0
    tensorflow-federated 0.13.0 depends on tensorflow~=2.1.0
    tensorflow-federated 0.12.0 depends on tensorflow~=2.1.0
    tensorflow-federated 0.11.0 depends on tensorflow-addons~=0.6.0
    tensorflow-federated 0.10.1 depends on tensorflow-addons~=0.6.0
    tensorflow-federated 0.10.0 depends on tensorflow-addons~=0.6.0
    tensorflow-federated 0.9.0 depends on tfa-nightly
    tensorflow-federated 0.7.0 depends on tf-nightly
    tensorflow-federated 0.6.0 depends on tf-nightly
    tensorflow-federated 0.5.0 depends on tf-nightly
    tensorflow-federated 0.4.0 depends on tensorflow~=1.13
    tensorflow-federated 0.3.0 depends on tensorflow~=1.13
    tensorflow-federated 0.2.0 depends on tensorflow~=1.13
    tensorflow-federated 0.1.0 depends on tensorflow&gt;=1.13.0rc2

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip attempt to solve the dependency conflict

ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies
</code></pre>
",6522746,,6522746,,44275.61319,44712.80972,Can Tensorflow Federated be installed on Apple Silicon M1?,<python-3.x><numpy><tensorflow><pip><tensorflow-federated>,1,3,,,,CC BY-SA 4.0
66776030,1,,,44279.28681,,2,226,"<p>I would like to train two independent <code>TFF</code> models using <code>emnist</code> dataset. Each model should train on a <code>1000</code> distinct participants randomly drawn from the dataset.</p>
<p>Code below</p>
<pre class=""lang-py prettyprint-override""><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data()

participants_ids = np.random.choice(a=emnist_train.client_ids, 
                                    size=1000,
                                    replace=False)

federated_dataset = 
        [data_train.create_tf_dataset_for_client(i) for i in participants_ids]

nested_dataset = tf.data.Dataset.from_tensor_slices(federated_dataset)

</code></pre>
<p>Trying to save the dataset</p>
<pre class=""lang-py prettyprint-override""><code>tf.data.experimental.save(nested_dataset, 'model_dataset')
</code></pre>
<p>the warning below is generated. However, the save is completed.</p>
<pre class=""lang-py prettyprint-override""><code>E tensorflow/core/framework/dataset.cc:89] The Encode() method is not implemented for DatasetVariantWrapper objects.
</code></pre>
<p>The problem occurs upon loading the dataset and trying to inspect its contents</p>
<pre class=""lang-py prettyprint-override""><code>dataset = tf.data.experimental.load('model_dataset', 
                      element_spec= 
                      DatasetSpec(collections.OrderedDict([
                         ('label', TensorSpec(shape=(), dtype=tf.int32)),
                         ('pixels', TensorSpec(shape=(28, 28), dtype=tf.float32))]), 
                      TensorShape([])

# verifying elements
for example in dataset:
        print(example)
</code></pre>
<p>Error below</p>
<pre class=""lang-py prettyprint-override""><code>tensorflow.python.framework.errors_impl.DataLossError: Unable to parse tensor from stored proto.
</code></pre>
<p>Trying other methods such as <code>pickle.dump</code> and <code>np.save</code>, all resulted in error below</p>
<pre class=""lang-py prettyprint-override""><code>tensorflow.python.framework.errors_impl.InternalError: Tensorflow type 21 not convertible to numpy dtype.
</code></pre>
<p>Is there any good way to save the newly created datasets ?</p>
",15092004,,14692,,44416.57222,44416.58333,Proper way of saving clients' federated datasets,<tensorflow><tensorflow-datasets><tensorflow-federated>,1,2,,,,CC BY-SA 4.0
77352499,1,,,45223.56181,,0,446,"<p>IÂ´m trying to install Tensorflow Federated by running pip install tensorflow-federated in a new Anaconda environment with Python 3.11 in Windows but it gives me this error:</p>
<pre><code>  Preparing metadata (setup.py) ... error
  error: subprocess-exited-with-error

  Ã— python setup.py egg_info did not run successfully.
  â”‚ exit code: 1
  â•°â”€&gt; [6 lines of output]
      Traceback (most recent call last):
        File &quot;&lt;string&gt;&quot;, line 2, in &lt;module&gt;
        File &quot;&lt;pip-setuptools-caller&gt;&quot;, line 34, in &lt;module&gt;
        File &quot;C:\Users\Public\Documents\Wondershare\CreatorTemp\pip-install-k_gm1isk\absl-py_2a985a0a199a4b93b9e364bfe5d6f101\setup.py&quot;, line 34, in &lt;module&gt;
          raise RuntimeError('Python version 2.7 or 3.4+ is required.')
      RuntimeError: Python version 2.7 or 3.4+ is required.
      [end of output]

note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

Ã— Encountered error while generating package metadata.
â•°â”€&gt; See above for output.
note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
</code></pre>
<p>IÂ´ve tried to install it in other versions of python but it only works on Python 3.8 and at that point some versions of libraries are to old to work and comes up with compatability issues.</p>
<p>Would appreciate some help!</p>
<p>And thanks for your time!</p>
",22794814,,5012099,,45223.575,45337.19444,Tensorflow federated installation giving error,<python><tensorflow><tensorflow-federated>,2,3,,,,CC BY-SA 4.0
77547784,1,,,45255.50417,,0,283,"<p>An attribute Error raised when importing tensorflow_federated on colab though I did install it.</p>
<p><code>!pip install --quiet --upgrade tensorflow-federated</code></p>
<p><code>import tensorflow as tf</code></p>
<p><code>import tensorflow_federated as tff</code></p>
<p>--&gt; import tensorflow_federated as tff : AttributeError: module 'numpy' has no attribute '_no_nep50_warning'</p>
<p>how can I solve it?
Thank you!</p>
<p><code>!pip install --quiet --upgrade tensorflow-federated</code></p>
<p><code>import tensorflow as tf</code></p>
<p><code>import tensorflow_federated as tff</code></p>
",22982880,,22982880,,45255.50625,45266.42153,Can't import tensorflow_federated,<tensorflow><tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
77732938,1,,,45289.67847,,0,56,"<p>I want to train a multi-modal model in the federated learning environment.
this is my model definition.</p>
<pre><code>num_classes=5
def image_text_model():
  # Define the image input
  image_input = Input(shape=(224, 224, 3), name='image_input')
  # text_input = Input(shape=(tokenizer.model_max_length, ), dtype=tf.int32, name='text_input')

  input_ids = Input(shape=(96,), dtype=tf.int32, name='input_ids')
  token_type_ids = Input(shape=(96,), dtype=tf.int32, name='token_type_ids')
  attention_mask = Input(shape=(96,), dtype=tf.int32, name='attention_mask')


  # Use the base_model to extract features from the image input
  # image_features = img_model()

  resnet_model = ResNet50(weights='imagenet', include_top=False)
  image_output = resnet_model(image_input)
  image_output = GlobalAveragePooling2D()(image_output)

  # Use the BERT model to extract features from the text input
  text_features = bert_model(input_ids, token_type_ids, attention_mask).pooler_output

  # Concatenate the image features and text features
  concatenated = concatenate([image_output,text_features])

  # Add a Dense layer
  x = Dense(units=128, activation='relu')(concatenated)

  # Add the output Dense layer with softmax activation for classification
  output = Dense(num_classes, activation='softmax')(x)

  # Define the model
  model = tf.keras.Model(inputs=[image_input, input_ids, token_type_ids, attention_mask], outputs=[output])

  return model

def federated_model():
  keras_model = image_text_model()
  return tff.learning.models.from_keras_model(
      keras_model,
      input_spec=[tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32),
          tf.TensorSpec(shape=(96,), dtype=tf.int32),
          tf.TensorSpec(shape=(96,), dtype=tf.int32),
          tf.TensorSpec(shape=(96,), dtype=tf.int32)
          ],

      loss=tf.keras.losses.SparseCategoricalCrossentropy(),
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]

  )

# Create a tff learning process
iterative_process =  tff.learning.algorithms.build_weighted_fed_avg(
    model_fn=federated_model,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),
    # metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]
    )

# Initialize the Federated Averaging algorithm to get the initial model state.
state = iterative_process.initialize()

# Run one round of Federated Averaging.
state, metrics = iterative_process.next(state, next(train_generator))
print('round  1, metrics={}'.format(metrics))

# You can continue training with additional rounds as needed.
# state, metrics = iterative_process.next(state, clients_data)
# print('round  2, metrics={}'.format(metrics))
</code></pre>
<p>this is my <code>bert_model</code> code <code>bert_model = TFBertForSequenceClassification.from_pretrained(&quot;bert-base-uncased&quot;, num_labels=5)</code>.
When I want to train the model I got this error. <a href=""https://i.sstatic.net/wCQEr.png"" rel=""nofollow noreferrer"">enter image description here</a>
I load my data by using the generator.
and this is my value error</p>
<pre><code>ValueError: Your Layer or Model is in an invalid state. This can happen for the following cases:
 1. You might be interleaving estimator/non-estimator models or interleaving models/layers made in tf.compat.v1.Graph.as_default() with models/layers created outside of it. Converting a model to an estimator (via model_to_estimator) invalidates all models/layers made before the conversion (even if they were not the model converted to an estimator). Similarly, making a layer or a model inside a a tf.compat.v1.Graph invalidates all layers/models you previously made outside of the graph.
2. You might be using a custom keras layer implementation with custom __init__ which didn't call super().__init__.  Please check the implementation of &lt;class 'transformers.models.bert.modeling_tf_bert.TFBertForSequenceClassification'&gt; and its bases.


</code></pre>
",23060018,,23060018,,45292.59514,45292.59514,training federated model by bert and resnet pre-train model,<tensorflow><deep-learning><huggingface-transformers><tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
77858001,1,,,45313.27153,,2,53,"<p>I have the following code:</p>
<pre><code>import grpc

ip_address = ['0.0.0.0'] * n_workers  #@param {type:&quot;string&quot;}
ports = [80+i for i in range(n_workers)]  #@param {type:list[&quot;integer&quot;]}

channels = [grpc.insecure_channel(f'{ip_address[i]}:{ports[i]}') for i in range(len(ports))]
tff.backends.native.set_remote_python_execution_context(channels)
</code></pre>
<p>when I run this part of code I got this error:</p>
<pre><code>AttributeError: module 'tensorflow_federated.python.core.backends.native' has no attribute 'set_remote_python_execution_context'
</code></pre>
<p>I know <code>set_remote_python_execution_context</code> is deprecated,
but how can I fix this?</p>
<p>I tried to use <code>cpp</code> executions based on <code>tff</code> released-notes, but none of them didn't exactly same as <code>set_remote_python_execution_context</code>.</p>
",19723451,,4136999,,45313.34028,45369.55,AttributeError: module 'tensorflow_federated.python.core.backends.native' has no attribute 'set_remote_python_execution_context',<python><tensorflow><tensorflow-federated><federated>,1,0,,,,CC BY-SA 4.0
77876217,1,,,45315.87917,,0,45,"<p>Iâ€™m apply federated learning on several datasets,having similar output feature but different input features, how cany I do that. By feature I mean columns in the dataset. I want to know is this even possible to do? Please provide a comprehensive answer?</p>
",20251201,,,,,45315.87917,How can I perform Federated Learning on different dataset files having same output feature but different input feature?,<tensorflow-federated><federated-learning>,0,0,,,,CC BY-SA 4.0
66778069,1,,,44279.39167,,1,300,"<p>I'm trying to find a way to utilise Tensorflow Federated in C++. I know it's possible to do it for the regular Tensorflow with the Core API, however I can't find a way for Federated. If it's not possible suggestions for workarounds would be highly appreciated!</p>
",1797895,,,,,44732.01944,Tensorflow Federated in C++,<tensorflow><tensorflow2.0><tensorflow-federated>,2,0,,,,CC BY-SA 4.0
67053731,1,67055368,,44298.28125,,2,134,"<p>I'm attempting to run the <a href=""https://github.com/tensorflow/federated/tree/master/tensorflow_federated/python/examples/simple_fedavg"" rel=""nofollow noreferrer"">Minimal Stand-Alone Implementation of Federated Averaging</a> from the TensorFlow Federated GitHub repository but receiving the following error in the server_update function:</p>
<p><strong>AttributeError: module 'tensorflow_federated.python.common_libs.structure' has no attribute 'update_struct'</strong></p>
<p>I have some old TensorFlow Federated code that uses the update_state function from the tff.utils package in place of update_struct() but according to a commit on GitHub this package is empty now. I'm using TensorFlow Federated version 0.18.0 and I also had the same problem trying on Google CoLab.</p>
<p>My question is how can I fix this error?</p>
<p>Thanks, any help appreciated.</p>
",2623004,,,,,44298.36806,Error using update_struct function in TensorFlow Federated,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
67057583,1,,,44298.47917,,3,76,"<p>what can I write in this code :</p>
<pre><code>def initialize_fn():
  ...

</code></pre>
",12682667,,12682667,,44341.47361,44341.47361,TFF : Modify the process that includes an initialization and iterated computation,<tensorflow-federated>,1,0,,,,CC BY-SA 4.0
67077757,1,,,44299.63889,,1,359,"<p>Hello I am trying to install tensorflow_federated from scratch by its source code in google colab with the instructions from <a href=""https://github.com/tensorflow/federated/blob/master/docs/install.md#build-the-tensorflow-federated-python-package-from-source"" rel=""nofollow noreferrer"">here</a> in order to execute the examples and the tests from the source code</p>
<p>I installed bazel in google colab with the following commands</p>
<pre><code>BAZEL_VERSION = '0.20.0'

!wget https://github.com/bazelbuild/bazel/releases/download/{BAZEL_VERSION}/bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh

!chmod +x bazel-{BAZEL_VERSION}-installer-linux-x86_64.sh

# !export PATH=&quot;$PATH:$HOME/bin:/root/bin&quot;
</code></pre>
<p>and when i type</p>
<pre><code>!bazel
</code></pre>
<p>the output seems fine</p>
<p>But when I try to install tensorflow federated with instructions mentioned above i get an error</p>
<p>more particularly when i type</p>
<pre><code>bazel run //tensorflow_federated/tools/development:build_pip_package -- \
    --nightly \
    --output_dir &quot;/tmp/tensorflow_federated&quot;
</code></pre>
<p>I get the following output</p>
<pre><code>INFO: Invocation ID: d0ba7553-9587-4f7e-a388-cf77e71fa004
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=0
INFO: Reading rc options for 'build' from /content/federated/.bazelrc:
  Inherited 'common' options: --announce_rc
INFO: Reading rc options for 'build' from /content/federated/.bazelrc:
  'build' options: --compilation_mode=opt --define=use_fast_cpp_protos=true --copt=-march=native --host_copt=-march=native --copt=-O3
Loading: 
Loading: 0 packages loaded
ERROR: Skipping '-output_dir': no such target '//:-output_dir': target '-output_dir' not declared in package '' defined by /content/federated/BUILD
Loading: 2 packages loaded
ERROR: no such target '//:-output_dir': target '-output_dir' not declared in package '' defined by /content/federated/BUILD
Loading: 2 packages loaded
INFO: Elapsed time: 0.233s
Loading: 2 packages loaded
INFO: 0 processes.
Loading: 2 packages loaded
FAILED: Build did NOT complete successfully (2 packages loaded)
FAILED: Build did NOT complete successfully (2 packages loaded)
</code></pre>
<p>And when i want to import tensorflow federated i get this output</p>
<pre><code>ImportError: cannot import name 'computation_pb2' from 'tensorflow_federated.proto.v0' (/content/federated/tensorflow_federated/proto/v0/__init__.py)
</code></pre>
<p>Can somebody help me  ?
Thank you in advance</p>
",14801895,,,,,44299.63889,TensorFlow Federated Python package from source in google colab,<python><tensorflow><google-colaboratory><bazel><tensorflow-federated>,0,1,,,,CC BY-SA 4.0
67077765,1,,,44299.63958,,1,68,"<p>I am trying to use Federated code to build my own federated learning algorithm. But I met one problem. In the official tutorial, it define the Model Spec like following:</p>
<blockquote>
</blockquote>
<pre><code>MODEL_SPEC = collections.OrderedDict(
            filter1 = tf.TensorSpec(shape=weights[0].shape, dtype=tf.float32),
            bias1 = tf.TensorSpec(shape=weights[1].shape, dtype=tf.float32),
            filter2 = tf.TensorSpec(shape=weights[2].shape, dtype=tf.float32),
            bias2 = tf.TensorSpec(shape=weights[3].shape, dtype=tf.float32),
            weight1 = tf.TensorSpec(shape=weights[4].shape, dtype=tf.float32),
            bias3 = tf.TensorSpec(shape=weights[5].shape, dtype=tf.float32)
        )
        MODEL_TYPE = tff.to_type(MODEL_SPEC)
</code></pre>
<p>I am wondering if it is required to input the model as an OrderedDict. Could I input the model as a trainable Keras model?</p>
<p>Thanks!</p>
",15624043,,,,,44299.65208,MODEL_SPEC in Federated Learning (Using Tensorflow Federated Core),<tensorflow><tensorflow-federated><federated-learning>,1,0,,,,CC BY-SA 4.0
67101197,1,,,44301.07986,,2,398,"<p>I'm hoping to explore how data augmentation work on federated learning, and I'm currently using tff to implement it. I notice that the datasets provide by tff is composed of tensors, and tensors cannot be adjusted directly, so a naive idea would be to change it to numpy arrays and then do augmentation. I tried</p>
<p><code>tfds.as_numpy(emnist_train.create_tf_dataset_for_client(n))</code>
and it did provided me with numpy arrays, but I got problems when trying to pass it to preprocess functions. If I do:
<code>preprocess(tfds.as_numpy(emnist_train.create_tf_dataset_for_client(n)))</code></p>
<p>where preprocess is defined as</p>
<pre><code>def preprocess(dataset):

    def batch_format_fn(element):
        &quot;&quot;&quot;Flatten a batch `pixels` and return the features as an `OrderedDict`.&quot;&quot;&quot;

        return collections.OrderedDict(
            x=tf.reshape(element['pixels'], [-1, 784]),
            y=tf.reshape(element['label'], [-1, 1]))

    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(
        BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)
</code></pre>
<p>I would get the following error:</p>
<pre><code>return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(
AttributeError: '_IterableDataset' object has no attribute 'repeat'
</code></pre>
<p>which seems to mean that this <strong>_IterableDataset</strong> object of numpy arrays cannot be applied for these methods.</p>
<p>And I tried wrapping <code>tf.data.Dataset.from_tensor_slices</code> method as <code>tf.data.Dataset.from_tensor_slices(tfds.as_numpy(emnist_train.create_tf_dataset_for_client(n)))</code>, but it ends up with this error:</p>
<p><code>ValueError: Attempt to convert a value (&lt;tensorflow_datasets.core.dataset_utils._IterableDataset object at 0x00000280AA695DF0&gt;) with an unsupported type (&lt;class 'tensorflow_datasets.core.dataset_utils._IterableDataset'&gt;) to a Tensor.</code></p>
<p>Is there any way to solve this problem? Or could I do augmentation just on the data it provides?</p>
<h3>Updates</h3>
<p>It would be enough to just use <code>map</code> function if I only want to convert each sample in the dataset to a augmented one. However, if I want to add new samples to the dataset(e.g. adding samples of different labels), how can I do it? Since we can't modify the client dataset directly, I was thinking converting it to a numpy array and make further processing, yet if I do:</p>
<p><code>state, metrics = iterative_process.next(state, tfds.as_numpy(federated_train_data))</code>
where <code>federated_train_data</code> is a client dataset, I got</p>
<p><code>TypeError: Expected tensorflow.python.data.ops.dataset_ops.DatasetV2 or tensorflow.python.data.ops.dataset_ops.DatasetV1, found tensorflow_datasets.core.dataset_utils._IterableDataset.</code></p>
<p>Seems this <code>_IterableDataset</code> couldn't be applied to the process. Is there a way that I can convert this dataset back to what is acceptable by <code>tff.learning.build_federated_averaging_process()</code>? Or is there a better way to do this kind of augmentation?</p>
<h3>Update 2</h3>
<p>I was trying to use a generator from a GAN model to generate new images to augment the dataset.  I have a pretrained GAN (written by tf.keras), and I wrote a dataGenerator to wrap this model for augmenting the client datasets. However, when I do the fed-avg training, the following error occurred:</p>
<pre><code>  File &quot;D:\Research\GAN_AUG_FL\utils\augment_utils.py&quot;, line 53, in generate_once
    generated_images = generator(generator_input)
  File &quot;D:\Research\GAN_AUG_FL\venv\lib\site-packages\tensorflow\python\keras\engine\base_layer_v1.py&quot;, line 665, in __call__
    self._assert_built_as_v1()
  File &quot;D:\Research\GAN_AUG_FL\venv\lib\site-packages\tensorflow\python\keras\engine\base_layer_v1.py&quot;, line 836, in _assert_built_as_v1
    raise ValueError(
ValueError: Your Layer or Model is in an invalid state. This can happen for the following cases:
 1. You might be interleaving estimator/non-estimator models or interleaving models/layers made in tf.compat.v1.Graph.as_default() with models/layers created outside of it. Converting a model to an estimator (via model_to_estimator) invalidates all models/layers made before the conversion (even if they were not the model converted to an estimator). Similarly, making a layer or a model inside a a tf.compat.v1.Graph invalidates all layers/models you previously made outside of the graph.
2. You might be using a custom keras layer implementation with  custom __init__ which didn't call super().__init__.  Please check the implementation of &lt;class 'tensorflow.python.keras.engine.functional.Functional'&gt; and its bases.
</code></pre>
<p>Here <code>generator</code> is just the keras model for generation. I suspect this is because in tff the computation graph is different from the one I used to create an instance of the generator model. The code for training is just like the toturial <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">here</a>.</p>
<pre><code>emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(only_digits=True, cache_dir=&quot;data/emnist&quot;)

example_dataset = emnist_train.create_tf_dataset_for_client(emnist_train.client_ids[0])
example_dataset = preprocess(example_dataset)

def model_fn():
    keras_model = create_keras_model()
    return tff.learning.from_keras_model(
        keras_model,
        input_spec=example_dataset.element_spec,
        loss=tf.keras.losses.SparseCategoricalCrossentropy(),
        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],
    )


iterative_process = tff.learning.build_federated_averaging_process(
    model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=0.02),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1.0),
)

state = iterative_process.initialize()

# state, metrics = iterative_process.next(state, [example_dataset])
# print('round  1, metrics={}'.format(metrics))


for round_num in range(NUM_ROUNDS):
    selected_clients = random.sample(emnist_train.client_ids, 1)
    federated_data = [
        preprocess(emnist_train.create_tf_dataset_for_client(n))
        for n in selected_clients
    ]
    state, metrics = iterative_process.next(state, federated_data)
    print(f&quot;round  {round_num + 1}, metrics={metrics}&quot;)
</code></pre>
<p>But at this point strange things happen if I uncomment the two lines before going into the loop. This time the training could go smoothly, but still reports the same bug after going into the loop. Therefore I guess after the first time this preprocess is done, tff is using some different graph? Is there any possible solution to it?</p>
",15640975,,15640975,,44434.51736,44434.51736,How to do data augmentation with tensorflow federated?,<tensorflow><data-augmentation><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
67138338,1,67139027,,44303.53125,,1,444,"<p>I'm trying to run a classification simulation in tff, but I'm getting this error:</p>
<pre><code>TypeError: Unable to interpret an argument of type tensorflow.python.data.ops.dataset_ops.PrefetchDataset as a TFF value.
</code></pre>
<p>Here is the code I'm using</p>
<pre><code>client_lr = 1e-3
server_lr = 1e-1
NUM_ROUNDS = 200
NUM_EPOCHS = 5
BATCH_SIZE = 2048
EPOCHS = 400
TH = 0.5

def base_model():
  return Sequential([
        Dense(256, activation='relu', input_shape=(x_train.shape[-1],)),
        Dropout(0.5),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(256, activation='relu'),
        Dropout(0.5),
        Dense(1, activation='sigmoid'),
    ])

client_train_dataset = collections.OrderedDict()
for i in range(1, total_clients+1):
  client_name = &quot;client_&quot; + str(i)
  start = samples_per_set * (i-1)
  end = samples_per_set * i
  data = collections.OrderedDict((('y', y_train[start:end]), ('x', x_train[start:end])))
  client_train_dataset[client_name] = data

train_dataset = tff.simulation.FromTensorSlicesClientData(client_train_dataset)

sample_dataset = train_dataset.create_tf_dataset_for_client(train_dataset.client_ids[0])
sample_element = next(iter(sample_dataset))
PREFETCH_BUFFER = 10
SHUFFLE_BUFFER = samples_per_set

def preprocess(dataset):

  def batch_format_fn(element):
    return collections.OrderedDict(
        x=element['x'],
        y=tf.reshape(element['y'], [-1, 1]))

  return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)

preprocessed_sample_dataset = preprocess(sample_dataset)
sample_batch = tf.nest.map_structure(lambda x: x.numpy(), next(iter(preprocessed_sample_dataset)))

def make_federated_data(client_data, client_ids):
    return [preprocess(client_data.create_tf_dataset_for_client(x)) for x in client_ids]

federated_train_data = make_federated_data(train_dataset, train_dataset.client_ids)

def model_tff():
  model = base_model()
  return tff.learning.from_keras_model(
      model,
      input_spec=preprocessed_sample_dataset.element_spec,
      loss=tf.keras.losses.BinaryCrossentropy(),
      metrics=[
               tfa.metrics.F1Score(num_classes=1, threshold=TH),
               keras.metrics.Precision(name=&quot;precision&quot;, thresholds=TH),
               keras.metrics.Recall(name=&quot;recall&quot;, thresholds=TH)
              ])

iterative_process = tff.learning.build_federated_averaging_process(
    model_tff,
    client_optimizer_fn=lambda: optimizers.Adam(learning_rate=client_lr),
    server_optimizer_fn=lambda: optimizers.SGD(learning_rate=server_lr))

state = iterative_process.initialize()

federated_model = None

for round_num in range(1, NUM_ROUNDS+1):
    state, tff_metrics = iterative_process.next(state, federated_train_data) # THE ERROR IS HERE
    federated_model = base_model()
    federated_model.compile(optimizer=optimizers.Adam(learning_rate=client_lr),
                        loss=tf.keras.losses.BinaryCrossentropy(),
                        metrics=[
                              tfa.metrics.F1Score(num_classes=1, threshold=TH),
                              keras.metrics.Precision(name=&quot;precision&quot;, thresholds=TH),
                              keras.metrics.Recall(name=&quot;recall&quot;, thresholds=TH)
                              ])
    state.model.assign_weights_to(model=federated_model)
    federated_result = federated_model.evaluate(x_val, y_val, verbose=1, return_dict=True)
    
federated_test = federated_model.evaluate(x_test, y_test, verbose=1, return_dict=True)
</code></pre>
<p>I'm using this creditcard dataset: <a href=""https://www.kaggle.com/mlg-ulb/creditcardfraud"" rel=""nofollow noreferrer"">https://www.kaggle.com/mlg-ulb/creditcardfraud</a></p>
<p>The <code>federated_train_data</code> is a list of <code>&lt;PrefetchDataset shapes: OrderedDict([(x, (None, 29)), (y, (None, 1))]), types: OrderedDict([(x, tf.float64), (y, tf.int64)])&gt;</code>, just like the tutorial from the Tensorflow Federated website <a href=""https://www.tensorflow.org/federated/tutorials/federated_learning_for_image_classification"" rel=""nofollow noreferrer"">Federated Learning for Image Classification</a>.</p>
",12288097,,,,,44303.58681,Unable to interpret an argument of type tensorflow.python.data.ops.dataset_ops.PrefetchDataset as a TFF value in iterative process,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
67147951,1,67150029,,44304.47361,,1,1852,"<p>I was using <code>tff.simulation.FromTensorSlicesClientData(client_train_dataset)</code> to create client's data with the stable version of tff, and it was working fine. I had to switch to tff-nightly, and now calling this gives me an error:</p>
<pre><code>AttributeError: module 'tensorflow_federated.python.simulation' has no attribute 'FromTensorSlicesClientData'
</code></pre>
<p>Here's the section of my code, where the error is thrown:</p>
<pre><code>total_clients = 3
total_samples = len(x_train)
samples_per_set = int(np.floor(total_samples/total_clients))

client_train_dataset = collections.OrderedDict()
for i in range(1, total_clients+1):
  client_name = &quot;client_&quot; + str(i)
  start = samples_per_set * (i-1)
  end = samples_per_set * i
  data = collections.OrderedDict((('y', y_train[start:end]), ('x', x_train[start:end])))
  client_train_dataset[client_name] = data

train_dataset = tff.simulation.FromTensorSlicesClientData(client_train_dataset)
</code></pre>
<p>Should I be doing this a different way?</p>
",12288097,,,,,44703.42153,'tensorflow_federated.python.simulation' has no attribute 'FromTensorSlicesClientData' when using tff-nightly,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
67213520,1,67217887,,44308.52847,,2,150,"<p>I'm trying to make a comparison between different federated learning frameworks.
When looking on the TFF site, I could not find any information about which models are supported.
Looking at the <a href=""https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model"" rel=""nofollow noreferrer"">'model' API</a> they only talked about weights,...</p>
<p>Am I missing something or can TFF not be used for other models except neural networks?</p>
",15423185,,6426337,,44308.67986,44309.12361,TFF: Does TFF support any other models except neurel networks?,<tensorflow-federated>,2,0,,,,CC BY-SA 4.0
67384361,1,,,44320.5,,0,408,"<p>I am using tensorflow-federated(TFF) to develop my own federated aggregation method. I wonder if I can use Homomorphic Encryption(HE) in tensorflow-federated. I notice that TFF uses tff.federated_mean() to aggregate the gradients from every clients. Does TFF provide a similar API or interface to implement HE? Thank you very much.</p>
",14816634,,,,,44345.28333,How to use Homomorphic Encryption in tensorflow-federated,<tensorflow><tensorflow-federated>,1,0,,,,CC BY-SA 4.0
78158329,1,,,45365.23264,,-1,71,"<p>I'm using NBIOT dataset where i have selected only Provision_PT_737E_Security_Camera dataset of benign, mirai and gagfyt attacks.</p>
<p>The error is:</p>
<pre><code>AttributeError          Traceback (most recent call last)
&lt;ipython-input-78-ca197d89c56d&gt; in &lt;cell line: 1&gt;()
----&gt; 1 train_metrics = evaluation(metrics.state, federated_train_data)

AttributeError: 'collections.OrderedDict' object has no attribute 'state'
</code></pre>
<p>Am I doing it the right way? or how to improve what i'm doing?</p>
<pre><code>!pip install tensorflow-federated

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

import os

benign_df = pd.read_csv('/content/drive/MyDrive/Collab Input dataset/5.benign.csv')
g_c_df = pd.read_csv('/content/drive/MyDrive/Collab Input dataset/5.gafgyt.combo.csv')
g_j_df = pd.read_csv('/content/drive/MyDrive/Collab Input dataset/5.gafgyt.junk.csv')
g_s_df = pd.read_csv('/content/drive/MyDrive/Collab Input dataset/5.gafgyt.scan.csv')
g_t_df = pd.read_csv('/content/drive/MyDrive/Collab Input dataset/5.gafgyt.tcp.csv')
g_u_df = pd.read_csv('/content/drive/MyDrive/Collab Input dataset/5.gafgyt.udp.csv')
m_a_df = pd.read_csv('/content/drive/MyDrive/Collab Input dataset/5.mirai.ack.csv')
m_sc_df = pd.read_csv('/content/drive/MyDrive/Collab Input dataset/5.mirai.scan.csv')
m_sy_df = pd.read_csv('/content/drive/MyDrive/Collab Input dataset/5.mirai.syn.csv')
m_u_df = pd.read_csv('/content/drive/MyDrive/Collab Input dataset/5.mirai.udp.csv')
m_u_p_df = pd.read_csv('/content/drive/MyDrive/Collab Input dataset/5.mirai.udpplain.csv')

benign_df['type'] = 'benign'
m_u_df['type'] = 'mirai_udp'
g_c_df['type'] = 'gafgyt_combo'
g_j_df['type'] = 'gafgyt_junk'
g_s_df['type'] = 'gafgyt_scan'
g_t_df['type'] = 'gafgyt_tcp'
g_u_df['type'] = 'gafgyt_udp'
m_a_df['type'] = 'mirai_ack'
m_sc_df['type'] = 'mirai_scan'
m_sy_df['type'] = 'mirai_syn'
m_u_p_df['type'] = 'mirai_udpplain'

df = pd.concat([benign_df, m_u_df, g_c_df,
                g_j_df, g_s_df, g_t_df,
                g_u_df, m_a_df, m_sc_df,
                m_sy_df, m_u_p_df],
                axis=0, sort=False, ignore_index=True)

df[&quot;type&quot;].value_counts()


from matplotlib import pyplot as plt

plt.title(&quot;Class Distribution&quot;)
df.groupby(&quot;type&quot;).size().plot(kind='pie', autopct='%.2f', figsize=(20,10))

df.info()

df = df.sample(frac=1).reset_index(drop=True)

df.head()

import random

num_client = 4

df[&quot;client&quot;] = [&quot;client_{}&quot;.format(random.randint(1, num_client)) for _ in range(df.shape[0])]

from sklearn.model_selection import train_test_split

train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[&quot;type&quot;])

features = list(train_df.columns)
features.remove(&quot;type&quot;)
features.remove(&quot;client&quot;)


from sklearn.preprocessing import LabelEncoder

label_encoder = LabelEncoder()
train_df[&quot;type&quot;] = label_encoder.fit_transform(train_df[&quot;type&quot;])
test_df[&quot;type&quot;] = label_encoder.transform(test_df[&quot;type&quot;])

from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
train_df[features] = scaler.fit_transform(train_df[features])
test_df[features] = scaler.transform(test_df[features])

train_df[features] = train_df[features].astype(&quot;float32&quot;)
test_df[features] = test_df[features].astype(&quot;float32&quot;)

train_df[&quot;type&quot;] = train_df[&quot;type&quot;].astype(&quot;int32&quot;)
test_df[&quot;type&quot;] = test_df[&quot;type&quot;].astype(&quot;int32&quot;)

import nest_asyncio
nest_asyncio.apply()

%load_ext tensorboard

import collections

import numpy as np
import tensorflow as tf
import tensorflow_federated as tff

np.random.seed(0)

tff.federated_computation(lambda: 'Hello, World!')()

client_id_colname = 'client'

client_ids = df[client_id_colname].unique()

train_client_ids = pd.DataFrame(client_ids).sample(frac=0.8).values.ravel().tolist()
test_client_ids = [x for x in client_ids if x not in train_client_ids]

train_client_ids

from collections import OrderedDict
from tensorflow.keras.utils import to_categorical

NUM_EPOCHS = 1
SHUFFLE_BUFFER = 100
PREFETCH_BUFFER = 5

def create_tf_dataset_for_client_fn(client_id):
    client_data = dataframe[dataframe[client_id_colname] == client_id]
    client_data_dict = OrderedDict()
    client_data_dict[&quot;features&quot;] = np.array(client_data[features].values, dtype=&quot;float32&quot;)
    client_data_dict[&quot;label&quot;] = np.array(client_data[&quot;type&quot;].values, dtype=&quot;int32&quot;)

    dataset = tf.data.Dataset.from_tensor_slices(client_data_dict)
    dataset = dataset.shuffle(SHUFFLE_BUFFER).batch(1).repeat(NUM_EPOCHS)
    return dataset

dataframe = train_df
train_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(
    client_ids=train_client_ids,
    serializable_dataset_fn=create_tf_dataset_for_client_fn)

dataframe = test_df
test_data = tff.simulation.datasets.ClientData.from_clients_and_tf_fn(
    client_ids=test_client_ids,
    serializable_dataset_fn=create_tf_dataset_for_client_fn)

train_data.element_type_structure

test_data.element_type_structure

example_dataset = train_data.create_tf_dataset_for_client(train_data.client_ids[0])

example_element = next(iter(example_dataset))

example_element['label'].numpy()

from collections import defaultdict

f = plt.figure(figsize=(20, 10))
f.suptitle('Label Counts for a Sample of Clients')
for i, c_ids in enumerate(train_data.client_ids):
    client_dataset = train_data.create_tf_dataset_for_client(c_ids)
    plot_data = defaultdict(list)
    for example in client_dataset:
        label = example['label'].numpy()[0]
        plot_data[label].append(label)
    plt.subplot(2, 4, i+1)
    plt.title('Client {}'.format(c_ids))
    for j in range(10):
        plt.hist(plot_data[j], density=False, bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

import collections

NUM_EPOCHS = 5
BATCH_SIZE = 128
SHUFFLE_BUFFER = 100
PREFETCH_BUFFER = 10

def preprocess(dataset):
    def batch_format_fn(element):
        return collections.OrderedDict(x=tf.reshape(element['features'], [-1, len(features)]),
                                       y=tf.reshape(element['label'], [-1, 1]))

    return dataset.repeat(NUM_EPOCHS).shuffle(SHUFFLE_BUFFER, seed=1).batch(
      BATCH_SIZE).map(batch_format_fn).prefetch(PREFETCH_BUFFER)

preprocessed_example_dataset = preprocess(example_dataset)

sample_batch = tf.nest.map_structure(lambda x: x.numpy(),
                                     next(iter(preprocessed_example_dataset)))

from tqdm import tqdm

def make_federated_data(client_data, client_ids):
    return [preprocess(client_data.create_tf_dataset_for_client(x)) for x in tqdm(client_ids)]

NUM_CLIENTS = len(np.unique(train_df[client_id_colname]))

sample_clients = train_data.client_ids[0:NUM_CLIENTS]

federated_train_data = make_federated_data(train_data, sample_clients)

print('Number of client datasets: {l}'.format(l=len(federated_train_data)))
print('First dataset: {d}'.format(d=federated_train_data[0]))

def create_keras_model():
    filters = 32
    input_shape = (len(features))
    num_classes = len(label_encoder.classes_)
    clf = tf.keras.models.Sequential(
        [
            tf.keras.layers.Dense(64, input_dim=input_shape, activation='relu'),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(num_classes, activation='softmax')
        ])
    return clf

keras_model = create_keras_model()
keras_model.summary()


import keras.backend as K

class F1Score(tf.keras.metrics.Metric):
    def __init__(self, name='F1-Score', **kwargs):
        super(F1Score, self).__init__(name=name, **kwargs)
        self.f1_score = self.add_weight(name='f1_score', initializer='zeros')

    def update_state(self, y_true, y_pred, sample_weight=None):
        true_positives = tf.math.reduce_sum(tf.math.round(tf.clip_by_value(y_true * y_pred, 0, 1)))

        possible_positives = tf.math.reduce_sum(tf.math.round(tf.clip_by_value(y_true, 0, 1)))
        recall = true_positives / (possible_positives + K.epsilon())

        predicted_positives = tf.math.reduce_sum(tf.math.round(tf.clip_by_value(y_pred, 0, 1)))
        precision = true_positives / (predicted_positives + K.epsilon())

        self.f1_score.assign(2*((precision*recall)/(precision+recall+K.epsilon())))

    def result(self):
        return self.f1_score

    def reset_states(self):
        self.f1_score.assign(0.0)


from keras.metrics import Recall, Precision

def model_fn():
    keras_model = tf.keras.models.Sequential([ tf.keras.layers.Dense(64, input_dim=115, activation='relu'),
            tf.keras.layers.Dense(len(features), activation='relu'),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')])  # Your model structure
    return tff.learning.models.from_keras_model(
        keras_model=keras_model,
        input_spec=preprocessed_example_dataset.element_spec,  # Define the expected input format
        loss=tf.keras.losses.SparseCategoricalCrossentropy(),
        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

keras_model = create_keras_model()
keras_model.summary()

iterative_process = tff.learning.algorithms.build_weighted_fed_avg(
    model_fn=model_fn,
    client_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=1),
    server_optimizer_fn=lambda: tf.keras.optimizers.SGD(learning_rate=2))

str(iterative_process.initialize.type_signature)

state = iterative_process.initialize()

state, metrics = iterative_process.next(state, federated_train_data)
print('round  1, metrics={}'.format(metrics))

NUM_ROUNDS = 11
for round_num in range(2, NUM_ROUNDS):
    state, metrics = iterative_process.next(state, federated_train_data)
    print('round {:2d}, metrics={}'.format(round_num, metrics))

train_logdir = &quot;training/&quot;
os.makedirs(train_logdir, exist_ok=True)

test_logdir = &quot;testing/&quot;
os.makedirs(test_logdir, exist_ok=True)

summary_writer = tf.summary.create_file_writer(train_logdir)
state = iterative_process.initialize()

with summary_writer.as_default():
    for round_num in range(1, NUM_ROUNDS):
        state, metrics = iterative_process.next(state, federated_train_data)
        client_work_metrics = metrics['client_work']
        for name, value in client_work_metrics['train'].items():
            tf.summary.scalar(name, value, step=round_num)




!ls {train_logdir}
%tensorboard --logdir {train_logdir} --port=0

ModelVariables = collections.namedtuple('ModelVariables', 'weights bias num_examples loss_sum accuracy_sum')

def create_model_variables():
    return ModelVariables(
        weights=tf.Variable(
            lambda: tf.zeros(dtype=tf.float32, shape=(len(features), len(label_encoder.classes_))),
            name='weights',
            trainable=True),
        bias=tf.Variable(
            lambda: tf.zeros(dtype=tf.float32, shape=(len(label_encoder.classes_))),
            name='bias',
            trainable=True),
        num_examples=tf.Variable(0.0, name='num_examples', trainable=False),
        loss_sum=tf.Variable(0.0, name='loss_sum', trainable=False),
        accuracy_sum=tf.Variable(0.0, name='accuracy_sum', trainable=False))

def predict_on_batch(variables, x):
    return tf.nn.softmax(tf.matmul(x, variables.weights) + variables.bias)

def model_forward_pass(variables, batch):
    y = predict_on_batch(variables, batch['x'])
    predictions = tf.cast(tf.argmax(y, 1), tf.int32)

    flat_labels = tf.reshape(batch['y'], [-1])
    loss = -tf.reduce_mean(tf.reduce_sum(tf.one_hot(flat_labels, len(label_encoder.classes_)) * tf.math.log(y), axis=[1]))
    accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, flat_labels), tf.float32))
    num_examples = tf.cast(tf.size(batch['y']), tf.float32)
    variables.num_examples.assign_add(num_examples)
    variables.loss_sum.assign_add(loss * num_examples)
    variables.accuracy_sum.assign_add(accuracy * num_examples)
    return loss, predictions

def get_local_model_metrics(variables):
    return collections.OrderedDict(
        num_examples=variables.num_examples,
        loss=variables.loss_sum / variables.num_examples,
        accuracy=variables.accuracy_sum / variables.num_examples)

@tff.federated_computation
def aggregate_model_metrics_across_clients(metrics):
    return collections.OrderedDict(
        num_examples=tff.federated_sum(metrics.num_examples),
        loss=tff.federated_mean(metrics.loss, metrics.num_examples),
        accuracy=tff.federated_mean(metrics.accuracy, metrics.num_examples))


def reset_metrics(self):
    self._variables.num_examples.assign(0)
    self._variables.loss_sum.assign(0.0)
    self._variables.accuracy_sum.assign(0.0)

from typing import Callable, List, OrderedDict

class IOTModel(tff.learning.models.VariableModel):
    def reset_metrics(self):
      self._variables.num_examples.assign(0)
      self._variables.loss_sum.assign(0.0)
      self._variables.accuracy_sum.assign(0.0)

    def __init__(self):
        self._variables = create_model_variables()
    @property
    def trainable_variables(self):
        return [self._variables.weights, self._variables.bias]

    @property
    def non_trainable_variables(self):
        return []

    @property
    def local_variables(self):
        return [
            self._variables.num_examples, self._variables.loss_sum,
            self._variables.accuracy_sum
        ]

    @property
    def input_spec(self):
        return OrderedDict(
            x=tf.TensorSpec([None, len(features)], tf.float32),
            y=tf.TensorSpec([None, 1], tf.int32))

    @tf.function
    def predict_on_batch(self, x, training=True):
        del training
        return predict_on_batch(self._variables, x)

    @tf.function
    def forward_pass(self, batch, training=True):
        del training
        loss, predictions = model_forward_pass(self._variables, batch)
        num_exmaples = tf.shape(batch['x'])[0]
        return tff.learning.models.BatchOutput(loss=loss, predictions=predictions, num_examples=num_exmaples)

    @tf.function
    def report_local_outputs(self):
        return get_local_model_metrics(self._variables)

    @property
    def federated_output_computation(self):
        return aggregate_model_metrics_across_clients

    @tf.function
    def report_local_unfinalized_metrics(self) -&gt; OrderedDict[str, List[tf.Tensor]]:
        &quot;&quot;&quot;Creates an `OrderedDict` of metric names to unfinalized values.&quot;&quot;&quot;
        return collections.OrderedDict(
            num_examples=[self._variables.num_examples],
            loss=[self._variables.loss_sum, self._variables.num_examples],
            accuracy=[self._variables.accuracy_sum, self._variables.num_examples])

    def metric_finalizers(self) -&gt; OrderedDict[str, Callable[[List[tf.Tensor]], tf.Tensor]]:
        &quot;&quot;&quot;Creates an `OrderedDict` of metric names to finalizers.&quot;&quot;&quot;
        return collections.OrderedDict(
            num_examples=tf.function(func=lambda x: x[0]),
            loss=tf.function(func=lambda x: x[0] / x[1]),
            accuracy=tf.function(func=lambda x: x[0] / x[1]))

iterative_process = tff.learning.algorithms.build_weighted_fed_avg (
    IOTModel,
    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(learning_rate=0.001))

state = iterative_process.initialize()

state, metrics = iterative_process.next(state, federated_train_data)
print('round  1, metrics={}'.format(metrics))

for round_num in range(2, 11):
    state, metrics = iterative_process.next(state, federated_train_data)
    print('round {:2d}, metrics={}'.format(round_num, metrics))

evaluation = tff.learning.algorithms.build_weighted_fed_avg(IOTModel)

 **str(evaluation.get_model_weights)**                                          //Error is Here

train_metrics = evaluation(metrics.state, federated_train_data)

str(train_metrics)

NUM_CLIENTS = len(np.unique(test_df[client_id_colname]))

sample_clients = test_data.client_ids[0:NUM_CLIENTS]

federated_test_data = make_federated_data(test_data, sample_clients)

len(federated_test_data), federated_test_data[0]

test_metrics = evaluation(state.model, federated_test_data)
</code></pre>
",23598801,,4685471,,45365.67708,45394.81736,"Facing error in ""Learning Attribute"" while working in Tensorflow federated",<python><tensorflow><machine-learning><tensorflow-federated><nb-iot>,1,0,,,,CC BY-SA 4.0
78177521,1,,,45369.04375,,1,80,"<p>I am trying to run the code given by Tensorflow in their official documentation, pertaining to Tensorflow-Federated. The code is as follows:</p>
<pre class=""lang-py prettyprint-override""><code>import tensorflow as tf
import tensorflow_federated as tff

training_process = tff.learning.algorithms.build_weighted_fed_avg(get_dense_nn, client_optimizer_fn=lambda: tf.keras.Sequential.SGD(learning_rate=client_lr),                                                                 server_optimizer_fn=lambda:tf.keras.optimizers.SGD(learning_rate=server_lr))
</code></pre>
<p>However, I am getting the following error:</p>
<blockquote>
<p>AttributeError: module 'tensorflow_federated.python.learning' has no attribute 'from_keras_model'</p>
</blockquote>
<p>Am I doing something wrong or is the documentation wrong?</p>
",23643654,,4621513,,45369.06181,45369.62847,"Running example code from Tensorflow documentation, pertaining to Tensorflow-Federated, results in AttributeError",<python><tensorflow><tensorflow-federated>,1,1,,,,CC BY-SA 4.0
78181211,1,,,45369.63958,,0,39,"<p>I'm new to Federated Learning so please bear with me. I'm working on a university project where I'd like to build a decentralized peer-to-peer network so that I can train models without data sharing and without the need for an aggregator (a central server with a joint model). The idea is to take TensorFlow Federated and add some client state and possibly use Gossip protocol to enable clients to talk to each other. I don't know if it's possible/feasible with TensorFlow Federated. I'd appreciate any feedback on this!</p>
<p>I tried looking for examples online but didn't find anything.</p>
",7520751,,,,,45369.63958,Extending TensorFlow Federated,<tensorflow-federated><gossip>,0,0,,,,CC BY-SA 4.0
78212508,1,,,45374.88542,,0,26,"<p>I was trying to convert a dataset as tensorflow tensor. However, it is not letting me to do so. I followed the keras video classification tutorial (<a href=""https://keras.io/examples/vision/video_classification/"" rel=""nofollow noreferrer"">https://keras.io/examples/vision/video_classification/</a>). The tutorial converts training video data into frame features and frame mask and then feeds both for model training.</p>
<pre><code>    history = seq_model.fit(
        [train_data[0], train_data[1]],
        train_labels,
        validation_split=0.3,
        epochs=EPOCHS,
        callbacks=[checkpoint],
    )
</code></pre>
<p>I tried to convert the frame features and frame masks into a single tensorflow tensor so that I can feed the data into a federated learning training. However it is not working. I applied  tf.ragged.constant but no luck on that.</p>
",23759752,,,,,45374.88542,How to convert frame features and frame mask as a single variable data?,<tensorflow><classification><video-processing><tensorflow-federated>,0,1,,,,CC BY-SA 4.0
78277626,1,,,45387.15,,0,87,"<ul>
<li>python version: 3.10</li>
<li>pip version: 24.0</li>
</ul>
<p>I use env.
TFF required: Python &lt;3.12, &gt;=3.9</p>
<p>when I pip install tensorflow_federated in terminal (env is on) and received this problem:</p>
<pre><code>  Getting requirements to build wheel ... error
  error: subprocess-exited-with-error

  Ã— Getting requirements to build wheel did not run successfully.
  â”‚ exit code: 1
  â•°â”€&gt; [17 lines of output]
      Traceback (most recent call last):
        File &quot;E:\UDA_LEARNING\UDA_DO AN TRI TUE NHAN TAO &amp; UNG DUNG\env\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py&quot;, line 353, in &lt;module&gt;
          main()
        File &quot;E:\UDA_LEARNING\UDA_DO AN TRI TUE NHAN TAO &amp; UNG DUNG\env\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py&quot;, line 335, in main
          json_out['return_val'] = hook(**hook_input['kwargs'])
        File &quot;E:\UDA_LEARNING\UDA_DO AN TRI TUE NHAN TAO &amp; UNG DUNG\env\lib\site-packages\pip\_vendor\pyproject_hooks\_in_process\_in_process.py&quot;, line 118, in get_requires_for_build_wheel
          return hook(config_settings)
        File &quot;C:\Users\JOS UC\AppData\Local\Temp\pip-build-env-51vn4i37\overlay\Lib\site-packages\setuptools\build_meta.py&quot;, line 325, in get_requires_for_build_wheel
          return self._get_build_requires(config_settings, requirements=['wheel'])
        File &quot;C:\Users\JOS UC\AppData\Local\Temp\pip-build-env-51vn4i37\overlay\Lib\site-packages\setuptools\build_meta.py&quot;, line 295, in _get_build_requires
          self.run_setup()
        File &quot;C:\Users\JOS UC\AppData\Local\Temp\pip-build-env-51vn4i37\overlay\Lib\site-packages\setuptools\build_meta.py&quot;, line 487, in run_setup   
          super().run_setup(setup_script=setup_script)
        File &quot;C:\Users\JOS UC\AppData\Local\Temp\pip-build-env-51vn4i37\overlay\Lib\site-packages\setuptools\build_meta.py&quot;, line 311, in run_setup   
          exec(code, locals())
        File &quot;&lt;string&gt;&quot;, line 34, in &lt;module&gt;
      RuntimeError: Python version 2.7 or 3.4+ is required.
      [end of output]

  note: This error originates from a subprocess, and is likely not a problem with pip.
error: subprocess-exited-with-error

Ã— Getting requirements to build wheel did not run successfully.
â”‚ exit code: 1
â•°â”€&gt; See above for output.

note: This error originates from a subprocess, and is likely not a problem with pip.
</code></pre>
<p>How do I fix it?</p>
<p>run: pip install tensorflow_federated in terminal and noticed:</p>
<blockquote>
<p>RuntimeError: Python version 2.7 or 3.4+ is required.</p>
</blockquote>
<p>my python version: 3.10.
what should I do?</p>
",23991869,,4420967,,45387.21111,45387.21111,python 3.10 and error when install tensorflow_federated,<tensorflow-federated>,0,0,,,,CC BY-SA 4.0
78302946,1,,,45392.34028,,0,35,"<p>This is my evaluate function for federated learning:</p>
<pre><code>def evaluate(num_rounds=10):
    state = trainer.initialize()
    for round in range(num_rounds):
        t1 = time.time()
        state, metrics = trainer.next(state, client_data)
        t2 = time.time()
        print('Round {}: metrics {}, round time {}'.format(
            round+1,metrics, t2 - t1))
</code></pre>
<p>I need to save the state after 10 rounds and need to load the state and resume from the 11th round.
How to do it? Help me...</p>
",24180928,,,,,45524.67153,How to save the State(tff.learning.templates.LearningAlgorithmState) and again load it to resume the training process,<tensorflow><save><tensorflow-federated><savestate>,1,0,,,,CC BY-SA 4.0
